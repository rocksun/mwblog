<!--
title: 开源数据基建：新经济浪潮
cover: https://cdn.thenewstack.io/media/2025/10/b3d03b97-data.jpg
summary: 开源数据基础设施现可高效实现复杂场景。Kafka分层存储降本，AI搜索赋能非结构化数据，ClickHouse加速分析，混合架构整合，同时优化性能、成本与灵活性。
-->

开源数据基础设施现可高效实现复杂场景。Kafka分层存储降本，AI搜索赋能非结构化数据，ClickHouse加速分析，混合架构整合，同时优化性能、成本与灵活性。

> 译自：[The New Economics of Open Source Data Infrastructure](https://thenewstack.io/the-new-economics-of-open-source-data-infrastructure/)
> 
> 作者：Anil Inamdar

询问任何数据架构师，五年前看似不可能经济高效地实现的事情是什么，你都会听到关于每秒处理数百万次交易的实时欺诈检测系统、能够理解数PB非结构化数据上下文的AI驱动搜索引擎，以及在实现全球洞察的同时尊重数据主权的分布式分析平台。

这些不再是理想化的用例，而是100%运行良好且高效的[开源数据基础设施](https://thenewstack.io/your-open-source-data-infrastructure-is-ready-for-agentic-ai/)上的生产工作负载。

这些实现与传统数据策略之间的区别，很大程度上归结于做出能够随应用程序演进的正确架构选择。传统方法将数据基础设施视为需要最小化的成本中心，而当今更明智的方向是构建能够同时积极优化性能、成本和操作灵活性的系统。

开源数据基础设施技术在实现这些智能架构方面具有独特的优势，它们提供了专有系统无法比拟的定制深度和社区创新能力。

五年前看似不可能的生产工作负载，现在之所以能够实现，是因为[开源生态系统](https://thenewstack.io/what-do-cloud-native-and-kubernetes-even-mean/)中成熟的特定架构创新。

## **分层存储改变实时数据经济性**

[Apache Kafka](https://kafka.apache.org/)长期以来一直是企业实时数据管道的支柱，但其存储模型制造了一个昂贵的悖论。为了维持实时处理的低延迟，组织必须将所有数据存储在高性能存储层中——即使绝大多数记录很少会被再次访问。一个欺诈检测系统可能需要毫秒级访问最近一小时的交易，但可以容忍对历史模式分析的更高延迟。然而，这两个数据集都位于同一个昂贵的存储层中。

Kafka的[分层存储](https://www.instaclustr.com/support/documentation/kafka/useful-concepts/kafka-tiered-storage/)从根本上重构了这些经济性。该架构将Kafka的日志存储分为热层和冷层，根据访问模式自动管理数据放置。最近生成的数据保留在低延迟的本地存储中，而较旧的段则迁移到S3等对象存储中。关键的创新在于Kafka消费者仍然可以通过相同的API透明地访问冷层数据。

热层访问保持低于10毫秒的p99延迟，而冷层检索通常会增加50到100毫秒。对于大多数实时用例来说，其中最近的数据驱动决策，历史数据支持周期性分析，这些权衡可以在不影响核心功能的情况下，将存储成本降低70%到80%。一个处理点击流数据的零售平台现在可以以边际成本保留数月的历史事件用于机器学习（ML）模型训练，而以前他们可能在几周内就归档或删除了这些数据。

## **AI驱动搜索使非结构化数据变得有用**

企业搜索一直令人失望。传统的基于关键词的系统返回太多不相关的结果，而高级选项则需要大多数用户从未学过的专业查询语言。向量搜索和嵌入模型最终正在改变这一局面。

OpenSearch、带[pgvector](https://github.com/pgvector)的PostgreSQL以及带向量搜索能力的[Apache Cassandra 5.0](https://thenewstack.io/why-apache-cassandra-5-0-is-a-game-changer-for-developers/)现在能够大规模实现语义搜索。文档和查询通过语言模型编码为高维向量，相似性在向量空间中度量，而不是通过关键词重叠。当客服代表搜索“运输延迟投诉”时，系统能理解与提及“延迟交付”或“订单未送达”的记录之间的语义关系，而无需精确的短语匹配。

分层可导航小世界（HNSW）等索引结构支持近似最近邻搜索，即使跨越数十亿个向量也能在毫秒内返回结果。对于已部署OpenSearch或PostgreSQL的企业，通向AI驱动搜索的路径无需全面替换平台。在现有系统上添加向量功能，团队可以迭代地增强搜索功能，在全面迁移前验证其价值。

更好的是，其操作影响不仅仅局限于搜索框。向量嵌入支持理解内容关系的推荐引擎、识别日志中异常模式的异常检测系统，以及能够对企业知识库进行推理的聊天机器人。

## **ClickHouse 提升运营分析性能**

数据仓库传统上是面向批处理的系统，按预定间隔摄取数据，并针对历史数据集上的复杂分析查询进行优化。[ClickHouse](https://www.instaclustr.com/blog/clickhouse-a-beginners-guide-to-the-fastest-open-source-olap-dbms/)和类似的开源列式数据库正在打破运营工作负载和分析工作负载之间的界限，使得对数十亿行最新数据进行亚秒级查询成为可能。

[ClickHouse通过积极的压缩和为分析访问模式优化的列式存储实现其高性能](https://thenewstack.io/vector-search-without-the-lock-in-why-devs-like-clickhouse/)。面向行的数据库连续存储一条记录的所有字段，而列式系统则单独存储每个列。当分析查询需要在数百万行中聚合少量列时，只需从磁盘读取相关列。结合可实现10倍或更高压缩比的基于编解码器的压缩，即使在海量数据集上，查询也通常可以完全在内存中操作。

从传统数据仓库迁移需要重新思考数据建模。ClickHouse倾向于非规范化的宽表，而非带有连接的规范化模式。对于拥有成熟的Snowflake或Redshift部署的组织来说，决策不一定是替换，而更多是确定哪些工作负载对实时性能的要求高于现有平台的功能。

## **混合基础设施终获成功**

传统的本地系统代表着巨大的既定投资，企业不能轻易放弃。然而，这些系统越来越需要与现代云原生服务（用于分析、机器学习和实时处理）进行互操作。

Kubernetes已成为实现混合部署的集成层。虽然最初是为微服务编排设计的，但Kubernetes现在托管有状态工作负载，包括数据库和消息队列。它抽象了基础设施差异，允许应用程序在本地数据中心和公共云之间可移植地部署。

数据平面集成与控制平面集成同样重要。Debezium等变更数据捕获工具将数据库变更从传统系统流式传输到Kafka主题，使数十年来的数据[可用于实时处理](https://thenewstack.io/mark-cache-the-clickhouse-speed-hack-youre-not-using-yet/)，而无需修改经过实战检验的生产数据库。

托管开源服务为构建混合架构的企业提供运营杠杆。可靠地运行Kafka、ClickHouse或OpenSearch需要这些特定技术方面的深厚运营专业知识。托管服务让组织能够专注于集成模式和数据模型，而不是集群调优和版本升级。

## **使智能基础设施成为现实**

重塑企业数据基础设施的这些趋势，除了其开源基础之外，还有一个共同点。它们都代表着同时优化多个维度的架构选择，而不是将性能、成本和灵活性视为相互竞争的问题。

对于评估这些技术的技术负责人来说，问题不在于是否采用它们，而在于如何安排实施顺序。从现有Kafka部署的分层存储开始，能以最小的风险立即节省成本。在现有数据库中添加向量搜索，能在不进行平台迁移的情况下实现AI功能。关键是确定哪些功能能够解决您当前最紧迫的限制，同时逐步构建更智能的架构。

这些技术100%开源的代码性质，在采用路径上提供了非凡的灵活性。您可以在将ClickHouse完全迁移之前，先在部分分析工作负载上进行试验。我不是说您应该同时部署所有东西，但低实验门槛意味着在您的特定环境中验证这些方法的成本非常低。

展望2026年，不知怎的，它已近在眼前，现在加速发展的基础设施趋势将越来越成为基本期望。如今在智能数据基础设施上快速行动的企业，正在为未来的发展奠定基础。那些等待的企业，不仅会发现自己在现有能力上落后，而且会为建立在这些基础之上的下一波需求毫无准备。