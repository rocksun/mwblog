## 使用 Celery 构建生产级工作流编排器

### 分步指南

本指南将介绍如何使用 Celery 为高 RPS 数据处理引擎构建复杂工作流，涵盖从设计到实现，再到在 K8s 上进行生产部署的各个步骤。

Celery 是一款出色的编排和数据工程工具，尤其是其画布工作流功能。无论您需要处理异步任务、长时间后台进程、构建复杂工作流、实现容错机制、构建微服务模式，还是其他需求，将其与 K8s 结合使用，您将获得最适合您产品的平台。

本文是我在使用 Celery 一年并部署产品后的总结。

将其视为您的“操作指南”，用于构建跨多个计算处理任务的工作流编排器，了解如何对其进行通信，如何协调和部署产品。

### 第 1 步：了解业务

在投入代码之前，了解业务流程是第一步，例如：

- 快速处理速度
- 如何实现功能
- 数据必须经历哪种处理以及中间的所有步骤
- 如何在本地和云基础设施上部署数据
- 以及许多其他类似问题

本案例中的业务流程始于数据摄取 API 引入原始数据，从而生成不同的 ML/NLP 数据集，获取分析见解并针对下一行系统调用回调 API。上图快速浏览了整个流程。

**工作流必须满足以下要求：**

- 模块化设计，以便轻松集成不同类型的分析服务
- 实时处理
- 扩展以实现高 RPS 摄取
- 必须在低至 10 秒内完成整个流程
- 该系统包括使用文件，并且将频繁与数据库（如 DynamoDB、S3、kms）进行交互，因此还必须满足成本优化架构

### 第 2 步：将其转换为 Celery 工作流

将其转换为工作流的真正难点在于定义任务、将执行这些任务的使用者以及如何使用队列进行所有通信。

Celery 的优点在于其功能，例如 Celery 画布工作流和它提供的不同类型的使用者池，这使其可以灵活地适应不同的设计模式和架构。

[Celery 工作流的奇特案例 — DEV 社区](https://dev.to/akarshan/the-curious-case-of-celery-work-flows-39f7)

**我们首先从定义不同的 Celery 任务开始。**

即把每个组件分解为一个单独的任务，该任务必须负责实现其自己的业务目标，它甚至可以失败或重试，但必须实现其目标。

下图中的域数据集生成器和分析师任务负责 ML、NLP 和 Pandas，并针对其特定业务目标进行隔离。每个业务域都可以使用自己的逻辑和模型生成自己的数据集，每个域都可以分解为自己的不同任务。

**然后是编排任务**

这些任务作为协调器出现，它们没有自己的业务逻辑，但实际上定义了如何执行实际数据处理任务并协调其顺序运行。

第一个流程发起者充当编排器的入口点，并按顺序与数据集生成器然后服务任务进行协调。

下一个数据生成器和服务任务确保正确执行适当的子任务。

**然后我们决定负责这些任务的 Celery 使用者并使用适当的配置。**

我们将有许多执行多个任务的使用者，但我们可以将它们广泛分类为 3 种类型：**编排**、**分发器**和**任务**使用者。

**编排使用者：**

这是整个工作流的中央协调器，它决定如何顺序执行任务、如何控制消息流并建立从摄取到分析再到消费的数据管道。

**分发器使用者：**

负责并行执行任务并等待它们完成，例如数据生成器和综合分析发起者使用者。

**任务使用者：**

负责执行涉及 Pandas 和模型预测的实际任务，并且计算量也很大。

此处的每个使用者都已容器化并作为 pod 部署在 K8s 集群上，并且可以按您希望的那样进行扩展。

**定义使用者配置：**

Celery 有一些不同类型的使用者配置，可用于不同的并发性和任务持续时间要求，例如 gevent、forkpool 和 eventlets。对于短且仅具有 IO 操作或简单 api 调用的内容，您可能需要使用以非阻塞方式执行任务的 gevent 和 eventlet，对于需要计算和内存的内容，请使用 forkpool 使用者，它在子进程上工作以实现并发。
### 翻译要求

- 不要翻译非名人姓名

### 待翻译文本

前 2 个工作程序编排和分发器用于不需要计算或内存的短时任务，通常会将消息定向到队列并处理 DynamoDB 操作。这些任务可以具有更高的
[并使用并发](https://docs.celeryq.dev/en/stable/userguide/concurrency/gevent.html) [工作程序池](https://docs.celeryq.dev/en/stable/userguide/concurrency/gevent.html) *gevent*
另一方面，**任务工作程序**是数据魔力发生的地方，并且具有较低的并发性，它计算繁重，并且必须使用默认的 celery *forkpool* **工作程序。**
使用正确的池配置正确的 worker 可以实现更快速的数据处理目标，在编排 worker 本身的情况下，从一个任务移动到另一个任务可以满足高 RPS 和并发处理。
**在定义了任务以及哪个工作程序将执行它们之后，下一步是** *路由* *.* [采用 Azure 服务总线异步消息传递 | Jamahl Carter | 初创公司 | Medium](/swlh/adopting-async-messaging-with-azure-service-bus-4c936396b334)
Celery 具有任务路由这一惊人的功能，可以在其配置中提及。
它根据名称自动将任务路由到不同的队列，是的！！名称……因此，如果你按照某种命名约定命名任务，Celery 将使用正则表达式和 glob 匹配模式将这些任务路由到该队列。
## 步骤 3：引入优化
Celery 有一些非常棒的生产系统功能，社区对此非常了解。
我遇到的某些功能加快了长时间运行的进程，这些功能侧重于工作程序轮询任务的方式、指定并发性上的任务分配机制、重试机制和处理故障。
**默认情况下，预分叉 Celery 工作程序会在收到任务后立即将其分配给其工作程序进程，而不管该进程当前是否忙于其他任务。-O 公平标志：** **-**选项禁用此行为，等待分配任务，直到每个工作程序进程可用于工作。*Ofair* [](http://Three quick tips from two years with Celery) [Three quick tips from two years with Celery](/@taylorhughes/three-quick-tips-from-two-years-with-celery-c05ff9d7f9eb) **分布式系统中的工作程序类型提供不同的并发模型以优化性能。Eventlet 和 Gevent 是 Python 中异步 I/O 操作的轻量级库。Eventlet 使用协程和绿色线程，而 Gevent 使用基于绿色线程的协作式多任务处理。Forkpool 工作程序（如 Celery 中的工作程序）利用基于进程的模型，创建独立的工作程序进程，适用于 CPU 绑定任务，确保稳健的资源管理和隔离。这些选项提供了根据应用程序需求增强性能的灵活性。工作程序池：** **默认情况下，工作程序从其队列轮询 4 倍于并发性的任务。对于长时间运行且需要从队列中立即处理的任务，将乘数更改为 1 将仅轮询与队列中可用并发性一样多的任务，从而允许另一个工作程序从队列中轮询消息。预取乘数：** **Celery 任务可以有自己的个人时间限制，如果运行时间过长，则会失败。但它也提供了多种处理它们的选择，例如任务时间限制和处理：*软时间限制*和*硬时间限制*异常处理。这些可以允许逆转由于任务因限制而被终止而发生的数据库事务。**你的代码可能会失败，但如何处理失败是一种选择，包括任务失败和重试：** *传播标志*在和弦和组中失败的任务不会影响其他任务的执行，添加重试机制将以原子方式确保任务由工作程序重试。*Redis 用于缓存：* **当你使用 ML 模型构建工作流应用程序时，最好的优化技术是将它们加载为全局变量，从这个意义上说，模型加载发生在工作程序初始化时，并且可以用作共享的静态文件。预加载机器学习模型文件：**
## 步骤 4：添加警报和监控设置
现在我们有了分布式计算架构，下一步最好的事情是添加用于警报、监控和日志记录的机制。
**ELK 堆栈：**发送所有 Celery 任务状态日志的一种方法是在工作进程启动时劫持 Celery 记录器，并为其附加 Fluentd 处理程序，这将发送包含任务持续时间、在执行期间传递给任务的参数和关键字参数以及任务状态的日志。

**Sentry：**在处理可能让你感到意外的不同类型数据时，错误可能是不可预料的，尤其是当流量很大时，Sentry 可能是你的好帮手，它会在出现问题时提醒你，在 Celery 工作进程启动时设置 Sentry，并让它通过错误堆栈跟踪向你的 Slack 和电子邮件组发出警报。

**Datadog：**需要一个极其强大的工具来进行日志监控、堆栈监控、网络跟踪吗？…Datadog 可能是一款满足所有需求的最先进工具。

## 第 5 步：部署到生产环境，开始吧！

工作流构建？✅
故障和异常处理？✅
优化？✅
处理速度？✅
日志记录和警报？✅

我们现在已准备好将此设置投入生产环境。我们通过将应用程序容器化并在 K8s 集群的不同 Pod 上启动每个工作进程来实现此目的。

此处的容器编排将使我们能够满足按需流量，我们的工作进程可以根据队列中的消息进行扩展，并更快地处理这些消息。

由于我们正在使用 SQS 队列，因此可以使用以下方法进行扩展：

**对于短 Kubernetes 事件驱动的自动扩展程序 KEDA**

KEDA 与 SQS 指标相结合，有助于根据队列中最旧消息的近似年龄实现扩展。

理想情况下，对于高 RPS 工作流，工作进程必须立即从队列中使用一条消息并对其进行处理。如果流量很大，则更多侦听同一队列的工作进程将解决此问题。为了定义最佳扩展策略，我们查看队列指标，例如 Amazon SQS 上提供的指标，

SQS 提供各种指标，例如正在传输的消息、近似年龄、数据包大小、已发送/已删除/已接收/不可见的邮件数。我们理想情况下希望最旧消息队列指标中的最小值。

扩展和生产设置？✅

所有系统都已准备就绪，我们已成功制作了一个生产级编排器，该编排器可以满足高 RPS 要求，并按需扩展。

因此，现在使用 Celery 以其最佳本质用于数据工程和构建复杂工作流以及部署你的产品。我希望这能让你大致了解如何使用 Celery 在多个计算中实现任务的复杂协调和执行，但不仅限于构建，还包括构建一个具有扩展、监控和优化的生产级系统。