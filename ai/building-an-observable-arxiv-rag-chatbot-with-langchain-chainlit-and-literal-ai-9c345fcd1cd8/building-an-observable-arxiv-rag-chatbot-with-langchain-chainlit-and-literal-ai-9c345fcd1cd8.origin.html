<!doctype html><html lang="en"><head><title data-rh="true">Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI | by Tahreem Rasul | May, 2024 | Towards Data Science</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2024-05-13T19:04:19.727Z"/><meta data-rh="true" name="title" content="Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI | by Tahreem Rasul | May, 2024 | Towards Data Science"/><meta data-rh="true" property="og:title" content="Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI"/><meta data-rh="true" property="al:android:url" content="medium://p/9c345fcd1cd8"/><meta data-rh="true" property="al:ios:url" content="medium://p/9c345fcd1cd8"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="In this guide, I’ll demonstrate how to build a semantic research paper engine using Retrieval Augmented Generation (RAG). I’ll utilize LangChain as the main framework for building our semantic…"/><meta data-rh="true" property="og:description" content="A tutorial on building a semantic paper engine using RAG with LangChain, Chainlit copilot apps, and Literal AI observability."/><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8"/><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1024/1*GUoz9w5z8FLzXHmQUarXyg.png"/><meta data-rh="true" property="article:author" content="https://medium.com/@tahreemrasul"/><meta data-rh="true" name="author" content="Tahreem Rasul"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI"/><meta data-rh="true" name="twitter:site" content="@TDataScience"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/9c345fcd1cd8"/><meta data-rh="true" property="twitter:description" content="A tutorial on building a semantic paper engine using RAG with LangChain, Chainlit copilot apps, and Literal AI observability."/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1024/1*GUoz9w5z8FLzXHmQUarXyg.png"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:creator" content="@tahreemrasul1"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="17 min read"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/resize:fill:256:256/1*VzTUkfeGymHP4Bvav-T-lA.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@tahreemrasul"/><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/9c345fcd1cd8"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*GUoz9w5z8FLzXHmQUarXyg.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8","dateCreated":"2024-05-13T19:04:19.727Z","datePublished":"2024-05-13T19:04:19.727Z","dateModified":"2024-05-13T19:22:57.453Z","headline":"Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI","name":"Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI","description":"In this guide, I’ll demonstrate how to build a semantic research paper engine using Retrieval Augmented Generation (RAG). I’ll utilize LangChain as the main framework for building our semantic…","identifier":"9c345fcd1cd8","author":{"@type":"Person","name":"Tahreem Rasul","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@tahreemrasul"},"creator":["Tahreem Rasul"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":192,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:384\u002F1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8"}</script><style type="text/css" data-fela-rehydration="579" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="579" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{fill:rgba(0, 0, 0, 1)}.av{height:22px}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.ds{margin-left:8px}.dt{color:#6B6B6B}.du{font-size:13px}.dv{height:100%}.eo{color:#FFFFFF}.ep{fill:#FFFFFF}.eq{background:rgba(102, 138, 170, 1)}.er{border-color:rgba(102, 138, 170, 1)}.ev:disabled{cursor:inherit !important}.ew:disabled{opacity:0.3}.ex:disabled:hover{background:rgba(102, 138, 170, 1)}.ey:disabled:hover{border-color:rgba(102, 138, 170, 1)}.ez{border-radius:99em}.fa{border-width:1px}.fb{border-style:solid}.fc{box-sizing:border-box}.fd{text-decoration:none}.fe{text-align:center}.fh{margin-right:32px}.fi{position:relative}.fj{fill:#6B6B6B}.fm{background:transparent}.fn svg{margin-left:4px}.fo svg{fill:#6B6B6B}.fq{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fr{position:absolute}.fy{margin:0 24px}.gc{background:rgba(255, 255, 255, 1)}.gd{border:1px solid #F2F2F2}.ge{box-shadow:0 1px 4px #F2F2F2}.gf{max-height:100vh}.gg{overflow-y:auto}.gh{left:0}.gi{top:calc(100vh + 100px)}.gj{bottom:calc(100vh + 100px)}.gk{width:10px}.gl{pointer-events:none}.gm{word-break:break-word}.gn{word-wrap:break-word}.go:after{display:block}.gp:after{content:""}.gq:after{clear:both}.gr{line-height:1.23}.gs{letter-spacing:0}.gt{font-style:normal}.gu{font-weight:700}.hp{margin-bottom:-0.27em}.hq{line-height:1.394}.ig{@media all and (max-width: 551.98px):8px}.ih{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.ii{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.ij{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.ik{@media all and (min-width: 1080px):16px}.iq{align-items:baseline}.ir{width:48px}.is{height:48px}.it{border:2px solid rgba(255, 255, 255, 1)}.iu{z-index:0}.iv{box-shadow:none}.iw{border:1px solid rgba(0, 0, 0, 0.05)}.ix{margin-left:-12px}.iy{width:28px}.iz{height:28px}.ja{z-index:1}.jb{width:24px}.jc{margin-bottom:2px}.jd{flex-wrap:nowrap}.je{font-size:16px}.jf{line-height:24px}.jh{margin:0 8px}.ji{display:inline}.jj{color:rgba(102, 138, 170, 1)}.jk{fill:rgba(102, 138, 170, 1)}.jn{flex:0 0 auto}.jq{flex-wrap:wrap}.jt{white-space:pre-wrap}.ju{margin-right:4px}.jv{overflow:hidden}.jw{max-height:20px}.jx{text-overflow:ellipsis}.jy{display:-webkit-box}.jz{-webkit-line-clamp:1}.ka{-webkit-box-orient:vertical}.kb{word-break:break-all}.kd{padding-left:8px}.ke{padding-right:8px}.lf> *{flex-shrink:0}.lg{overflow-x:scroll}.lh::-webkit-scrollbar{display:none}.li{scrollbar-width:none}.lj{-ms-overflow-style:none}.lk{width:74px}.ll{flex-direction:row}.lm{z-index:2}.lp{-webkit-user-select:none}.lq{border:0}.lr{fill:rgba(117, 117, 117, 1)}.lu{outline:0}.lv{user-select:none}.lw> svg{pointer-events:none}.mf{cursor:progress}.mg{opacity:1}.mh{padding:4px 0}.mk{margin-top:0px}.ml{width:16px}.mn{display:inline-flex}.mt{max-width:100%}.mu{padding:8px 2px}.mv svg{color:#6B6B6B}.nm{line-height:1.58}.nn{letter-spacing:-0.004em}.no{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.oh{margin-bottom:-0.46em}.oi{text-decoration:underline}.oj{margin-left:auto}.ok{margin-right:auto}.ol{max-width:1024px}.or{clear:both}.ot{cursor:zoom-in}.ou{z-index:auto}.ow{height:auto}.ox{margin-top:10px}.oy{max-width:728px}.pb{list-style-type:disc}.pc{margin-left:30px}.pd{padding-left:0px}.pj{max-width:1920px}.pp{box-shadow:inset 0 0 0 1px #F2F2F2}.pq{padding:0px}.pr{padding:16px 20px}.ps{flex:1 1 auto}.pu{max-height:40px}.pv{-webkit-line-clamp:2}.pw{margin-top:8px}.px{margin-top:12px}.py{line-height:1.12}.pz{letter-spacing:-0.022em}.qa{font-weight:600}.qt{margin-bottom:-0.28em}.qz{padding:2px 4px}.ra{font-size:75%}.rb> strong{font-family:inherit}.rc{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.rd{overflow-x:auto}.re{padding:32px}.rf{border:1px solid #E5E5E5}.rg{line-height:1.4}.rh{margin-top:-0.2em}.ri{margin-bottom:-0.2em}.rj{white-space:pre}.rk{min-width:fit-content}.rl{line-height:1.18}.rz{margin-bottom:-0.31em}.sa{list-style-type:decimal}.sb{max-width:3298px}.sc{max-width:3358px}.sd{max-width:2500px}.se{width:160px}.sf{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/1*YRp7gT3rySVA3JWHwd_rFQ.gif)}.sg{background-origin:border-box}.sh{background-size:cover}.si{height:167px}.sj{background-position:50% 50%}.sk{max-width:3356px}.sl{max-width:802px}.sm{max-width:2338px}.sn{max-width:2454px}.so{max-width:2830px}.sp{max-width:2448px}.sq{max-width:2832px}.sr{max-width:2444px}.ss{max-width:1818px}.st{margin-bottom:26px}.su{margin-top:6px}.sv{margin-right:8px}.sw{padding:8px 16px}.sx{border-radius:100px}.sy{transition:background 300ms ease}.ta{white-space:nowrap}.tb{border-top:none}.th{height:52px}.ti{max-height:52px}.tj{box-sizing:content-box}.tk{position:static}.tm{max-width:155px}.ts{margin-right:20px}.ty{align-items:flex-end}.tz{width:76px}.ua{height:76px}.ub{border:2px solid #F9F9F9}.uc{height:72px}.ud{width:72px}.ue{margin-left:-16px}.uf{width:36px}.ug{height:36px}.uh{width:auto}.ui{stroke:#F2F2F2}.uj{color:#F2F2F2}.uk{fill:#F2F2F2}.ul{background:#F2F2F2}.um{border-color:#F2F2F2}.us{font-weight:500}.ut{font-size:24px}.uu{line-height:30px}.uv{letter-spacing:-0.016em}.uw{margin-top:16px}.ux{height:0px}.uy{border-bottom:solid 1px #E5E5E5}.ve{margin-top:72px}.vf{padding:24px 0}.vg{margin-bottom:0px}.vh{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.es:hover{background:rgba(90, 118, 144, 1)}.et:hover{border-color:rgba(90, 118, 144, 1)}.eu:hover{cursor:pointer}.fk:hover{color:#242424}.fl:hover{fill:#242424}.fp:hover svg{fill:#242424}.fs:hover{background-color:rgba(0, 0, 0, 0.1)}.jg:hover{text-decoration:underline}.jl:hover:not(:disabled){color:rgba(90, 118, 144, 1)}.jm:hover:not(:disabled){fill:rgba(90, 118, 144, 1)}.lt:hover{fill:rgba(8, 8, 8, 1)}.mi:hover{fill:#000000}.mj:hover p{color:#000000}.mm:hover{color:#000000}.mw:hover svg{color:#000000}.sz:hover{background-color:#F2F2F2}.un:hover{background:#F2F2F2}.uo:hover{border-color:#F2F2F2}.up:hover{cursor:wait}.uq:hover{color:#F2F2F2}.ur:hover{fill:#F2F2F2}.bc:focus-within path{fill:#242424}.ls:focus{fill:rgba(8, 8, 8, 1)}.mx:focus svg{color:#000000}.ov:focus{transform:scale(1.01)}.lx:active{border-style:none}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ee{font-size:14px}.ef{line-height:20px}.el{font-size:13px}.em{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:68px}.gb{max-width:680px}.hl{font-size:42px}.hm{margin-top:1.19em}.hn{line-height:52px}.ho{letter-spacing:-0.011em}.id{font-size:22px}.ie{margin-top:0.92em}.if{line-height:28px}.ip{align-items:center}.kr{border-top:solid 1px #F2F2F2}.ks{border-bottom:solid 1px #F2F2F2}.kt{margin:32px 0 0}.ku{padding:3px 8px}.ld> *{margin-right:24px}.le> :last-child{margin-right:0}.me{margin-top:0px}.ms{margin:0}.od{font-size:20px}.oe{margin-top:2.14em}.of{line-height:32px}.og{letter-spacing:-0.003em}.oq{margin-top:56px}.pi{margin-top:1.14em}.po{margin-top:32px}.qp{font-size:24px}.qq{margin-top:1.95em}.qr{line-height:30px}.qs{letter-spacing:-0.016em}.qy{margin-top:0.94em}.rw{margin-top:1.72em}.rx{line-height:24px}.ry{letter-spacing:0}.tg{margin-bottom:88px}.tr{display:inline-block}.tx{padding-top:72px}.vd{margin-top:40px}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.md{margin-top:0px}.oz{margin-left:auto}.pa{text-align:center}.tq{display:inline-block}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.mc{margin-top:0px}.tp{display:inline-block}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.ma{margin-top:0px}.mb{margin-right:0px}.pt{padding:10px 12px 10px}.to{display:inline-block}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.dw{font-size:13px}.dx{line-height:20px}.eg{padding:0px 8px 1px}.ft{margin-bottom:4px}.gv{font-size:32px}.gw{margin-top:1.01em}.gx{line-height:38px}.gy{letter-spacing:-0.014em}.hr{font-size:18px}.hs{margin-top:0.79em}.ht{line-height:24px}.il{align-items:flex-start}.jo{flex-direction:column}.jr{margin-bottom:2px}.kf{margin:24px -24px 0}.kg{padding:0}.kv> *{margin-right:8px}.kw> :last-child{margin-right:24px}.ln{margin-left:0px}.ly{margin-top:0px}.lz{margin-right:0px}.mo{margin:0}.my{border:1px solid #F2F2F2}.mz{border-radius:99em}.na{padding:0px 16px 0px 12px}.nb{height:38px}.nc{align-items:center}.ne svg{margin-right:8px}.np{margin-top:1.56em}.nq{line-height:28px}.nr{letter-spacing:-0.003em}.om{margin-top:40px}.pe{margin-top:1.34em}.pk{margin-top:24px}.qb{font-size:20px}.qc{margin-top:1.2em}.qd{letter-spacing:0}.qu{margin-top:0.67em}.rm{font-size:16px}.rn{margin-top:1.23em}.tc{margin-bottom:80px}.tn{display:inline-block}.tt{padding-top:48px}.uz{margin-top:32px}.nd:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.ec{font-size:14px}.ed{line-height:20px}.ej{font-size:13px}.ek{padding:5px 12px}.ff{display:flex}.fw{margin-bottom:68px}.ga{max-width:680px}.hh{font-size:42px}.hi{margin-top:1.19em}.hj{line-height:52px}.hk{letter-spacing:-0.011em}.ia{font-size:22px}.ib{margin-top:0.92em}.ic{line-height:28px}.io{align-items:center}.kn{border-top:solid 1px #F2F2F2}.ko{border-bottom:solid 1px #F2F2F2}.kp{margin:32px 0 0}.kq{padding:3px 8px}.lb> *{margin-right:24px}.lc> :last-child{margin-right:0}.mr{margin:0}.nz{font-size:20px}.oa{margin-top:2.14em}.ob{line-height:32px}.oc{letter-spacing:-0.003em}.op{margin-top:56px}.ph{margin-top:1.14em}.pn{margin-top:32px}.ql{font-size:24px}.qm{margin-top:1.95em}.qn{line-height:30px}.qo{letter-spacing:-0.016em}.qx{margin-top:0.94em}.rt{margin-top:1.72em}.ru{line-height:24px}.rv{letter-spacing:0}.tf{margin-bottom:88px}.tw{padding-top:72px}.vc{margin-top:40px}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.ea{font-size:13px}.eb{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:68px}.fz{max-width:680px}.hd{font-size:42px}.he{margin-top:1.19em}.hf{line-height:52px}.hg{letter-spacing:-0.011em}.hx{font-size:22px}.hy{margin-top:0.92em}.hz{line-height:28px}.in{align-items:center}.kj{border-top:solid 1px #F2F2F2}.kk{border-bottom:solid 1px #F2F2F2}.kl{margin:32px 0 0}.km{padding:3px 8px}.kz> *{margin-right:24px}.la> :last-child{margin-right:0}.mq{margin:0}.nv{font-size:20px}.nw{margin-top:2.14em}.nx{line-height:32px}.ny{letter-spacing:-0.003em}.oo{margin-top:56px}.pg{margin-top:1.14em}.pm{margin-top:32px}.qh{font-size:24px}.qi{margin-top:1.95em}.qj{line-height:30px}.qk{letter-spacing:-0.016em}.qw{margin-top:0.94em}.rq{margin-top:1.72em}.rr{line-height:24px}.rs{letter-spacing:0}.te{margin-bottom:88px}.tv{padding-top:72px}.vb{margin-top:40px}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dy{font-size:13px}.dz{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:4px}.gz{font-size:32px}.ha{margin-top:1.01em}.hb{line-height:38px}.hc{letter-spacing:-0.014em}.hu{font-size:18px}.hv{margin-top:0.79em}.hw{line-height:24px}.im{align-items:flex-start}.jp{flex-direction:column}.js{margin-bottom:2px}.kh{margin:24px 0 0}.ki{padding:0}.kx> *{margin-right:8px}.ky> :last-child{margin-right:8px}.lo{margin-left:0px}.mp{margin:0}.nf{border:1px solid #F2F2F2}.ng{border-radius:99em}.nh{padding:0px 16px 0px 12px}.ni{height:38px}.nj{align-items:center}.nl svg{margin-right:8px}.ns{margin-top:1.56em}.nt{line-height:28px}.nu{letter-spacing:-0.003em}.on{margin-top:40px}.pf{margin-top:1.34em}.pl{margin-top:24px}.qe{font-size:20px}.qf{margin-top:1.2em}.qg{letter-spacing:0}.qv{margin-top:0.67em}.ro{font-size:16px}.rp{margin-top:1.23em}.td{margin-bottom:80px}.tu{padding-top:48px}.va{margin-top:32px}.nk:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="print">.tl{display:none}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.kc{max-height:none}</style><style type="text/css" data-fela-rehydration="579" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.os{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="dt ag du be ak b am an ao ap aq ar as at s u w i d q dv z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9c345fcd1cd8&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="ds"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg viewBox="0 0 3940 610" class="au av"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search" value=""/></div></div></div><div class="h k w ff fg"><div class="fh ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------" rel="noopener follow"><div class="be b bf z dt fi fj ab q fk fl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="ds l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fh ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dt fi fj ab q fk fl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="fh h k j"><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ax fm am ab q ao fn fo fp" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fi"><img alt="" class="l fc bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fq bx l by bz fr n ax fs"></div></div></button></div></div></div><div class="l"><div class="ft fu fv fw fx l"><div class="ab ca"><div class="ch bg fy fz ga gb"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fr gh gi gj gk gl"></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><div><h1 id="8e26" class="pw-post-title gr gs gt be gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp bj" data-testid="storyTitle">Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI</h1></div><div><h2 id="7c56" class="pw-subtitle-paragraph hq gs gt be b hr hs ht hu hv hw hx hy hz ia ib ic id ie if cp dt">A tutorial on building a semantic paper engine using RAG with LangChain, Chainlit copilot apps, and Literal AI observability.</h2><div class="ig ih ii ij ik"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="il im in io ip ab"><div><div class="ab iq"><a href="https://medium.com/@tahreemrasul?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="l ir is bx it iu"><div class="l fi"><img alt="Tahreem Rasul" class="l fc bx dc dd cw" src="https://miro.medium.com/v2/resize:fill:88:88/1*whixGo6nrkNkKhlYSE9UUw.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"/><div class="iv bx l dc dd fr n iw fs"></div></div></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><div class="ix ab fi"><div><div class="bl" aria-hidden="false"><div class="l iy iz bx it ja"><div class="l fi"><img alt="Towards Data Science" class="l fc bx bq jb cw" src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"/><div class="iv bx l bq jb fr n iw fs"></div></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="jc ab q"><div class="ab q jd"><div class="ab q"><div><div class="bl" aria-hidden="false"><p class="be b je jf bj"><a class="af ag ah ai aj ak al am an ao ap aq ar jg" data-testid="authorName" href="https://medium.com/@tahreemrasul?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow">Tahreem Rasul</a></p></div></div></div><span class="jh ji" aria-hidden="true"><span class="be b bf z dt">·</span></span><p class="be b je jf dt"><span><a class="jj jk ah ai aj ak al am an ao ap aq ar ew jl jm" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F795f7e79f0ce&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;user=Tahreem+Rasul&amp;userId=795f7e79f0ce&amp;source=post_page-795f7e79f0ce----9c345fcd1cd8---------------------post_header-----------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l jn"><span class="be b bf z dt"><div class="ab cm jo jp jq"><div class="jr js ab"><div class="be b bf z dt ab jt"><span class="ju l jn">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jg ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b bf z jv jw jx jy jz ka kb kc bj">Towards Data Science</p></a></div></div></div><div class="h k"><span class="jh ji" aria-hidden="true"><span class="be b bf z dt">·</span></span></div></div><span class="be b bf z dt"><div class="ab ae"><span data-testid="storyReadTime">17 min read</span><div class="kd ke l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dt">·</span></span></div>1 day ago</div></span></div></span></div></div></div><div class="ab co kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku"><div class="h k w ff fg q"><div class="lk l"><div class="ab q ll lm"><div class="pw-multi-vote-icon fi ju ln lo lp"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c345fcd1cd8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;user=Tahreem+Rasul&amp;userId=795f7e79f0ce&amp;source=-----9c345fcd1cd8---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="lq ao lr ls lt lu am lv lw lx lp"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l ly lz ma mb mc md me"><p class="be b du z dt"><span class="mf">--</span></p></div></div></div><div><div class="bl" aria-hidden="false"><button class="ao lq mg mh ab q fj mi mj" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="mk"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></button></div></div></div><div class="ab q kv kw kx ky kz la lb lc ld le lf lg lh li lj"><div class="ml k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c345fcd1cd8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;source=-----9c345fcd1cd8---------------------bookmark_footer-----------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt mm" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div><div class="fc mn cm"><div class="l ae"><div class="ab ca"><div class="mo mp mq mr ms mt ch bg"><div class="ab"><div class="bl bg" aria-hidden="false"><div><div class="bl" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af fj ah ai aj ak al mu an ao ap ew mv mw mj mx my mz na nb s nc nd ne nf ng nh ni u nj nk nl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fj ah ai aj ak al mu an ao ap ew mv mw mj mx my mz na nb s nc nd ne nf ng nh ni u nj nk nl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Share</p></div></button></div></div></div></div></div></div></div></div></div><p id="2e86" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">In this guide, I’ll demonstrate how to build a semantic research paper engine using Retrieval Augmented Generation (RAG). I’ll utilize <a class="af oi" href="https://www.langchain.com" rel="noopener ugc nofollow" target="_blank">LangChain</a> as the main framework for building our semantic engine, along-with <a class="af oi" href="https://openai.com" rel="noopener ugc nofollow" target="_blank">OpenAI’s</a> language model and <a class="af oi" href="https://www.trychroma.com" rel="noopener ugc nofollow" target="_blank">Chroma DB’s</a> vector database. For building the Copilot embedded web application, I’ll use <a class="af oi" href="https://docs.chainlit.io/get-started/overview" rel="noopener ugc nofollow" target="_blank">Chainlit’s</a> Copilot feature and incorporate observability features from <a class="af oi" href="https://literalai.com" rel="noopener ugc nofollow" target="_blank">Literal AI</a>. This tool can facilitate academic research by making it easier to find relevant papers. Users will also be able to interact directly with the content by asking questions about the recommended papers. Lastly, we will integrate observability features in the application to track and debug calls to the LLM.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok ol"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GUoz9w5z8FLzXHmQUarXyg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*GUoz9w5z8FLzXHmQUarXyg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*GUoz9w5z8FLzXHmQUarXyg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*GUoz9w5z8FLzXHmQUarXyg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*GUoz9w5z8FLzXHmQUarXyg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GUoz9w5z8FLzXHmQUarXyg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUoz9w5z8FLzXHmQUarXyg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*GUoz9w5z8FLzXHmQUarXyg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*GUoz9w5z8FLzXHmQUarXyg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*GUoz9w5z8FLzXHmQUarXyg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*GUoz9w5z8FLzXHmQUarXyg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*GUoz9w5z8FLzXHmQUarXyg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*GUoz9w5z8FLzXHmQUarXyg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*GUoz9w5z8FLzXHmQUarXyg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="525" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">App Schema for Copilot-embedded semantic research paper application. Illustration by Author.</figcaption></figure><p id="5f23" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Here is an overview of everything we will cover in this tutorial:</p><ul class=""><li id="4334" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pb pc pd bj">Develop a RAG pipeline with OpenAI, LangChain and Chroma DB to process and retrieve the most relevant PDF documents from the arXiv API.</li><li id="8389" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh pb pc pd bj">Develop a Chainlit application with a Copilot for online paper retrieval.</li><li id="ca27" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh pb pc pd bj">Enhance the application with LLM observability features with Literal AI.</li></ul><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok pj"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*jtr_Sbj0Dt7nIBV2JAesuA.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="394" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Copilot-embedded semantic research paper application in action. By Author</figcaption></figure><p id="8b89" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Code for this tutorial can be found in <a class="af oi" href="https://github.com/tahreemrasul/semantic_research_engine" rel="noopener ugc nofollow" target="_blank">this GitHub repo</a>:</p><div class="pk pl pm pn po pp"><a href="https://github.com/tahreemrasul/semantic_research_engine?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pq ab jn"><div class="pr ab cn ca ps pt"><h2 class="be gu je z jv pu jx jy pv ka kc gs bj">GitHub - tahreemrasul/semantic_research_engine: A semantic research engine to get relevant papers…</h2><div class="pw l"><h3 class="be b je z jv pu jx jy pv ka kc dt">A semantic research engine to get relevant papers based on a user query. Application frontend with Chainlit Copilot…</h3></div><div class="px l"><p class="be b du z jv pu jx jy pv ka kc dt">github.com</p></div></div></div></a></div><h1 id="0596" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Environment Setup</h1><p id="f123" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Create a new <code class="cw qz ra rb rc b">conda</code> environment:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="47a5" class="rg pz gt rc b bf rh ri l rj rk">conda create -n semantic_research_engine python=3.10</span></pre><p id="643c" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Activate the environment:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="d451" class="rg pz gt rc b bf rh ri l rj rk">conda activate semantic_research_engine</span></pre><p id="b6dc" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Install all required dependencies in your activated environment by running the following command:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="ab2f" class="rg pz gt rc b bf rh ri l rj rk">pip install -r requirements.txt</span></pre><h1 id="631b" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">RAG Pipeline Creation</h1><p id="1e99" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Retrieval Augmented Generation (RAG) is a popular technique that allows you to build custom conversational AI applications with your own data. The principle of RAG is fairly simple: we convert our textual data into vector embeddings and insert these into a vector database. This database is then linked to a large language model (LLM). We are constraining our LLM to get information from our own database instead of relying on prior knowledge to answer user queries. In the next few steps, I will detail how to do this for our semantic research paper engine. We will create a test script named <code class="cw qz ra rb rc b">rag_test.py</code> to understand and build the components for our RAG pipeline. These will be reused when building our Copilot integrated Chainlit application.</p><h2 id="2b04" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 1</h2><p id="adeb" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Secure an OpenAI API key by registering an account. Once done, create a <code class="cw qz ra rb rc b">.env</code> file in your project directory and add your OpenAI API key as follows:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="72dc" class="rg pz gt rc b bf rh ri l rj rk">OPENAI_API_KEY=&quot;your_openai_api_key&quot;</span></pre><p id="db72" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">This <code class="cw qz ra rb rc b">.env</code> will house all of our API keys for the project.</p><h2 id="ae7a" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 2: Ingestion</h2><p id="28bc" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">In this step, we will create a database to store the research papers for a given user query. To do this, we first need to retrieve a list of relevant papers from the arXiv API for the query. We will be using the <code class="cw qz ra rb rc b">ArxivLoader()</code> package from LangChain as it abstracts API interactions, and retrieves the papers for further processing. We can split these papers into smaller chunks to ensure efficient processing and relevant information retrieval later on. To do this, we will use the <code class="cw qz ra rb rc b">RecursiveTextSplitter()</code> from LangChain, since it ensures semantic preservation of information while splitting documents. Next, we will create embeddings for these chunks using the <code class="cw qz ra rb rc b">sentence-transformers</code> embeddings from <a class="af oi" href="https://python.langchain.com/docs/integrations/platforms/huggingface/#embedding-models" rel="noopener ugc nofollow" target="_blank">HuggingFace</a>. Finally, we will ingest these split document embeddings into a Chroma DB database for further querying.</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="22e8" class="rg pz gt rc b bf rh ri l rj rk"># rag_test.py <br/>from langchain_community.document_loaders import ArxivLoader<br/>from langchain.text_splitter import RecursiveCharacterTextSplitter<br/>from langchain_community.vectorstores import Chroma<br/>from langchain_community.embeddings import HuggingFaceEmbeddings<br/><br/>query = &quot;lightweight transformer for language tasks&quot;<br/>arxiv_docs = ArxivLoader(query=query, load_max_docs=3).load()<br/>pdf_data = []<br/>for doc in arxiv_docs:<br/>    text_splitter = RecursiveCharacterTextSplitter(<br/>                    chunk_size=1000,<br/>                    chunk_overlap=100)<br/>    texts = text_splitter.create_documents([doc.page_content])<br/>    pdf_data.append(texts)<br/><br/>embeddings = HuggingFaceEmbeddings(model_name=&quot;sentence-transformers/all-MiniLM-l6-v2&quot;)<br/>db = Chroma.from_documents(pdf_data[0], embeddings)</span></pre><h2 id="76c8" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 3: Retrieval and Generation</h2><p id="ba08" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Once the database for a particular topic has been created, we can use this database as a retriever to answer user questions based on the provided context. LangChain offers a few different chains for retrieval, the simplest being the <code class="cw qz ra rb rc b">RetrievalQA</code> chain that we will use in this tutorial. We will set it up using the <code class="cw qz ra rb rc b">from_chain_type()</code> method, specifying the model and the retriever. For document integration into the LLM, we’ll use the <code class="cw qz ra rb rc b">stuff</code> chain type, as it stuffs all documents into a single prompt.</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="8fb6" class="rg pz gt rc b bf rh ri l rj rk"># rag_test.py<br/>from langchain.chains import RetrievalQA<br/>from langchain_openai import OpenAI<br/>from dotenv import load_dotenv<br/><br/>load_dotenv()<br/>llm = OpenAI(model=&#x27;gpt-3.5-turbo-instruct&#x27;, temperature=0)<br/>qa = RetrievalQA.from_chain_type(llm=llm, <br/>                                 chain_type=&quot;stuff&quot;, <br/>                                 retriever=db.as_retriever())<br/><br/>question = &quot;how many and which benchmark datasets and tasks were <br/>            compared for light weight transformer?&quot;<br/>result = qa({&quot;query&quot;: question})</span></pre><p id="cdcb" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Now that we have covered online retrieval from the arXiv API and the ingestion and retrieval steps for our RAG pipeline, we are ready to develop the web application for our semantic research engine.</p><h1 id="270d" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Understanding Literal AI</h1><p id="25d8" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj"><a class="af oi" href="https://literalai.com" rel="noopener ugc nofollow" target="_blank">Literal AI</a> is an observability, evaluation and analytics platform for building production-grade LLM apps. Some key features offered by Literal AI include:</p><ol class=""><li id="9128" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh sa pc pd bj"><strong class="no gu">Observability</strong>: enables monitoring of LLM apps, including conversations, intermediary steps, prompts, etc.</li><li id="ad29" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">Datasets</strong>: allows creation of datasets mixing production data and hand written examples.</li><li id="489c" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">Online Evals</strong>: enables evaluation of threads and execution in production using different evaluators.</li><li id="36d4" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">Prompt Playground</strong>: allows iteration, versioning, and deployment of prompts.</li></ol><p id="aa21" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">We will use the observability and prompt iteration features to evaluate and debug the calls made with our semantic research paper app.</p><h1 id="dd0f" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Prompt Playground with Literal AI</h1><p id="e429" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">When creating conversational AI applications, developers need to iterate through multiple versions of a prompt to get to the one that generates the best results. Prompt engineering plays a crucial role in most LLM tasks, as minor modifications can significantly alter the responses from a language model. Literal AI’s prompt playground can be used to streamline this process. Once you select the model provider, you can input your initial prompt template, add any additional information, and iteratively refine the prompts to find the most suitable one. In the next few steps, we will be using this playground to find the best prompt for our application.</p><h2 id="e58d" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 1</h2><p id="db5f" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Create an API key by navigating to the <a class="af oi" href="https://cloud.getliteral.ai/" rel="noopener ugc nofollow" target="_blank">Literal AI Dashboard</a>. Register an account, navigate to the <strong class="no gu">projects</strong> page, and create a new project. Each project comes with its unique API key. On the <strong class="no gu">Settings</strong> tab, you will find your API key in the <strong class="no gu">API Key</strong> section. Add it to your <code class="cw qz ra rb rc b">.env</code> file:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="3b86" class="rg pz gt rc b bf rh ri l rj rk">LITERAL_API_KEY=&quot;your_literal_api_key&quot;</span></pre><h2 id="2cd9" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 2</h2><p id="022e" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">In the left sidebar, click <strong class="no gu">Prompts,</strong> and then navigate to <strong class="no gu">New Prompt.</strong> This should open a new prompt creation session.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sb"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Cpr1rSci_IWLv5gNOoT_Cg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Cpr1rSci_IWLv5gNOoT_Cg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Cpr1rSci_IWLv5gNOoT_Cg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Cpr1rSci_IWLv5gNOoT_Cg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Cpr1rSci_IWLv5gNOoT_Cg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Cpr1rSci_IWLv5gNOoT_Cg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cpr1rSci_IWLv5gNOoT_Cg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*Cpr1rSci_IWLv5gNOoT_Cg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Cpr1rSci_IWLv5gNOoT_Cg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Cpr1rSci_IWLv5gNOoT_Cg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Cpr1rSci_IWLv5gNOoT_Cg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Cpr1rSci_IWLv5gNOoT_Cg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Cpr1rSci_IWLv5gNOoT_Cg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Cpr1rSci_IWLv5gNOoT_Cg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="181" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Literal AI Prompts Dashboard. Image by Author</figcaption></figure><p id="4518" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Once inside the playground, on the left sidebar, add a new <strong class="no gu">System</strong> message in the <strong class="no gu">Template</strong> section. Anything in parenthesis will be added to the <strong class="no gu">Variables, </strong>and treated as input in the prompt:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="60e8" class="rg pz gt rc b bf rh ri l rj rk">You are a helpful assistant. Use provided {{context}} to answer user <br/>{{question}}. Do not use prior knowledge. <br/>Answer:</span></pre><p id="6451" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">In the right sidebar, you can provide your OpenAI API Key. Select parameters such as the <strong class="no gu">Model</strong>, <strong class="no gu">Temperature</strong>, and <strong class="no gu">Maximum Length </strong>for completion to play around with the prompt.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sc"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*vbuEXySvfaAJiO8SaHdrIA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*vbuEXySvfaAJiO8SaHdrIA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*vbuEXySvfaAJiO8SaHdrIA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*vbuEXySvfaAJiO8SaHdrIA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*vbuEXySvfaAJiO8SaHdrIA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vbuEXySvfaAJiO8SaHdrIA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vbuEXySvfaAJiO8SaHdrIA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*vbuEXySvfaAJiO8SaHdrIA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*vbuEXySvfaAJiO8SaHdrIA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*vbuEXySvfaAJiO8SaHdrIA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*vbuEXySvfaAJiO8SaHdrIA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*vbuEXySvfaAJiO8SaHdrIA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*vbuEXySvfaAJiO8SaHdrIA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*vbuEXySvfaAJiO8SaHdrIA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="401" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Literal AI’s Prompt Playground. Image by Author</figcaption></figure><p id="82f8" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Once you are satisfied with a prompt version, click <strong class="no gu">Save</strong>. You will be prompted to enter a name for your prompt, and an optional description. We can add this version to our code. In a new script named <code class="cw qz ra rb rc b">search_engine.py</code>, add the following code:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="ee45" class="rg pz gt rc b bf rh ri l rj rk">#search_engine.py<br/>from literalai import LiteralClient<br/>from dotenv import load_dotenv<br/><br/>load_dotenv()<br/><br/>client = LiteralClient()<br/><br/># This will fetch the champion version, you can also pass a specific version<br/>prompt = client.api.get_prompt(name=&quot;test_prompt&quot;)<br/>prompt = prompt.to_langchain_chat_prompt_template()<br/>prompt.input_variables = [&quot;context&quot;, &quot;question&quot;]</span></pre><p id="77c1" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Literal AI allows you to save different runs of a prompt, with a version feature. You can also view how each version is different from the previous one. By default, the champion version is pulled. If you want to change a version to be the champion version, you can select it in the playground, and then click on <strong class="no gu">Promote.</strong></p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sd"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*lw4ZXIkRGo7bCCtk-1cPvQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="176" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Literal AI Prompt Versions. Image by Author</figcaption></figure><p id="6b7b" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Once the above code has been added, we will be able to view generations for specific prompts in the Literal AI Dashboard (more on this later).</p><h1 id="7376" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Understanding Chainlit’s Copilot</h1><p id="c1c0" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj"><a class="af oi" href="https://github.com/Chainlit/chainlit" rel="noopener ugc nofollow" target="_blank">Chainlit</a> is an open-source Python package designed to build production-ready conversational AI applications. It provides decorators for several events (chat start, user message, session resume, session stop, etc.). You can check out my article below for a more thorough explanation:</p><div class="pk pl pm pn po pp"><a href="https://medium.com/@tahreemrasul/building-a-chatbot-application-with-chainlit-and-langchain-3e86da0099a6?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow" target="_blank"><div class="pq ab jn"><div class="pr ab cn ca ps pt"><h2 class="be gu je z jv pu jx jy pv ka kc gs bj">Building a Chatbot Application with Chainlit and LangChain</h2><div class="pw l"><h3 class="be b je z jv pu jx jy pv ka kc dt">In this article, we will develop an application interface for our custom chatbot, Scoopsie, using Chainlit, a framework…</h3></div><div class="px l"><p class="be b du z jv pu jx jy pv ka kc dt">medium.com</p></div></div><div class="se l"><div class="sf l sg sh si se sj mt pp"></div></div></div></a></div><p id="4e83" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Specifically in this tutorial, we will focus on building a <a class="af oi" href="https://docs.chainlit.io/deployment/copilot" rel="noopener ugc nofollow" target="_blank">Software Copilot</a> for our RAG application using Chainlit. Chainlit Copilot offers contextual guidance and automated user actions within applications.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok ol"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*MU5RE5o3NYKhgYv7d9ko7g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*MU5RE5o3NYKhgYv7d9ko7g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*MU5RE5o3NYKhgYv7d9ko7g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*MU5RE5o3NYKhgYv7d9ko7g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*MU5RE5o3NYKhgYv7d9ko7g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*MU5RE5o3NYKhgYv7d9ko7g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MU5RE5o3NYKhgYv7d9ko7g.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*MU5RE5o3NYKhgYv7d9ko7g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*MU5RE5o3NYKhgYv7d9ko7g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*MU5RE5o3NYKhgYv7d9ko7g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*MU5RE5o3NYKhgYv7d9ko7g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*MU5RE5o3NYKhgYv7d9ko7g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*MU5RE5o3NYKhgYv7d9ko7g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*MU5RE5o3NYKhgYv7d9ko7g.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="525" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Research paper app schema with relevant tools. Illustration by Author.</figcaption></figure><h1 id="0fb7" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Building a Copilot</h1><p id="f119" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Embedding a copilot in your application website can be useful for several reasons. We will build a simple web interface for our semantic research paper engine, and integrate a copilot inside it. This copilot will have a few different features, but here are the most prominent ones:</p><ol class=""><li id="d5f1" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh sa pc pd bj">It will be embedded inside our website’s HTML file.</li><li id="5b68" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj">The copilot will be able to take actions on behalf of the user. Let’s say the user asks for online research papers on a specific topic. These can be displayed in a modal, and we can configure our copilot to do this automatically without needing user inputs.</li></ol><p id="d1ca" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">In the next few steps, I will detail how to create a software copilot for our semantic research engine using Chainlit.</p><h2 id="97eb" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 1</h2><p id="5619" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">The first step involves writing logic for our <code class="cw qz ra rb rc b">chainlit</code> application. We will use two <code class="cw qz ra rb rc b">chainlit</code> decorator functions for our use case: <code class="cw qz ra rb rc b">@cl.on_chat_start</code> and <code class="cw qz ra rb rc b">@cl.on_message</code>. We will add the logic from the online search and RAG pipeline to these functions. A few things to remember:</p><ul class=""><li id="c44f" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pb pc pd bj"><code class="cw qz ra rb rc b">@cl.on_chat_start</code> contains all code required to be executed at the start of a new user session.</li><li id="da11" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh pb pc pd bj"><code class="cw qz ra rb rc b">@cl.on_message</code> contains all code required to be executed when a user sends in a new message.</li></ul><p id="f0aa" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">We will encapsulate the entire process from receiving a research topic to creating a database and ingesting documents within the <code class="cw qz ra rb rc b">@cl.on_chat_start</code> decorator. In the <code class="cw qz ra rb rc b">search_engine.py</code> script, import all necessary modules and libraries:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="b622" class="rg pz gt rc b bf rh ri l rj rk"># search_engine.py<br/>import chainlit as cl<br/>from langchain_community.document_loaders import ArxivLoader<br/>from langchain_community.vectorstores import Chroma<br/>from langchain_community.embeddings import HuggingFaceEmbeddings<br/>from langchain.text_splitter import RecursiveCharacterTextSplitter<br/>from langchain.chains import RetrievalQA<br/>from langchain_openai import ChatOpenAI<br/>from dotenv import load_dotenv<br/><br/>load_dotenv()</span></pre><p id="d724" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Let’s now add the code for the <code class="cw qz ra rb rc b">@cl.on_chat_start</code> decorator. We will make this function asynchronous to ensure multiple tasks can run concurrently.</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="e26f" class="rg pz gt rc b bf rh ri l rj rk"># search_engine.py<br/># contd.<br/><br/>@cl.on_chat_start<br/>async def retrieve_docs():<br/>    # QUERY PORTION<br/>    arxiv_query = None<br/>    # Wait for the user to send in a topic<br/>    while arxiv_query is None:<br/>        arxiv_query = await cl.AskUserMessage(<br/>            content=&quot;Please enter a topic to begin!&quot;, timeout=15).send()<br/>    query = arxiv_query[&#x27;output&#x27;]<br/><br/>    # ARXIV DOCS PORTION<br/>    arxiv_docs = ArxivLoader(query=arxiv_query, load_max_docs=3).load()<br/>    # Prepare arXiv results for display<br/>    arxiv_papers = [f&quot;Published: {doc.metadata[&#x27;Published&#x27;]} \n &quot;<br/>                    f&quot;Title: {doc.metadata[&#x27;Title&#x27;]} \n &quot;<br/>                    f&quot;Authors: {doc.metadata[&#x27;Authors&#x27;]} \n &quot;<br/>                    f&quot;Summary: {doc.metadata[&#x27;Summary&#x27;][:50]}... \n---\n&quot;<br/>                    for doc in arxiv_docs]<br/><br/>    await cl.Message(content=f&quot;{arxiv_papers}&quot;).send()<br/><br/>    await cl.Message(content=f&quot;Downloading and chunking articles for {query} &quot;<br/>                             f&quot;This operation can take a while!&quot;).send()<br/><br/>    # DB PORTION<br/>    pdf_data = []<br/>    for doc in arxiv_docs:<br/>        text_splitter = RecursiveCharacterTextSplitter(<br/>                        chunk_size=1000, chunk_overlap=100)<br/>        texts = text_splitter.create_documents([doc.page_content])<br/>        pdf_data.append(texts)<br/>  <br/>    llm = ChatOpenAI(model=&#x27;gpt-3.5-turbo&#x27;,<br/>                         temperature=0)<br/>    embeddings = HuggingFaceEmbeddings(<br/>                 model_name=&quot;sentence-transformers/all-MiniLM-l6-v2&quot;)<br/>    db = Chroma.from_documents(pdf_data[0], embeddings)<br/><br/>    # CHAIN PORTION<br/>    chain = RetrievalQA.from_chain_type(llm=llm,<br/>                                            chain_type=&quot;stuff&quot;,<br/>                                            retriever=db.as_retriever(),<br/>                                            chain_type_kwargs={<br/>                                                &quot;verbose&quot;: True,<br/>                                                &quot;prompt&quot;: prompt<br/>                                            }<br/>                                            )<br/><br/>    # Let the user know that the pipeline is ready<br/>    await cl.Message(content=f&quot;Database creation for `{query}` complete. &quot;<br/>                             f&quot;You can now ask questions!&quot;).send()<br/><br/>    cl.user_session.set(&quot;chain&quot;, chain)<br/>    cl.user_session.set(&quot;db&quot;, db)</span></pre><p id="1c52" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Let’s go through the code we have wrapped in this function:</p><ol class=""><li id="a185" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh sa pc pd bj"><strong class="no gu">Prompting user query</strong>: We begin by having the user send in a research topic. This function will not proceed until the user submits a topic.</li><li id="bf57" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">Online Search: </strong>We retrieve relevant papers using LangChain’s wrapper for arXiv searches, and display the relevant fields from each entry in a readable format.</li><li id="0761" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">Ingestion: </strong>Next, we chunk the articles and create embeddings for further processing. Chunking ensures large papers are handled efficiently. Afterward, a <code class="cw qz ra rb rc b">Chroma</code> database is created from processed document chunks and embeddings.</li><li id="e613" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">Retrieval: </strong>Finally, we set up a <code class="cw qz ra rb rc b">RetrievalQA</code> chain, integrating the LLM and the newly created database as a retriever. We also provide the prompt we created earlier in our Literal AI playground.</li><li id="5ff8" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">Storing variables: </strong>We store the <code class="cw qz ra rb rc b">chain</code> and <code class="cw qz ra rb rc b">db</code> in variables using the <code class="cw qz ra rb rc b">cl.user_session.set</code> functionality for reuse later on.</li><li id="09e6" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">User messages</strong>: We use Chainlit’s <code class="cw qz ra rb rc b">cl.Message</code> functionality throughout the function to interact with the user.</li></ol><p id="b30e" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Let’s now define our <code class="cw qz ra rb rc b">@cl.on_message</code> function, and add the generation portion of our RAG pipeline. A user should be able to ask questions from the ingested papers, and the application should provide relevant answers.</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="d73e" class="rg pz gt rc b bf rh ri l rj rk">@cl.on_message<br/>async def retrieve_docs(message: cl.Message):<br/>    question = message.content<br/>    chain = cl.user_session.get(&quot;chain&quot;)<br/>    db = cl.user_session.get(&quot;db&quot;)<br/>    # Create a new instance of the callback handler for each invocation<br/>    cb = client.langchain_callback()<br/>    variables = {&quot;context&quot;: db.as_retriever(search_kwargs={&quot;k&quot;: 1}), <br/>                 &quot;query&quot;: question}<br/>    database_results = await chain.acall(variables,<br/>                                         callbacks=[cb])<br/>    results = [f&quot;Question: {question} &quot;<br/>               f&quot;\n Answer: {database_results[&#x27;result&#x27;]}&quot;]<br/>    await cl.Message(results).send()</span></pre><p id="51d9" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Here is a breakdown of the code in the function above:</p><ol class=""><li id="0f83" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh sa pc pd bj"><strong class="no gu">Chain and Database Retrieval: </strong>We first retrieve the previously stored chain and database from the user session.</li><li id="a64b" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">LangChain Callback Integration: </strong>To ensure we can track our prompt and all generations that use a particular prompt version, we need to add the LangChain callback handler from Literal AI when invoking our chain. We are creating the callback handler using the <code class="cw qz ra rb rc b">langchain_callback()</code> method from the <code class="cw qz ra rb rc b">LiteralClient</code> instance. This callback will automatically log all LangChain interactions to Literal AI.</li><li id="b1ed" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj"><strong class="no gu">Generation: </strong>We define the variables: the database as the context for retrieval and the user’s question as the query, also specifying to retrieve the top result (<code class="cw qz ra rb rc b"><strong class="no gu">k: 1</strong></code>). Finally, we call the chain with the provided variables and callback.</li></ol><h2 id="5ea3" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 2</h2><p id="fdc4" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">The second step involves embedding the copilot in our application website. We will create a simple website for demonstration. Create an <code class="cw qz ra rb rc b">index.html</code> file and add the following code to it:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="f894" class="rg pz gt rc b bf rh ri l rj rk">&lt;!DOCTYPE html&gt;<br/>&lt;html&gt;<br/>  &lt;head&gt;<br/>    &lt;title&gt;Semantic Search Engine&lt;/title&gt;<br/>  &lt;/head&gt;<br/> &lt;body&gt;<br/>   &lt;!-- ... --&gt;<br/>   &lt;script src=&quot;http://localhost:8000/copilot/index.js&quot;&gt;&lt;/script&gt;<br/>   &lt;script&gt;<br/>     window.mountChainlitWidget({<br/>       chainlitServer: &quot;http://localhost:8000&quot;,<br/>     });<br/>   &lt;/script&gt;<br/> &lt;/body&gt;</span></pre><p id="8925" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">In the code above, we have embedded the copilot inside our website by pointing to the location of the Chainlit server hosting our app. The <code class="cw qz ra rb rc b">window.mountChainlitWidget</code> adds a floating button on the bottom right corner of your website. Clicking on it will open the Copilot. To ensure our Copilot is working correctly, we need to first run our Chainlit application. Navigate inside your project directory and run:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="d279" class="rg pz gt rc b bf rh ri l rj rk">chainlit run search_engine.py -w</span></pre><p id="a539" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">The code above runs the application on <a class="af oi" href="https://localhost:8000/" rel="noopener ugc nofollow" target="_blank"><strong class="no gu">https://localhost:8000</strong></a>. Next, we need to host our application website. Opening the <code class="cw qz ra rb rc b">index.html</code> script inside a browser doesn’t work. Instead, we need to create an HTTPS testing server. You can do this in different ways, but one straightforward approach is to use <code class="cw qz ra rb rc b">npx</code>. <code class="cw qz ra rb rc b">npx</code> is included with <code class="cw qz ra rb rc b">npm</code> (Node Package Manager), which comes with Node.js. To get <code class="cw qz ra rb rc b">npx</code>, you simply need to <a class="af oi" href="https://nodejs.org/" rel="noopener ugc nofollow" target="_blank">install Node.js</a> on your system. Navigate inside your directory and run:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="f418" class="rg pz gt rc b bf rh ri l rj rk">npx http-server</span></pre><p id="3143" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Running the command above will serve our website at <a class="af oi" href="https://localhost:8080/" rel="noopener ugc nofollow" target="_blank">https://localhost:8080</a>. Navigate to the address and you will be able to see a simple web interface with the copilot embedded.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sk"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*0LaafwaQAUvI9koYCOdNzQ.gif 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*0LaafwaQAUvI9koYCOdNzQ.gif 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*0LaafwaQAUvI9koYCOdNzQ.gif 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*0LaafwaQAUvI9koYCOdNzQ.gif 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*0LaafwaQAUvI9koYCOdNzQ.gif 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*0LaafwaQAUvI9koYCOdNzQ.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0LaafwaQAUvI9koYCOdNzQ.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*0LaafwaQAUvI9koYCOdNzQ.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*0LaafwaQAUvI9koYCOdNzQ.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*0LaafwaQAUvI9koYCOdNzQ.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*0LaafwaQAUvI9koYCOdNzQ.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*0LaafwaQAUvI9koYCOdNzQ.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*0LaafwaQAUvI9koYCOdNzQ.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*0LaafwaQAUvI9koYCOdNzQ.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="428" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Launching the Copilot. Image by Author</figcaption></figure><p id="2c25" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Since we will be using the <code class="cw qz ra rb rc b">@cl.on_chat_start</code> wrapper function to welcome users, we can set the <code class="cw qz ra rb rc b">show_readme_as_default</code> to <code class="cw qz ra rb rc b">false</code> in our Chainlit config to avoid flickering. You can find your config file in your project directory at <code class="cw qz ra rb rc b">.chainlit/config.toml</code>.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sl"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*az796gnhvAxN-PYluaE7gQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*az796gnhvAxN-PYluaE7gQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*az796gnhvAxN-PYluaE7gQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*az796gnhvAxN-PYluaE7gQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*az796gnhvAxN-PYluaE7gQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*az796gnhvAxN-PYluaE7gQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*az796gnhvAxN-PYluaE7gQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*az796gnhvAxN-PYluaE7gQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*az796gnhvAxN-PYluaE7gQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*az796gnhvAxN-PYluaE7gQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*az796gnhvAxN-PYluaE7gQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*az796gnhvAxN-PYluaE7gQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*az796gnhvAxN-PYluaE7gQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*az796gnhvAxN-PYluaE7gQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="1414" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Copilot Overview. Image by Author</figcaption></figure><h2 id="fca2" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 3</h2><p id="38a4" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">To execute the code only inside the Copilot, we can add the following:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="abe4" class="rg pz gt rc b bf rh ri l rj rk">@cl.on_message<br/>async def retrieve_docs(message: cl.Message):<br/>    if cl.context.session.client_type == &quot;copilot&quot;:<br/>        # code to be executed only inside the Copilot</span></pre><p id="4efb" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Any code inside this block will only be executed when you interact with your application from within your Copilot. For example, if you run a query at the Chainlit application interface hosted at <a class="af oi" href="https://localhost:8000," rel="noopener ugc nofollow" target="_blank"><strong class="no gu">https://localhost:8000</strong>,</a> the code inside the above if block will not be executed, since it’s expecting the client type to be the Copilot. This is a helpful feature that you can use to differentiate between actions taken directly in the Chainlit application and those initiated through the Copilot interface. By doing so, you can tailor the behavior of your application based on the context of the request, allowing for a more dynamic and responsive user experience.</p><h2 id="77b5" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 4</h2><p id="9726" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">The Copilot can call functions on your website. This is useful for taking actions on behalf of the user, such as opening a modal, creating a new document, etc. We will modify our Chainlit decorator functions to include two new Copilot functions. We need to specify in the <code class="cw qz ra rb rc b">index.html</code> file how the frontend should respond when Copilot functions in our Chainlit backend application are activated. The specific reaction will vary based on the application. For our semantic research paper engine, we&#x27;ll generate pop-up notifications on the frontend whenever it&#x27;s necessary to show relevant papers or database answers in response to a user query.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sm"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*U_Exn9X-_-g5TQUbLbm8qw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*U_Exn9X-_-g5TQUbLbm8qw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*U_Exn9X-_-g5TQUbLbm8qw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*U_Exn9X-_-g5TQUbLbm8qw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*U_Exn9X-_-g5TQUbLbm8qw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*U_Exn9X-_-g5TQUbLbm8qw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U_Exn9X-_-g5TQUbLbm8qw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*U_Exn9X-_-g5TQUbLbm8qw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*U_Exn9X-_-g5TQUbLbm8qw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*U_Exn9X-_-g5TQUbLbm8qw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*U_Exn9X-_-g5TQUbLbm8qw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*U_Exn9X-_-g5TQUbLbm8qw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*U_Exn9X-_-g5TQUbLbm8qw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*U_Exn9X-_-g5TQUbLbm8qw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="486" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Popups in response to user queries in the copilot. Image by Author</figcaption></figure><p id="1142" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">We will create two Copilot functions in our application:</p><ul class=""><li id="6ff5" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pb pc pd bj"><code class="cw qz ra rb rc b">showArxivResults</code>: this function will be responsible for displaying the online results pulled by the <code class="cw qz ra rb rc b">arxiv</code> API against a user query.</li><li id="42c3" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh pb pc pd bj"><code class="cw qz ra rb rc b">showDatabaseResults</code>: this function will be responsible for displaying the results pulled from our ingested database against a user question.</li></ul><p id="acca" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">First, let’s set up the backend logic in the <code class="cw qz ra rb rc b">search_engine.py</code> script and modify the <code class="cw qz ra rb rc b">@cl.on_chat_start</code> function:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="af0f" class="rg pz gt rc b bf rh ri l rj rk">@cl.on_chat_start<br/>async def retrieve_docs():<br/>    if cl.context.session.client_type == &quot;copilot&quot;:<br/>        # same code as before<br/><br/>        # Trigger popup for arXiv results<br/>        fn_arxiv = cl.CopilotFunction(name=&quot;showArxivResults&quot;, <br/>                   args={&quot;results&quot;: &quot;\n&quot;.join(arxiv_papers)})<br/>        await fn_arxiv.acall()<br/>        <br/>        # same code as before</span></pre><p id="af1e" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">In the code above, a Copilot function named <code class="cw qz ra rb rc b">showArxivResults</code> is defined and called asynchronously. This function is designed to display the formatted list of arXiv papers directly in the Copilot interface. The function signature is quite simple: we specify the name of the function and the arguments it will send back. We will use this information in our <code class="cw qz ra rb rc b">index.html</code> file to create a popup.</p><p id="198c" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Next, we need to modify our <code class="cw qz ra rb rc b">@cl.on_message</code> function with the second Copilot function that will be executed when a user asks a question based on the ingested papers:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="399f" class="rg pz gt rc b bf rh ri l rj rk">@cl.on_message<br/>async def retrieve_docs(message: cl.Message):<br/>    if cl.context.session.client_type == &quot;copilot&quot;:<br/>        # same code as before<br/>        <br/>        # Trigger popup for database results<br/>        fn_db = cl.CopilotFunction(name=&quot;showDatabaseResults&quot;, <br/>                args={&quot;results&quot;: &quot;\n&quot;.join(results)})<br/>        await fn_db.acall()<br/>        <br/>        # same code as before</span></pre><p id="58d0" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">In the code above, we have defined the second Copilot function named <code class="cw qz ra rb rc b">showDatabaseResults</code> to be called asynchronously. This function is tasked with displaying the results retrieved from the database in the Copilot interface. The function signature specifies the name of the function and the arguments it will send back.</p><h2 id="cdce" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Step 5</h2><p id="eeb8" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">We will now edit our <code class="cw qz ra rb rc b">index.html</code> file to include the following changes:</p><ol class=""><li id="a7d2" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh sa pc pd bj">Add the two Copilot functions.</li><li id="c24b" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj">Specify what would happen on our website when either of the two Copilot functions gets triggered. We will create a popup to display results from the application backend.</li><li id="4dd4" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh sa pc pd bj">Add simple styling for popups.</li></ol><p id="ae53" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">First, we need to add the event listeners for our Copilot functions. In the <code class="cw qz ra rb rc b">&lt;script&gt;</code> tag of your <code class="cw qz ra rb rc b">index.html</code> file, add the following code:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="00d6" class="rg pz gt rc b bf rh ri l rj rk">&lt;script&gt;<br/> // previous code<br/> window.addEventListener(&quot;chainlit-call-fn&quot;, (e) =&gt; {<br/> const { name, args, callback } = e.detail;<br/> if (name === &quot;showArxivResults&quot;) {<br/>   document.getElementById(&quot;arxiv-result-text&quot;).innerHTML =<br/>     args.results.replace(/\n/g, &quot;&lt;br&gt;&quot;);<br/>   document.getElementById(&quot;popup&quot;).style.display = &quot;flex&quot;;<br/>   if (callback) callback();<br/> } else if (name === &quot;showDatabaseResults&quot;) {<br/>   document.getElementById(&quot;database-results-text&quot;).innerHTML =<br/>     args.results.replace(/\n/g, &quot;&lt;br&gt;&quot;);<br/>   document.getElementById(&quot;popup&quot;).style.display = &quot;flex&quot;;<br/>   if (callback) callback();<br/> }<br/> });<br/>&lt;/script&gt;</span></pre><p id="8402" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Here is a breakdown of the above code:</p><ul class=""><li id="ecc4" class="nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pb pc pd bj">Includes functions to show (<code class="cw qz ra rb rc b">showPopup()</code>) and hide (<code class="cw qz ra rb rc b">hidePopup()</code>) the popup modal.</li><li id="3fb2" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh pb pc pd bj">An event listener is registered for the <code class="cw qz ra rb rc b">chainlit-call-fn</code> event, which is triggered when a Copilot function (<code class="cw qz ra rb rc b">showArxivResults</code> or <code class="cw qz ra rb rc b">showDatabaseResults</code>) is called.</li><li id="604f" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh pb pc pd bj">Upon detecting an event, the listener checks the name of the Copilot function called. Depending on the function name, it updates the content of the relevant section within the popup with the results provided by the function. It replaces newline characters (<code class="cw qz ra rb rc b">\\n</code>) with HTML line breaks (<code class="cw qz ra rb rc b">&lt;br&gt;</code>) to format the text properly for HTML display.</li><li id="98ac" class="nm nn gt no b hr pe nq nr hu pf nt nu nv pg nx ny nz ph ob oc od pi of og oh pb pc pd bj">After updating the content, the popup modal is displayed (<code class="cw qz ra rb rc b">display: &quot;flex&quot;</code>), allowing the user to see the results. The modal can be hidden using the close button, which calls the <code class="cw qz ra rb rc b">hidePopup()</code> function.</li></ul><p id="a7f8" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Next, we need to define the popup modal we have specified above. We can do this by adding the following code to the <code class="cw qz ra rb rc b">&lt;body&gt;</code> tag of our <code class="cw qz ra rb rc b">index.html</code> script:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="b672" class="rg pz gt rc b bf rh ri l rj rk">&lt;div id=&quot;popup&quot; class=&quot;popup&quot;&gt;<br/> &lt;span class=&quot;close-btn&quot; onclick=&quot;hidePopup()&quot;&gt;&amp;times;&lt;/span&gt;<br/> &lt;div class=&quot;arxiv-results-wrapper&quot;&gt;<br/>   &lt;h1&gt;Arxiv Results&lt;/h1&gt;<br/>   &lt;p id=&quot;arxiv-result-text&quot;&gt;Online results will be displayed here.&lt;/p&gt;<br/> &lt;/div&gt;<br/> &lt;div class=&quot;database-results-wrapper&quot;&gt;<br/>   &lt;h1&gt;Database Results&lt;/h1&gt;<br/>   &lt;p id=&quot;database-results-text&quot;&gt;Database results will be displayed here.&lt;/p&gt;<br/> &lt;/div&gt;<br/>&lt;/div&gt;</span></pre><p id="2aea" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Let’s also add some styling for our popups. Edit the <code class="cw qz ra rb rc b">&lt;head&gt;</code> tag of the <code class="cw qz ra rb rc b">index.html</code> file:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="96fd" class="rg pz gt rc b bf rh ri l rj rk">&lt;style&gt;<br/> * {<br/>   box-sizing: border-box;<br/> }<br/> <br/> body {<br/>   font-family: sans-serif;<br/> }<br/> <br/> .close-btn {<br/>   position: absolute;<br/>   top: 10px;<br/>   right: 20px;<br/>   font-size: 24px;<br/>   cursor: pointer;<br/> }<br/> <br/> .popup {<br/>   display: none;<br/>   position: fixed;<br/>   top: 50%;<br/>   left: 50%;<br/>   transform: translate(-50%, -50%);<br/>   background-color: white;<br/>   padding: 20px;<br/>   box-shadow: rgba(99, 99, 99, 0.2) 0px 2px 8px 0px;<br/>   width: 40%;<br/>   flex-direction: column;<br/>   gap: 50px;<br/> }<br/> <br/> p {<br/>   color: #00000099;<br/> }<br/>&lt;/style&gt;</span></pre><h1 id="7e71" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Launching the Application</h1><p id="73a6" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Now that we have added our Copilot logic to our Chainlit application, we can run both our application and the website. For the Copilot to work, our application must already be running. Open a terminal inside your project directory, and run the following command to launch the Chainlit server:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="3eef" class="rg pz gt rc b bf rh ri l rj rk">chainlit run search.py -h</span></pre><p id="ed40" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">In a new terminal, launch the website using:</p><pre class="om on oo op oq rd rc re bo rf ba bj"><span id="ed4c" class="rg pz gt rc b bf rh ri l rj rk"><br/>npx http-server</span></pre><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok pj"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*mzr5PWSePHW8dNByWZFmQw.gif 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*mzr5PWSePHW8dNByWZFmQw.gif 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*mzr5PWSePHW8dNByWZFmQw.gif 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*mzr5PWSePHW8dNByWZFmQw.gif 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*mzr5PWSePHW8dNByWZFmQw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*mzr5PWSePHW8dNByWZFmQw.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mzr5PWSePHW8dNByWZFmQw.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*mzr5PWSePHW8dNByWZFmQw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*mzr5PWSePHW8dNByWZFmQw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*mzr5PWSePHW8dNByWZFmQw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*mzr5PWSePHW8dNByWZFmQw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*mzr5PWSePHW8dNByWZFmQw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*mzr5PWSePHW8dNByWZFmQw.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*mzr5PWSePHW8dNByWZFmQw.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="394" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">App Demo. By Author</figcaption></figure><h1 id="bbba" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">LLM Observability with Literal AI</h1><p id="30ce" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Integrating observability features into a production-grade application, such as our Copilot-run semantic research engine, is typically required to ensure the application’s reliability in a production environment. We will be using this with the Literal AI framework.</p><p id="90a1" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">For any Chainlit application, Literal AI automatically starts monitoring the application and sends data to the Literal AI platform. We already initiated the Literal AI client when creating our prompt in the <code class="cw qz ra rb rc b">search_engine.py</code> script. Now, each time the user interacts with our application, we will see the logs in the Literal AI dashboard.</p><h1 id="5577" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Dashboard</h1><p id="5a7a" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">Navigate to the <a class="af oi" href="https://cloud.getliteral.ai/projects/" rel="noopener ugc nofollow" target="_blank">Literal AI Dashboard</a>, select the project from the left panel, and then click on <strong class="no gu">Observability</strong>. You will see logs for the following features.</p><h2 id="1e7d" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Threads</h2><p id="4579" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">A thread represents a conversation session between an assistant and a user. You should be able to see all the conversations a user has had in the application.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sn"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*yLCUB410nsY8LmBCxRMRoA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*yLCUB410nsY8LmBCxRMRoA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*yLCUB410nsY8LmBCxRMRoA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*yLCUB410nsY8LmBCxRMRoA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*yLCUB410nsY8LmBCxRMRoA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*yLCUB410nsY8LmBCxRMRoA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yLCUB410nsY8LmBCxRMRoA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*yLCUB410nsY8LmBCxRMRoA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*yLCUB410nsY8LmBCxRMRoA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*yLCUB410nsY8LmBCxRMRoA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*yLCUB410nsY8LmBCxRMRoA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*yLCUB410nsY8LmBCxRMRoA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*yLCUB410nsY8LmBCxRMRoA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*yLCUB410nsY8LmBCxRMRoA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="213" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Literal AI Threads. Image by Author</figcaption></figure><p id="1cb9" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">Expanding on a particular conversation will give key details, such as the time each step took, details of the user message, and a tree-based view detailing all steps. You can also add a conversation to a dataset.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok so"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hCusw7T_NzpG7FMMg85HpQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*hCusw7T_NzpG7FMMg85HpQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*hCusw7T_NzpG7FMMg85HpQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*hCusw7T_NzpG7FMMg85HpQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*hCusw7T_NzpG7FMMg85HpQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hCusw7T_NzpG7FMMg85HpQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hCusw7T_NzpG7FMMg85HpQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*hCusw7T_NzpG7FMMg85HpQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*hCusw7T_NzpG7FMMg85HpQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*hCusw7T_NzpG7FMMg85HpQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*hCusw7T_NzpG7FMMg85HpQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*hCusw7T_NzpG7FMMg85HpQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*hCusw7T_NzpG7FMMg85HpQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*hCusw7T_NzpG7FMMg85HpQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="465" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Literal AI Thread Overview. Image by Author</figcaption></figure><h2 id="b59f" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Runs</h2><p id="9390" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">A run is a sequence of steps taken by an agent or a chain. This gives details of all steps taken each time a chain or agent is executed. With this tab, we get both the input and the output for each user query.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sp"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*EqWQgjLQQxrDqbySuF6YJQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*EqWQgjLQQxrDqbySuF6YJQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*EqWQgjLQQxrDqbySuF6YJQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*EqWQgjLQQxrDqbySuF6YJQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*EqWQgjLQQxrDqbySuF6YJQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*EqWQgjLQQxrDqbySuF6YJQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EqWQgjLQQxrDqbySuF6YJQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*EqWQgjLQQxrDqbySuF6YJQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*EqWQgjLQQxrDqbySuF6YJQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*EqWQgjLQQxrDqbySuF6YJQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*EqWQgjLQQxrDqbySuF6YJQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*EqWQgjLQQxrDqbySuF6YJQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*EqWQgjLQQxrDqbySuF6YJQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*EqWQgjLQQxrDqbySuF6YJQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="261" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Literal AI Runs Dashboard. Image by Author</figcaption></figure><p id="27c3" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">You can expand on a run, and this will give further details. Once again, you can add this info to a dataset.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sq"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*e3DoFWyDjX1G1QyS618N2Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*e3DoFWyDjX1G1QyS618N2Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*e3DoFWyDjX1G1QyS618N2Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*e3DoFWyDjX1G1QyS618N2Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*e3DoFWyDjX1G1QyS618N2Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*e3DoFWyDjX1G1QyS618N2Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e3DoFWyDjX1G1QyS618N2Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*e3DoFWyDjX1G1QyS618N2Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*e3DoFWyDjX1G1QyS618N2Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*e3DoFWyDjX1G1QyS618N2Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*e3DoFWyDjX1G1QyS618N2Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*e3DoFWyDjX1G1QyS618N2Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*e3DoFWyDjX1G1QyS618N2Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*e3DoFWyDjX1G1QyS618N2Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="281" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Literal AI Run Overview. Image by Author</figcaption></figure><h2 id="8ac8" class="rl pz gt be qa rm rn dx qd ro rp dz qg nv rq rr rs nz rt ru rv od rw rx ry rz bj">Generations</h2><p id="bee3" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">A generation contains both the input sent to an LLM and its completion. This gives key details including the model used for a completion, the token count, as well as the user requesting the completion, if you have configured multiple user sessions.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok sr"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*_jbmHk9Md9LTmelnoodTuQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*_jbmHk9Md9LTmelnoodTuQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*_jbmHk9Md9LTmelnoodTuQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*_jbmHk9Md9LTmelnoodTuQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*_jbmHk9Md9LTmelnoodTuQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*_jbmHk9Md9LTmelnoodTuQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_jbmHk9Md9LTmelnoodTuQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*_jbmHk9Md9LTmelnoodTuQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*_jbmHk9Md9LTmelnoodTuQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*_jbmHk9Md9LTmelnoodTuQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*_jbmHk9Md9LTmelnoodTuQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*_jbmHk9Md9LTmelnoodTuQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*_jbmHk9Md9LTmelnoodTuQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_jbmHk9Md9LTmelnoodTuQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="400" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Literal AI Generations Overview. Image by Author</figcaption></figure><h1 id="311d" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Prompts Evaluation in Literal AI</h1><p id="b4cb" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">We can track generations and threads against each prompt created and used in the application code since we added LangChain integrations. Therefore, each time the chain is invoked for a user query, logs are added against it in the Literal AI dashboard. This is helpful to see which prompts were responsible for a particular generation, and compare performance for different versions.</p><figure class="om on oo op oq or oj ok paragraph-image"><div role="button" tabindex="0" class="os ot fi ou bg ov"><div class="oj ok ss"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*IBe_ITfKPlt3Yng-NpqqGg.gif 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*IBe_ITfKPlt3Yng-NpqqGg.gif 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*IBe_ITfKPlt3Yng-NpqqGg.gif 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*IBe_ITfKPlt3Yng-NpqqGg.gif 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*IBe_ITfKPlt3Yng-NpqqGg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IBe_ITfKPlt3Yng-NpqqGg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IBe_ITfKPlt3Yng-NpqqGg.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*IBe_ITfKPlt3Yng-NpqqGg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*IBe_ITfKPlt3Yng-NpqqGg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*IBe_ITfKPlt3Yng-NpqqGg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*IBe_ITfKPlt3Yng-NpqqGg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*IBe_ITfKPlt3Yng-NpqqGg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*IBe_ITfKPlt3Yng-NpqqGg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*IBe_ITfKPlt3Yng-NpqqGg.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mt ow c" width="700" height="416" loading="lazy" role="presentation"/></picture></div></div><figcaption class="ox fe oy oj ok oz pa be b bf z dt">Copilot integrated semantic research engine app with observability features. Image by Author</figcaption></figure><h1 id="fd84" class="py pz gt be qa qb qc ht qd qe qf hw qg qh qi qj qk ql qm qn qo qp qq qr qs qt bj">Conclusion</h1><p id="fc63" class="pw-post-body-paragraph nm nn gt no b hr qu nq nr hu qv nt nu nv qw nx ny nz qx ob oc od qy of og oh gm bj">In this tutorial, I demonstrated how to create a semantic research paper engine using RAG features with LangChain, OpenAI, and ChromaDB. Additionally, I showed how to develop a web app for this engine, integrating Copilot and observability features from Literal AI. Incorporating evaluation and observability is generally required for ensuring optimal performance in real-world language model applications. Furthermore, the Copilot can be an extremely useful feature for different software applications, and this tutorial can be a good starting point to understand how to set it up for your application.</p><p id="4469" class="pw-post-body-paragraph nm nn gt no b hr np nq nr hu ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gm bj">You can find the code from this tutorial on my <a class="af oi" href="https://github.com/tahreemrasul/semantic_research_engine" rel="noopener ugc nofollow" target="_blank">GitHub</a>. If you found this tutorial helpful, consider supporting by giving it fifty claps. You can <a class="af oi" href="/@tahreemrasul" rel="noopener ugc nofollow" target="_blank">follow along</a> as I share working demos, explanations and cool side projects on things in the AI space. Come say hi on <a class="af oi" href="https://www.linkedin.com/in/tahreem-r-20b7b8218/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> and <a class="af oi" href="https://twitter.com/tahreemrasul1" rel="noopener ugc nofollow" target="_blank">X</a>! I share guides, code snippets and other useful content there. 👋</p></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg fy fz ga gb"></div></div></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="st su ab jq"><div class="pw ab"><a class="sv ax am ao" href="https://medium.com/tag/retrieval-augmented-gen?source=post_page-----9c345fcd1cd8---------------retrieval_augmented_gen-----------------" rel="noopener follow"><div class="sw fi cw sx gd sy sz be b bf z bj ta">Retrieval Augmented Gen</div></a></div><div class="pw ab"><a class="sv ax am ao" href="https://medium.com/tag/langchain?source=post_page-----9c345fcd1cd8---------------langchain-----------------" rel="noopener follow"><div class="sw fi cw sx gd sy sz be b bf z bj ta">Langchain</div></a></div><div class="pw ab"><a class="sv ax am ao" href="https://medium.com/tag/llm-evaluation?source=post_page-----9c345fcd1cd8---------------llm_evaluation-----------------" rel="noopener follow"><div class="sw fi cw sx gd sy sz be b bf z bj ta">Llm Evaluation</div></a></div><div class="pw ab"><a class="sv ax am ao" href="https://medium.com/tag/llmops?source=post_page-----9c345fcd1cd8---------------llmops-----------------" rel="noopener follow"><div class="sw fi cw sx gd sy sz be b bf z bj ta">Llmops</div></a></div><div class="pw ab"><a class="sv ax am ao" href="https://medium.com/tag/hands-on-tutorials?source=post_page-----9c345fcd1cd8---------------hands_on_tutorials-----------------" rel="noopener follow"><div class="sw fi cw sx gd sy sz be b bf z bj ta">Hands On Tutorials</div></a></div></div></div></div><div class="l"></div><footer class="tb tc td te tf tg th ti tj ab q tk ja c"><div class="l ae"><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="ab co tl"><div class="ab q ll"><div class="tm l"><span class="l tn to tp e d"><div class="ab q ll lm"><div class="pw-multi-vote-icon fi ju ln lo lp"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c345fcd1cd8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;user=Tahreem+Rasul&amp;userId=795f7e79f0ce&amp;source=-----9c345fcd1cd8---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="lq ao lr ls lt lu am lv lw lx lp"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l ly lz ma mb mc md me"><p class="be b du z dt"><span class="mf">--</span></p></div></div></span><span class="l h g f tq tr"><div class="ab q ll lm"><div class="pw-multi-vote-icon fi ju ln lo lp"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c345fcd1cd8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;user=Tahreem+Rasul&amp;userId=795f7e79f0ce&amp;source=-----9c345fcd1cd8---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="lq ao lr ls lt lu am lv lw lx lp"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l ly lz ma mb mc md me"><p class="be b du z dt"><span class="mf">--</span></p></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false"><button class="ao lq mg mh ab q fj mi mj" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="mk"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></button></div></div></div></div><div class="ab q"><div class="ts l jn"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c345fcd1cd8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt mm" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div><div class="ts l jn"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fj ah ai aj ak al mu an ao ap ew mv mw mj mx"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="tt tu tv tw tx l bw"><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="ck ab ty co"><div class="ab iq"><a href="https://medium.com/@tahreemrasul?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><div class="l tz ua bx ub iu"><div class="l fi"><img alt="Tahreem Rasul" class="l fc bx uc ud cw" src="https://miro.medium.com/v2/resize:fill:144:144/1*whixGo6nrkNkKhlYSE9UUw.jpeg" width="72" height="72" loading="lazy"/><div class="iv bx l uc ud fr n iw fs"></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><div class="ue ab fi"><div><div class="bl" aria-hidden="false"><div class="l uf ug bx ub ja"><div class="l fi"><img alt="Towards Data Science" class="l fc bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="32" height="32" loading="lazy"/><div class="iv bx l by bz fr n iw fs"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><span><a class="be b bf z eo sw ep eq er es et eu ev ew ex ey ez uh fa fb fc bl fd fe" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F795f7e79f0ce&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;user=Tahreem+Rasul&amp;userId=795f7e79f0ce&amp;source=post_page-795f7e79f0ce----9c345fcd1cd8---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8effe3fa1b23&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;newsletterV3=795f7e79f0ce&amp;newsletterV3Id=8effe3fa1b23&amp;user=Tahreem+Rasul&amp;userId=795f7e79f0ce&amp;source=-----9c345fcd1cd8---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z uj am uk ul um un uo up uq ur ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="ui ug uf"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@tahreemrasul?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><h2 class="pw-author-name be us ut uu uv bj"><span class="gm">Written by <!-- -->Tahreem Rasul</span></h2></a></div><div class="pw ab"><div class="l jn"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar jg" href="https://medium.com/@tahreemrasul/followers?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow">330 Followers</a></span></div><div class="be b bf z jv jw jx ab jz ka kb kc dt jt"><span class="jh l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span class="l jn">Writer for </span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jg ab q" href="https://towardsdatascience.com/?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b bf z jv jw jx jy jz ka kb kc bj">Towards Data Science</p></a></div></div></div></div><div class="uw l"><p class="be b bf z bj">ML Engineer. I am interested in talking about all things in the AI space, specifically language and vision models. <a class="af ag ah ai aj ak al am an ao ap aq ar oi gn" href="https://linktr.ee/tahreemrasul" rel="noopener  ugc nofollow">https://linktr.ee/tahreemrasul</a></p></div></div><div class="h k"><div class="ab"><span><a class="be b bf z eo sw ep eq er es et eu ev ew ex ey ez uh fa fb fc bl fd fe" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F795f7e79f0ce&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;user=Tahreem+Rasul&amp;userId=795f7e79f0ce&amp;source=post_page-795f7e79f0ce----9c345fcd1cd8---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8effe3fa1b23&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&amp;newsletterV3=795f7e79f0ce&amp;newsletterV3Id=8effe3fa1b23&amp;user=Tahreem+Rasul&amp;userId=795f7e79f0ce&amp;source=-----9c345fcd1cd8---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z uj am uk ul um un uo up uq ur ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="ui ug uf"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ux bg uy uz va vb vc vd"></div></div></div><div class="h k j"><div class="ux bg uy ve"></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="vf ab ll jq"><div class="vg vh l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">Help</p></a></div><div class="vg vh l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">Status</p></a></div><div class="vg vh l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">About</p></a></div><div class="vg vh l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">Careers</p></a></div><div class="vg vh l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">Blog</p></a></div><div class="vg vh l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">Privacy</p></a></div><div class="vg vh l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">Terms</p></a></div><div class="vg vh l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">Text to speech</p></a></div><div class="vg l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----9c345fcd1cd8--------------------------------" rel="noopener follow"><p class="be b du z dt">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20240514-224200-6797c1ec8c"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"This request is not using the cache middleware worker","group":"disabled","tags":["group-edgeCachePosts","post-9c345fcd1cd8","user-795f7e79f0ce","collection-7f60cf5620c9"],"serverVariantState":"","middlewareEnabled":false,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[],"updatedPostPreviewsEnabled":false,"enableLohpEditorEntry":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"03e9e7bc-16f6-4fba-ae8d-dbf4f137088d","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"3fa3543d491fa861","ot-tracer-traceid":"48149726d0ff2452","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"https:\u002F\u002Fwww.google.com","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"config":{"nodeEnv":"production","version":"main-20240514-224200-6797c1ec8c","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20240514-224200-6797c1ec8c","commit":"6797c1ec8c26f801c9f3e7f36ebe7fb570d5fd0e"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"isLoggedIn":false,"variantFlags":[{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_yearly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound-source-serif-pro"}},{"__typename":"VariantFlag","name":"android_enable_friend_links_creation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"onboarding_tags_from_top_views","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_premium_tier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"android_enable_topic_portals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_aggregator_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"rex_generator_max_candidates","valueType":{"__typename":"VariantFlagNumber"}},{"__typename":"VariantFlag","name":"ios_display_paywall_after_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pre_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mps_pp_writer_stats","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_two_hour_refresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members_username_selection","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_spam_buster","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_ios_easy_resubscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_friend_links_postpage_banners","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_members_only_audio","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recaptcha_enterprise","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_redesign_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_verified_book_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_lists_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_switch_plan_premium_tier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_fs_cache_user_vals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_autorefresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_receive_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_remove_twitter_onboarding_step","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_friend_links_postpage_banners","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_programming_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lohp_focused","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"enable_android_verified_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_widget","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_dashboard_referred_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_image_sharer","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_new_user_onboarding_emails_flow","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sharer_validate_post_share_key","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_monthly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"redefined_top_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_syntax_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_premium_tier_badge","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_stripe_customers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"crm_send_contact_to_sendgrid","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_deprecate_legacy_providers_v3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_bg_post_post","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recirc_model","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_miro_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_follow_on_subscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_entities_to_follow_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_eventstats_event_processing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_premium_plan","valueType":{"__typename":"VariantFlagString","value":"4a442ace1476"}},{"__typename":"VariantFlag","name":"available_monthly_premium_plan","valueType":{"__typename":"VariantFlagString","value":"12a660186432"}},{"__typename":"VariantFlag","name":"can_send_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sharer_create_post_share_key","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_friend_links_creation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"textshots_userid","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sprig","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mobile_lohp_short_hero","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_rex_new_push_notification_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_rating_prompt_stories_read_threshold","valueType":{"__typename":"VariantFlagNumber"}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_aspiriational","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cache_less_following_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_diversification_rex","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_moc_load_processor_c","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reengagement_notification_duration","valueType":{"__typename":"VariantFlagNumber"}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_archive_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_redesign_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_play_purchase_on_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_maim_the_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_new_user_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_expired_membership_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_simplified_digest_v2_b","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_verifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_programming","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lohp_with_search","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_mastodon_avatar_upload","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_editor_new_publishing_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"web_enable_syntax_highlighting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"9c345fcd1cd8\"})":{"__ref":"Post:9c345fcd1cd8"}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:7e12c71dfa81"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:e6ad8abedec9"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:895063a310f4"}}],"name":"Towards Data Science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"domain":"towardsdatascience.com","slug":"towards-data-science","description":"Your home for data science. A Medium publication sharing concepts, ideas and codes.","subscriberCount":690041,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_b49173192da9"},"twitterUsername":"TDataScience","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"User:7e12c71dfa81":{"__typename":"User","id":"7e12c71dfa81"},"User:e6ad8abedec9":{"__typename":"User","id":"e6ad8abedec9"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4"},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"LinkedAccounts:795f7e79f0ce":{"__typename":"LinkedAccounts","mastodon":null,"id":"795f7e79f0ce"},"UserViewerEdge:userId:795f7e79f0ce-viewerId:lo_b49173192da9":{"__typename":"UserViewerEdge","id":"userId:795f7e79f0ce-viewerId:lo_b49173192da9","isFollowing":false,"isUser":false,"isMuting":false},"NewsletterV3:8effe3fa1b23":{"__typename":"NewsletterV3","id":"8effe3fa1b23","type":"NEWSLETTER_TYPE_AUTHOR","slug":"795f7e79f0ce","name":"795f7e79f0ce","collection":null,"user":{"__ref":"User:795f7e79f0ce"}},"User:795f7e79f0ce":{"__typename":"User","id":"795f7e79f0ce","name":"Tahreem Rasul","username":"tahreemrasul","newsletterV3":{"__ref":"NewsletterV3:8effe3fa1b23"},"linkedAccounts":{"__ref":"LinkedAccounts:795f7e79f0ce"},"isSuspended":false,"imageId":"1*whixGo6nrkNkKhlYSE9UUw.jpeg","mediumMemberAt":1713263842000,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":330},"customDomainState":null,"hasSubdomain":false,"bio":"ML Engineer. I am interested in talking about all things in the AI space, specifically language and vision models. https:\u002F\u002Flinktr.ee\u002Ftahreemrasul","isPartnerProgramEnrolled":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:795f7e79f0ce-viewerId:lo_b49173192da9"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"membership":{"__ref":"Membership:ff4137682f0f"},"twitterScreenName":"tahreemrasul1"},"Topic:1eca0103fff3":{"__typename":"Topic","slug":"machine-learning","id":"1eca0103fff3","name":"Machine Learning"},"Paragraph:7341d75fdf96_0":{"__typename":"Paragraph","id":"7341d75fdf96_0","name":"8e26","type":"H3","href":null,"layout":null,"metadata":null,"text":"Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_1":{"__typename":"Paragraph","id":"7341d75fdf96_1","name":"7c56","type":"H4","href":null,"layout":null,"metadata":null,"text":"A tutorial on building a semantic paper engine using RAG with LangChain, Chainlit copilot apps, and Literal AI observability.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_2":{"__typename":"Paragraph","id":"7341d75fdf96_2","name":"2e86","type":"P","href":null,"layout":null,"metadata":null,"text":"In this guide, I’ll demonstrate how to build a semantic research paper engine using Retrieval Augmented Generation (RAG). I’ll utilize LangChain as the main framework for building our semantic engine, along-with OpenAI’s language model and Chroma DB’s vector database. For building the Copilot embedded web application, I’ll use Chainlit’s Copilot feature and incorporate observability features from Literal AI. This tool can facilitate academic research by making it easier to find relevant papers. Users will also be able to interact directly with the content by asking questions about the recommended papers. Lastly, we will integrate observability features in the application to track and debug calls to the LLM.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":135,"end":144,"href":"https:\u002F\u002Fwww.langchain.com","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":212,"end":220,"href":"https:\u002F\u002Fopenai.com","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":240,"end":251,"href":"https:\u002F\u002Fwww.trychroma.com","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":329,"end":339,"href":"https:\u002F\u002Fdocs.chainlit.io\u002Fget-started\u002Foverview","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":400,"end":410,"href":"https:\u002F\u002Fliteralai.com","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*GUoz9w5z8FLzXHmQUarXyg.png":{"__typename":"ImageMetadata","id":"1*GUoz9w5z8FLzXHmQUarXyg.png","originalHeight":768,"originalWidth":1024,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_3":{"__typename":"Paragraph","id":"7341d75fdf96_3","name":"5f7f","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*GUoz9w5z8FLzXHmQUarXyg.png"},"text":"App Schema for Copilot-embedded semantic research paper application. Illustration by Author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_4":{"__typename":"Paragraph","id":"7341d75fdf96_4","name":"5f23","type":"P","href":null,"layout":null,"metadata":null,"text":"Here is an overview of everything we will cover in this tutorial:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_5":{"__typename":"Paragraph","id":"7341d75fdf96_5","name":"4334","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Develop a RAG pipeline with OpenAI, LangChain and Chroma DB to process and retrieve the most relevant PDF documents from the arXiv API.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_6":{"__typename":"Paragraph","id":"7341d75fdf96_6","name":"8389","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Develop a Chainlit application with a Copilot for online paper retrieval.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_7":{"__typename":"Paragraph","id":"7341d75fdf96_7","name":"ca27","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Enhance the application with LLM observability features with Literal AI.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*jtr_Sbj0Dt7nIBV2JAesuA.gif":{"__typename":"ImageMetadata","id":"1*jtr_Sbj0Dt7nIBV2JAesuA.gif","originalHeight":1080,"originalWidth":1920,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_8":{"__typename":"Paragraph","id":"7341d75fdf96_8","name":"b2c6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*jtr_Sbj0Dt7nIBV2JAesuA.gif"},"text":"Copilot-embedded semantic research paper application in action. By Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_9":{"__typename":"Paragraph","id":"7341d75fdf96_9","name":"8b89","type":"P","href":null,"layout":null,"metadata":null,"text":"Code for this tutorial can be found in this GitHub repo:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":39,"end":55,"href":"https:\u002F\u002Fgithub.com\u002Ftahreemrasul\u002Fsemantic_research_engine","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_10":{"__typename":"Paragraph","id":"7341d75fdf96_10","name":"e2e6","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"GitHub - tahreemrasul\u002Fsemantic_research_engine: A semantic research engine to get relevant papers…\nA semantic research engine to get relevant papers based on a user query. Application frontend with Chainlit Copilot…github.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":225,"href":"https:\u002F\u002Fgithub.com\u002Ftahreemrasul\u002Fsemantic_research_engine","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":98,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":99,"end":215,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fgithub.com\u002Ftahreemrasul\u002Fsemantic_research_engine","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":""}},"Paragraph:7341d75fdf96_11":{"__typename":"Paragraph","id":"7341d75fdf96_11","name":"0596","type":"H3","href":null,"layout":null,"metadata":null,"text":"Environment Setup","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_12":{"__typename":"Paragraph","id":"7341d75fdf96_12","name":"f123","type":"P","href":null,"layout":null,"metadata":null,"text":"Create a new conda environment:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":13,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_13":{"__typename":"Paragraph","id":"7341d75fdf96_13","name":"47a5","type":"PRE","href":null,"layout":null,"metadata":null,"text":"conda create -n semantic_research_engine python=3.10","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_14":{"__typename":"Paragraph","id":"7341d75fdf96_14","name":"643c","type":"P","href":null,"layout":null,"metadata":null,"text":"Activate the environment:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_15":{"__typename":"Paragraph","id":"7341d75fdf96_15","name":"d451","type":"PRE","href":null,"layout":null,"metadata":null,"text":"conda activate semantic_research_engine","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_16":{"__typename":"Paragraph","id":"7341d75fdf96_16","name":"b6dc","type":"P","href":null,"layout":null,"metadata":null,"text":"Install all required dependencies in your activated environment by running the following command:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_17":{"__typename":"Paragraph","id":"7341d75fdf96_17","name":"ab2f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"pip install -r requirements.txt","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_18":{"__typename":"Paragraph","id":"7341d75fdf96_18","name":"631b","type":"H3","href":null,"layout":null,"metadata":null,"text":"RAG Pipeline Creation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_19":{"__typename":"Paragraph","id":"7341d75fdf96_19","name":"1e99","type":"P","href":null,"layout":null,"metadata":null,"text":"Retrieval Augmented Generation (RAG) is a popular technique that allows you to build custom conversational AI applications with your own data. The principle of RAG is fairly simple: we convert our textual data into vector embeddings and insert these into a vector database. This database is then linked to a large language model (LLM). We are constraining our LLM to get information from our own database instead of relying on prior knowledge to answer user queries. In the next few steps, I will detail how to do this for our semantic research paper engine. We will create a test script named rag_test.py to understand and build the components for our RAG pipeline. These will be reused when building our Copilot integrated Chainlit application.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":594,"end":605,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_20":{"__typename":"Paragraph","id":"7341d75fdf96_20","name":"2b04","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 1","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_21":{"__typename":"Paragraph","id":"7341d75fdf96_21","name":"adeb","type":"P","href":null,"layout":null,"metadata":null,"text":"Secure an OpenAI API key by registering an account. Once done, create a .env file in your project directory and add your OpenAI API key as follows:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":72,"end":76,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_22":{"__typename":"Paragraph","id":"7341d75fdf96_22","name":"72dc","type":"PRE","href":null,"layout":null,"metadata":null,"text":"OPENAI_API_KEY=\"your_openai_api_key\"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"ini"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_23":{"__typename":"Paragraph","id":"7341d75fdf96_23","name":"db72","type":"P","href":null,"layout":null,"metadata":null,"text":"This .env will house all of our API keys for the project.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":5,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_24":{"__typename":"Paragraph","id":"7341d75fdf96_24","name":"ae7a","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 2: Ingestion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_25":{"__typename":"Paragraph","id":"7341d75fdf96_25","name":"28bc","type":"P","href":null,"layout":null,"metadata":null,"text":"In this step, we will create a database to store the research papers for a given user query. To do this, we first need to retrieve a list of relevant papers from the arXiv API for the query. We will be using the ArxivLoader() package from LangChain as it abstracts API interactions, and retrieves the papers for further processing. We can split these papers into smaller chunks to ensure efficient processing and relevant information retrieval later on. To do this, we will use the RecursiveTextSplitter() from LangChain, since it ensures semantic preservation of information while splitting documents. Next, we will create embeddings for these chunks using the sentence-transformers embeddings from HuggingFace. Finally, we will ingest these split document embeddings into a Chroma DB database for further querying.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":212,"end":225,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":482,"end":505,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":662,"end":683,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":700,"end":711,"href":"https:\u002F\u002Fpython.langchain.com\u002Fdocs\u002Fintegrations\u002Fplatforms\u002Fhuggingface\u002F#embedding-models","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_26":{"__typename":"Paragraph","id":"7341d75fdf96_26","name":"22e8","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# rag_test.py \nfrom langchain_community.document_loaders import ArxivLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\nquery = \"lightweight transformer for language tasks\"\narxiv_docs = ArxivLoader(query=query, load_max_docs=3).load()\npdf_data = []\nfor doc in arxiv_docs:\n    text_splitter = RecursiveCharacterTextSplitter(\n                    chunk_size=1000,\n                    chunk_overlap=100)\n    texts = text_splitter.create_documents([doc.page_content])\n    pdf_data.append(texts)\n\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers\u002Fall-MiniLM-l6-v2\")\ndb = Chroma.from_documents(pdf_data[0], embeddings)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_27":{"__typename":"Paragraph","id":"7341d75fdf96_27","name":"76c8","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 3: Retrieval and Generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_28":{"__typename":"Paragraph","id":"7341d75fdf96_28","name":"ba08","type":"P","href":null,"layout":null,"metadata":null,"text":"Once the database for a particular topic has been created, we can use this database as a retriever to answer user questions based on the provided context. LangChain offers a few different chains for retrieval, the simplest being the RetrievalQA chain that we will use in this tutorial. We will set it up using the from_chain_type() method, specifying the model and the retriever. For document integration into the LLM, we’ll use the stuff chain type, as it stuffs all documents into a single prompt.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":233,"end":244,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":314,"end":331,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":433,"end":438,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_29":{"__typename":"Paragraph","id":"7341d75fdf96_29","name":"8fb6","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# rag_test.py\nfrom langchain.chains import RetrievalQA\nfrom langchain_openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\nllm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\nqa = RetrievalQA.from_chain_type(llm=llm, \n                                 chain_type=\"stuff\", \n                                 retriever=db.as_retriever())\n\nquestion = \"how many and which benchmark datasets and tasks were \n            compared for light weight transformer?\"\nresult = qa({\"query\": question})","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_30":{"__typename":"Paragraph","id":"7341d75fdf96_30","name":"cdcb","type":"P","href":null,"layout":null,"metadata":null,"text":"Now that we have covered online retrieval from the arXiv API and the ingestion and retrieval steps for our RAG pipeline, we are ready to develop the web application for our semantic research engine.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_31":{"__typename":"Paragraph","id":"7341d75fdf96_31","name":"270d","type":"H3","href":null,"layout":null,"metadata":null,"text":"Understanding Literal AI","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_32":{"__typename":"Paragraph","id":"7341d75fdf96_32","name":"25d8","type":"P","href":null,"layout":null,"metadata":null,"text":"Literal AI is an observability, evaluation and analytics platform for building production-grade LLM apps. Some key features offered by Literal AI include:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":10,"href":"https:\u002F\u002Fliteralai.com","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_33":{"__typename":"Paragraph","id":"7341d75fdf96_33","name":"9128","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Observability: enables monitoring of LLM apps, including conversations, intermediary steps, prompts, etc.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_34":{"__typename":"Paragraph","id":"7341d75fdf96_34","name":"ad29","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Datasets: allows creation of datasets mixing production data and hand written examples.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_35":{"__typename":"Paragraph","id":"7341d75fdf96_35","name":"489c","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Online Evals: enables evaluation of threads and execution in production using different evaluators.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_36":{"__typename":"Paragraph","id":"7341d75fdf96_36","name":"36d4","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Prompt Playground: allows iteration, versioning, and deployment of prompts.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_37":{"__typename":"Paragraph","id":"7341d75fdf96_37","name":"aa21","type":"P","href":null,"layout":null,"metadata":null,"text":"We will use the observability and prompt iteration features to evaluate and debug the calls made with our semantic research paper app.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_38":{"__typename":"Paragraph","id":"7341d75fdf96_38","name":"dd0f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Prompt Playground with Literal AI","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_39":{"__typename":"Paragraph","id":"7341d75fdf96_39","name":"e429","type":"P","href":null,"layout":null,"metadata":null,"text":"When creating conversational AI applications, developers need to iterate through multiple versions of a prompt to get to the one that generates the best results. Prompt engineering plays a crucial role in most LLM tasks, as minor modifications can significantly alter the responses from a language model. Literal AI’s prompt playground can be used to streamline this process. Once you select the model provider, you can input your initial prompt template, add any additional information, and iteratively refine the prompts to find the most suitable one. In the next few steps, we will be using this playground to find the best prompt for our application.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_40":{"__typename":"Paragraph","id":"7341d75fdf96_40","name":"e58d","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 1","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_41":{"__typename":"Paragraph","id":"7341d75fdf96_41","name":"db5f","type":"P","href":null,"layout":null,"metadata":null,"text":"Create an API key by navigating to the Literal AI Dashboard. Register an account, navigate to the projects page, and create a new project. Each project comes with its unique API key. On the Settings tab, you will find your API key in the API Key section. Add it to your .env file:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":270,"end":274,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":39,"end":59,"href":"https:\u002F\u002Fcloud.getliteral.ai\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":98,"end":106,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":190,"end":198,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":238,"end":245,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_42":{"__typename":"Paragraph","id":"7341d75fdf96_42","name":"3b86","type":"PRE","href":null,"layout":null,"metadata":null,"text":"LITERAL_API_KEY=\"your_literal_api_key\"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"ini"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_43":{"__typename":"Paragraph","id":"7341d75fdf96_43","name":"2cd9","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 2","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_44":{"__typename":"Paragraph","id":"7341d75fdf96_44","name":"022e","type":"P","href":null,"layout":null,"metadata":null,"text":"In the left sidebar, click Prompts, and then navigate to New Prompt. This should open a new prompt creation session.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":27,"end":35,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":57,"end":68,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*Cpr1rSci_IWLv5gNOoT_Cg.png":{"__typename":"ImageMetadata","id":"1*Cpr1rSci_IWLv5gNOoT_Cg.png","originalHeight":850,"originalWidth":3298,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_45":{"__typename":"Paragraph","id":"7341d75fdf96_45","name":"3303","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*Cpr1rSci_IWLv5gNOoT_Cg.png"},"text":"Literal AI Prompts Dashboard. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_46":{"__typename":"Paragraph","id":"7341d75fdf96_46","name":"4518","type":"P","href":null,"layout":null,"metadata":null,"text":"Once inside the playground, on the left sidebar, add a new System message in the Template section. Anything in parenthesis will be added to the Variables, and treated as input in the prompt:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":59,"end":65,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":81,"end":89,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":144,"end":155,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_47":{"__typename":"Paragraph","id":"7341d75fdf96_47","name":"60e8","type":"PRE","href":null,"layout":null,"metadata":null,"text":"You are a helpful assistant. Use provided {{context}} to answer user \n{{question}}. Do not use prior knowledge. \nAnswer:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_48":{"__typename":"Paragraph","id":"7341d75fdf96_48","name":"6451","type":"P","href":null,"layout":null,"metadata":null,"text":"In the right sidebar, you can provide your OpenAI API Key. Select parameters such as the Model, Temperature, and Maximum Length for completion to play around with the prompt.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":89,"end":94,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":96,"end":107,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":113,"end":128,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*vbuEXySvfaAJiO8SaHdrIA.png":{"__typename":"ImageMetadata","id":"1*vbuEXySvfaAJiO8SaHdrIA.png","originalHeight":1920,"originalWidth":3358,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_49":{"__typename":"Paragraph","id":"7341d75fdf96_49","name":"4561","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*vbuEXySvfaAJiO8SaHdrIA.png"},"text":"Literal AI’s Prompt Playground. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_50":{"__typename":"Paragraph","id":"7341d75fdf96_50","name":"82f8","type":"P","href":null,"layout":null,"metadata":null,"text":"Once you are satisfied with a prompt version, click Save. You will be prompted to enter a name for your prompt, and an optional description. We can add this version to our code. In a new script named search_engine.py, add the following code:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":200,"end":216,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":52,"end":56,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_51":{"__typename":"Paragraph","id":"7341d75fdf96_51","name":"ee45","type":"PRE","href":null,"layout":null,"metadata":null,"text":"#search_engine.py\nfrom literalai import LiteralClient\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = LiteralClient()\n\n# This will fetch the champion version, you can also pass a specific version\nprompt = client.api.get_prompt(name=\"test_prompt\")\nprompt = prompt.to_langchain_chat_prompt_template()\nprompt.input_variables = [\"context\", \"question\"]","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_52":{"__typename":"Paragraph","id":"7341d75fdf96_52","name":"77c1","type":"P","href":null,"layout":null,"metadata":null,"text":"Literal AI allows you to save different runs of a prompt, with a version feature. You can also view how each version is different from the previous one. By default, the champion version is pulled. If you want to change a version to be the champion version, you can select it in the playground, and then click on Promote.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":312,"end":320,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*lw4ZXIkRGo7bCCtk-1cPvQ.png":{"__typename":"ImageMetadata","id":"1*lw4ZXIkRGo7bCCtk-1cPvQ.png","originalHeight":626,"originalWidth":2500,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_53":{"__typename":"Paragraph","id":"7341d75fdf96_53","name":"811d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*lw4ZXIkRGo7bCCtk-1cPvQ.png"},"text":"Literal AI Prompt Versions. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_54":{"__typename":"Paragraph","id":"7341d75fdf96_54","name":"6b7b","type":"P","href":null,"layout":null,"metadata":null,"text":"Once the above code has been added, we will be able to view generations for specific prompts in the Literal AI Dashboard (more on this later).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_55":{"__typename":"Paragraph","id":"7341d75fdf96_55","name":"7376","type":"H3","href":null,"layout":null,"metadata":null,"text":"Understanding Chainlit’s Copilot","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_56":{"__typename":"Paragraph","id":"7341d75fdf96_56","name":"c1c0","type":"P","href":null,"layout":null,"metadata":null,"text":"Chainlit is an open-source Python package designed to build production-ready conversational AI applications. It provides decorators for several events (chat start, user message, session resume, session stop, etc.). You can check out my article below for a more thorough explanation:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":8,"href":"https:\u002F\u002Fgithub.com\u002FChainlit\u002Fchainlit","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_57":{"__typename":"Paragraph","id":"7341d75fdf96_57","name":"35be","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"Building a Chatbot Application with Chainlit and LangChain\nIn this article, we will develop an application interface for our custom chatbot, Scoopsie, using Chainlit, a framework…medium.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":189,"href":"https:\u002F\u002Fmedium.com\u002F@tahreemrasul\u002Fbuilding-a-chatbot-application-with-chainlit-and-langchain-3e86da0099a6","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":58,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":59,"end":179,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fmedium.com\u002F@tahreemrasul\u002Fbuilding-a-chatbot-application-with-chainlit-and-langchain-3e86da0099a6","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"1*YRp7gT3rySVA3JWHwd_rFQ.gif"}},"Paragraph:7341d75fdf96_58":{"__typename":"Paragraph","id":"7341d75fdf96_58","name":"4e83","type":"P","href":null,"layout":null,"metadata":null,"text":"Specifically in this tutorial, we will focus on building a Software Copilot for our RAG application using Chainlit. Chainlit Copilot offers contextual guidance and automated user actions within applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":59,"end":75,"href":"https:\u002F\u002Fdocs.chainlit.io\u002Fdeployment\u002Fcopilot","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*MU5RE5o3NYKhgYv7d9ko7g.png":{"__typename":"ImageMetadata","id":"1*MU5RE5o3NYKhgYv7d9ko7g.png","originalHeight":768,"originalWidth":1024,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_59":{"__typename":"Paragraph","id":"7341d75fdf96_59","name":"6f78","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*MU5RE5o3NYKhgYv7d9ko7g.png"},"text":"Research paper app schema with relevant tools. Illustration by Author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_60":{"__typename":"Paragraph","id":"7341d75fdf96_60","name":"0fb7","type":"H3","href":null,"layout":null,"metadata":null,"text":"Building a Copilot","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_61":{"__typename":"Paragraph","id":"7341d75fdf96_61","name":"f119","type":"P","href":null,"layout":null,"metadata":null,"text":"Embedding a copilot in your application website can be useful for several reasons. We will build a simple web interface for our semantic research paper engine, and integrate a copilot inside it. This copilot will have a few different features, but here are the most prominent ones:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_62":{"__typename":"Paragraph","id":"7341d75fdf96_62","name":"d5f1","type":"OLI","href":null,"layout":null,"metadata":null,"text":"It will be embedded inside our website’s HTML file.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_63":{"__typename":"Paragraph","id":"7341d75fdf96_63","name":"5b68","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The copilot will be able to take actions on behalf of the user. Let’s say the user asks for online research papers on a specific topic. These can be displayed in a modal, and we can configure our copilot to do this automatically without needing user inputs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_64":{"__typename":"Paragraph","id":"7341d75fdf96_64","name":"d1ca","type":"P","href":null,"layout":null,"metadata":null,"text":"In the next few steps, I will detail how to create a software copilot for our semantic research engine using Chainlit.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_65":{"__typename":"Paragraph","id":"7341d75fdf96_65","name":"97eb","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 1","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_66":{"__typename":"Paragraph","id":"7341d75fdf96_66","name":"5619","type":"P","href":null,"layout":null,"metadata":null,"text":"The first step involves writing logic for our chainlit application. We will use two chainlit decorator functions for our use case: @cl.on_chat_start and @cl.on_message. We will add the logic from the online search and RAG pipeline to these functions. A few things to remember:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":46,"end":54,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":84,"end":92,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":131,"end":148,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":153,"end":167,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_67":{"__typename":"Paragraph","id":"7341d75fdf96_67","name":"c44f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"@cl.on_chat_start contains all code required to be executed at the start of a new user session.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_68":{"__typename":"Paragraph","id":"7341d75fdf96_68","name":"da11","type":"ULI","href":null,"layout":null,"metadata":null,"text":"@cl.on_message contains all code required to be executed when a user sends in a new message.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_69":{"__typename":"Paragraph","id":"7341d75fdf96_69","name":"f0aa","type":"P","href":null,"layout":null,"metadata":null,"text":"We will encapsulate the entire process from receiving a research topic to creating a database and ingesting documents within the @cl.on_chat_start decorator. In the search_engine.py script, import all necessary modules and libraries:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":129,"end":146,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":165,"end":181,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_70":{"__typename":"Paragraph","id":"7341d75fdf96_70","name":"b622","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# search_engine.py\nimport chainlit as cl\nfrom langchain_community.document_loaders import ArxivLoader\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.chains import RetrievalQA\nfrom langchain_openai import ChatOpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_71":{"__typename":"Paragraph","id":"7341d75fdf96_71","name":"d724","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s now add the code for the @cl.on_chat_start decorator. We will make this function asynchronous to ensure multiple tasks can run concurrently.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":31,"end":48,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_72":{"__typename":"Paragraph","id":"7341d75fdf96_72","name":"e26f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# search_engine.py\n# contd.\n\n@cl.on_chat_start\nasync def retrieve_docs():\n    # QUERY PORTION\n    arxiv_query = None\n    # Wait for the user to send in a topic\n    while arxiv_query is None:\n        arxiv_query = await cl.AskUserMessage(\n            content=\"Please enter a topic to begin!\", timeout=15).send()\n    query = arxiv_query['output']\n\n    # ARXIV DOCS PORTION\n    arxiv_docs = ArxivLoader(query=arxiv_query, load_max_docs=3).load()\n    # Prepare arXiv results for display\n    arxiv_papers = [f\"Published: {doc.metadata['Published']} \\n \"\n                    f\"Title: {doc.metadata['Title']} \\n \"\n                    f\"Authors: {doc.metadata['Authors']} \\n \"\n                    f\"Summary: {doc.metadata['Summary'][:50]}... \\n---\\n\"\n                    for doc in arxiv_docs]\n\n    await cl.Message(content=f\"{arxiv_papers}\").send()\n\n    await cl.Message(content=f\"Downloading and chunking articles for {query} \"\n                             f\"This operation can take a while!\").send()\n\n    # DB PORTION\n    pdf_data = []\n    for doc in arxiv_docs:\n        text_splitter = RecursiveCharacterTextSplitter(\n                        chunk_size=1000, chunk_overlap=100)\n        texts = text_splitter.create_documents([doc.page_content])\n        pdf_data.append(texts)\n  \n    llm = ChatOpenAI(model='gpt-3.5-turbo',\n                         temperature=0)\n    embeddings = HuggingFaceEmbeddings(\n                 model_name=\"sentence-transformers\u002Fall-MiniLM-l6-v2\")\n    db = Chroma.from_documents(pdf_data[0], embeddings)\n\n    # CHAIN PORTION\n    chain = RetrievalQA.from_chain_type(llm=llm,\n                                            chain_type=\"stuff\",\n                                            retriever=db.as_retriever(),\n                                            chain_type_kwargs={\n                                                \"verbose\": True,\n                                                \"prompt\": prompt\n                                            }\n                                            )\n\n    # Let the user know that the pipeline is ready\n    await cl.Message(content=f\"Database creation for `{query}` complete. \"\n                             f\"You can now ask questions!\").send()\n\n    cl.user_session.set(\"chain\", chain)\n    cl.user_session.set(\"db\", db)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_73":{"__typename":"Paragraph","id":"7341d75fdf96_73","name":"1c52","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s go through the code we have wrapped in this function:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_74":{"__typename":"Paragraph","id":"7341d75fdf96_74","name":"a185","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Prompting user query: We begin by having the user send in a research topic. This function will not proceed until the user submits a topic.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_75":{"__typename":"Paragraph","id":"7341d75fdf96_75","name":"bf57","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Online Search: We retrieve relevant papers using LangChain’s wrapper for arXiv searches, and display the relevant fields from each entry in a readable format.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_76":{"__typename":"Paragraph","id":"7341d75fdf96_76","name":"0761","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Ingestion: Next, we chunk the articles and create embeddings for further processing. Chunking ensures large papers are handled efficiently. Afterward, a Chroma database is created from processed document chunks and embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":153,"end":159,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_77":{"__typename":"Paragraph","id":"7341d75fdf96_77","name":"e613","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Retrieval: Finally, we set up a RetrievalQA chain, integrating the LLM and the newly created database as a retriever. We also provide the prompt we created earlier in our Literal AI playground.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":32,"end":43,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_78":{"__typename":"Paragraph","id":"7341d75fdf96_78","name":"5ff8","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Storing variables: We store the chain and db in variables using the cl.user_session.set functionality for reuse later on.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":32,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":42,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":68,"end":87,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_79":{"__typename":"Paragraph","id":"7341d75fdf96_79","name":"09e6","type":"OLI","href":null,"layout":null,"metadata":null,"text":"User messages: We use Chainlit’s cl.Message functionality throughout the function to interact with the user.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":33,"end":43,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_80":{"__typename":"Paragraph","id":"7341d75fdf96_80","name":"b30e","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s now define our @cl.on_message function, and add the generation portion of our RAG pipeline. A user should be able to ask questions from the ingested papers, and the application should provide relevant answers.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":21,"end":35,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_81":{"__typename":"Paragraph","id":"7341d75fdf96_81","name":"d73e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"@cl.on_message\nasync def retrieve_docs(message: cl.Message):\n    question = message.content\n    chain = cl.user_session.get(\"chain\")\n    db = cl.user_session.get(\"db\")\n    # Create a new instance of the callback handler for each invocation\n    cb = client.langchain_callback()\n    variables = {\"context\": db.as_retriever(search_kwargs={\"k\": 1}), \n                 \"query\": question}\n    database_results = await chain.acall(variables,\n                                         callbacks=[cb])\n    results = [f\"Question: {question} \"\n               f\"\\n Answer: {database_results['result']}\"]\n    await cl.Message(results).send()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_82":{"__typename":"Paragraph","id":"7341d75fdf96_82","name":"51d9","type":"P","href":null,"layout":null,"metadata":null,"text":"Here is a breakdown of the code in the function above:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_83":{"__typename":"Paragraph","id":"7341d75fdf96_83","name":"0f83","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Chain and Database Retrieval: We first retrieve the previously stored chain and database from the user session.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":30,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_84":{"__typename":"Paragraph","id":"7341d75fdf96_84","name":"a64b","type":"OLI","href":null,"layout":null,"metadata":null,"text":"LangChain Callback Integration: To ensure we can track our prompt and all generations that use a particular prompt version, we need to add the LangChain callback handler from Literal AI when invoking our chain. We are creating the callback handler using the langchain_callback() method from the LiteralClient instance. This callback will automatically log all LangChain interactions to Literal AI.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":258,"end":278,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":295,"end":308,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":32,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_85":{"__typename":"Paragraph","id":"7341d75fdf96_85","name":"b1ed","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Generation: We define the variables: the database as the context for retrieval and the user’s question as the query, also specifying to retrieve the top result (k: 1). Finally, we call the chain with the provided variables and callback.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":161,"end":165,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":161,"end":165,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_86":{"__typename":"Paragraph","id":"7341d75fdf96_86","name":"5ea3","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 2","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_87":{"__typename":"Paragraph","id":"7341d75fdf96_87","name":"fdc4","type":"P","href":null,"layout":null,"metadata":null,"text":"The second step involves embedding the copilot in our application website. We will create a simple website for demonstration. Create an index.html file and add the following code to it:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":136,"end":146,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_88":{"__typename":"Paragraph","id":"7341d75fdf96_88","name":"f894","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003C!DOCTYPE html\u003E\n\u003Chtml\u003E\n  \u003Chead\u003E\n    \u003Ctitle\u003ESemantic Search Engine\u003C\u002Ftitle\u003E\n  \u003C\u002Fhead\u003E\n \u003Cbody\u003E\n   \u003C!-- ... --\u003E\n   \u003Cscript src=\"http:\u002F\u002Flocalhost:8000\u002Fcopilot\u002Findex.js\"\u003E\u003C\u002Fscript\u003E\n   \u003Cscript\u003E\n     window.mountChainlitWidget({\n       chainlitServer: \"http:\u002F\u002Flocalhost:8000\",\n     });\n   \u003C\u002Fscript\u003E\n \u003C\u002Fbody\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"xml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_89":{"__typename":"Paragraph","id":"7341d75fdf96_89","name":"8925","type":"P","href":null,"layout":null,"metadata":null,"text":"In the code above, we have embedded the copilot inside our website by pointing to the location of the Chainlit server hosting our app. The window.mountChainlitWidget adds a floating button on the bottom right corner of your website. Clicking on it will open the Copilot. To ensure our Copilot is working correctly, we need to first run our Chainlit application. Navigate inside your project directory and run:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":139,"end":165,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_90":{"__typename":"Paragraph","id":"7341d75fdf96_90","name":"d279","type":"PRE","href":null,"layout":null,"metadata":null,"text":"chainlit run search_engine.py -w","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_91":{"__typename":"Paragraph","id":"7341d75fdf96_91","name":"a539","type":"P","href":null,"layout":null,"metadata":null,"text":"The code above runs the application on https:\u002F\u002Flocalhost:8000. Next, we need to host our application website. Opening the index.html script inside a browser doesn’t work. Instead, we need to create an HTTPS testing server. You can do this in different ways, but one straightforward approach is to use npx. npx is included with npm (Node Package Manager), which comes with Node.js. To get npx, you simply need to install Node.js on your system. Navigate inside your directory and run:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":122,"end":132,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":301,"end":304,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":306,"end":309,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":327,"end":330,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":388,"end":391,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":39,"end":61,"href":"https:\u002F\u002Flocalhost:8000\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":412,"end":427,"href":"https:\u002F\u002Fnodejs.org\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":39,"end":61,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_92":{"__typename":"Paragraph","id":"7341d75fdf96_92","name":"f418","type":"PRE","href":null,"layout":null,"metadata":null,"text":"npx http-server","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_93":{"__typename":"Paragraph","id":"7341d75fdf96_93","name":"3143","type":"P","href":null,"layout":null,"metadata":null,"text":"Running the command above will serve our website at https:\u002F\u002Flocalhost:8080. Navigate to the address and you will be able to see a simple web interface with the copilot embedded.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":52,"end":74,"href":"https:\u002F\u002Flocalhost:8080\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*0LaafwaQAUvI9koYCOdNzQ.gif":{"__typename":"ImageMetadata","id":"1*0LaafwaQAUvI9koYCOdNzQ.gif","originalHeight":2050,"originalWidth":3356,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_94":{"__typename":"Paragraph","id":"7341d75fdf96_94","name":"dde9","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*0LaafwaQAUvI9koYCOdNzQ.gif"},"text":"Launching the Copilot. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_95":{"__typename":"Paragraph","id":"7341d75fdf96_95","name":"2c25","type":"P","href":null,"layout":null,"metadata":null,"text":"Since we will be using the @cl.on_chat_start wrapper function to welcome users, we can set the show_readme_as_default to false in our Chainlit config to avoid flickering. You can find your config file in your project directory at .chainlit\u002Fconfig.toml.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":27,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":95,"end":117,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":121,"end":126,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":230,"end":251,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*az796gnhvAxN-PYluaE7gQ.png":{"__typename":"ImageMetadata","id":"1*az796gnhvAxN-PYluaE7gQ.png","originalHeight":1620,"originalWidth":802,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_96":{"__typename":"Paragraph","id":"7341d75fdf96_96","name":"f0a1","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*az796gnhvAxN-PYluaE7gQ.png"},"text":"Copilot Overview. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_97":{"__typename":"Paragraph","id":"7341d75fdf96_97","name":"fca2","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 3","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_98":{"__typename":"Paragraph","id":"7341d75fdf96_98","name":"38a4","type":"P","href":null,"layout":null,"metadata":null,"text":"To execute the code only inside the Copilot, we can add the following:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_99":{"__typename":"Paragraph","id":"7341d75fdf96_99","name":"abe4","type":"PRE","href":null,"layout":null,"metadata":null,"text":"@cl.on_message\nasync def retrieve_docs(message: cl.Message):\n    if cl.context.session.client_type == \"copilot\":\n        # code to be executed only inside the Copilot","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_100":{"__typename":"Paragraph","id":"7341d75fdf96_100","name":"4efb","type":"P","href":null,"layout":null,"metadata":null,"text":"Any code inside this block will only be executed when you interact with your application from within your Copilot. For example, if you run a query at the Chainlit application interface hosted at https:\u002F\u002Flocalhost:8000, the code inside the above if block will not be executed, since it’s expecting the client type to be the Copilot. This is a helpful feature that you can use to differentiate between actions taken directly in the Chainlit application and those initiated through the Copilot interface. By doing so, you can tailor the behavior of your application based on the context of the request, allowing for a more dynamic and responsive user experience.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":195,"end":218,"href":"https:\u002F\u002Flocalhost:8000,","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":195,"end":217,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_101":{"__typename":"Paragraph","id":"7341d75fdf96_101","name":"77b5","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 4","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_102":{"__typename":"Paragraph","id":"7341d75fdf96_102","name":"9726","type":"P","href":null,"layout":null,"metadata":null,"text":"The Copilot can call functions on your website. This is useful for taking actions on behalf of the user, such as opening a modal, creating a new document, etc. We will modify our Chainlit decorator functions to include two new Copilot functions. We need to specify in the index.html file how the frontend should respond when Copilot functions in our Chainlit backend application are activated. The specific reaction will vary based on the application. For our semantic research paper engine, we'll generate pop-up notifications on the frontend whenever it's necessary to show relevant papers or database answers in response to a user query.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":272,"end":282,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*U_Exn9X-_-g5TQUbLbm8qw.png":{"__typename":"ImageMetadata","id":"1*U_Exn9X-_-g5TQUbLbm8qw.png","originalHeight":1620,"originalWidth":2338,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_103":{"__typename":"Paragraph","id":"7341d75fdf96_103","name":"ae22","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*U_Exn9X-_-g5TQUbLbm8qw.png"},"text":"Popups in response to user queries in the copilot. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_104":{"__typename":"Paragraph","id":"7341d75fdf96_104","name":"1142","type":"P","href":null,"layout":null,"metadata":null,"text":"We will create two Copilot functions in our application:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_105":{"__typename":"Paragraph","id":"7341d75fdf96_105","name":"6ff5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"showArxivResults: this function will be responsible for displaying the online results pulled by the arxiv API against a user query.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":100,"end":105,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_106":{"__typename":"Paragraph","id":"7341d75fdf96_106","name":"42c3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"showDatabaseResults: this function will be responsible for displaying the results pulled from our ingested database against a user question.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_107":{"__typename":"Paragraph","id":"7341d75fdf96_107","name":"acca","type":"P","href":null,"layout":null,"metadata":null,"text":"First, let’s set up the backend logic in the search_engine.py script and modify the @cl.on_chat_start function:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":45,"end":61,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":84,"end":101,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_108":{"__typename":"Paragraph","id":"7341d75fdf96_108","name":"af0f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"@cl.on_chat_start\nasync def retrieve_docs():\n    if cl.context.session.client_type == \"copilot\":\n        # same code as before\n\n        # Trigger popup for arXiv results\n        fn_arxiv = cl.CopilotFunction(name=\"showArxivResults\", \n                   args={\"results\": \"\\n\".join(arxiv_papers)})\n        await fn_arxiv.acall()\n        \n        # same code as before","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_109":{"__typename":"Paragraph","id":"7341d75fdf96_109","name":"af1e","type":"P","href":null,"layout":null,"metadata":null,"text":"In the code above, a Copilot function named showArxivResults is defined and called asynchronously. This function is designed to display the formatted list of arXiv papers directly in the Copilot interface. The function signature is quite simple: we specify the name of the function and the arguments it will send back. We will use this information in our index.html file to create a popup.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":44,"end":60,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":355,"end":365,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_110":{"__typename":"Paragraph","id":"7341d75fdf96_110","name":"198c","type":"P","href":null,"layout":null,"metadata":null,"text":"Next, we need to modify our @cl.on_message function with the second Copilot function that will be executed when a user asks a question based on the ingested papers:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":28,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_111":{"__typename":"Paragraph","id":"7341d75fdf96_111","name":"399f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"@cl.on_message\nasync def retrieve_docs(message: cl.Message):\n    if cl.context.session.client_type == \"copilot\":\n        # same code as before\n        \n        # Trigger popup for database results\n        fn_db = cl.CopilotFunction(name=\"showDatabaseResults\", \n                args={\"results\": \"\\n\".join(results)})\n        await fn_db.acall()\n        \n        # same code as before","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_112":{"__typename":"Paragraph","id":"7341d75fdf96_112","name":"58d0","type":"P","href":null,"layout":null,"metadata":null,"text":"In the code above, we have defined the second Copilot function named showDatabaseResults to be called asynchronously. This function is tasked with displaying the results retrieved from the database in the Copilot interface. The function signature specifies the name of the function and the arguments it will send back.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":69,"end":88,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_113":{"__typename":"Paragraph","id":"7341d75fdf96_113","name":"cdce","type":"H4","href":null,"layout":null,"metadata":null,"text":"Step 5","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_114":{"__typename":"Paragraph","id":"7341d75fdf96_114","name":"eeb8","type":"P","href":null,"layout":null,"metadata":null,"text":"We will now edit our index.html file to include the following changes:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":21,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_115":{"__typename":"Paragraph","id":"7341d75fdf96_115","name":"a7d2","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Add the two Copilot functions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_116":{"__typename":"Paragraph","id":"7341d75fdf96_116","name":"c24b","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Specify what would happen on our website when either of the two Copilot functions gets triggered. We will create a popup to display results from the application backend.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_117":{"__typename":"Paragraph","id":"7341d75fdf96_117","name":"4dd4","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Add simple styling for popups.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_118":{"__typename":"Paragraph","id":"7341d75fdf96_118","name":"ae53","type":"P","href":null,"layout":null,"metadata":null,"text":"First, we need to add the event listeners for our Copilot functions. In the \u003Cscript\u003E tag of your index.html file, add the following code:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":76,"end":84,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":97,"end":107,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_119":{"__typename":"Paragraph","id":"7341d75fdf96_119","name":"00d6","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003Cscript\u003E\n \u002F\u002F previous code\n window.addEventListener(\"chainlit-call-fn\", (e) =\u003E {\n const { name, args, callback } = e.detail;\n if (name === \"showArxivResults\") {\n   document.getElementById(\"arxiv-result-text\").innerHTML =\n     args.results.replace(\u002F\\n\u002Fg, \"\u003Cbr\u003E\");\n   document.getElementById(\"popup\").style.display = \"flex\";\n   if (callback) callback();\n } else if (name === \"showDatabaseResults\") {\n   document.getElementById(\"database-results-text\").innerHTML =\n     args.results.replace(\u002F\\n\u002Fg, \"\u003Cbr\u003E\");\n   document.getElementById(\"popup\").style.display = \"flex\";\n   if (callback) callback();\n }\n });\n\u003C\u002Fscript\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"xml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_120":{"__typename":"Paragraph","id":"7341d75fdf96_120","name":"8402","type":"P","href":null,"layout":null,"metadata":null,"text":"Here is a breakdown of the above code:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_121":{"__typename":"Paragraph","id":"7341d75fdf96_121","name":"ecc4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Includes functions to show (showPopup()) and hide (hidePopup()) the popup modal.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":28,"end":39,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":51,"end":62,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_122":{"__typename":"Paragraph","id":"7341d75fdf96_122","name":"3fb2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"An event listener is registered for the chainlit-call-fn event, which is triggered when a Copilot function (showArxivResults or showDatabaseResults) is called.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":40,"end":56,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":108,"end":124,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":128,"end":147,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_123":{"__typename":"Paragraph","id":"7341d75fdf96_123","name":"604f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Upon detecting an event, the listener checks the name of the Copilot function called. Depending on the function name, it updates the content of the relevant section within the popup with the results provided by the function. It replaces newline characters (\\\\n) with HTML line breaks (\u003Cbr\u003E) to format the text properly for HTML display.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":257,"end":260,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":285,"end":289,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_124":{"__typename":"Paragraph","id":"7341d75fdf96_124","name":"98ac","type":"ULI","href":null,"layout":null,"metadata":null,"text":"After updating the content, the popup modal is displayed (display: \"flex\"), allowing the user to see the results. The modal can be hidden using the close button, which calls the hidePopup() function.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":58,"end":73,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":178,"end":189,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_125":{"__typename":"Paragraph","id":"7341d75fdf96_125","name":"a7f8","type":"P","href":null,"layout":null,"metadata":null,"text":"Next, we need to define the popup modal we have specified above. We can do this by adding the following code to the \u003Cbody\u003E tag of our index.html script:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":116,"end":122,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":134,"end":144,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_126":{"__typename":"Paragraph","id":"7341d75fdf96_126","name":"b672","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003Cdiv id=\"popup\" class=\"popup\"\u003E\n \u003Cspan class=\"close-btn\" onclick=\"hidePopup()\"\u003E&times;\u003C\u002Fspan\u003E\n \u003Cdiv class=\"arxiv-results-wrapper\"\u003E\n   \u003Ch1\u003EArxiv Results\u003C\u002Fh1\u003E\n   \u003Cp id=\"arxiv-result-text\"\u003EOnline results will be displayed here.\u003C\u002Fp\u003E\n \u003C\u002Fdiv\u003E\n \u003Cdiv class=\"database-results-wrapper\"\u003E\n   \u003Ch1\u003EDatabase Results\u003C\u002Fh1\u003E\n   \u003Cp id=\"database-results-text\"\u003EDatabase results will be displayed here.\u003C\u002Fp\u003E\n \u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"xml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_127":{"__typename":"Paragraph","id":"7341d75fdf96_127","name":"2aea","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s also add some styling for our popups. Edit the \u003Chead\u003E tag of the index.html file:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":53,"end":59,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":71,"end":81,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_128":{"__typename":"Paragraph","id":"7341d75fdf96_128","name":"96fd","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003Cstyle\u003E\n * {\n   box-sizing: border-box;\n }\n \n body {\n   font-family: sans-serif;\n }\n \n .close-btn {\n   position: absolute;\n   top: 10px;\n   right: 20px;\n   font-size: 24px;\n   cursor: pointer;\n }\n \n .popup {\n   display: none;\n   position: fixed;\n   top: 50%;\n   left: 50%;\n   transform: translate(-50%, -50%);\n   background-color: white;\n   padding: 20px;\n   box-shadow: rgba(99, 99, 99, 0.2) 0px 2px 8px 0px;\n   width: 40%;\n   flex-direction: column;\n   gap: 50px;\n }\n \n p {\n   color: #00000099;\n }\n\u003C\u002Fstyle\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"xml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_129":{"__typename":"Paragraph","id":"7341d75fdf96_129","name":"7e71","type":"H3","href":null,"layout":null,"metadata":null,"text":"Launching the Application","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_130":{"__typename":"Paragraph","id":"7341d75fdf96_130","name":"73a6","type":"P","href":null,"layout":null,"metadata":null,"text":"Now that we have added our Copilot logic to our Chainlit application, we can run both our application and the website. For the Copilot to work, our application must already be running. Open a terminal inside your project directory, and run the following command to launch the Chainlit server:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_131":{"__typename":"Paragraph","id":"7341d75fdf96_131","name":"3eef","type":"PRE","href":null,"layout":null,"metadata":null,"text":"chainlit run search.py -h","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"undefined"},"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_132":{"__typename":"Paragraph","id":"7341d75fdf96_132","name":"ed40","type":"P","href":null,"layout":null,"metadata":null,"text":"In a new terminal, launch the website using:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_133":{"__typename":"Paragraph","id":"7341d75fdf96_133","name":"ed4c","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\nnpx http-server","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*mzr5PWSePHW8dNByWZFmQw.gif":{"__typename":"ImageMetadata","id":"1*mzr5PWSePHW8dNByWZFmQw.gif","originalHeight":1080,"originalWidth":1920,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_134":{"__typename":"Paragraph","id":"7341d75fdf96_134","name":"3569","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*mzr5PWSePHW8dNByWZFmQw.gif"},"text":"App Demo. By Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_135":{"__typename":"Paragraph","id":"7341d75fdf96_135","name":"bbba","type":"H3","href":null,"layout":null,"metadata":null,"text":"LLM Observability with Literal AI","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_136":{"__typename":"Paragraph","id":"7341d75fdf96_136","name":"30ce","type":"P","href":null,"layout":null,"metadata":null,"text":"Integrating observability features into a production-grade application, such as our Copilot-run semantic research engine, is typically required to ensure the application’s reliability in a production environment. We will be using this with the Literal AI framework.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_137":{"__typename":"Paragraph","id":"7341d75fdf96_137","name":"90a1","type":"P","href":null,"layout":null,"metadata":null,"text":"For any Chainlit application, Literal AI automatically starts monitoring the application and sends data to the Literal AI platform. We already initiated the Literal AI client when creating our prompt in the search_engine.py script. Now, each time the user interacts with our application, we will see the logs in the Literal AI dashboard.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":207,"end":223,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_138":{"__typename":"Paragraph","id":"7341d75fdf96_138","name":"5577","type":"H3","href":null,"layout":null,"metadata":null,"text":"Dashboard","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_139":{"__typename":"Paragraph","id":"7341d75fdf96_139","name":"5a7a","type":"P","href":null,"layout":null,"metadata":null,"text":"Navigate to the Literal AI Dashboard, select the project from the left panel, and then click on Observability. You will see logs for the following features.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":16,"end":36,"href":"https:\u002F\u002Fcloud.getliteral.ai\u002Fprojects\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":96,"end":109,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_140":{"__typename":"Paragraph","id":"7341d75fdf96_140","name":"1e7d","type":"H4","href":null,"layout":null,"metadata":null,"text":"Threads","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_141":{"__typename":"Paragraph","id":"7341d75fdf96_141","name":"4579","type":"P","href":null,"layout":null,"metadata":null,"text":"A thread represents a conversation session between an assistant and a user. You should be able to see all the conversations a user has had in the application.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*yLCUB410nsY8LmBCxRMRoA.png":{"__typename":"ImageMetadata","id":"1*yLCUB410nsY8LmBCxRMRoA.png","originalHeight":744,"originalWidth":2454,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_142":{"__typename":"Paragraph","id":"7341d75fdf96_142","name":"a957","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*yLCUB410nsY8LmBCxRMRoA.png"},"text":"Literal AI Threads. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_143":{"__typename":"Paragraph","id":"7341d75fdf96_143","name":"1cb9","type":"P","href":null,"layout":null,"metadata":null,"text":"Expanding on a particular conversation will give key details, such as the time each step took, details of the user message, and a tree-based view detailing all steps. You can also add a conversation to a dataset.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*hCusw7T_NzpG7FMMg85HpQ.png":{"__typename":"ImageMetadata","id":"1*hCusw7T_NzpG7FMMg85HpQ.png","originalHeight":1876,"originalWidth":2830,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_144":{"__typename":"Paragraph","id":"7341d75fdf96_144","name":"9b72","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*hCusw7T_NzpG7FMMg85HpQ.png"},"text":"Literal AI Thread Overview. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_145":{"__typename":"Paragraph","id":"7341d75fdf96_145","name":"b59f","type":"H4","href":null,"layout":null,"metadata":null,"text":"Runs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_146":{"__typename":"Paragraph","id":"7341d75fdf96_146","name":"9390","type":"P","href":null,"layout":null,"metadata":null,"text":"A run is a sequence of steps taken by an agent or a chain. This gives details of all steps taken each time a chain or agent is executed. With this tab, we get both the input and the output for each user query.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*EqWQgjLQQxrDqbySuF6YJQ.png":{"__typename":"ImageMetadata","id":"1*EqWQgjLQQxrDqbySuF6YJQ.png","originalHeight":912,"originalWidth":2448,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_147":{"__typename":"Paragraph","id":"7341d75fdf96_147","name":"faf9","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*EqWQgjLQQxrDqbySuF6YJQ.png"},"text":"Literal AI Runs Dashboard. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_148":{"__typename":"Paragraph","id":"7341d75fdf96_148","name":"27c3","type":"P","href":null,"layout":null,"metadata":null,"text":"You can expand on a run, and this will give further details. Once again, you can add this info to a dataset.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*e3DoFWyDjX1G1QyS618N2Q.png":{"__typename":"ImageMetadata","id":"1*e3DoFWyDjX1G1QyS618N2Q.png","originalHeight":1136,"originalWidth":2832,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_149":{"__typename":"Paragraph","id":"7341d75fdf96_149","name":"269d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*e3DoFWyDjX1G1QyS618N2Q.png"},"text":"Literal AI Run Overview. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_150":{"__typename":"Paragraph","id":"7341d75fdf96_150","name":"8ac8","type":"H4","href":null,"layout":null,"metadata":null,"text":"Generations","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_151":{"__typename":"Paragraph","id":"7341d75fdf96_151","name":"bee3","type":"P","href":null,"layout":null,"metadata":null,"text":"A generation contains both the input sent to an LLM and its completion. This gives key details including the model used for a completion, the token count, as well as the user requesting the completion, if you have configured multiple user sessions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*_jbmHk9Md9LTmelnoodTuQ.png":{"__typename":"ImageMetadata","id":"1*_jbmHk9Md9LTmelnoodTuQ.png","originalHeight":1394,"originalWidth":2444,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_152":{"__typename":"Paragraph","id":"7341d75fdf96_152","name":"a3eb","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*_jbmHk9Md9LTmelnoodTuQ.png"},"text":"Literal AI Generations Overview. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_153":{"__typename":"Paragraph","id":"7341d75fdf96_153","name":"311d","type":"H3","href":null,"layout":null,"metadata":null,"text":"Prompts Evaluation in Literal AI","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_154":{"__typename":"Paragraph","id":"7341d75fdf96_154","name":"b4cb","type":"P","href":null,"layout":null,"metadata":null,"text":"We can track generations and threads against each prompt created and used in the application code since we added LangChain integrations. Therefore, each time the chain is invoked for a user query, logs are added against it in the Literal AI dashboard. This is helpful to see which prompts were responsible for a particular generation, and compare performance for different versions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*IBe_ITfKPlt3Yng-NpqqGg.gif":{"__typename":"ImageMetadata","id":"1*IBe_ITfKPlt3Yng-NpqqGg.gif","originalHeight":1080,"originalWidth":1818,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:7341d75fdf96_155":{"__typename":"Paragraph","id":"7341d75fdf96_155","name":"5029","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*IBe_ITfKPlt3Yng-NpqqGg.gif"},"text":"Copilot integrated semantic research engine app with observability features. Image by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_156":{"__typename":"Paragraph","id":"7341d75fdf96_156","name":"fd84","type":"H3","href":null,"layout":null,"metadata":null,"text":"Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_157":{"__typename":"Paragraph","id":"7341d75fdf96_157","name":"fc63","type":"P","href":null,"layout":null,"metadata":null,"text":"In this tutorial, I demonstrated how to create a semantic research paper engine using RAG features with LangChain, OpenAI, and ChromaDB. Additionally, I showed how to develop a web app for this engine, integrating Copilot and observability features from Literal AI. Incorporating evaluation and observability is generally required for ensuring optimal performance in real-world language model applications. Furthermore, the Copilot can be an extremely useful feature for different software applications, and this tutorial can be a good starting point to understand how to set it up for your application.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:7341d75fdf96_158":{"__typename":"Paragraph","id":"7341d75fdf96_158","name":"4469","type":"P","href":null,"layout":null,"metadata":null,"text":"You can find the code from this tutorial on my GitHub. If you found this tutorial helpful, consider supporting by giving it fifty claps. You can follow along as I share working demos, explanations and cool side projects on things in the AI space. Come say hi on LinkedIn and X! I share guides, code snippets and other useful content there. 👋","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":47,"end":53,"href":"https:\u002F\u002Fgithub.com\u002Ftahreemrasul\u002Fsemantic_research_engine","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":145,"end":157,"href":"\u002F@tahreemrasul","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":262,"end":270,"href":"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Ftahreem-r-20b7b8218\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":275,"end":276,"href":"https:\u002F\u002Ftwitter.com\u002Ftahreemrasul1","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_b49173192da9":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:lo_b49173192da9","isEditor":false,"isMuting":false},"Membership:ff4137682f0f":{"__typename":"Membership","tier":"MEMBER","id":"ff4137682f0f"},"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png":{"__typename":"ImageMetadata","id":"1*cFFKn8rFH4ZndmaYeAs6iQ.png","originalWidth":2381,"originalHeight":743},"Tag:retrieval-augmented-gen":{"__typename":"Tag","id":"retrieval-augmented-gen","displayTitle":"Retrieval Augmented Gen","normalizedTagSlug":"retrieval-augmented-gen"},"Tag:langchain":{"__typename":"Tag","id":"langchain","displayTitle":"Langchain","normalizedTagSlug":"langchain"},"Tag:llm-evaluation":{"__typename":"Tag","id":"llm-evaluation","displayTitle":"Llm Evaluation","normalizedTagSlug":"llm-evaluation"},"Tag:llmops":{"__typename":"Tag","id":"llmops","displayTitle":"Llmops","normalizedTagSlug":"llmops"},"Tag:hands-on-tutorials":{"__typename":"Tag","id":"hands-on-tutorials","displayTitle":"Hands On Tutorials","normalizedTagSlug":"hands-on-tutorials"},"Post:9c345fcd1cd8":{"__typename":"Post","id":"9c345fcd1cd8","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"71f4","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:7341d75fdf96_0"},{"__ref":"Paragraph:7341d75fdf96_1"},{"__ref":"Paragraph:7341d75fdf96_2"},{"__ref":"Paragraph:7341d75fdf96_3"},{"__ref":"Paragraph:7341d75fdf96_4"},{"__ref":"Paragraph:7341d75fdf96_5"},{"__ref":"Paragraph:7341d75fdf96_6"},{"__ref":"Paragraph:7341d75fdf96_7"},{"__ref":"Paragraph:7341d75fdf96_8"},{"__ref":"Paragraph:7341d75fdf96_9"},{"__ref":"Paragraph:7341d75fdf96_10"},{"__ref":"Paragraph:7341d75fdf96_11"},{"__ref":"Paragraph:7341d75fdf96_12"},{"__ref":"Paragraph:7341d75fdf96_13"},{"__ref":"Paragraph:7341d75fdf96_14"},{"__ref":"Paragraph:7341d75fdf96_15"},{"__ref":"Paragraph:7341d75fdf96_16"},{"__ref":"Paragraph:7341d75fdf96_17"},{"__ref":"Paragraph:7341d75fdf96_18"},{"__ref":"Paragraph:7341d75fdf96_19"},{"__ref":"Paragraph:7341d75fdf96_20"},{"__ref":"Paragraph:7341d75fdf96_21"},{"__ref":"Paragraph:7341d75fdf96_22"},{"__ref":"Paragraph:7341d75fdf96_23"},{"__ref":"Paragraph:7341d75fdf96_24"},{"__ref":"Paragraph:7341d75fdf96_25"},{"__ref":"Paragraph:7341d75fdf96_26"},{"__ref":"Paragraph:7341d75fdf96_27"},{"__ref":"Paragraph:7341d75fdf96_28"},{"__ref":"Paragraph:7341d75fdf96_29"},{"__ref":"Paragraph:7341d75fdf96_30"},{"__ref":"Paragraph:7341d75fdf96_31"},{"__ref":"Paragraph:7341d75fdf96_32"},{"__ref":"Paragraph:7341d75fdf96_33"},{"__ref":"Paragraph:7341d75fdf96_34"},{"__ref":"Paragraph:7341d75fdf96_35"},{"__ref":"Paragraph:7341d75fdf96_36"},{"__ref":"Paragraph:7341d75fdf96_37"},{"__ref":"Paragraph:7341d75fdf96_38"},{"__ref":"Paragraph:7341d75fdf96_39"},{"__ref":"Paragraph:7341d75fdf96_40"},{"__ref":"Paragraph:7341d75fdf96_41"},{"__ref":"Paragraph:7341d75fdf96_42"},{"__ref":"Paragraph:7341d75fdf96_43"},{"__ref":"Paragraph:7341d75fdf96_44"},{"__ref":"Paragraph:7341d75fdf96_45"},{"__ref":"Paragraph:7341d75fdf96_46"},{"__ref":"Paragraph:7341d75fdf96_47"},{"__ref":"Paragraph:7341d75fdf96_48"},{"__ref":"Paragraph:7341d75fdf96_49"},{"__ref":"Paragraph:7341d75fdf96_50"},{"__ref":"Paragraph:7341d75fdf96_51"},{"__ref":"Paragraph:7341d75fdf96_52"},{"__ref":"Paragraph:7341d75fdf96_53"},{"__ref":"Paragraph:7341d75fdf96_54"},{"__ref":"Paragraph:7341d75fdf96_55"},{"__ref":"Paragraph:7341d75fdf96_56"},{"__ref":"Paragraph:7341d75fdf96_57"},{"__ref":"Paragraph:7341d75fdf96_58"},{"__ref":"Paragraph:7341d75fdf96_59"},{"__ref":"Paragraph:7341d75fdf96_60"},{"__ref":"Paragraph:7341d75fdf96_61"},{"__ref":"Paragraph:7341d75fdf96_62"},{"__ref":"Paragraph:7341d75fdf96_63"},{"__ref":"Paragraph:7341d75fdf96_64"},{"__ref":"Paragraph:7341d75fdf96_65"},{"__ref":"Paragraph:7341d75fdf96_66"},{"__ref":"Paragraph:7341d75fdf96_67"},{"__ref":"Paragraph:7341d75fdf96_68"},{"__ref":"Paragraph:7341d75fdf96_69"},{"__ref":"Paragraph:7341d75fdf96_70"},{"__ref":"Paragraph:7341d75fdf96_71"},{"__ref":"Paragraph:7341d75fdf96_72"},{"__ref":"Paragraph:7341d75fdf96_73"},{"__ref":"Paragraph:7341d75fdf96_74"},{"__ref":"Paragraph:7341d75fdf96_75"},{"__ref":"Paragraph:7341d75fdf96_76"},{"__ref":"Paragraph:7341d75fdf96_77"},{"__ref":"Paragraph:7341d75fdf96_78"},{"__ref":"Paragraph:7341d75fdf96_79"},{"__ref":"Paragraph:7341d75fdf96_80"},{"__ref":"Paragraph:7341d75fdf96_81"},{"__ref":"Paragraph:7341d75fdf96_82"},{"__ref":"Paragraph:7341d75fdf96_83"},{"__ref":"Paragraph:7341d75fdf96_84"},{"__ref":"Paragraph:7341d75fdf96_85"},{"__ref":"Paragraph:7341d75fdf96_86"},{"__ref":"Paragraph:7341d75fdf96_87"},{"__ref":"Paragraph:7341d75fdf96_88"},{"__ref":"Paragraph:7341d75fdf96_89"},{"__ref":"Paragraph:7341d75fdf96_90"},{"__ref":"Paragraph:7341d75fdf96_91"},{"__ref":"Paragraph:7341d75fdf96_92"},{"__ref":"Paragraph:7341d75fdf96_93"},{"__ref":"Paragraph:7341d75fdf96_94"},{"__ref":"Paragraph:7341d75fdf96_95"},{"__ref":"Paragraph:7341d75fdf96_96"},{"__ref":"Paragraph:7341d75fdf96_97"},{"__ref":"Paragraph:7341d75fdf96_98"},{"__ref":"Paragraph:7341d75fdf96_99"},{"__ref":"Paragraph:7341d75fdf96_100"},{"__ref":"Paragraph:7341d75fdf96_101"},{"__ref":"Paragraph:7341d75fdf96_102"},{"__ref":"Paragraph:7341d75fdf96_103"},{"__ref":"Paragraph:7341d75fdf96_104"},{"__ref":"Paragraph:7341d75fdf96_105"},{"__ref":"Paragraph:7341d75fdf96_106"},{"__ref":"Paragraph:7341d75fdf96_107"},{"__ref":"Paragraph:7341d75fdf96_108"},{"__ref":"Paragraph:7341d75fdf96_109"},{"__ref":"Paragraph:7341d75fdf96_110"},{"__ref":"Paragraph:7341d75fdf96_111"},{"__ref":"Paragraph:7341d75fdf96_112"},{"__ref":"Paragraph:7341d75fdf96_113"},{"__ref":"Paragraph:7341d75fdf96_114"},{"__ref":"Paragraph:7341d75fdf96_115"},{"__ref":"Paragraph:7341d75fdf96_116"},{"__ref":"Paragraph:7341d75fdf96_117"},{"__ref":"Paragraph:7341d75fdf96_118"},{"__ref":"Paragraph:7341d75fdf96_119"},{"__ref":"Paragraph:7341d75fdf96_120"},{"__ref":"Paragraph:7341d75fdf96_121"},{"__ref":"Paragraph:7341d75fdf96_122"},{"__ref":"Paragraph:7341d75fdf96_123"},{"__ref":"Paragraph:7341d75fdf96_124"},{"__ref":"Paragraph:7341d75fdf96_125"},{"__ref":"Paragraph:7341d75fdf96_126"},{"__ref":"Paragraph:7341d75fdf96_127"},{"__ref":"Paragraph:7341d75fdf96_128"},{"__ref":"Paragraph:7341d75fdf96_129"},{"__ref":"Paragraph:7341d75fdf96_130"},{"__ref":"Paragraph:7341d75fdf96_131"},{"__ref":"Paragraph:7341d75fdf96_132"},{"__ref":"Paragraph:7341d75fdf96_133"},{"__ref":"Paragraph:7341d75fdf96_134"},{"__ref":"Paragraph:7341d75fdf96_135"},{"__ref":"Paragraph:7341d75fdf96_136"},{"__ref":"Paragraph:7341d75fdf96_137"},{"__ref":"Paragraph:7341d75fdf96_138"},{"__ref":"Paragraph:7341d75fdf96_139"},{"__ref":"Paragraph:7341d75fdf96_140"},{"__ref":"Paragraph:7341d75fdf96_141"},{"__ref":"Paragraph:7341d75fdf96_142"},{"__ref":"Paragraph:7341d75fdf96_143"},{"__ref":"Paragraph:7341d75fdf96_144"},{"__ref":"Paragraph:7341d75fdf96_145"},{"__ref":"Paragraph:7341d75fdf96_146"},{"__ref":"Paragraph:7341d75fdf96_147"},{"__ref":"Paragraph:7341d75fdf96_148"},{"__ref":"Paragraph:7341d75fdf96_149"},{"__ref":"Paragraph:7341d75fdf96_150"},{"__ref":"Paragraph:7341d75fdf96_151"},{"__ref":"Paragraph:7341d75fdf96_152"},{"__ref":"Paragraph:7341d75fdf96_153"},{"__ref":"Paragraph:7341d75fdf96_154"},{"__ref":"Paragraph:7341d75fdf96_155"},{"__ref":"Paragraph:7341d75fdf96_156"},{"__ref":"Paragraph:7341d75fdf96_157"},{"__ref":"Paragraph:7341d75fdf96_158"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:795f7e79f0ce"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fbuilding-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8","primaryTopic":{"__ref":"Topic:1eca0103fff3"},"topics":[{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"data-science"},{"__typename":"Topic","slug":"programming"}],"isPublished":true,"latestPublishedVersion":"7341d75fdf96","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":0},"createdAt":1714980677299,"firstPublishedAt":1715627059727,"latestPublishedAt":1715627059727,"clapCount":372,"allowResponses":true,"isLimitedState":false,"title":"Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI","isSeries":false,"sequence":null,"uniqueSlug":"building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","readingTime":16.82547169811321,"previewContent":{"__typename":"PreviewContent","subtitle":"A tutorial on building a semantic paper engine using RAG with LangChain, Chainlit copilot apps, and Literal AI observability."},"previewImage":{"__ref":"ImageMetadata:1*GUoz9w5z8FLzXHmQUarXyg.png"},"isShortform":false,"seoTitle":"","updatedAt":1715628177453,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:retrieval-augmented-gen"},{"__ref":"Tag:langchain"},{"__ref":"Tag:llm-evaluation"},{"__ref":"Tag:llmops"},{"__ref":"Tag:hands-on-tutorials"}],"isNewsletter":false,"statusForCollection":"APPROVED","pendingCollection":null,"detectedLanguage":"en","wordCount":4048,"layerCake":1}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.9e5bec4a.js"></script><script src="https://cdn-client.medium.com/lite/static/js/3057.5e22bbb0.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.25da4dfa.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.7c58a71f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.2021fe63.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6068.e9093f2e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4398.db4d4378.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7883.0e445e04.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9281.e9be8bce.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7111.1421aaa2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6481.e3e8b67f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8695.17d1af21.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9662.114aae57.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5971.c8339d3b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5514.97be1308.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5203.910c275f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7098.7bbb418a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/703.3c2501fc.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1711.b70f1a35.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8597.4e70742a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9174.244cf6ba.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8883.c8b03d13.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/705.da9267d6.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5781.39279ff8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8580.feeb2549.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6046.f9be485b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1525.dc069e3a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/500.596a9584.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9408.93ecc1af.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6605.84e81b15.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2790.1bf395da.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7421.3f94f5ea.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4667.993ebc2b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.3a6fa1ab.chunk.js"></script><script>window.main();</script></body></html>