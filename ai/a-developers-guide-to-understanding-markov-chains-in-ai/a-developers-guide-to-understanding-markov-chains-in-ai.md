
<!--
title: 马尔可夫链在人工智能中的开发者指南
cover: https://cdn.thenewstack.io/media/2024/03/e02889d6-fre-sonneveld-k8ihtzoikq4-unsplash.jpg
-->

马尔科夫链在解决问题时有什么用？当你想对处于离散状态的事物建模时，David Eastman 写道。

> 译自 [A Developer's Guide to Understanding Markov Chains in AI](https://thenewstack.io/a-developers-guide-to-understanding-markov-chains-in-ai/)，作者 David Eastman。

深入研究 [人工智能](https://thenewstack.io/3-vectors-of-artificial-intelligence-and-machine-learning/) (AI) 中使用的理论数学知识可以帮助你过渡到 AI 开发人员使用的技能。或者至少，它可以帮助你理解幕后发生的事情。

人工智能中有很多数学知识（以及从中衍生的术语）——尽管其中大部分是概念性的，而不是代数性的。尽管如此，我们不想深入研究它，而只是环顾四周，这样我们对技术白皮书就不会那么盲目。

**马尔可夫**是一位俄罗斯数学家（也是一名出色的国际象棋选手），他在过程和概率方面的研究早于现代计算，但此后一直被人们心存感激地利用。

任何过程都可以简化为**状态**和**转换**，虽然这些对于计算机来说自然很好，但实际上这也是人类解释叙述的方式。我们不会尝试实时解释事物，我们只会跳到重要的事件。例如，如果我们采用“约翰走到商店，他走进面包店，买了一些面包，走进熟食店买了一个三明治，向朋友打招呼，离开商店并返回家”这一叙述，这对我们来说是有意义的。但没有任何时间信息，只是一个有序的**事件序列**。

我们可以随时将约翰的状态总结为以下状态之一：

- 旅行（往返商店）
- 购物（买面包或三明治）
- 聊天（与朋友）

我们可以将转换总结为：

- 从家到商店再返回。
- 从一家商店到另一家商店。
- 从购物到聊天再回到购物。

我们已经创建了约翰进出其中的区域。对于约翰来说，这些都是正常的日常事务。如果一个爱管闲事的邻居观察到约翰的许多类似旅程，它们看起来是随机的，即使它们只是由一小部分选项组成的。约翰的旅程可以被描述为一个**随机**过程。

让我们暂时让约翰待在家里。以下是维基百科对马尔可夫链的定义：“马尔可夫链或马尔可夫过程是**一个随机模型，描述一系列可能的事件，其中每个事件的概率仅取决于前一个事件中达到的状态**。”

换句话说，接下来发生的事情只取决于之前发生的事情。现在，如果我们从那个爱管闲事的邻居的角度考虑约翰的旅程，似乎他接下来所做的任何事情都只真正取决于他当时正在做什么。例如，他只有在已经接近商店时才会偶遇朋友并聊天。

![](https://cdn.thenewstack.io/media/2024/03/e186b34b-untitled.png)

*约翰的旅程*

请注意，从每个状态发生的选项有不同的机会，但如果我们从每个状态中加起来，则总和为 100%。请注意，约翰可以从一家商店走到另一家商店，因此转换指向它刚刚离开的状态。聊天也是如此。当邻居看的时候，约翰似乎只从家走到商店，所以那个转换是唯一可用的选项——因此是 100%。

如果我生成一系列介于 1 到 100 之间的随机数，并适当地分配每个选项，那么我们就可以“与约翰同行”。所以我请[Claude 3](https://www.anthropic.com/news/claude-3-family) 帮忙：

![](https://cdn.thenewstack.io/media/2024/03/3bd665bb-untitled-1.png)

所以这就是从家开始的旅程。

| 随机数 | 约翰的旅程事件 |
|---|---|
| 42 | 约翰去商店 |
| 87 | 约翰从一家商店走到另一家商店 |
| 16 | 约翰回家 |
| 64 | 约翰去商店 |
| 29 | 约翰从一家商店走到另一家商店 |

最后还有一件事；数学家喜欢将这种类型的模型转换为**矩阵**。百分比机会始终被视为 0 到 1 之间的十进制数。

| 旅行 | 购物 | 聊天 |
|---|---|---|
| 旅行 | 0 | 1 | 0 |
| 购物 | 0.2 | 0.75 | 0.05 |
| 聊天 | 0 | 0.85 | 0.15 |

- **转换矩阵**始终是方阵或 n 乘 n 矩阵，其中大小由可能状态的数量决定。
- 行表示当前状态，列表示下一个状态。
- 每个当前状态（即行）的总概率为 1。

那么，什么时候马尔可夫链对于解决问题是有用的呢？基本上，当你想要对处于离散状态的事物进行建模时，但你不知道它是如何工作的。

你可能会想，“但约翰知道他在做什么，不是吗？”但我们正在观察约翰（也许是从爱管闲事的邻居那里），从观察者的角度来看，约翰的行为确实显得随机。数学并不是试图理解任何东西，它只是一个进行预测的平台。

我们在[状态机](https://thenewstack.io/state-machines-for-devs-from-blockchain-to-aws-to-tv-sets/)通常用于建模内部软件状态，而不是现实生活系统。

## 马尔可夫链在人工智能中的应用

马尔可夫链被用于预测文本的设计。随着模型获得并输入更多单词，一组新的统计数据将附加到更新的马尔可夫链中。

注意，即使添加了额外的单词，字母表中的字母也不会改变。只是概率权重会改变，并且会出现一些新的转换。我在糟糕的 [莎士比亚生成器](https://thenewstack.io/beware-chatgpt-a-language-model-in-the-shape-of-shakespeare/) 中对此进行了少量介绍。我们使用莎士比亚十四行诗的**语料库**，然后尝试计算一些权重。

当我们在英语中使用预测文本时，我们更有可能查看当前的两个字母，并使用它们。通过允许选择每个连续字母的概率取决于前一个字母或字母，我们获得了更精细的模型。因此，我们使用“标记”而不是单个字母。

因此，*2* 阶马尔可夫模型预测每个字母以固定概率出现，但该概率可能取决于前两个连续字母 (**)。您可能还遇到过术语 k-gram** **ngram**。例如，如果我们的语料库包含 100 个“th”的出现，其中 60 个出现“the”，25 个出现“thi”，10 个出现“tha”，5 个出现“tho”，则模型预测 2-gram “th” 后面的下一个字母为“e”的概率为 0.6，“i”的概率为 0.25，“a”的概率为 0.1，“o”的概率为 0.05。

![图片](https://cdn.thenewstack.io/media/2024/03/59f6aebb-untitled-2-750x1024.png)

*the、this、tha 或 tho*

在 Google 搜索栏中完成句子时，语料库是全球搜索词。但这个语料库非常庞大，以至于可以发现拼写错误——总体而言，这使得系统略有不同。

![图片](https://cdn.thenewstack.io/media/2024/03/cc366506-untitled-3-1024x289.png)

*你让我完整。*

如果您已经完成了相当数量的开发，那么您会对其中的大部分内容感到满意，因为信息链接链会不时以不同的形式出现。通过回到数学，您会发现未来的 AI 发展的神秘过去会减少。
