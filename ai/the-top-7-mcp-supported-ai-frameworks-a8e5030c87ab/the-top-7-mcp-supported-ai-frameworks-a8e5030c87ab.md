<!--
title: æ”¯æŒMCPçš„7å¤§AIæ¡†æ¶
cover: https://res.cloudinary.com/dkrpg71cx/image/upload/v1744523808/kkentw6wchisgct5u3tr.png
summary: æƒ³è®©ä½ çš„ LLM åƒå¼€äº†å¤–æŒ‚ï¼Ÿé€Ÿçœ‹ï¼è§£é” AI åº”ç”¨æ–°å§¿åŠ¿ï¼Œé›†æˆ MCP åè®®æ˜¯å…³é”®ï¼æœ¬æ–‡è¯¦è§£ MCP å¦‚ä½•èµ‹èƒ½ AI ä»£ç†ï¼Œå¯¹æ¥ OpenAI Agents SDK ç­‰ 7 å¤§æ¡†æ¶ï¼Œå®ç°ä¸ Git ç­‰å¤–éƒ¨å·¥å…·çš„æ— ç¼è¿æ¥ã€‚æ›´æœ‰ Composioã€OpenTools ç­‰æµ·é‡ MCP æœåŠ¡å™¨ç­‰ä½ æ¥æ¢ç´¢ï¼
-->
-->

æƒ³è®©ä½ çš„ LLM åƒå¼€äº†å¤–æŒ‚ï¼Ÿé€Ÿçœ‹ï¼è§£é” AI åº”ç”¨æ–°å§¿åŠ¿ï¼Œé›†æˆ MCP åè®®æ˜¯å…³é”®ï¼æœ¬æ–‡è¯¦è§£ MCP å¦‚ä½•èµ‹èƒ½ AI ä»£ç†ï¼Œå¯¹æ¥ OpenAI Agents SDK ç­‰ 7 å¤§æ¡†æ¶ï¼Œå®ç°ä¸ Git ç­‰å¤–éƒ¨å·¥å…·çš„æ— ç¼è¿æ¥ã€‚æ›´æœ‰ Composioã€OpenTools ç­‰æµ·é‡ MCP æœåŠ¡å™¨ç­‰ä½ æ¥æ¢ç´¢ï¼

> è¯‘è‡ªï¼š[The Top 7 MCP-Supported AI Frameworks](https://medium.com/@amosgyamfi/the-top-7-mcp-supported-ai-frameworks-a8e5030c87ab)
> 
> ä½œè€…ï¼šAmos Gyamfi

ä½¿ç”¨ Python å’Œ Typescript æ¡†æ¶åˆ›å»º AI åº”ç”¨ç¨‹åºï¼Œè¿™äº›æ¡†æ¶åˆ©ç”¨ MCP æœåŠ¡å™¨ä¸º LLM æä¾›ä¸Šä¸‹æ–‡ã€‚

[AI ä»£ç†å·¥å…·åŒ…](https://getstream.io/blog/ai-agent-toolkits/) å‘å¼€å‘äººå‘˜å…¬å¼€å„ç§ APIï¼Œä½¿ AI è§£å†³æ–¹æ¡ˆèƒ½å¤Ÿä½¿ç”¨å·¥å…·æ¥æ‰§è¡Œä»»åŠ¡å¹¶ç¡®ä¿å‡†ç¡®çš„ç»“æœï¼Œä»è€Œæé«˜ç”¨æˆ·æ»¡æ„åº¦ã€‚ä½†æ˜¯ï¼Œå°†è¿™äº›å·¥å…·é›†æˆåˆ° AI åº”ç”¨ç¨‹åºä¸­å¹¶å¯¹å…¶è¿›è¡Œç®¡ç†å¯èƒ½ä¼šå¾ˆéº»çƒ¦ã€‚æœ¬æ–‡å‘æ‚¨ä»‹ç»ä½¿ç”¨[æ¨¡å‹ä¸Šä¸‹æ–‡åè®®](https://modelcontextprotocol.io/introduction) (MCP) ä¸º LLM å’Œä»£ç†æä¾›ä¸Šä¸‹æ–‡çš„è¡Œä¸šæ ‡å‡†ã€‚

## LLM ä¸Šä¸‹æ–‡é…ç½®æ–¹æ³•å’Œè§„èŒƒ

é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœä¸ä¸º LLM å’Œ [AI èŠå¤©æœºå™¨äºº](https://getstream.io/chat/solutions/ai-integration/) æä¾›é€‚å½“çš„ä¸Šä¸‹æ–‡ï¼Œå®ƒä»¬å°†æ— æ³•è·å–å®æ—¶ä¿¡æ¯ã€æ‰§è¡Œä»£ç ã€è°ƒç”¨å¤–éƒ¨å·¥å…·å’Œ APIï¼Œç”šè‡³æ— æ³•ä»£è¡¨ç”¨æˆ·ä½¿ç”¨ Web æµè§ˆå™¨ã€‚å¼€å‘äººå‘˜å¯ä»¥åˆ©ç”¨ä»¥ä¸‹æ–¹æ³•æ¥è§£å†³ LLM å’Œä»£ç†çš„è¿™ä¸€é™åˆ¶ã€‚

- [Composio](https://composio.dev/): Composio å…·æœ‰ç”¨äºé›†æˆ AI ä»£ç†å’Œ LLM çš„è§„èŒƒå’Œå·¥å…·åŒ…åº“ã€‚é™¤äº† Composio çš„ç°æˆå·¥å…·åŒ…åº“ä¹‹å¤–ï¼Œä»–ä»¬æœ€è¿‘è¿˜å®£å¸ƒäº† [Composio MCP](https://mcp.composio.dev/?_gl=1*1tcsvb5*_ga*MTk0ODc0NjU2OS4xNzM3MjM1ODgx*_ga_J9WD56TEBS*MTc0MjQ1NTUwMC4yMC4wLjE3NDI0NTU1MDAuMC4wLjA.*_ga_YKMWVQS9W0*MTc0MjQ1NTUwMC4yMC4wLjE3NDI0NTU1MDAuNjAuMC4xNjQwNzI1NjY1)ï¼Œå…è®¸å¼€å‘äººå‘˜è¿æ¥åˆ° 100 å¤šä¸ªç”¨äº IDE çš„ MCP æœåŠ¡å™¨ã€‚ä»ä¸Šé¢çš„é“¾æ¥æŸ¥çœ‹ Composio MCP å·¥å…·ç±»åˆ«ï¼Œä»¥å°†å¤šä¸ªåº”ç”¨ç¨‹åºè¿æ¥åˆ° MCP æ”¯æŒçš„ IDEï¼ˆå¦‚ Cursorã€Claude å’Œ Windsurfï¼‰ä¸­çš„é¡¹ç›®ã€‚
- [Agents.json](https://docs.wild-card.ai/agentsjson/introduction): ä¸€ç§åŸºäº OpenAI æ ‡å‡†æ„å»ºçš„è§„èŒƒï¼Œæ—¨åœ¨ç¡®ä¿ [AI ä»£ç†](https://getstream.io/blog/xai-python-multi-agent/) åŠå…¶å¯¹ API å’Œå¤–éƒ¨å·¥å…·çš„è®¿é—®ä¹‹é—´çš„æ— ç¼å’Œå¢å¼ºçš„äº¤äº’ã€‚è™½ç„¶ Agent.json æ˜¯ä¸€ä¸ªå‡ºè‰²çš„è§„èŒƒï¼Œä½†å®ƒæ²¡æœ‰å¾—åˆ°å¹¿æ³›ä½¿ç”¨å’Œé‡‡ç”¨ï¼Œè¿™ä¸ MCP ä¸åŒã€‚è¯·å‚é˜…å…¶ [GitHub repo](https://github.com/wild-card-ai/agents-json) ä»¥äº†è§£æ›´å¤šä¿¡æ¯å¹¶å¼€å§‹ä½¿ç”¨ã€‚
- **MCP**: MCP ä¸ºå¼€å‘äººå‘˜æä¾›äº†å‘ LLM å’Œ AI åŠ©æ‰‹æä¾›ä¸Šä¸‹æ–‡æ•°æ®ä»¥è§£å†³é—®é¢˜çš„æœ€ä½³æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥æ„å»ºä¸€ä¸ª MCP æ–‡æ¡£æœåŠ¡å™¨ï¼Œä»¥åƒä½¿ç”¨ [llms.txt file](https://llmstxt.org/) ä¸€æ ·ï¼Œä¸º IDE å’Œä»£ç†æ¡†æ¶æä¾›å¯¹å…¶æ–‡æ¡£çš„å®Œå…¨è®¿é—®æƒé™ã€‚

## ä»€ä¹ˆæ˜¯ MCPï¼Ÿ

å°† MCP è§†ä¸º LLM çš„ç¬¬ä¸‰æ¬¡è¿›åŒ–ã€‚åœ¨ç¬¬ä¸€æ¬¡è¿›åŒ–ä¸­ï¼Œå¦‚æœ LLM åœ¨å…¶è®­ç»ƒæ•°æ®ä¸­æ‰¾åˆ°æŸ¥è¯¢ï¼Œå®ƒä»¬å°±èƒ½å¤Ÿå‡†ç¡®åœ°å›ç­”ç”¨æˆ·æç¤ºã€‚åœ¨æ­¤é˜¶æ®µï¼Œç”±äºä»–ä»¬æ— æ³•è®¿é—®å¤–éƒ¨å·¥å…·ï¼Œå› æ­¤ä»–ä»¬æ— æ³•æœ‰æ„ä¹‰åœ°å“åº”å…¶è®­ç»ƒæ•°æ®ä¹‹å¤–çš„æç¤ºã€‚åœ¨ LLM çš„ç¬¬äºŒæ¬¡è¿›åŒ–ä¸­ï¼Œæˆ‘ä»¬è®©ä»–ä»¬è®¿é—®é¢å¤–çš„ä¸Šä¸‹æ–‡ï¼ˆå·¥å…·ï¼‰ï¼Œè¿™äº›ä¸Šä¸‹æ–‡å¹¶ä¸å®¹æ˜“ä½¿ç”¨ã€‚ä½†æ˜¯ï¼Œå®ƒä»¬èƒ½å¤Ÿå¸®åŠ© LLM å‡†ç¡®åœ°é¢„æµ‹å’Œå›ç­”ç”¨æˆ·æ„å›¾ã€‚ç¬¬ä¸‰æ¬¡è¿›åŒ–ä»ç„¶ç”± LLM å’Œå·¥å…·ç»„æˆï¼Œä½†æˆ‘ä»¬å®æ–½äº†é€‚å½“çš„åŸºç¡€è®¾æ–½ï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿè®¿é—®å¤–éƒ¨åº”ç”¨ç¨‹åºå¹¶ç¡®ä¿å®ƒä»¬æ˜“äºç»´æŠ¤ã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*bCo43NBH4xnjZkyR)

åœ¨æ„å»º AI æœåŠ¡æ—¶ï¼Œæ‚¨çš„æ•°æ®å¯èƒ½ä½äºäº‘ä¸­ï¼Œç”¨äºåœ¨ä¼ä¸šç¯å¢ƒä¸­å›ç­” [å®¢æˆ·æ”¯æŒ](https://getstream.io/blog/build-a-customer-support-chat-bot-with-luis-react-hooks-azure-serverless-and-stream/) å·¥å•çš„ AI åŠ©æ‰‹åº”ç”¨ç¨‹åºã€‚[MCP](https://www.anthropic.com/news/model-context-protocol) æ˜¯æ¥è‡ª [Anthropic](https://www.anthropic.com/) çš„å¼€æºåè®®ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒå°†æ‚¨çš„ä¼ä¸šæ•°æ®è¿æ¥åˆ° AI ç³»ç»Ÿã€‚

å®ƒæä¾›äº†ä¸€ç§æ ‡å‡†æ–¹å¼æ¥è¿æ¥å†…å®¹å­˜å‚¨åº“ï¼ˆGitHubã€Notionï¼‰ã€å¼€å‘ç¯å¢ƒã€Web å’Œ [ä¸šåŠ¡å·¥å…·](https://github.com/atharvagupta2003/mcp-stripe) åˆ°è¾…åŠ© AI æŠ€æœ¯ã€‚MCP çš„ä¸€ä¸ªæµè¡Œçš„ä¸”ä¸æ–­å¢é•¿çš„ç”¨ä¾‹æ˜¯ AI è¾…åŠ©ç¼–ç ã€‚æ•°ç™¾ä¸ªä¸å¼€å‘ç¯å¢ƒå’Œå·¥å…·ï¼ˆå¦‚ [Cursor](https://docs.cursor.com/context/model-context-protocol) å’Œ [Windsurf](https://docs.codeium.com/windsurf/mcp)ï¼‰çš„ MCP é›†æˆå…è®¸å¼€å‘äººå‘˜è¿æ¥å¤–éƒ¨åº”ç”¨ç¨‹åºå¹¶ä¸ä¹‹äº¤äº’ä»¥è¿›è¡Œå¼€å‘ã€‚

**æ³¨æ„**ï¼šæœ¬æ–‡æ—¨åœ¨å®ç° MCP ä¸ AI åŠ©æ‰‹å’Œä»£ç†ç³»ç»Ÿå¼€å‘äººå‘˜ä½¿ç”¨ Python å’Œ TypeScript æ„å»ºçš„é›†æˆï¼Œè€Œä¸æ˜¯åŸºäº IDE çš„ MCP é›†æˆã€‚

## MCP çš„å·¥ä½œåŸç†

åœ¨ LLM å’Œä»£ç†çš„ä¸Šä¸‹æ–‡ä¸­ï¼ŒMCP ååŠ©ä»–ä»¬å¯¹ç”¨æˆ·æŸ¥è¯¢æä¾›è¶…å‡ºå…¶å†…ç½®çŸ¥è¯†çš„æœ‰æ„ä¹‰çš„å“åº”ã€‚ä¾‹å¦‚ï¼Œè¦æ±‚ ChatGPT å‘ç‰¹å®šçš„ Slack é¢‘é“å‘é€æ¶ˆæ¯ã€æ£€æŸ¥æ‚¨æ—¥å†ä¸Šçš„å¯ç”¨æ€§ä»¥åŠå®‰æ’ä»Šå¤©ä¸å›¢é˜Ÿæˆå‘˜çš„ä¼šè®®ã€‚æ‚¨ä¼šå¯¹ ChatGPT çš„å“åº”æ„Ÿåˆ°å¤±æœ›ï¼Œå› ä¸ºå®ƒæ— æƒè®¿é—®è¿™äº›åº”ç”¨ç¨‹åºã€‚MCP çš„å®æ–½æœ‰åŠ©äºè¿™äº›åŠ©æ‰‹è¾“å‡ºæœ‰ç”¨çš„ç»“æœã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*UW4NCgcpQthyMFk4)

å¼€å‘è€…é€šå¸¸ä¼šé—®çš„ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ MCP å¦‚ä½•å·¥ä½œã€‚åœ¨ MCP çš„åŸºæœ¬æ“ä½œä¸­ï¼Œç”¨æˆ·å‘ä»£ç†å‘é€æŸ¥è¯¢ã€‚ç„¶åï¼Œä»£ç†å†³å®šè°ƒç”¨å“ªä¸ª MCP æœåŠ¡å™¨å’Œå·¥å…·æ¥è·å–æ“ä½œçš„ç›¸å…³ä¿¡æ¯ã€‚ç„¶åï¼Œä»£ç†ä½¿ç”¨æ¥è‡ªç‰¹å®šå·¥å…·çš„æ•°æ®æ¥å“åº”ç”¨æˆ·ã€‚

### ä¸ºä»€ä¹ˆä¸º AI ä»£ç†å’ŒåŸºäº LLM çš„åº”ç”¨é‡‡ç”¨ MCPï¼Ÿ

MCP æ­£åœ¨æˆä¸ºä¸€ç§æ ‡å‡†ï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…æ„å»º AI ç³»ç»Ÿï¼Œä½¿è¿™äº›ç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆåœ°ä¸å…¶ä»–å¤–éƒ¨åº”ç”¨ç¨‹åºé€šä¿¡ã€‚å¾®è½¯æœ€è¿‘å®£å¸ƒåœ¨å…¶ [Copilot Studio](https://www.microsoft.com/en-us/microsoft-copilot/blog/copilot-studio/introducing-model-context-protocol-mcp-in-copilot-studio-simplified-integration-with-ai-apps-and-agents/) ä¸­é›†æˆ MCPï¼Œä»¥ç®€åŒ– AI åº”ç”¨å’Œä»£ç†è®¿é—®å·¥å…·çš„æ–¹å¼ã€‚æ­¤å¤–ï¼ŒOpenAI å·²ç»[å®£å¸ƒ](https://x.com/sama/status/1904957253456941061)åœ¨å…¶äº§å“ï¼ˆå¦‚ [Agents SDK](https://openai.github.io/openai-agents-python/) å’Œ ChatGPT çš„æ¡Œé¢åº”ç”¨ï¼‰ä¸­æ”¯æŒ MCPã€‚ç›´æ¥ä¸º AI åŠ©æ‰‹é…å¤‡å·¥å…·å¹¶æ²¡æœ‰é”™ã€‚ä½†æ˜¯ï¼Œå¯¹äºç”±å¤šä¸ªæ‰§è¡Œå¤šé¡¹ä»»åŠ¡çš„å¤šä»£ç†ç»„æˆçš„ AI ä»£ç†ç³»ç»Ÿæ¥è¯´ï¼Œè¿™ä¼šå˜å¾—å¾ˆéº»çƒ¦ï¼Œä¾‹å¦‚è¯»å–å’Œå›å¤ç”µå­é‚®ä»¶ã€è¿›è¡Œç½‘ç»œæŠ“å–ã€è´¢åŠ¡åˆ†æã€è·å–å®æ—¶å¤©æ°”ä¿¡æ¯ç­‰ã€‚

### å…·æœ‰å·¥å…·é›†æˆçš„ AI ä»£ç†

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*zaNoKiaMbyIEmEMJ)

åœ¨ä¸Šå›¾ä¸­ï¼Œä¸‰ä¸ªå¤–éƒ¨å·¥å…·è¿æ¥åˆ° LLMã€‚å¦‚æœæ•°é‡å¢åŠ åˆ° 100+ï¼Œç®¡ç†å’Œä¿æŠ¤æ‰€æœ‰è¿™äº›å·¥å…·å°†ä¼šä»¤äººæ²®ä¸§ã€‚ä¸€ç§æ”¹è¿›çš„æ–¹æ³•æ˜¯é€šè¿‡ MCP æ³¨å†Œè¡¨è®¿é—®ç›¸åŒçš„å·¥å…·æˆ–è¶…è¿‡ 100+ çš„å·¥å…·ï¼Œå¦‚ä¸‹ä¸€èŠ‚æ‰€ç¤ºã€‚

### å…·æœ‰ MCP é›†æˆçš„ AI ä»£ç†

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*NFs1Hl2LIrxKzADp)

åœ¨æ­¤å›¾ä¸­ï¼Œæˆ‘ä»¬ç»„åˆäº†ä»£ç†ç³»ç»Ÿæ‰€éœ€çš„å·¥å…·ï¼Œå¹¶é€šè¿‡ MCP æœåŠ¡å™¨è®¿é—®å®ƒä»¬ï¼Œä»¥æä¾›æ›´å…·å‡èšåŠ›çš„ç”¨æˆ·ä½“éªŒã€‚MCP æ–¹æ³•ä½¿é€šè¿‡ä¸­å¿ƒä½ç½®ä¿æŠ¤å’Œç®¡ç†è¿™äº›å·¥å…·å˜å¾—æ›´åŠ å®¹æ˜“ã€‚

### ä½¿ç”¨ MCP ä¼˜äºä¼ ç»Ÿå·¥å…·åŒ…é›†æˆçš„ä¼˜åŠ¿

ä¸ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å°†å·¥å…·ä¸ AI ä»£ç†é›†æˆç›¸æ¯”ï¼ŒMCP å…·æœ‰å‡ ä¸ªå…³é”®ä¼˜åŠ¿ã€‚ä¾‹å¦‚ï¼Œæ²¡æœ‰ MCP çš„å·¥å…·é›†æˆçš„å¯é æ€§å€¼å¾—æ€€ç–‘ï¼Œå› ä¸ºå®ƒåœ¨ç”±äºä¸å…¼å®¹çš„ AI åŸºç¡€è®¾æ–½è€Œå¯¹å¤–éƒ¨åº”ç”¨ç¨‹åºè¿›è¡Œå¤šæ¬¡ API è°ƒç”¨æ—¶å¯èƒ½å¯¼è‡´å¤šä¸ªé”™è¯¯ã€‚åœ¨ MCP ä¹‹å‰ï¼Œæ‚¨æƒ³è¦æ·»åŠ åˆ°ä»£ç†çš„æ¯ä¸ªå·¥å…·éƒ½å¿…é¡»ä½¿ç”¨è‡ªå®šä¹‰ä»£ç æ¥å®ç°ï¼Œè¿™éœ€è¦å‡ å‘¨çš„æ—¶é—´æ‰èƒ½å®ç°ã€‚

- **æ¶æ„**ï¼šä¸ AI ä»£ç†çš„é¢„æ„å»ºå·¥å…·è§„èŒƒä¸åŒï¼ŒMCP å…·æœ‰ç”¨äºä¸å·¥å…·å’Œ API äº¤äº’çš„æ¸…æ™°çµæ´»çš„æ¶æ„ã€‚
- **æ”¹è¿›çš„å¤–éƒ¨å·¥å…·è®¿é—®å’Œç®¡ç†**ï¼šå®ƒé€šè¿‡æ ‡å‡†åŒ–æ¥å£ä¸º AI æ¨¡å‹æä¾›å·¥å…·è®¿é—®ï¼Œä»¥å¼¥åˆ LLM ä¸å…¶ä¸ç¬¬ä¸‰æ–¹ç³»ç»Ÿäº¤äº’ä¹‹é—´çš„é€šä¿¡å·®è·ã€‚
- **è§£å†³äº†ç‹¬ç«‹å·¥å…·å®ç°çš„å±€é™æ€§**ï¼šMCP å·¥å…·é€‚ç”¨äºå•ç”¨æˆ·åœºæ™¯å’Œå›¢é˜Ÿã€‚
- **ç¤¾åŒºé©±åŠ¨**ï¼šMCP æœ‰è®¸å¤šå¼€æºæœåŠ¡å™¨å’Œä¸€ä¸ªå¼€å‘è€…ç”Ÿæ€ç³»ç»Ÿã€‚å®ƒè¿˜åœ¨å¼€å‘è€…ç¤¾åŒºä¸­è¢«å¹¿æ³›é‡‡ç”¨ï¼Œç”¨äºè®¸å¤šç”¨ä¾‹ã€‚
- **èº«ä»½éªŒè¯**ï¼šå®ƒå…·æœ‰å¼ºå¤§çš„å†…ç½®èº«ä»½éªŒè¯å’Œæƒé™ç³»ç»Ÿæ¥æ§åˆ¶å·¥å…·è®¿é—®ã€‚ä¾‹å¦‚ï¼Œå½“ä½¿ç”¨ Composio æä¾›çš„ MCP å·¥å…·æ—¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ Google Sheets æˆ– Gmail å¯¹ç”¨æˆ·è¿›è¡Œèº«ä»½éªŒè¯ã€‚
- **å·¥å…·æœç´¢**ï¼šä¸å®‰è£…ã€é…ç½®å’Œå°†å·¥å…·ä¸ AI èŠå¤©æœºå™¨äººé›†æˆçš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒMCP ä½¿æœç´¢å’ŒæŸ¥æ‰¾å¤–éƒ¨å·¥å…·å˜å¾—æ›´åŠ å®¹æ˜“ã€‚
- **å¯æ‰©å±•æ€§**ï¼šMCP æ˜“äºæ‰©å±•åˆ°è®¸å¤šç”¨æˆ·å’Œåº”ç”¨ç¨‹åºã€‚
- **è¡Œä¸šæ ‡å‡†**ï¼šæ‚¨å¯ä»¥å®‰è£…ç¡¬ç¼–ç å·¥å…·æ¥ä¸º AI åº”ç”¨ç¨‹åºæä¾›ä¸Šä¸‹æ–‡ã€‚ä½†æ˜¯ï¼ŒMCP æä¾›äº†ä¸€ä¸ªè¡Œä¸šæ ‡å‡†ï¼Œä¸ºä»£ç†å’Œ LLM æä¾›æ‰€éœ€çš„ä¸Šä¸‹æ–‡ã€‚

### MCP æœåŠ¡å™¨çš„ç§ç±»

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*rfOg6ug_UQ_gtiJt)

Anthropic çš„ MCP è§„èŒƒæœ‰ä¸¤ç§æœåŠ¡å™¨å½¢å¼ï¼Œç”¨äºå‘ä»£ç†å’Œ AI é¡¹ç›®æ·»åŠ å·¥å…·ã€‚è¿™äº› MCP æœåŠ¡å™¨è¿æ¥ç±»å‹åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ã€‚

- **æœåŠ¡å™¨å‘é€äº‹ä»¶ (SSE)**ï¼šé€šè¿‡ HTTP è¿æ¥åˆ°è¿œç¨‹æœåŠ¡ã€‚
- **STDIO**ï¼šå…è®¸æ‰§è¡Œæœ¬åœ°å‘½ä»¤å¹¶é€šè¿‡æ ‡å‡† I/O è¿›è¡Œé€šä¿¡ã€‚

æ‚¨é€‰æ‹©æ„å»º AI åº”ç”¨ç¨‹åºçš„æ¡†æ¶æä¾›äº†è¿æ¥åˆ°è¿™äº›æœåŠ¡å™¨æ‰€éœ€çš„ç±»ã€‚

### è®¿é—® MCP æ³¨å†Œè¡¨/æœåŠ¡å™¨çš„ç”Ÿæ€ç³»ç»Ÿ

æœ‰å‡ ä¸ªæ‰˜ç®¡ MCP å·¥å…·çš„å¼€æºåº“å¯ä»¥å¢å¼º LLM å’Œä»£ç†ï¼Œä»¥ç¡®ä¿å®ƒä»¬ç”Ÿæˆçš„å“åº”çš„å¯é æ€§ã€‚è¿™äº›æ‰˜ç®¡ MCP å·¥å…·çš„åº“ç§°ä¸ºæ³¨å†Œè¡¨ï¼Œæä¾›ç²¾é€‰çš„æœåŠ¡é›†åˆã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®ƒä»¬çš„å·¥å…·å°†æ‚¨çš„ AI åº”ç”¨ç¨‹åºè¿æ¥åˆ°ä»¥ä¸‹æ³¨å†Œè¡¨ã€‚æ­¤å¤–ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä¸åŒçš„æœåŠ¡å™¨ç±»å‹ï¼Œä¾‹å¦‚ `uvx`ï¼Œå®ƒç”±åŸºäº Python çš„å·¥å…·ç»„æˆï¼Œæ— éœ€å®‰è£…è¦æ±‚ã€‚è¿˜æœ‰ä¸€ä¸ªç”¨äºè¿è¡Œ MCP å·¥å…·çš„ Docker é€‰é¡¹å’Œä¸€ä¸ªåŸºäº `npx` çš„æœåŠ¡å™¨ï¼Œéœ€è¦å®‰è£… Node.jsã€‚

- [GitHub ä¸Šçš„ MCP æœåŠ¡å™¨](https://github.com/modelcontextprotocol/servers)ï¼šä¸€ä¸ªç”±ç¤¾åŒºæ„å»ºçš„æœåŠ¡å™¨é›†åˆï¼ŒåŒ…å«é¢å¤–çš„ MCP èµ„æºã€‚
- [Glama Registry](https://glama.ai/mcp/servers?attributes=category%3Abrowser-automation)ï¼šä¸ºå¼€å‘è€…æä¾›çš„ç”Ÿäº§å°±ç»ªå‹å¼€æº MCP æœåŠ¡å™¨ã€‚
- **Smithery Registry**ï¼šé€šè¿‡[Smithery](https://smithery.ai/)ï¼Œå¼€å‘è€…å¯ä»¥è®¿é—® 2000 å¤šä¸ª MCP æœåŠ¡å™¨ï¼Œä»¥å¢å¼º AI ä»£ç†å’Œ LLM çš„èƒ½åŠ›ã€‚
- **OpenTools**ï¼š[OpenTools](https://opentools.com/) ä¸º MCP å·¥å…·çš„ä½¿ç”¨æä¾›ç”Ÿæˆå¼ APIã€‚æ‚¨å¯ä»¥è®¿é—®æ•°ç™¾ä¸ªç°æˆçš„ MCP å·¥å…·ï¼Œä»¥åœ¨æ‚¨çš„ AI é¡¹ç›®ä¸­å®æ–½ã€‚ä½¿ç”¨ OpenTools APIï¼Œå¼€å‘è€…å¯ä»¥æ‰©å±• LLM çš„ç½‘ç»œæœç´¢ã€è·å–å®æ—¶ä½ç½®æ•°æ®å’Œç½‘ç»œæŠ“å–åŠŸèƒ½ã€‚è¯¥ API æ”¯æŒ Curlã€Python å’Œ TypeScriptã€‚è®¿é—® OpenTools [å¿«é€Ÿå…¥é—¨æŒ‡å—](https://opentools.com/docs/quickstart) ä»¥ä½¿ç”¨è¯¥ APIã€‚

```python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.opentools.com",
    api_key="<OPENTOOLS_API_KEY>"
)

completion = client.chat.completions.create(
    model="anthropic/claude-3.7-sonnet",
    messages=[
        { "role": "user", "content": "Compare specs of top 5 EVs on caranddriver.com" }
    ],
    tools=[{ "type": "mcp", "ref": "firecrawl" }]
)
```

- [PulseMCP Registry](https://www.pulsemcp.com/)ï¼šä½¿ç”¨ PulseMCPï¼Œæ‚¨å¯ä»¥æµè§ˆæ‰˜ç®¡çš„ MCP å·¥å…·å’Œ AI é¡¹ç›®çš„ç”¨ä¾‹ã€‚æŸ¥çœ‹ [PulseMCP æ–°é—»](https://www.pulsemcp.com/posts)ï¼Œäº†è§£æœ€è¿‘æµè¡Œçš„ MCP æœåŠ¡å™¨å’Œåº”ç”¨ç¨‹åºã€‚
- [mcp.run](https://www.mcp.run/)ï¼šæ­¤æ³¨å†Œè¡¨ä½¿å¼€å‘è€…å¯ä»¥è®¿é—®æ•°ç™¾ä¸ªç”¨äºå…¶ä¸šåŠ¡çš„ MCP åº”ç”¨ç¨‹åºã€‚
- [Composio Registry](https://mcp.composio.dev/)ï¼šComposio åŸºäº SSE çš„ MCP æœåŠ¡å™¨å…è®¸å°†å·¥å…·ä¸ä¸åŒçš„ AI æ¡†æ¶è½»æ¾é›†æˆï¼Œä»¥æ„å»ºåº”ç”¨ç¨‹åºã€‚
- [guMCP](https://www.gumloop.com/mcp)ï¼šGumloop çš„ guMCP æä¾›å…è´¹ã€å¼€æºä¸”å®Œå…¨æ‰˜ç®¡çš„ [MCP æœåŠ¡å™¨](https://github.com/gumloop/GuMCP)ï¼Œå¯ä¸ä»»ä½• AI åº”ç”¨ç¨‹åºæ— ç¼é›†æˆã€‚

## å°† MCP æ·»åŠ åˆ° LLM å’Œ Agent çš„ 7 å¤§å®¢æˆ·ç«¯æ¡†æ¶

è™½ç„¶ MCP å·²æˆä¸ºä¸€ä¸ªæµè¡Œè¯­ï¼Œå¹¶ä¸”æ‰€æœ‰å¼€å‘è€…ç¤¾åŒºæœ€è¿‘éƒ½åœ¨è®¨è®ºå®ƒï¼Œä½†è¦çŸ¥é“ä½¿ç”¨å“ªäº› MCP å®¢æˆ·ç«¯æ¡†æ¶ä¸ AI åº”ç”¨ç¨‹åºå’Œä»£ç†é›†æˆå¹¶ä¸å®¹æ˜“ã€‚æˆ‘ä»¬ç ”ç©¶å¹¶æ‰¾åˆ°äº†ä»¥ä¸‹é¢†å…ˆçš„ MCP å®¢æˆ·ç«¯å¹³å°ï¼Œç”¨äºåŸºäº Python å’Œ TypeScript çš„ä»£ç†å·¥ä½œæµç¨‹å’Œ AI åŠ©æ‰‹ã€‚

**æ³¨æ„**ï¼šä»¥ä¸‹éƒ¨åˆ†æ¼”ç¤ºäº†åœ¨ç”¨äºæ„å»º AI è§£å†³æ–¹æ¡ˆçš„æ¡†æ¶ä¸­ MCP çš„å®ç°ï¼Œè€Œä¸æ˜¯ MCP ä¸ AI ä»£ç ç¼–è¾‘å™¨ï¼ˆå¦‚ Cursor æˆ– Windsurfï¼‰çš„é›†æˆã€‚

## 1. ä½¿ç”¨ OpenAI Agents SDK æ„å»º Git MCP ä»£ç†

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*ES4r_jccFu1U2JrK)

åœ¨ä½¿ç”¨ [OpenAI Agents SDK](https://openai.github.io/openai-agents-python/mcp/) æ„å»ºä»£ç†æ—¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ SDK çš„ [MCPServerSse](https://openai.github.io/openai-agents-python/ref/mcp/server/#agents.mcp.server.MCPServerSse) å’Œ [MCPServerStdio](https://openai.github.io/openai-agents-python/ref/mcp/server/#agents.mcp.server.MCPServerStdio) ç±»è¿æ¥åˆ°è¿™äº›ç¤¾åŒºæ„å»ºçš„ MCP æœåŠ¡å™¨ã€‚ä»¥ä¸‹ MCP ä»£ç†å®ç°è®¿é—®æœ¬åœ° Git å­˜å‚¨åº“çš„æ ¹ç›®å½•ï¼Œå¹¶å“åº”ç”¨æˆ·å…³äºè¯¥å­˜å‚¨åº“çš„æŸ¥è¯¢ã€‚

```python
import asyncio
import shutil
import streamlit as st
from agents import Agent, Runner, trace
from agents.mcp import MCPServer, MCPServerStdio

async def query_git_repo(mcp_server: MCPServer, directory_path: str, query: str):
    agent = Agent(
        name="Assistant",
        instructions=f"Answer questions about the localgit repository at {directory_path}, use that for repo_path",
        mcp_servers=[mcp_server],
    )

    with st.spinner(f"Running query: {query}"):
        result = await Runner.run(starting_agent=agent, input=query)
        return result.final_output

async def run_streamlit_app():
    st.title("Local Git Repo Explorer")
    st.write("This app allows you to query information about a local git repository.")

    directory_path = st.text_input("Enter the path to the git repository:")

    if directory_path:
        # Common queries as buttons
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Most frequent contributor"):
                query = "Who's the most frequent contributor?"
                run_query(directory_path, query)

        with col2:
            if st.button("Last change summary"):
                query = "Summarize the last change in the repository."
                run_query(directory_path, query)

        # Custom query
        custom_query = st.text_input("Or enter your own query:")
        if st.button("Run Custom Query") and custom_query:
            run_query(directory_path, custom_query)

def run_query(directory_path, query):
    if not shutil.which("uvx"):
        st.error("uvx is not installed. Please install it with `pip install uvx`.")
        return

    async def execute_query():
        async with MCPServerStdio(
            cache_tools_list=True,
            params={
                "command": "python", 
                "args": [
                    "-m", 
                    "mcp_server_git", 
                    "--repository", 
                    directory_path
                ]
            },
        ) as server:
            with trace(workflow_name="MCP Git Query"):
                result = await query_git_repo(server, directory_path, query)
                st.markdown("### Result")
                st.write(result)

    asyncio.run(execute_query())

if __name__ == "__main__":
    st.set_page_config(
        page_title="Local Git Repo Explorer",
        page_icon="ğŸ“Š",
        layout="centered"
    )
    # Change from async to synchronous implementation
    # Since Streamlit doesn't work well with asyncio in the main thread

    # Define a synchronous version of our app
    def main_streamlit_app():
        st.title("Local Git Repo Explorer")
        st.write("This app allows you to query information about a Git repository.")

        directory_path = st.text_input("Enter the path to the git repository:")

        if directory_path:
            # Common queries as buttons
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Most frequent contributor"):
                    query = "Who's the most frequent contributor?"
                    run_query(directory_path, query)

            with col2:
                if st.button("Last change summary"):
                    query = "Summarize the last change in the repository."
                    run_query(directory_path, query)

            # Custom query
            custom_query = st.text_input("Or enter your own query:")
            if st.button("Run Custom Query") and custom_query:
                run_query(directory_path, custom_query)

    # Run the synchronous app
    main_streamlit_app()
```

ä¸Šé¢çš„ä»£ç å°† Streamlit ä¸ OpenAI MCP ä»£ç†é›†æˆï¼Œå…è®¸æ‚¨ä½¿ç”¨ [Git MCP æœåŠ¡å™¨](https://github.com/modelcontextprotocol/servers/tree/main/src/git) ä¸æœ¬åœ° Git ä»“åº“èŠå¤©ã€‚è¦è¿è¡Œæ­¤ç¤ºä¾‹ï¼Œæ‚¨åº”è¯¥å®‰è£…ä»¥ä¸‹å†…å®¹ã€‚

```bash
pip install streamlit openai-agents mcp-server-git
```

ç„¶åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯¼å‡ºæ‚¨çš„ OpenAI API å¯†é’¥

```bash
export OPENAI_API_KEY=sk-...
```

è¿è¡Œ Python æ–‡ä»¶æ—¶ï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼äºæ­¤é¢„è§ˆçš„ç»“æœã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*7Kamfw6StW-9vgEGpeq-KQ.gif)

æ‚¨å¯ä»¥åœ¨ [GitHub](https://github.com/openai/openai-agents-python/tree/main/examples/mcp) ä¸Šæµè§ˆ OpenAI MCP çš„å…¶ä»–ç¤ºä¾‹ã€‚

ä½¿ç”¨ Agents SDK çš„ MCP é›†æˆçš„ä¸€ä¸ªä¼˜åŠ¿æ˜¯å…¶å†…ç½®çš„ MCP ä»£ç† [ç›‘æ§ç³»ç»Ÿ](https://openai.github.io/openai-agents-python/tracing/) åœ¨ OpenAI çš„ä»ªè¡¨æ¿ä¸Šã€‚æ­¤åŠŸèƒ½ä¼šè‡ªåŠ¨æ•è·æ‚¨ä»£ç†çš„ MCP æ“ä½œï¼Œä¾‹å¦‚å·¥å…·åˆ—è¡¨ã€`POST` å“åº”ä»¥åŠè·å–æœ‰å…³å‡½æ•°è°ƒç”¨çš„æ•°æ®ã€‚ä¸‹å›¾è¡¨ç¤ºè¿è¡Œä¸Šè¿°ä»£ç åï¼Œæœ¬èŠ‚ä¸­ Git MCP ç¤ºä¾‹çš„è·Ÿè¸ªã€‚æ‚¨å¯ä»¥ä» OpenAI çš„ä»ªè¡¨æ¿è®¿é—®æ‰€æœ‰è®°å½•çš„ä¿¡æ¯ã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*IuN2AHFf1Lhwpnbg)

## 2. ä½¿ç”¨ Praison AI æ„å»º MCP AI ä»£ç†

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*QG0ihBHt0brpSMJI)

[Praison AI](https://docs.praison.ai/) æ˜¯ä¸€ä¸ªåŸºäº Python çš„ AI æ¡†æ¶ï¼Œç”¨äºæ„å»ºä»£ç†å›¢é˜Ÿã€‚å®ƒæä¾›äº†ä»¥å•è¡Œä»£ç å°† MCP æœåŠ¡å™¨å·¥å…·æ·»åŠ åˆ°ä»£ç†å·¥ä½œæµç¨‹çš„æœ€ç®€å•æ–¹æ³•ï¼Œå°±åƒæ‚¨ä¸ºä»£ç†é…å¤‡ä¼ ç»Ÿå·¥å…·ä¸€æ ·ã€‚

ä»¥ä¸‹ç¤ºä¾‹å°† [Airbnb MCP æœåŠ¡å™¨](https://github.com/openbnb-org/mcp-server-airbnb) ä¸ Praison AI ä»£ç†é›†æˆï¼Œä½¿ç”¨ Streamlit UI æ¥å¸®åŠ©æŸ¥æ‰¾æŒ‡å®šä½ç½®çš„å…¬å¯“ã€‚æ‚¨åº”è¯¥å®‰è£…è¿™äº›æ¥ä½¿ç”¨ Praison AI åˆ›å»ºæ‚¨çš„ç¬¬ä¸€ä¸ª MCP ä»£ç†ã€‚

```bash
pip install praisonaiagents mcp streamlit
```

æ¥ä¸‹æ¥ï¼Œå¯¼å‡ºæ‚¨çš„ OpenAI API å¯†é’¥

```bash
export OPENAI_API_KEY='sk-proj-qZIGbi...`
```

åˆ›å»ºä¸€ä¸ª Python æ–‡ä»¶ï¼Œä¾‹å¦‚ **streamlit_praison_airbnb_mcp_agent.py**ï¼Œå¹¶ä½¿ç”¨æ­¤ä»£ç å¡«å……å…¶å†…å®¹ã€‚

```python
import streamlit as st
from praisonaiagents import Agent, MCP

st.title("ğŸ  Airbnb Booking Assistant")

# Create the agent
@st.cache_resource
def get_agent():
    return Agent(
        instructions="""You help book apartments on Airbnb.""",
        llm="gpt-4o-mini",
        tools=MCP("npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt")
    )

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# User input form
with st.form("booking_form"):
    st.subheader("Enter your booking details")

    destination = st.text_input("Destination:", "Paris")

    col1, col2 = st.columns(2)
    with col1:
        check_in = st.date_input("Check-in date")
    with col2:
        check_out = st.date_input("Check-out date")

    adults = st.number_input("Number of adults:", min_value=1, max_value=10, value=2)

    submitted = st.form_submit_button("Search for accommodations")

    if submitted:
        search_agent = get_agent()

        # Format the query
        query = f"I want to book an apartment in {destination} from {check_in.strftime('%m/%d/%Y')} to {check_out.strftime('%m/%d/%Y')} for {adults} adults"

        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": query})

        # Display user message
        with st.chat_message("user"):
            st.markdown(query)

        # Get response from the agent
        with st.chat_message("assistant"):
            with st.spinner("Searching for accommodations..."):
                response = search_agent.start(query)
                st.markdown(response)

        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": response})

# Allow for follow-up questions
if st.session_state.messages:
    prompt = st.chat_input("Ask a follow-up question about the accommodations")
    if prompt:
        search_agent = get_agent()

        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Display user message
        with st.chat_message("user"):
            st.markdown(prompt)

        # Get response from the agent
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                response = search_agent.start(prompt)
                st.markdown(response)

        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": response}) 
```

è¿è¡Œç¤ºä¾‹ä»£ç å°†è°ƒç”¨æ‰€éœ€çš„ Airbnb MCP å·¥å…·ï¼Œä»¥åœ¨ç‰¹å®šä½ç½®ä¸ºæ‚¨æŸ¥æ‰¾å…¬å¯“ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*93CrDz5wcJANv460ikv6Eg.gif)

æ‚¨å·²ç»æ³¨æ„åˆ°å®ƒé€šè¿‡å•è¡Œä»£ç  `tools=MCP("npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt")` å‘ä»£ç†æ·»åŠ äº† MCP æ”¯æŒï¼Œå…¶ä¸­ `npx` è¡¨ç¤ºè¦è¿è¡Œä»¥å¯åŠ¨ MCP æœåŠ¡å™¨çš„å‘½ä»¤ã€‚`-y` æ˜¯è¦ä¼ é€’ç»™å‘½ä»¤çš„å‘½ä»¤è¡Œå‚æ•°ã€‚è¯·å‚é˜… OpenAI Agents SDK æ–‡æ¡£ä¸­çš„ [MCP Servers](https://openai.github.io/openai-agents-python/ref/mcp/server/) ä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚

## 3. å°† MCP ç”¨äº LangChain AI åº”ç”¨

[LangChain](https://www.langchain.com/) å…·æœ‰å¯¹ [MCP](https://github.com/rectalogic/langchain-mcp/tree/main) çš„å·¥å…·è°ƒç”¨æ”¯æŒã€‚æ­¤æ”¯æŒå…è®¸æ‚¨è®¾ç½® Python å‡½æ•°ä»¥è®¿é—®ä¸åŒçš„ MCP æœåŠ¡å™¨å¹¶æ£€ç´¢å·¥å…·ï¼Œä»¥åœ¨ AI é¡¹ç›®ä¸­æ‰§è¡Œä»»åŠ¡ã€‚ä¸‹é¢çš„ç¤ºä¾‹ä»£ç è¿æ¥åˆ°å®‰å…¨çš„ MCP æ–‡ä»¶ç³»ç»ŸæœåŠ¡å™¨ï¼Œä½¿ LLM èƒ½å¤Ÿå‡†ç¡®åœ°å›ç­”æœ‰å…³æ‚¨æä¾›çš„ä»»ä½•æ–‡ä»¶çš„é—®é¢˜ã€‚

```python
# Copyright (C) 2024 Andrew Wason
# SPDX-License-Identifier: MIT
import asyncio
import pathlib
import sys
import typing as t

from langchain_core.messages import AIMessage, BaseMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.tools import BaseTool
from langchain_groq import ChatGroq
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain_mcp import MCPToolkit


async def run(tools: list[BaseTool], prompt: str) -> str:
    model = ChatGroq(model_name="llama-3.1-8b-instant", stop_sequences=None)  # requires GROQ_API_KEY
    tools_map = {tool.name: tool for tool in tools}
    tools_model = model.bind_tools(tools)
    messages: list[BaseMessage] = [HumanMessage(prompt)]
    ai_message = t.cast(AIMessage, await tools_model.ainvoke(messages))
    messages.append(ai_message)
    for tool_call in ai_message.tool_calls:
        selected_tool = tools_map[tool_call["name"].lower()]
        tool_msg = await selected_tool.ainvoke(tool_call)
        messages.append(tool_msg)
    return await (tools_model | StrOutputParser()).ainvoke(messages)


async def main(prompt: str) -> None:
    server_params = StdioServerParameters(
        command="npx",
        args=["-y", "@modelcontextprotocol/server-filesystem", str(pathlib.Path(__file__).parent.parent)],
    )
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            toolkit = MCPToolkit(session=session)
            await toolkit.initialize()
            response = await run(toolkit.get_tools(), prompt)
            print(response)


if __name__ == "__main__":
    prompt = sys.argv[1] if len(sys.argv) > 1 else "Read and summarize the file ./readme.md"
    asyncio.run(main(prompt))
```

åœ¨è¿è¡Œæ­¤ Python è„šæœ¬ä¹‹å‰ï¼Œæ‚¨åº”è¯¥å®‰è£…æ‰€éœ€çš„ä¾èµ–é¡¹ `langchain-core`ã€`langchain-groq` å’Œ `langchain-mcp`ã€‚

```bash
pip install langchain-core langchain-groq langchain-mcp
```

ä¸Šé¢çš„ MCP é…ç½®ä½¿ç”¨ `npx` æœåŠ¡å™¨ç±»å‹ã€‚å› æ­¤ï¼Œæ‚¨åº”è¯¥å®‰è£… `server-filesystem` åŒ…ã€‚

```bash
pm install -g @modelcontextprotocol/server-filesystem
```

å®‰è£…å®Œæ‰€æœ‰å¿…éœ€çš„è½¯ä»¶åŒ…åï¼Œå¦‚æœæ‚¨å°†æ–‡ä»¶æ·»åŠ åˆ°æ‚¨çš„é¡¹ç›®å¹¶åœ¨ Python è„šæœ¬ä¸­å¼•ç”¨å®ƒï¼Œå¦‚ç¤ºä¾‹ä»£ç  `./readme.md` æ‰€ç¤ºï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼äºæ­¤å›¾åƒçš„è¾“å‡ºã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*sfh5j25UW_VqMxnB)

**æ³¨æ„**ï¼šæ­¤ç¤ºä¾‹å–è‡ª LangChain çš„ [GitHub repo](https://github.com/rectalogic/langchain-mcp/tree/main)ã€‚

## 4. å°† MCP ç”¨äº Chainlit AI åº”ç”¨

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*joqnr_PR36914smI)

[Chainlit](https://docs.chainlit.io/advanced-features/mcp) æ˜¯ä¸€ä¸ªç”¨äºåœ¨ Python ä¸­æ„å»º AI åº”ç”¨ç¨‹åºçš„å¹³å°ã€‚å®ƒå†…ç½®äº†å¯¹ MCP æœåŠ¡å™¨çš„æ”¯æŒï¼Œå› æ­¤æ‚¨å¯ä»¥é…ç½®æ‚¨çš„åº”ç”¨ç¨‹åºä»¥å‘ç°å¯ç”¨çš„ MCP å·¥å…·ï¼Œå¹¶å°†å·¥å…·è°ƒç”¨é›†æˆåˆ°æ‚¨çš„åº”ç”¨ç¨‹åºæµç¨‹ä¸­ï¼Œä»¥è·å¾—æ›´å¥½çš„ç»“æœã€‚æ‚¨å¯ä»¥å°† Chainlit åº”ç”¨ç¨‹åºä¸ [server-sent events](https://modelcontextprotocol.io/docs/concepts/transports#server-sent-events-sse) (SSE) å’Œ [command-line](https://introcs.cs.princeton.edu/python/code/stdio.py) (stdio) åŸºäºæœåŠ¡é›†æˆã€‚åœ¨ä»¥ä¸‹ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°† Chainlit åº”ç”¨ç¨‹åºè¿æ¥åˆ° [Linear MCP server](https://github.com/ibraheem4/linear-mcp)ï¼Œä»¥å…è®¸è¯¥åº”ç”¨ç¨‹åºç®¡ç† Linear é—®é¢˜ã€é¡¹ç›®å’Œå›¢é˜Ÿã€‚æ‚¨å¯ä»¥ä½¿ç”¨æ­¤ç¤ºä¾‹ä¸­æä¾›çš„ Linear å·¥å…·æ¥åˆ›å»ºã€æ›´æ–°ã€æœç´¢å’Œè·å–ç”¨æˆ·é—®é¢˜æˆ–å‘é—®é¢˜æ·»åŠ è¯„è®ºã€‚

**é…ç½®æ‚¨çš„ Chainlit åº”ç”¨ç¨‹åºä»¥è¿æ¥åˆ° MCP æœåŠ¡å™¨**

å°†æ‚¨çš„ Chainlit åº”ç”¨ç¨‹åºè¿æ¥åˆ° MCP æœåŠ¡å™¨ä»¥è®¿é—®å·¥å…·æ¶‰åŠä¸¤ä¸ªä¸»è¦æ­¥éª¤ã€‚

**1. æ³¨å†Œ MCP è¿æ¥**ï¼šåœ¨æ­¤æ­¥éª¤ä¸­ï¼Œæ‚¨åº”è¯¥å®ç° Chainlit çš„ `on_mcp_connect` å¼‚æ­¥å‡½æ•°ä»¥åˆ›å»ºæˆåŠŸçš„è¿æ¥ã€‚æ‚¨è¿˜å¯ä»¥å®ç° `on_mcp_disconnect` å‡½æ•°æ¥å¤„ç†æ¸…ç†ã€‚

```python
# pip install chainlit

import chainlit as cl
from mcp import ClientSession

@cl.on_mcp_connect
async def on_mcp_connect(connection, session: ClientSession):
    """Called when an MCP connection is established"""
    # Your connection initialization code here
    # This handler is required for MCP to work

@cl.on_mcp_disconnect
async def on_mcp_disconnect(name: str, session: ClientSession):
    """Called when an MCP connection is terminated"""
    # Optional handler: Cleanup your code here
```

**2. é…ç½® MCP å®¢æˆ·ç«¯ (Chainlit, LangChain, Mastra)**ï¼šä¸ºäº†ä½¿ MCP æœåŠ¡å™¨ä¸ Chainlit åº”ç”¨ç¨‹åºä¸€èµ·å·¥ä½œï¼Œå®¢æˆ·ç«¯åº”é€šè¿‡ Chainlit çš„ UI æä¾›è¿æ¥è¯¦ç»†ä¿¡æ¯ã€‚æ­¤é…ç½®æ¶‰åŠä»¥ä¸‹å†…å®¹ã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*RUM0q1-IBoaUTl71)

- ä»£è¡¨è¿æ¥åç§°çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚
**å®¢æˆ·ç«¯ç±»å‹**ï¼šä½ åº”è¯¥æŒ‡å®šæ˜¯å¦è¦ä½¿ç”¨`sse` æˆ–`stdio`ã€‚å¯¹äº`sse`ï¼Œä½ åº”è¯¥æ·»åŠ ä¸€ä¸ª URL ç«¯ç‚¹ã€‚å½“ä½¿ç”¨`stdio`æ—¶ï¼Œéœ€è¦ä¸€ä¸ªå®Œæ•´çš„å‘½ä»¤ï¼ˆä¾‹å¦‚ï¼Œ`npx` your-tool-package æˆ–`uvx` your-tool-packageï¼‰ã€‚ä¸‹é¢æ˜¾ç¤ºäº†ä¸€ä¸ªå®Œæ•´çš„å‘½ä»¤ç¤ºä¾‹ã€‚

`npx -y linear-mcp-server --tools=all --api-key=lin_api_your_linear_API_Key`

å»ºç«‹ MCP æœåŠ¡å™¨è¿æ¥åï¼Œä½ å¯ä»¥ä½¿ç”¨ MCP ä¼šè¯æ‰§è¡Œå·¥å…·ã€‚æœ€åï¼Œä½ å¯ä»¥é€šè¿‡å·¥å…·è°ƒç”¨å°† MCP å·¥å…·ä¸ Chainlit åº”ç”¨ç¨‹åºçš„æ¨¡å‹/ä»£ç†æ— ç¼é›†æˆã€‚ä½ å¯ä»¥åœ¨ [GitHub](https://github.com/Chainlit/cookbook/tree/main/mcp-linear) ä¸Šçš„ Chainlit ç¤ºä¾‹åº”ç”¨ç¨‹åºä¸­æ‰¾åˆ°æ­¤ Linear MCP é›†æˆçš„å®Œæ•´æºä»£ç ã€‚

å½“ä½ ä» Chainlit çš„ GitHub ä»“åº“è·å–ä¸Šè¿°æºä»£ç ï¼Œè¿è¡Œå®ƒï¼Œå¹¶é€šè¿‡ Chainlit ç•Œé¢è®¾ç½® `npx -y linear-mcp-server --tools=all --api-key=lin_api_your_linear_API_Key` æ—¶ï¼Œä½ å°†èƒ½å¤Ÿåˆ›å»ºå’Œæ›´æ–° Linear é—®é¢˜/é¡¹ç›®ã€‚ä½†æ˜¯ï¼Œæ­£å¦‚æœ¬ç¤ºä¾‹æ‰€ç¤ºï¼Œæ‰§è¡Œè¿™äº›æ“ä½œéœ€è¦ä½ çš„ Linear å›¢é˜Ÿçš„ IDã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*QYdgotqHcRcPY5Yly5NbVw.gif)

## 5. é›†æˆ MCP ä»¥ç”¨äº Agno AI ä»£ç†

[Agno](https://www.agno.com/) æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤æ‚ä»£ç†å·¥ä½œæµç¨‹çš„ Python æ¡†æ¶ã€‚å®ƒä»¥å…¶ç®€å•æ€§ã€æ˜“ç”¨æ€§ä»¥åŠä¸ MCP æœåŠ¡å™¨çš„æ— ç¼é›†æˆè€Œå¹¿å—æ¬¢è¿ã€‚æœ¬èŠ‚ä¸­çš„ç¤ºä¾‹ MCP å®ç°ä¸ç”±å››ä¸ªç‹¬ç«‹è´¡çŒ®ä»£ç†ï¼ˆä¾‹å¦‚ Airbnbã€Google Mapsã€Web æœç´¢å’Œå¤©æ°” MCP ä»£ç†ï¼‰ç»„æˆçš„å¤šä»£ç†å›¢é˜Ÿé›†æˆã€‚Agno å¤šä»£ç†ååŒå·¥ä½œä»¥æä¾›æœ‰å…³æŒ‡å®šä½ç½®çš„æ—…è¡Œä¿¡æ¯ã€‚

**[å‰ææ¡ä»¶](https://miro.medium.com/v2/resize:fit:720/format:webp/1*QYdgotqHcRcPY5Yly5NbVw.gif)**

è¦æµ‹è¯•æœ¬èŠ‚ä¸­çš„ Agno MCP å®ç°ç¤ºä¾‹ï¼Œ

1. å®‰è£… Agnoï¼Œ[DuckDuckGo](https://duckduckgo.com/) å’Œ [Exa](https://exa.ai/):`pip install -U openai agno duckduckgo-search exa-py`ã€‚
2. è·å– [GOOGLE_MAPS_API_KEY](https://console.cloud.google.com/projectselector2/google/maps-apis/credentials) å¹¶å°†å…¶æ·»åŠ åˆ°ä½ çš„é¡¹ç›®çš„ `.env` æ–‡ä»¶ä¸­ã€‚
3. è·å– [APIFY_TOKEN](https://console.apify.com/settings/integrations) å¹¶å°†å…¶æ·»åŠ åˆ°ä½ çš„ `.env` ä¸­ã€‚
4. éªŒè¯ [Google Address API](https://console.developers.google.com/apis/api/addressvalidation.googleapis.com)ã€‚

**é…ç½® Agno MCP ä»£ç†å›¢é˜Ÿ**

å¯¹äºæ­¤æ­¥éª¤ï¼Œä½ åº”è¯¥å®šä¹‰ä½ çš„ MCP æœåŠ¡å™¨å‚æ•°ï¼Œå¹¶ä½¿ç”¨ `AsyncExitStack` ç®¡ç†å¤šä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚ç„¶åï¼Œåˆ›å»ºä»£ç†å¹¶è¿è¡Œå®ƒä»¬ã€‚

```python
    # Define server parameters
    airbnb_server_params = StdioServerParameters(
        command="npx",
        args=["-y", "@openbnb/mcp-server-airbnb", "--ignore-robots-txt"],
        env=env,
    )

    maps_server_params = StdioServerParameters(
        command="npx", args=["-y", "@modelcontextprotocol/server-google-maps"], env=env
    )

    # Use contextlib.AsyncExitStack to manage multiple async context managers
    async with contextlib.AsyncExitStack() as stack:
        # Create stdio clients for each server
        airbnb_client, _ = await stack.enter_async_context(stdio_client(airbnb_server_params))
        maps_client, _ = await stack.enter_async_context(stdio_client(maps_server_params))

        # Create all agents
        airbnb_agent = Agent(
            name="Airbnb",
            role="Airbnb Agent",
            model=OpenAIChat("gpt-4o"),
            tools=[airbnb_client],
            instructions=dedent("""\
                You are an agent that can find Airbnb listings for a given location.\
            """),
            add_datetime_to_instructions=True,
        )
```

ä» Agno çš„ GitHub ä»“åº“è·å–å®Œæ•´çš„ [æºä»£ç ](https://github.com/agno-agi/agno/blob/main/cookbook/examples/teams/coordinate/travel_planner_mcp_team.py)ã€‚å®‰è£…æ‰€éœ€çš„è½¯ä»¶åŒ…ï¼Œæ‰§è¡Œä¸Šè¿°æ‰€æœ‰é…ç½®ï¼Œå¹¶è¿è¡Œå®Œæ•´çš„ GitHub ç¤ºä¾‹ä»£ç åº”æ˜¾ç¤ºç±»ä¼¼äºæ­¤é¢„è§ˆçš„è¾“å‡ºã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*YumVRyIAfGljteD1PW35kw.gif)

## 6. å°† MCP ç”¨äº Upsonic ä»£ç†

[Upsonic](https://docs.upsonic.ai/introduction) æ˜¯ä¸€ä¸ªç”¨äºåˆ›å»º AI ä»£ç†çš„ Python æ¡†æ¶ã€‚ä½¿ç”¨ Upsonicï¼Œä½ å¯ä»¥æ„å»ºä½ çš„ä»£ç†ï¼Œå®šä¹‰ä»£ç†çš„ä»»åŠ¡ï¼Œå¹¶ä½¿ç”¨ [MCP å·¥å…·](https://docs.upsonic.ai/concepts/mcp_tools) å¤„ç†æ¯ä¸ªä»»åŠ¡å®šä¹‰ï¼Œå¦‚ä¸‹é¢çš„ç¤ºä¾‹ä»£ç æ‰€ç¤ºã€‚


```python
import os
from dotenv import load_dotenv
from upsonic import Task, Agent, Direct
from upsonic.client.tools import Search  # Adding Search as a fallback tool

# Load environment variables from .env file
load_dotenv()

# Get the OpenAI API key from environment variables
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY not found in .env file")

# Set your OpenAI API key for the session
os.environ["OPENAI_API_KEY"] = openai_api_key

# Define the HackerNews MCP tool
# Using the correct MCP setup for HackerNews based on Upsonic documentation
class HackerNewsMCP:
    command = "uvx"
    args = ["mcp-hn"]
    # No environment variables are needed for this MCP

# Create a task to analyze the latest HackerNews stories
# Adding Search as a fallback in case HackerNews MCP fails
task = Task(
    "Analyze the top 5 HackerNews stories for today. Provide a brief summary of each story, "
    "identify any common themes or trends, and highlight which stories might be most relevant "
    "for someone interested in AI and software development.",
    tools=[HackerNewsMCP, Search]  # Include both HackerNews MCP and Search tools
)

# Create an agent specialized in tech news analysis
agent = Agent(
    "Tech News Analyst",
    company_url="https://news.ycombinator.com/",
    company_objective="To provide insightful analysis of tech industry news and trends"
)

# Execute the task with the agent and print the results
print("Analyzing HackerNews stories...")
agent.print_do(task)

# Alternatively, you can use a Direct LLM call if the task is straightforward
# print("Direct analysis of HackerNews stories...")
# Direct.print_do(task)

# If you want to access the response programmatically:
# agent.do(task)
# result = task.response
# print(result)
```

åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬åœ¨ Upsonic ä¸­åˆ›å»ºäº†ä¸€ä¸ª AI ä»£ç†ï¼Œè¯¥ä»£ç†æ£€ç´¢ Hackernews ä¸­æœ€æ–°çš„äº”ä¸ªæ•…äº‹ã€‚ å¦‚æœæ‚¨ `pip install upsonic` å¹¶è¿è¡Œä¸Šé¢çš„ Python ä»£ç ï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼äºæ­¤å›¾åƒçš„è¾“å‡ºã€‚

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*1xoOQBGWUL99G8An)

## 7. å°† MCP ç”¨äº Mastra ä»£ç†

[Mastra](https://mastra.ai/) æ˜¯ä¸€ä¸ª TypeScript æ¡†æ¶ï¼Œç”¨äºæ„å»ºåŸå‹å’Œå¯ç”¨äºç”Ÿäº§çš„ AI ä»£ç†ã€‚ ä¸ Chainlit ç±»ä¼¼ï¼ŒMastra æä¾›äº†ä¸€ç§æ ‡å‡†åŒ–çš„æ–¹å¼æ¥è¿æ¥åˆ° MCP æœåŠ¡å™¨ï¼Œä»¥é€šè¿‡ `stdio` æˆ– `sse`-based è¿æ¥è®¿é—®å„ç§å·¥å…·ã€‚

è¦å°†æ‚¨çš„ Mastra ä»£ç†è¿æ¥åˆ° MCP æœåŠ¡å™¨ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨å…¶ `MCPConfiguration` ç±»ã€‚ æ­¤ç±»å¤„ç†å¤šä¸ªæœåŠ¡å™¨è¿æ¥ï¼Œä¾‹å¦‚ç”Ÿå‘½å‘¨æœŸã€å‘½åç©ºé—´å’Œå·¥å…·ï¼Œåœ¨ä»»ä½• Mastra ä»£ç†å·¥ä½œæµç¨‹ä¸­ã€‚ åœ¨ Master åº”ç”¨ç¨‹åºå’Œ MCP æœåŠ¡å™¨ä¹‹é—´åˆ›å»ºè¿æ¥æ¶‰åŠä»¥ä¸‹æ­¥éª¤ã€‚

1. åˆ›å»º `MCPConfiguration` ç±»çš„å®ä¾‹å¹¶æ·»åŠ æœåŠ¡å™¨é…ç½®ã€‚
2. ä½¿ç”¨ `getTools()` æˆ– `getToolsets()` æ–¹æ³•æ£€ç´¢ MCP å·¥å…·ã€‚

ä¸‹é¢çš„ç¤ºä¾‹ä»£ç è¡¨ç¤ºä½¿ç”¨ Mastra ä»£ç†å®ç° MCP æœåŠ¡å™¨çš„åŸºæœ¬ç”¨æ³•ã€‚

```typescript
import { MCPConfiguration } from "@mastra/mcp";
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";

const mcp = new MCPConfiguration({
  servers: {
    stockPrice: {
      command: "npx",
      args: ["tsx", "stock-price.ts"],
      env: {
        API_KEY: "your-api-key",
      },
    },
    weather: {
      url: new URL("http://localhost:8080/sse"),
    },
  },
});

// Create an agent with access to all tools
const agent = new Agent({
  name: "Multi-tool Agent",
  instructions: "You have access to multiple tool servers.",
  model: openai("gpt-4"),
  tools: await mcp.getTools(),
});
```

è¯·å‚é˜… Mastra çš„ [MCPConfiguration](https://mastra.ai/docs/reference/tools/mcp_configuration) äº†è§£æ›´å¤šä¿¡æ¯ã€‚

## LLM åº”ç”¨å’Œä»£ç†ä¸­ MCP çš„æŒ‘æˆ˜å’Œæœªæ¥å‘å±•æ–¹å‘

æœ¬æ•™ç¨‹å‘æ‚¨ä»‹ç» MCPï¼Œå¹¶è§£é‡Šäº†ä¸ºä»€ä¹ˆå®ƒåœ¨å¼€å‘è€…ç¤¾åŒºä¸­å˜å¾—æµè¡Œã€‚ æˆ‘ä»¬é‡ç‚¹ä»‹ç»äº† MCP ä¸ IDEï¼ˆå¦‚ Cursor å’Œ Windsurfï¼‰çš„é›†æˆã€‚ é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜åœ¨ä¸ƒä¸ªä¸åŒçš„ Python å’Œ TypeScript æ¡†æ¶ä¸­å®ç°äº† MCPï¼Œç”¨äºæ„å»ºåŸºäº LLM çš„åº”ç”¨ç¨‹åºã€AI åŠ©æ‰‹å’Œä»£ç†ã€‚

MCP çš„å¼ºå¤§åŠŸèƒ½è¿˜å¸¦æ¥äº†ä»¥ä¸‹[æŒ‘æˆ˜](https://x.com/tobi/status/1891137636720419191)ã€‚ åœ¨ä¸ºæ‚¨çš„é¡¹ç›®æœç´¢ MCP å·¥å…·æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šå‘ç°æ£€æŸ¥æˆ–éªŒè¯è´¨é‡ä»¥åŠæŸ¥çœ‹ AI é¡¹ç›®çš„ç¡®åˆ‡åº”ç”¨ç¨‹åºå…·æœ‰æŒ‘æˆ˜æ€§ã€‚ è¿™æ˜¯å› ä¸ºå®ƒçš„å·¥å…·æœç´¢å’Œå‘ç°å°šæœªæ ‡å‡†åŒ–ã€‚ æ­¤å¤–ï¼Œç”±äº MCP æœåŠ¡å™¨æä¾›å•†çš„ä¸åŒæ¨¡å¼ï¼Œå…¶é…ç½®æœªæä¾›ä¸€è‡´çš„ç”¨æˆ·ä½“éªŒã€‚

ç›®å‰ï¼ŒMCP ç”Ÿæ€ç³»ç»Ÿæ­£åœ¨[è®¨è®º](https://github.com/orgs/modelcontextprotocol/discussions/159)æ ‡å‡†åŒ– MCP çš„å„ä¸ªæ–¹é¢ã€‚ æœªæ¥å¯èƒ½ä¼šæœ‰ä¸€ç§å®‰è£…åŸºäº MCP çš„åº”ç”¨ç¨‹åºçš„æ ‡å‡†æ–¹æ³•ï¼Œå°±åƒæˆ‘ä»¬åœ¨ Python ä¸­ `pip install` åŒ…ä¸€æ ·ã€‚[PulseMCP](https://www.pulsemcp.com/) ä¹Ÿåœ¨å°è¯•ä½¿æµè§ˆå’Œå‘ç° MCP å˜å¾—æ›´å®¹æ˜“ã€‚