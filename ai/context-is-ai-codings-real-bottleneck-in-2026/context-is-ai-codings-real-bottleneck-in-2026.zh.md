如今，走进任何一个工程领导会议，都会有人质疑AI生成的代码是否安全，或者代理在生产环境中是否值得信任。这些都是合理的担忧，但它们并不能决定你的团队是否能更快地交付产品。瓶颈在于上下文：工程师脑中的知识与AI能够理解或交流的知识之间的差距。

解决了上下文问题的公司将更快发展。他们的工具将减少需要人工纠正的错误，而忽视此问题的团队则会以开发者无法完全解释的代码形式积累技术债务。安全和质量固然重要，但它们大多可以在技术层面解决；真正的限制是将工程师的隐性知识转移到系统中。

## 代码质量工具已就绪，但上下文仍未解决

到2025年，AI[代码审查](https://thenewstack.io/traditional-code-review-is-dead-what-comes-next/)已真正成熟，静态应用安全测试（SAST）工具也已能捕捉到明显问题。如今，大多数公司在每次代码更改时都会运行一个或多个AI审查器，并且误报率足够低，这些工具已物有所值。其机制运作良好。Claude Code及类似工具在2025年表明，AI可以编写大量多文件更改，并能编译和运行。

但不起作用的是交接。工程师需要数周时间来吸收的不仅是技术架构，还有管理代码库的潜规则：何时优先考虑性能而非可读性，团队实际维护哪些抽象，以及在处理边缘情况时应有多强的防御性。当AI代理编写或审查代码时，它是在没有这些[积累的知识](https://thenewstack.io/why-agentic-ai-needs-a-context-based-approach/)的情况下运行的。你可以喂给它文档，但文档总是不完整的；它记录的是某人想到要写下来的东西，而不是[塑造当前系统的几十个微决策](https://thenewstack.io/how-to-find-success-with-code-reviews/)。

## 双向问题

[将上下文导入AI工具](https://thenewstack.io/better-context-will-always-beat-a-better-model/)需要大多数团队尚未系统化的刻意努力。工程师需要将他们的隐性知识转化为代理可以解析的东西。一些公司正在尝试将详细的架构文档存储在代码库中，专门供AI使用，而另一些公司则在构建编码了风格偏好的专用提示。但这些都只是权宜之计。上下文交接的用户体验仍然笨拙，并且工具几乎不存在。

从AI中提取理解同样棘手。当AI生成代码更改时，工程师仍然需要建立一个关于发生什么的心理模型，以便他们以后能够维护系统。阅读AI生成的代码与阅读人类编写的代码需要不同的认知工作：你是从输出中逆向工程意图，而不是遵循同事的推理过程。跳过这一步，你最终会得到一个没人完全理解的代码库。

## 2026年将发生什么变化，哪些团队将更快交付

今年，将出现新工具来解决上下文传输问题。这不仅仅是更好的提示或更高级的检索增强生成（RAG）实现，更是用于捕获和传达目前仅存在于工程师头脑中的隐性知识的接口。将其视为交接本身的基础设施。

这远非取代工程师，而是要精确地识别出他们工作中哪些部分需要人工判断，哪些部分在上下文问题解决后可以自动化。目前，工程师同时运行Cursor、Claude和Aider，因为边际收益超过了每位工程师的每月预算。我们仍处于每个工具都有所帮助，且没有哪个工具的成本足以证明整合是合理的阶段。

到2026年，这种情况将继续；真正的变化将在工作流程中体现。AI评审将能够足够准确地评估拉取请求（PR）风险，从而智能地路由更改：有些会立即进行人工审查，有些只进行AI审查，还有一些会在24小时内进行合并后审查。在云端启动、克隆代码库、执行更改并返回PR的后台代理将变得更加普遍，用于范围受限的外部循环工作，如修复CI、添加单元测试或拆分大型PR。这些不适用于大型全新项目，但对于目前需要上下文切换开销的小型重复更改来说，它们非常高效。

安全和代码质量仍然很重要，但它们在技术层面已基本解决。上下文鸿沟才是真正决定你的团队今年能从AI潜在生产力提升中获益多少的关键。能够很好地运用这些工具的团队不仅会更快发展；他们将开始形成一种节奏，即人类负责判断和创意工作，而AI则处理重复性任务，从而使更改更容易进行和维护。