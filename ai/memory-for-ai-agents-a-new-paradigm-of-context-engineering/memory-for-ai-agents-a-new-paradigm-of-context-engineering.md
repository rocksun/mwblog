<!--
title: AI智能体的记忆：上下文工程的新范式
cover: https://cdn.thenewstack.io/media/2026/01/ead2801b-memory.jpg
summary: AI智能体需要记忆来提升性能，传统大型语言模型缺乏上下文。文章探讨了向量存储、摘要、图方法等记忆架构，并强调记忆对企业效率、用户体验的价值，同时提出了关于隐私和遗忘的伦理挑战。
-->

AI智能体需要记忆来提升性能，传统大型语言模型缺乏上下文。文章探讨了向量存储、摘要、图方法等记忆架构，并强调记忆对企业效率、用户体验的价值，同时提出了关于隐私和遗忘的伦理挑战。

> 译自：[Memory for AI Agents: A New Paradigm of Context Engineering](https://thenewstack.io/memory-for-ai-agents-a-new-paradigm-of-context-engineering/)
> 
> 作者：Nicole Seah

对于今天的AI智能体来说，记忆是其核心优势。每一次对话都至关重要，但传统[大型语言模型（LLMs）](https://thenewstack.io/introduction-to-llms/)是无状态的——它们在每次交互开始时都[没有任何上下文或记忆](https://thenewstack.io/ai-agents-key-concepts-and-how-they-overcome-llm-limitations/)，导致潜能未被开发，洞察力也随之流失。

设想新的智能体记忆范式已成为AI开发中最紧迫的前沿之一，它允许记忆的主动形成和更新，以便智能体能够以有意义的方式利用所有过去的交互。这与人类记忆有许多相似之处，回忆之前的交流和经验能让对话对所有参与方来说都更丰富、更相关。

其重要性巨大。一个能在跨对话中保留上下文的销售助手可以把研究时间缩短一半。一个具有持久回忆功能的客户服务智能体可以减少客户流失，提高客户满意度。然而，随着公司竞相构建持久、上下文丰富的系统，他们发现记忆不仅需要技术基础设施，还需要哲学上的清晰度。

## **为什么记忆现在很重要**

当大型语言模型首次进入企业技术栈时，不断膨胀的令牌窗口似乎预示着我们可以简单地将[所有它可能需要的信息](https://thenewstack.io/how-to-add-persistence-and-long-term-memory-to-ai-agents/)填入上下文窗口。但这种幻想在实际工作负载下破灭了。性能下降，检索昂贵，成本累积。

之前的记忆方法因上下文污染而失败。一些研究人员称之为“上下文腐烂”，即简单地增大上下文窗口导致性能下降。如果没有上下文管理，或者管理进入上下文窗口的内容，AI智能体的响应可能会不准确或不可靠。对于短暂的交互，这很有效。对于跨越数天或部门的工作流程，它会变得瘫痪、不人性化且无效。

人类记忆进化为一个分层系统，正是因为将所有东西都保存在工作记忆中是不可能的。我们通过压缩、抽象和遗忘来运作。神经科学家描述了至少三个相互关联的系统：工作记忆（易失性，像RAM）、短期记忆（短暂、易受干扰）和长期记忆（稳定，通过重复和相关性巩固）。同样，解锁AI记忆需要采用正确的技术来压缩、存储和检索用户的记忆。

## **从提示到角色**

2024年，开发者开始试验智能体的合成长期记忆：跨调用的外部持久化上下文数据库。最初，这些系统很粗糙。工程师将之前的消息序列化为文本文件，重新喂入提示，并称之为记忆。但随着智能体的成熟，其基础设施也随之成熟。

今天，三种设计理念主导着这个领域：

1.  **向量存储方法（记忆即检索）：** Pinecone和Weaviate等系统将过去的交互作为嵌入存储在向量数据库中。当被查询时，智能体通过余弦相似性检索最相关的片段。它快速而简单，但容易出现表面层次的记忆。
2.  **摘要方法（记忆即压缩）：** 模型定期将文本记录浓缩成滚动摘要。
3.  **新兴AI初创公司中的图方法（记忆即知识）：** 更具雄心的系统，如Zep，将记忆组织为节点和关系：人物、地点、事件和时间。图存储“谁对谁说了什么以及何时说的”。

许多新兴初创公司正在解决这个问题：

*   [Zep](https://www.getzep.com/)的“时间知识图谱”在[长周期准确性上比基线检索系统高出18.5%](https://blog.getzep.com/content/files/2025/01/ZEP__USING_KNOWLEDGE_GRAPHS_TO_POWER_LLM_AGENT_MEMORY_2025011700.pdf)，同时将延迟降低了近90%。
*   [Mem0](https://mem0.ai/)通过结构化摘要和冲突解决采取了不同的方法。它在标准记忆基准上实现了26%的准确性提升，并大幅削减了令牌成本。
*   [Letta](https://letta.com/)最近发布的结果显示，即使是[简单的“文件系统”记忆](https://www.letta.com/blog/benchmarking-ai-agent-memory)（按时间戳索引的原始文本文件）也超越了几个专业系统。

计算领域的每一次革命都依赖于记忆的突破。磁带、半导体记忆、云存储。每个阶段都带来了新的能力和新的风险。现在，智能体平台正聚焦于一个关键洞察：构建记忆对于性能至关重要。

## **记忆的架构**

### **提取**

智能体生成大量的文本，其中许多是冗余的。良好的记忆需要显著性检测：识别哪些事实重要。Mem0使用“记忆候选选择器”来分离原子语句；Zep编码实体和关系；Letta依赖于基于时间的索引。

### **整合**

人类的回忆是递归的，每次我们检索记忆时都会重新编码它们，强化一些，丢弃另一些。AI系统可以通过在出现新证据时总结或重写旧条目来模仿这一点。这可以防止研究人员称之为上下文漂移的问题，即过时的事实持续存在。

### **检索**

系统根据新近度和重要性来权衡相关性。做得好，这些层级会产生能够与用户共同进化的智能体。做得不好，它们会创建脆弱的系统：那些会产生旧事实幻觉、重复错误或完全失去信任的系统。

## **企业从记忆中获得什么**

对于尝试AI助手的公司来说，记忆问题是即时且实际的。

一个呼叫中心智能体，能够回忆客户之前的P问题而无需重新查询，可以减少平均处理时间。在营销自动化中，支持记忆的助手通过更好地回忆买家意图，提高了潜在客户的资格认定准确性。总体而言，这些效率可以累积为每年数百万美元的节省。

记忆降低了员工的认知摩擦。当内部助手“记住”项目历史时，新团队成员的入职变得更顺畅。系统成为一个机构历史学家，它捕捉了组织内部存储的隐性知识。持久化记忆改变了人类对助手和AI智能体有用性和相关性的感受。当一个智能体回忆起过去的对话时，它感觉更个性化、更具协作性。情感上的连续性建立了信任。

需要明确的是，并非所有人都同意记忆值得大肆宣传。一些工程师认为上下文窗口将继续扩大，记忆将成为模型实验室拥有的战略要务。另一些人则指出性能复杂性：维护持久状态会增加基础设施开销、延迟和不一致的风险。

## **遗忘的伦理**

每一种记忆技术也需要一种[遗忘技术](https://thenewstack.io/techniques-for-tackling-catastrophic-forgetting-in-ai-models/)。

采用持久AI记忆的企业很快就会遇到关于隐私、匿名化和权力的问题：

*   机器应该记住我们什么？
*   谁控制它的记忆？
*   当遗忘成为一种隐私形式时会发生什么？

未来是否会有针对存储记忆的GDPR？在美国，数据保留政策模糊不清，特别是当AI系统存储嵌入而非明确文本时。回忆、索引和个人数据之间的界限仍然模糊。

对于企业来说，这是一个迫切的问题。如果记忆系统存储客户数据而没有精心设计，它们可能会成为合规责任。加密、删除协议和访问控制必须是原生功能，而不是事后才考虑的。

偏见和隐私又如何呢？哪些记忆被强化？在人类中，选择性回忆塑造了身份。当AI具有选择性回忆时，它可能会放大某些用户偏好或压制异议信号。

## **未来的形态**

三种轨迹似乎很有可能：

1.  **记忆即基础设施：** 开发者将像现在调用`db.save()`一样轻松地调用`memory.write()`。预计专门的中间件记忆提供商将发展成为每个智能体平台的中间件。
2.  **记忆即治理：** 企业将要求了解智能体知道什么以及为什么知道。仪表板将显示学习到的事实的“记忆图”，并带有编辑或删除的控件。透明度将成为基本要求；记忆将以自然语言编写。
3.  **记忆即身份：** 随着时间的推移，智能体将发展出个人历史：协作记录、偏好，甚至情绪。这些历史将锚定信任，但也会引发新的哲学问题。当一个根据您的交互进行微调的模型产生洞察时，这是谁的记忆？

我们猜测答案将反映人类的问题：所有权、同意和共享上下文的混合。记忆是一种活生生的关系，而不是一个呆板的数据库。

智慧是善于记忆的能力。当我们教机器记忆时，我们可能会发现一个有趣的人类相似之处：我们记住和遗忘什么定义了我们是谁。