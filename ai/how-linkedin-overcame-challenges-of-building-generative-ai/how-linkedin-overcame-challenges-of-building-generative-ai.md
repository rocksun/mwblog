<!--
title: 领英应对生成式AI难题
cover: https://cdn.thenewstack.io/media/2023/11/01a07da0-souvik-banerjee-jlj_nbvlddo-unsplash-1024x683.jpg
-->

本文独家揭密领英如何自主研发首个生成式AI工具，并在应对过程中逐步完善。

> 译自 [How LinkedIn Overcame Challenges of Building Generative AI](https://thenewstack.io/how-linkedin-overcame-challenges-of-building-generative-ai/)，作者 Jennifer Riggins 是一位讲述技术文化方面的故事家、记者、作家以及活动和播客主持人，她帮助分享文化和技术碰撞的故事，并诠释我们正在构建的技术的影响。她一直在......

随着成员人数现在超过 10 亿，LinkedIn 已经不得不以全球规模做事。但是就在一年多前，当公司开始构建其新的协作文章公共功能时，他们需要弄清楚如何利用当时还处于初级阶段的生成式 AI 来加速世界最大的专业网络中的建议共享。

这四个月的设计和构建过程发现了几个社会技术挑战，需要用 GenAI 来解决，其中两名团队成员与 The New Stack 独家分享了这些挑战。学习 LinkedIn 的 [Shweta Patira](https://www.linkedin.com/in/patirashweta/)(创作工程主管兼该项目负责人)和 [Lakshman Somasundaram](https://www.linkedin.com/in/lakshmansom/)(Moonshots 团队产品管理主任)的经验。这样你也可以为大规模构建具有生产力的 AI 做好准备，同时考虑 AI 和人类用户。

## LinkedIn 寻求利用 GenAI 激发对话

“它始于这样一个事实：每个人每天在工作中都会遇到问题，对吧？可能是 ‘嘿，我希望能得到提升，但我不知道如何获得提升’，或者 ‘我需要进行面试，但我不太清楚如何进行面试。’ 每个人每天在工作中都会遇到自己的问题，”Somasundaram 告诉 The New Stack。到目前为止，“获得答案的最佳途径是询问你认识的人的建议，他们已经走过这条路，解决过这些问题，并且解决得非常好。”

但是，这些当然不是是非题。如何进行技术面试或获得提升，都有许多正确和错误的方法——这两者都受到很多影响结果的上下文和偏见的影响。拥有更多、更广泛的视角会增加获得更好答案的机会。

但是，并不是每个人都拥有如此丰富的网络。

“这意味着，那些经常能够获得这些问题最佳答案的人往往是拥有大型网络的人。因为他们实际上可以利用自己网络中的多个人来获取建议、观点和意见，以解决如何解决这个问题。” Somasundaram 继续说道，“世界上大多数人都没有大型网络。大多数人都没有很多可以求助的人，向他们提出问题并从多个人那里获得不同的视角。”

拥有超过 10 亿用户的 LinkedIn 现在拥有超过 1000 亿年的工作经验，这使得该公司处于一个独特的位置，可以集中注意网络的社会性，并利用并共享其成员的专业知识和群体智慧，实现大规模运作。

另一方面，有名人声称[批评某事比创造某事更容易](https://www.goodreads.com/quotes/3222312-it-s-easier-to-criticize-than-to-create)，这一点尤其如此。当工人时间有限需要完成工作时——在 LinkedIn 上搜索问题并发布响应不是你的实际工作。

当然，如果你是 AI，你会有相反的问题。在当前的人工智能世界中，创造某事的限制越来越少——更多的是我们需要批判的眼光来审查它所创造的东西。

“如果你可以把某件事放在某人面前，他们就更容易说 ‘嘿，这说不通。我会以不同的方式做这件事。’”Somasundaram 解释道。“这正是生成式 AI 所实现并为我们实现的。这就是为什么在协作文章中，我们一直在做的就是用 AI 的力量创建所有这些初始文章，然后用这些初始文章实际上邀请世界上所有这些主题的专家在 LinkedIn 上发表评论。”

部分原因是，这些往往是你可能会向可信赖的同行提出的问题，但你可能不想发布的问题——例如，你想要获得更高的薪资，或者你不知道如何最好地进行面试。因此，故事团队已经在 LinkedIn 配置文件中的 40000 项技能上训练了生成式 AI，以便它可以提出问题并建议这些问题的子主题，以便识别出的专家可以回答，而无需你来提问。

但是，当他们决定在 2022 年 10 月为 LinkedIn 构建他们的第一个主要的生成式 AI 功能时，没有一个确切的指南来实现这一切。他们遇到了生成式 AI 空间所特有的重大挑战。以下是故事工程团队从中吸取的经验。

## 生成式 AI 社会技术挑战#1：提示工程

是的，LinkedIn——与 GitHub(Copilot 的创建者)和 OpenAI(ChatGPT 的创建者)一样，都归微软所有。但这并不意味着他们可以很快获得内部访问权限。Patira 告诉 The New Stack，当该项目启动时，他们只能有限地访问 ChatGPT 3.5，而且他们无法大规模访问 3.5。在构建和发布此功能时，他们主要依赖其前身 GPT-3。

“当时生成式 AI 处于初级阶段，这给了我们很多启示，即我们不仅必须创作 LLM(大型语言模型)提示，而且我们还必须从零开始构建大部分生成式 AI 支架、程序到工作流程管理、工具，同时构建产品。”她说。

他们很快意识到生成式 AI 当时和现在还没有达到可以完全自主工作的水平。当然，[GPT-3 也达不到要求](https://thenewstack.io/qcon-keynote-why-generative-ai-is-harmful-to-earth-and-society/)。人类评估生成式 AI 是必要的，也仍然是必要的，这正是 LinkedIn 故事团队遵循的模式，Patira 解释说——“对这些文章质量的人类评估”。

他们会从这样的提示开始：公开演讲的常见恐惧原因是什么？

“然后，一旦我们得到了这些提示的回应，我们现在想要针对一些问题的回应开发这些初始文章。我们想批量大规模地完成这件事。我们不只想生成一个，我们想生成很多，”她继续说道。然后，“我们将其提供给了我们出色的编辑团队。他们基本上会仔细检查每个初始文章的质量，并说，‘好的，我们会根据相关性、准确性以及确保没有红色标志来对其进行评分’。”

在这一点上，他们会批准或拒绝生成式 AI 的结果，然后继续改进，例如要求生成式 AI 使文章更加简洁明快。

“所以我们一次又一次地重复这些。当你开始一次又一次地做同样的事情时，你会很快意识到你需要工具。用电子表格来做这件事没有意义，”Patira 说。“因此，在我们构建产品的同时，我们也正在构建这些工具，以确保我们可以批量大规模地进行此操作，并带有人工评估、信任分类器，所有这些都嵌入到工作流中。”

**相关阅读**：面向开发者的生成式 AI 提示技巧

## 生成式 AI 社会技术挑战#2：信任

但在机器人身上信任意味着什么？

“对于我们来说，信任是我们构建的每个产品中内嵌的一部分，”Patira说。“所以在整个生成这些文章的端到端流程中，以及最终将您的答案分发给某人的每一步，我们都使用所谓的信任分类器，这些分类器是主动防御，我们使用[瑞士奶酪模型](https://en.wikipedia.org/wiki/Swiss_cheese_model)，因为我们知道一种防御是不够的。所以在整个过程中，我们都设定了这些防线。”

她解释说，这实际上是AI，而不是生成式AI，例如能够区分异议和骚扰之间的区别。

“虽然我们想要邀请辩论，但我们不想邀请毒性内容，”她继续说道。 “我们有分类器，本质上是AI模型，它们查看每个人的贡献。它们还查看所有这些生成式AI生成的初始文章的所有内容——AI内容和人类内容，在整个过程中的每一步——并问，这是否包含有毒内容?这是否是骚扰？这是否是欺凌？”

这种必要的人机循环干预意味着团队必须迅速扩大规模，以大规模支持这一协作文章项目。他们最终组建了大约12个社会技术团队，每个团队由4或5人组成，围绕解决我们概述的挑战和子挑战组织。

“在整个过程中，我们发现AI仍然比人类更值得信赖，”Patira反思道，因为他们试图根除仇恨言论和垃圾信息，并尽早设置更多的主动防御。“人类实际上可能相当不可预测。AI更可预测。这在我们的产品中表现为我们设立了很多信任护栏来检查AI。我们意识到我们需要为人类设立比AI更多的信任护栏。”

她继续为使用生成式AI的人提供指导意见:“为了保证LinkedIn上的对话保持健康，我们需要做更多工作来确保这是由人而不是AI完成的。”

## 生成式AI社会技术挑战#3：专家识别

LinkedIn是世界上最大的专业网络，所以毫无疑问，人们都想在那里显得像专家，这使得区分真正的专家和所谓的专家变得很棘手。在今年3月推出此功能之前，在10亿用户中识别专家就已经是一个真正的问题。

“LinkedIn在这方面尤其擅长，因为我们有一个非常稠密的[Caley图](https://cayley.io/)，”Patira说，其中包括个人的工作历史、我们的技能、技能认可和任何基于技能的熟练程度测试。“根据此，我们实际上在判断某人是否是某个领域的真正专家方面处于独特的优势。”

在所有这些公开可用的个人资料数据中，LinkedIn然后使用AI来识别40，000项技能中排名前10%的人，这些技能已被分组为当时的约[1,000个专家主题](https://www.linkedin.com/pulse/topics/browse/a)。

“我们将根据我们认为最相关的内容为您排名，”她解释道。

当然，如果你想被打上专家的标签，就有动机去回复，因为如果你对一个主题领域的足够多协作故事进行回复，你可以在个人资料顶部获得一个漂亮的“顶级之声”徽章。她明确指出，“除非我们认为贡献质量真的很低或我们的专业社区政策被违反，否则我们不会隐藏内容或隐藏您的贡献。只有在这种情况下，我们才会将其删除或不向您显示。”

但在这些协作文章的早期阶段，“专家”也会受到人工审核。此外，LinkedIn成员对故事的反应与帖子的反应相同，这反过来又会反馈到AI建议算法和LinkedIn人机循环中。此外，此功能具有相同的违规报告系统。

## 生成式AI社会技术挑战#4：分发

首先是专家，然后是从协作故事中学习的最终专家。

“假设你是播客专家。一旦你发表了你的故事，我们就想要将其传递给那些实际上想了解更多有关公众演讲的人，或者那些正在寻找这些答案的人。所以我们想在他们需要的地方满足这些知识寻求者，正如我们所说的那样。” Patira说。“所以分销是另一个大的技术挑战。”

当然，LinkedIn用户是人，所以我们首先查找问题答案的地方是谷歌。谷歌碰巧设置了“人们还会问”等整洁的功能，而LinkedIn正在努力在其中获得排名。他们还会在你的LinkedIn提要中推荐此专家协作，如果你注册了LinkedIn电子邮件通知，也会推送。如果你要求获取某个用户的更新，他们也会立即向你发出提醒。

“我们本质上想改变人们的习惯，他们寻找这些答案的时间和地点，”她说。“我们想要将这些内容带到他们已经存在的地方。”

## 生成式AI社会技术挑战#5：大规模

“这些问题的很多在更小的规模下并不算难题。随着规模的扩大，它们会变得更加困难，”Patira说。这对人估计LinkedIn已标记了约4000万潜在专家。此外，还有通过提示工程和生成式AI的组合获得的数百万个问题。LinkedIn后端还拥有数百万个职位。再加上识别评估专家以大规模解决的工作。

对于提示工作流，她解释道：“我们使用的工作流中，我们将大量数据转储到队列中，然后从Kafka队列中读取它们，将它们转储到工作流程的另一部分，然后进行某些在线GPT调用，获取这些响应并存储它们——所有这些端到端操作。”

下一个工作流是专家识别，他们每隔几小时在后端离线运行作业来计算专家挖掘的数据。

“让我们看看我们当前的专家名单。谁现在可能是专家？发生了什么变化?然后再次返回所有数据，”Patira说，其中大部分发生在后端。

尤其是导出识别和提示工作流管理主要是脱机完成的。在线保留了及时通知，例如成员的提要通知，“比如你分享的一个答案对我很有用。所以你希望我及时收到通知说：‘詹妮弗刚刚分享了这个，你可能对它感兴趣’。”

LinkedIn协作故事团队正在持续工作来优化并限制需要在线与离线处理的数据量，中间是一种不像在线或实时数据那么快但比检索离线数据更快的数据。而所有这些，提要和通知是需要大规模管理的两个大型在线系统。

“在这两个方面，我们大量使用了我们的LinkedIn图谱，”Patira说，指的是[LinkedIn的经济图谱](https://economicgraph.linkedin.com/)。

并且这种规模预计会继续扩大。他们也开始实施 Chat GPT-4，预计会进一步加速增长。

“自我们推出以来已经过去了 8 个月，从那时起，增长速度一直在加快，尤其是在过去一个月到一个月半的时间里，”Somasundaram 说，包括英语的全球覆盖范围，以及最近推出的法语、西班牙语、葡萄牙语和德语版本。他们最近还发布了一个大规模的桌面重新设计。

成员最终也将能够提出问题。因为他们都强调，这些文章的目标不是全部使用 AI 文本，而是利用生成式 AI 来启动专业的、由人主导的对话。
