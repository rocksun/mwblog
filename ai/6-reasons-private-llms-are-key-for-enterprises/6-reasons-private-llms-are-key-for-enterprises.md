<!--
# 六个理由说明为什么企业需要专属大型语言模型
https://cdn.thenewstack.io/media/2023/10/0d795587-private-23-1024x683.jpg
Image from Fer Gregory on Shutterstock.
-->

为公司或产品运行一个大型语言模型有许多好处，但最根本的是能提供针对实际情景的即时数据。

译自 [6 Reasons Private LLMs Are Key for Enterprises](https://thenewstack.io/6-reasons-private-llms-are-key-for-enterprises/) 。

随着 OpenAI 的 ChatGPT 面向公众发布，[大语言模型](https://roadmap.sh/guides/introduction-to-llms)(LLM)席卷全球，这也情理之中。LLM 有趣且功能强大，为我们工作和人机交互方式带来了全新思路。几十年来，我们一直通过编程语言和用户界面等结构化方式与计算机交互。这些结构化交互方式门槛较高，需要用户按计算机预期的方式和语言与其交互。大型语言模型则完全颠覆了这种模式，允许用户用自然语言与计算机交互。

[Nvidia](https://blogs.nvidia.com/blog/2023/01/26/what-are-large-language-models-used-for/) 将 LLM 定义为“一种深度学习算法，可根据从海量数据集中获得的知识来识别、总结、翻译、预测和生成文本及其他形式的内容”。遗憾的是，训练一个大语言模型需要大量计算资源，需要数百乃至数千块图形处理卡、TB 级数据和大量时间，这使得定制模型的训练只有极少数大企业才具备实力。此外，它提出了以下考量：

* 如果您需要 LLM 中的数据更新及时，该怎么办？
* 如果您需要 LLM 中包含客户特定的数据，该怎么办？
* 如果您需要 LLM 中包含敏感或专有数据，该怎么办？

如果这些问题对您的业务至关重要，那么您就需要一个专属大型语言模型。

## 什么是专属大型语言模型？

专属大型语言模型可以概括为以下几点关键特征：

- 它托管在您的计算基础设施内，与其他业务工作负载一起运行。
- 它基于公司、行业或产品数据进行训练。可用的数据是实时的、可操作的。
- 它只向被授权访问的各方提供针对情景的准确信息。

专属大型语言模型主要有两种形式。第一种是使用公司或行业特定数据集进行自定义训练的模型，第二种是将专属托管的[大语言模型](https://roadmap.sh/guides/free-resources-to-learn-llms)(如 [Llama 2.0](https://thenewstack.io/why-open-source-developers-are-using-llama-metas-ai-model/))与[检索增强生成](https://thenewstack.io/freshen-up-llms-with-retrieval-augmented-generation/)(RAG)相结合。本文重点讨论第二种形式，即 RAG。

## 检索增强生成

根据 [IBM](https://research.ibm.com/blog/retrieval-augmented-generation-RAG) 的说法，“RAG 是一种 AI 框架，可从外部知识库检索事实，将大型语言模型基于最新、最准确的信息进行训练，让用户洞察大型语言模型的生成过程。”

描述 RAG 为大型语言模型所做工作时使用“ground”一词十分贴切，它描绘了在查询中为大型语言模型提供额外信息时发生的事情。当在查询中为大型语言模型提供情境信息时，它往往比训练用的更大规模语料库中的信息赋予更高权重，使模型的响应以提供的情境为基础，这就是“使其具备现实基础”。这种使其具备现实基础的做法可以减少幻象的发生，同时为用户提供更准确的响应。

典型的 RAG 设计如下：

![](https://cdn.thenewstack.io/media/2023/10/54cf08ad-image1b.jpg)

*检索增强生成设计图*

为公司或产品运行一个专属大型语言模型有许多好处，但最本质的是能够为用户提供实时、情境化的数据，这些数据可以用自然语言进行查询。

### 数据保护

专属大型语言模型可以处理敏感数据，如医疗病历或金融数据，然后利用生成式 AI 的力量在这些领域取得突破。由于模型托管在内部基础设施上，只向授权人员公开，您可以构建强大的以客户为中心的应用程序、聊天机器人，或者简化员工访问公司数据的方式，而无需将数据发送给第三方，降低了风险。

### 定制化

使用专属大型语言模型，您可以根据公司、行业或客户需求调整模型和响应。这种具体信息通常不会包含在通用或公开的大型语言模型中。您可以为模型提供客户支持案例、内部知识库文章、销售数据、应用使用数据等，以确保获得所需的响应。

### 掌控权

公共大型语言模型的更新往往需要等待数月。然而，专属模型可以根据用户需求控制更新周期等因素。

控制版本或使用的模型非常重要，因为如果改变用于创建嵌入的模型，则需要重新创建所有嵌入或对其进行版本管理。版本化嵌入将允许您继续使用旧嵌入，因为如有必要可以引用旧模型。

### 降低成本

使用专属大型语言模型可以减少从外部公司购买模型或专利 AI 软件的成本。据 LeewayHertz 称，这对中小企业和预算有限的开发者尤其重要。此外，使用专属模型有助于公司避免供应商锁定，从长期来看可以节省大量成本。

### 更准确

在更具体信息上训练的大型语言模型可以提供更准确、更具针对性的信息。同时，它减少了荒诞响应的风险。您可能已经使用过 ChatGPT 等公共大型语言模型，并见识过其古怪的反应。有时它会提供非常准确的信息，有时却给出完全错误的信息并将其作为事实呈现。这在很大程度上是由于公共模型训练所用的数据集过于广泛。当为模型提供非常具体的上下文时，获取准确响应的可能性将成指数增长。

### 可靠性

公共大型语言模型的性能有时不可靠，基础设施过载使查询延迟并不鲜见。众所周知，用户注意力是有限的，增加交互延迟会提高用户流失的风险。运行专属大型语言模型允许您密切关注模型的响应时间，并在必要时增加资源。

## 下一步?

使用 SingleStore，您可以将关系数据与向量结合，从而使用应用程序的实时数据为查询提供情境。SingleStoreDB 是一个分布式、实时分析和事务数据库，其强大性能确保您的专属大型语言模型的响应比任何人都快。

随着 AI 的广泛应用，企业将需求获得实时新数据以为基础模型提供适当情景。大型语言模型和其他多结构基础模型需要实时响应请求，反过来，它们也需要数据平面具备实时处理和分析不同格式数据的能力。

要实现实时 AI，企业必须在采集数据流时持续对其进行向量化，并将其用于 AI 应用。我认为这对确保业务为眼前的未来做好准备至关重要。

如果您有兴趣尽可能深入了解专属大型语言模型，请加入 10 月 17 日的 [SingleStore Now ](https://singlestorenowtherealtimeaicon.splashthat.com/?utm_source=thenewstack&utm_medium=website&utm_content=inline-mention&utm_campaign=platform)活动，我将介绍开发者如何构建和扩展引人注目的面向企业的生成式 AI 应用。欲了解更多信息和注册，请访问 [singlestore.com/now](https://www.singlestore.com/resources/singlestore-now-the-real-time-ai-conference/)。