
<!--
title: 新工具帮助LLM开发者选择更好的预训练数据
cover: https://cdn.thenewstack.io/media/2025/05/88a7dd8c-choose-data-2.jpg
summary: AI新突破！DataDecide工具包助力LLM开发者高效选择预训练数据，小规模实验精准预测大规模性能，降低训练成本。告别"垃圾进垃圾出"，优化数据集，微调AI任务，企业合规更轻松！结合RAG和架构技术，效果更佳！
-->

AI新突破！DataDecide工具包助力LLM开发者高效选择预训练数据，小规模实验精准预测大规模性能，降低训练成本。告别"垃圾进垃圾出"，优化数据集，微调AI任务，企业合规更轻松！结合RAG和架构技术，效果更佳！

> 译自：[New Tools Help LLM Developers Choose Better Pre-Training Data](https://thenewstack.io/new-tools-help-llm-developers-choose-better-pre-training-data/)
> 
> 作者：Bill Doerrfeld

在开发新的[大型语言模型 (LLM)](https://thenewstack.io/what-is-a-large-language-model/)时，选择正确的训练数据至关重要。华盛顿大学和 [Allen Institute for AI (Ai2)](https://allenai.org/) 的 AI 研究员 Ian Magnusson 告诉 The New Stack：“你用什么来训练你的模型将完全决定不同的能力。”

AI 的训练数据会影响效率、偏差和准确性。NeuroHeart 创始人 Sreekanth Gopi 告诉 The New Stack：“选择不当的数据集会放大偏差，降低任务性能，并需要大规模的下游修正。”

面对无数庞大的数据集或语料库，你如何知道哪些会产生最佳结果？彻底的测试需要大量的计算能力，这很快就会变得成本高昂。Gopi 补充说：“随着模型越来越大，训练它们的成本也会增加。”

云原生服务公司 Caylent 的 CTO Randall Hunt 告诉 The New Stack：“预训练 LLM，即使是较小的模型，在时间和计算方面也需要大量的资源，Caylent 是 [Amazon Web Services](https://aws.amazon.com/?utm_content=inline+mention) 的合作伙伴。“准确预测额外预训练数据的[投资回报率]可以节省浪费的模型训练运行。”

为了解决这个问题，今年 4 月，Ai2 发布了 [DataDecide](https://allenai.org/blog/datadecide)——一套模型、基准和建议，用于指导数据集的选择。Magnusson 在 Ai2 博客上写道：“DataDecide 是迄今为止对数据决策在规模和随机种子方面进行的最广泛的公开可用扫描。”

该研究发现，开发者不需要大量的预算就可以做出明智的训练数据选择。小规模的实验可能出奇地准确。Magnusson 告诉我们：“你可以用非常少的计算量来预测什么是最佳选择。”

## 测试训练数据：通常是临时的

迄今为止，预训练数据决策涉及大量的试验和错误。Caylent 的 Hunt 说，几乎每个人都会使用 [Common Crawl dataset](https://commoncrawl.org/)，这是一个公开可用的网页存档。“在那之后，人们往往会根据他们希望模型做什么而有所不同。”

其他人也认为，数据选择留给用户自己去解决。Gopi 说：“尽管现代模型的规模很大，但数据选择过程仍然出奇地随意。”团队通常使用开放数据集，而不进行实证测试，而是依赖直觉和过去的经验。

对象存储系统 [MinIO](https://min.io/?utm_content=inline+mention) 的 AI 解决方案工程师 Keith Pijanowski 告诉 The New Stack，早期训练涉及数据清理、向量数据库准备以及对每份文档的安全检查。在企业环境中，它通常从组织内部数据开始。
Magnusson 说，测试预训练数据最严格的方法是进行全规模训练、基准测试和重复——但这并不实际。相反，在开始全面训练之前运行小规模实验要划算得多。

他说：“这使我们能够进行分析，描述计算量与预测要训练的预训练数据集之间的关系。”

为了评估模型性能，AI 研究人员使用 MMLU、ARC、HellaSwag 和 SocialIQA 等基准来测试 LLM 在各种任务中的表现，例如推理、数学、符号解释、社会智能等。在小规模基准测试中表现良好的数据集通常在大规模测试中也表现良好。Magnusson 说：“你可以将这种关系与它在下游任务中的表现相匹配。”

## 主要发现：降低 LLM 训练成本

Ai2 在各种数据集和模型大小上测试了 DataDecide，使用 10 个基准来评估小型模型预测大规模性能的能力。这些发现并非石破天惊，但它们为 AI 开发者和研究人员提供了有用的启示。

其中，Ai2 发现小型模型（约 1.5 亿个参数）可以出人意料地准确地预测大规模结果。与数十亿参数的模型相比，一些基准仅使用 0.01% 的计算量就达到了 80% 以上的决策准确率。

由于小型模型实验使用的计算量比其他方法少，因此开发者无需运行全规模测试即可预测结果。Pijanowski 说：“这项工作的希望是降低训练期间的计算成本。”
Ai2 发现，通过小模型结果对数据集进行排序这种更简单的方法，其效果优于缩放定律。缩放定律是一种更复杂、成本更高的测试方法，旨在预测准确性如何随着模型大小的增加而提高。Magnusson 建议说，目前，“只需坚持在一个规模上进行消融研究”。

Hunt 说，这些发现应该让 LLM 开发人员停下来思考：“有一些缩放定律是从数据量、计算资源和性能之间的经验研究中得出的。Ai2 的研究表明，我们可能需要重新审视其中的一些假设。”

计算需求因基准而异。在某些情况下，准确性会提前达到稳定水平，所需的计算量远低于预期。例如，ARC Easy 是一项包含多项选择题的小学水平科学问题测试，需要的资源最少。相比之下，HellaSwag 侧重于推理和句子补全，对资源的要求更高。

Ai2 的发现对于小型实验室和初创公司尤其重要，因为它们的每一 GPU 小时都很重要。Gopi 说：“语言模型开发中最昂贵的阶段之一一直是预训练实验。”

## 选择数据集以微调 AI 任务

Gopi 说，Ai2 的研究还可以支持微调模型开发。在这个阶段，数据选择成为一个战略问题。“实际上，从一开始就选择更好的数据可以减少以后进行复杂微调和资源密集型修复的需求。”

人们通常认为更多的训练数据会导致更好的性能，但事实并非总是如此。每个 LLM 都有权衡，更多的训练数据甚至可能导致收益递减。这就是[微调的、特定于任务的模型](https://thenewstack.io/the-rise-of-small-language-models/)兴起的原因之一。[Gartner 预测](https://www.gartner.com/en/newsroom/press-releases/2025-04-09-gartner-predicts-by-2027-organizations-will-use-small-task-specific-ai-models-three-times-more-than-general-purpose-large-language-models)，到 2027 年，小型、专业模型的使用量将以三比一的速度超过大型模型。

Pijanowski 说：“如果一个组织有多个语料库用于训练 LLM，并且他们没有足够的计算能力在所有语料库上训练一个 10 亿或更多参数的 LLM，那么这项研究可以帮助他们选择能够产生最佳结果的语料库。”

DataDecide 可以帮助开发人员确定哪些数据最适合给定的 LLM 用例——无论是用于代码完成、数学、推理还是艺术生成。Magnusson 说：“这有助于我们分离出哪种信息对于培养特定任务的能力最有帮助。”

作为一项额外的好处，准确地知道您的数据来自哪里有助于企业合规性。Magnusson 说：“从头开始训练让您有信心声明您所训练的内容是基于可保证的现实。”“DataDecide 帮助您全面了解基准以及权衡。”

## 这是否有助于解决“垃圾进，垃圾出”的问题？

更明智的数据决策似乎与经典的“垃圾进，垃圾出”问题相关。LLM 通常在 PB 级的非结构化、开放式数据上进行训练，这使得检测错误、错误信息、偏见、他人的知识产权或有害内容（即垃圾）变得困难。

Pijanowski 指出，Ai2 的研究有助于解决上游问题。“它可以用于对语料库执行初始过滤，或进行一系列小型实验，以确定某个文档集合是否足够用于 LLM 微调。”

然而，Hunt 指出，DataDecide 只是一个更大整体的一部分：“如果将其与其他训练技术相结合，可能会带来福音，但它不是一种神奇的解决方案。”

Gopi 也赞同这种观点。他说：“DataDecide 使避免明显糟糕的数据选择变得更容易，但它并没有解决更深层次的数据质量问题。”将数据集与预测结果联系起来并不会自动转化为道德或长期价值。

他补充说：“DataDecide 的优点在于尽早发现比较效用，从而为预训练输入启用分类系统。”“经典的‘垃圾进’问题变得不那么随机，但并未完全解决。”

开发人员可以使用 DataDecide 在管道中更早地识别哪些数据支持他们的特定目标。Magnusson 说：“DataDecide 帮助您评估评估，以进行对数据差异敏感的新评估。”从某种意义上说，它通过首先测试结果来帮助逆向工程哪些输入实际上很重要。

## 盲点依然存在

为您的预训练数据选择正确的数据集是一个决定，它对您的 LLM 衍生应用程序的最终效率和准确性具有重大影响。

Gopi 说：“模型行为更多地受到其训练数据的影响，而不仅仅是架构本身。”不相关或冗余的数据可能导致效率低下并影响模型质量，从而使训练数据描述成为 AI 开发中一个重要但经常被忽视的领域。
尽早排除质量较差的数据集可以避免浪费计算资源并加速创新。然而，到目前为止，开发人员一直缺乏一种可靠的方法来衡量他们训练数据选择的质量。DataDecide 填补了这一空白，帮助标准化了模型开发中曾经非正式的步骤。

不过，仅靠数据选择并不能解决围绕数据质量或模型架构的更深层次的问题。“数据集选择工具是许多所需工具中的一个有用工具，”Hunt 说。“为了获得真正更强大的模型，我们需要比现在更多的架构技术。”

Pijanowski 并不完全信服：为什么不直接使用 [检索增强生成 (RAG)](https://thenewstack.io/why-rag-is-essential-for-next-gen-ai-development/)？“这允许使用所有语料库，而无需通过 LLM 运行所有内容。”

在企业环境中，他认为一个主要的挑战是将数据分割成不同的语料库，以反映模型必须学习的不同技能。

Gopi 说，还存在为可衡量的基准过度优化的风险，这些基准测试的是分数，而不是实际性能。这些指标并不总是反映在开放式、多语言或对抗性环境中的行为。“如果没有定性审查、偏差检查或代表性分析，”他说，“此类工具只能部分缓解与数据相关的风险。”

虽然没有一个工具可以解决 AI 的所有挑战，但 DataDecide 降低了做出具有深远影响的预训练决策的门槛。正如 Hunt 告诉 TNS 的那样，“这并没有显着改变事情，但这是一组令人兴奋的发现。”