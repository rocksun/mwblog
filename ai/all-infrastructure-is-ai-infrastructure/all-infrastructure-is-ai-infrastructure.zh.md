在不久的将来，所有技术基础设施都将有效地成为AI基础设施。这并非夸张。随着企业扩大其生成式AI模型和自主代理的使用，技术栈的每一层——从芯片到编排——都将为支持AI工作负载而重塑。

继从物理数据中心转向[云计算](https://thenewstack.io/cloud-native/)之后的又一次颠覆。几年内，大量传统应用空间可能会消失，取而代之的是由[AI本身](https://thenewstack.io/ai-engineering/)设计，甚至可能实时修改的AI驱动系统和工作流程。

## **为什么AI基础设施打破了旧模式**

云计算的历史是由抽象定义的。虚拟化、[容器](https://thenewstack.io/containers/)、[API](https://thenewstack.io/api-management/)和[编排引擎](https://thenewstack.io/orchestration-is-your-secret-weapon-for-smoother-workflows/)使底层——硬件、操作系统——逐渐变得不可见。

AI工作负载逆转了这一趋势。规模化性能直接取决于底层的硬件和结构。训练和推理工作负载与CPU、GPU、内存和网络紧密绑定。AI没有隐藏复杂性，反而将其暴露出来。

这造成了一个悖论：AI普及速度越快，企业就越需要细致入微地理解和优化其硬件和基础设施。当平台工程师为了实现可用的吞吐量，不得不面对NUMA（非统一内存访问）节点、PCI（外围组件互连）通道或GPU互连时，‘无服务器’简化的承诺便消失了。

## **新堆栈的复杂性**

这场变革的核心是CPU和GPU之间的关系。GPU是AI的引擎，但它们不能独立运行。CPU负责数据管道的供给、预处理和调度管理。在许多情况下，作为协调管道的一部分，作业在CPU上运行比单独在GPU上运行效果更好。扩展模型意味着要整体编排这些资源，而不是将其视为独立的孤岛。

网络同样至关重要。四种不同的网络结构塑造了AI基础设施：用于东西向和南北向数据流的数据网络；连接区域的广域网；设备间的PCI互连；以及用于超低延迟GPU集群的RDMA（远程直接内存访问）网络。在构建AI基础设施时，必须考虑到每一种网络结构，一直到存储层。

稀缺性使挑战更加严峻。GPU供应短缺，但真正的瓶颈延伸到数据中心电力和物理空间。Mirantis的一个合作伙伴在只占用其设施20%的地面空间的情况下，消耗了其100%的可用电力预算。在AI的需求下，数据中心的设计规则正在被重写——每机架更高的功耗、更高的冷却要求以及更长的设备交付周期。

## **治理与主权**

AI工作负载引入了传统应用鲜少遇到的主权问题。数据本地化要求、法律和监管控制以及欧盟的[GDPR](https://en.wikipedia.org/wiki/General_Data_Protection_Regulation)或[数字运营弹性法案（DORA）](https://en.wikipedia.org/wiki/Digital_Operational_Resilience_Act)等跨境合规框架对模型的运行地点和方式提出了新的限制。

企业不仅要确保可用性和性能，还要确保其部署的每个代理、模型和工具都具有可证明的治理能力。主权同时涵盖地理、法律和操作层面。多租户增加了另一个维度，要求对可能跨越团队、部门甚至合作组织的各种工作负载进行严格隔离。

## **开发者与抽象鸿沟**

创建AI应用的开发者不希望管理互连、网络结构和硬件管道的微小细节。

解决方案不是将复杂性推给开发者，而是设计能够隐藏基础设施细节，同时确保规模化控制、安全和性能的平台。

## **AI基础设施的构成要素**

AI基础设施可以理解为四个相互依赖的层次。

1.  **工作负载**：最上层是工作负载本身——训练、微调、推理或代理编排。虽然大规模训练会涉及成千上万个GPU的协同工作，但微调或小模型推理可能只需要少数几个。处理这两种极端情况的灵活性至关重要。
2.  **开发者体验**：接下来是可用性层。开发者需要一致性：模型应该以可预测的性能运行，无需过多的手动调优。随着老旧设备达到生命周期终点，他们需要访问训练资源、推理环境和GPU分区能力。这一层是自助服务门户、API和目录使AI在组织内普及的关键。
3.  **基础设施即服务**：在工作负载和体验之下是原始基础设施，无论是本地部署、在云端还是在边缘。
4.  **管理和可观测性**：基础是管理平面，这一层负责配置、监控和优化其上的一切。它必须将控制与数据分离，以确保管理故障不会中断工作负载。它必须通过模板提供可重复性，在每一层提供可观测性以及根据需要灵活更换供应商、框架或网络结构。企业在此层决定其主权的得失。

## **平台的战略要务**

哪些原则应该指导下一代AI基础设施平台？有几个关键点脱颖而出。

*   **可管理性**：平台不能是手动构建和脆弱的。它们必须支持全生命周期升级和持续改进。
*   **可观测性**：每一层——从GPU利用率到应用程序响应——都必须进行仪表化。性能不是可选项；它是一个硬性要求。
*   **灵活性**：随着供应商发展，企业必须保持改变堆栈层面的能力，避免厂商锁定。基础设施应在无需大规模重写的情况下进行适应。
*   **可重复性**：模板和声明式模式捕获已知的良好架构，减少复杂性并消除不必要的重复发明。
*   **无边界计算**：资源必须能够在数据中心、云端和边缘之间定位和使用，无论它们在哪里运行，都应是安全的和可观测的。
*   **资源契约**：工作负载不应抽象化硬件，而是应声明性能要求并获得有保证的契约。这把抽象转变为保证：应用程序请求其所需，基础设施做出可预测的响应。

这些关键点共同定义了战略性开放基础设施必须具备的特质：可组合、可观测且能响应AI工作负载的现实需求。

## **开源是前进的方向**

快速实现价值是一个关键的业务要求。投资AI基础设施的企业不能承受数月等待回报的代价。供应商堆栈通过将所有内容捆绑到一个封闭生态系统中来承诺便捷性。但这种便捷性是有代价的：创新受限于供应商的路线图，灵活性也被牺牲。

开源方法提供了另一种选择。基于声明式模式构建的可组合基础设施，确保平台随生态系统一同演进。模板提供可重复性。契约提供保证。无边界计算允许在任何地方发现和保护资源。企业掌控自己的命运，而不是等待单一平台来适应。

这就是Mirantis在构建[k0rdent](https://k0rdent.io/)时所遵循的愿景，k0rdent是一个从零开始设计的开源平台，旨在支持AI工作负载。K0rdent是多云、多集群和裸金属感知的。它使用基于模式的解决方案来提供声明式AI基础设施编排。它使企业能够从模糊的抽象转向明确的性能契约。通过这样做，它使组织能够按照自己的意愿，在任何地点运行工作负载，并拥有完全的可观测性和主权。

## **结论**

所有基础设施都正在成为AI基础设施。这一转变将像云计算的崛起一样具有戏剧性，但更为复杂、资源受限更多且对主权更敏感。成功的企业将拥抱可管理性、可观测性、灵活性和开放性。他们将为稀缺性和主权而设计。他们将采用提供性能契约而非抽象幻象的平台。

AI不会等待行业稳定下来。组织现在必须决定是将自己锁定在封闭生态系统中，还是拥抱战略性的开放基础设施。我们相信选择是明确的：未来属于那些能够在自己控制的基础设施上安全、规模化地利用AI的人。