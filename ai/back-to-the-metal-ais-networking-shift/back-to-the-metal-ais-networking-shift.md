<!--
title: AI网络大变局：回归“裸金属”时代
cover: https://cdn.thenewstack.io/media/2025/12/44fecf71-network.jpg
summary: AI工作负载推动网络从纯软件定义转向软硬结合，强调物理硬件性能以满足规模、延迟和安全需求，形成混合式网络架构。
-->

AI工作负载推动网络从纯软件定义转向软硬结合，强调物理硬件性能以满足规模、延迟和安全需求，形成混合式网络架构。

> 译自：[Back to the Metal: AI’s Networking Shift](https://thenewstack.io/back-to-the-metal-ais-networking-shift/)
> 
> 作者：Lee Peterson

在过去十年中，[网络](https://thenewstack.io/networking/)领域与许多IT领域遵循了相同的轨迹：将智能从单个设备中抽象出来，将控制集中到软件中，并将底层硬件视为大致可互换。软件定义广域网（WAN）、软件定义局域网（LAN）和集中式编排工具成为常态。

在许多方面，这种转变确实满足了企业的需求：更高的敏捷性、集中式策略控制、大规模自动化和简化的网络操作。[跨广泛地理区域的策略强制执行](https://thenewstack.io/the-impact-of-regular-training-and-timely-security-policy-changes-on-dev-teams/)和配置速度改变了IT团队的工作方式。

但AI现在正在重写这些规则。 [AI工作负载](https://thenewstack.io/how-agentic-ai-is-redefining-campus-and-branch-network-needs/)对网络的需求——在规模、延迟敏感性、安全性方面——更类似于高性能计算而不是传统的业务应用程序。这使得物理网络底层重新受到关注，这是我们多年未见的。

当你观察云计算领域正在发生的一切时，这种变化似曾相识。

## **从云优先到工作负载至上**

当公有云首次普及时，其优势是变革性的：即时可扩展性、快速配置、无需维护大量数据中心基础设施的运营自由以及按需付费的经济模式。企业将其视为加速创新和响应市场变化需求的方式。

但随着AI工作负载的加入，它们的独特特性正在影响[它们的最佳运行位置](https://thenewstack.io/ai-in-network-observability-the-dawn-of-network-intelligence/)。大规模模型训练可以生成海量数据，通常是PB级，这些数据在更靠近创建或聚合位置处理效率更高。实时AI服务，例如制造业中的计算机视觉或客户服务中的自然语言助手，可能受益于超低延迟执行，这在本地或边缘位置更容易实现。对于处理敏感或受监管数据的组织，将部分工作流本地化可以简化[合规性和治理](https://thenewstack.io/3-steps-cloud-governance-steps-to-avoid-the-next-hack/)。

这种演变通常被称为“云回迁”，它并非远离云，而是智能地将工作负载放置在它们表现、扩展和合规性最佳的位置。公有云对于许多AI应用程序仍然至关重要，但它现在是更深思熟虑的混合生态系统的一部分，其中一些AI工作负载或AI生命周期的阶段更接近于旨在满足[性能和效率目标的基础设施](https://thenewstack.io/cios-heed-on-premises-app-and-infrastructure-performance/)。

## **为何AI工作负载会打破虚拟舒适区**

在传统的企业环境中，即使是要求苛刻的应用程序也能通过尽力而为的互联网带宽和以几十毫秒计的延迟良好运行。在这些条件下，运行在通用转发硬件上的软件定义覆盖网络表现出色。

AI工作负载改变了这种局面。训练大型模型涉及GPU集群和存储之间持续的大容量数据移动，这会迅速将虚拟化转发平面推向其吞吐量极限。虽然训练通常在核心数据中心进行，但推理现在正开始转向边缘和分支机构，为分布式基础设施带来了新的要求。

延迟也变得至关重要。用于实时分析、自动驾驶车辆协调或工业自动化的AI推理可能需要以微秒而不是毫秒为单位的数据包传输。确定性延迟——一致且有保证的传输时间——必须在硬件中强制执行。

安全性同样重要。AI数据通常包含敏感的知识产权或受监管的个人信息。在不降低性能的情况下加密这些高吞吐量流需要能够实现线速处理的专用芯片。在AI经常部署的坚固或工业环境中，硬件本身必须经久耐用，能够承受恶劣条件，有时还需要与现代工作负载同时运行传统协议。

## AI‑优化网络硬件的案例

这些需求并非否定软件定义网络的价值，恰恰相反。控制器、编排器和覆盖网络在制定策略、自动化配置和智能路由流量方面从未如此重要。但如果没有AI优化的硬件底层，这些系统可能会受到限制。

可以将其类比为运行高级AI模型：编排层可能调度和管理训练任务，但执行性能来自于专为工作负载构建的GPU和专用加速器。在网络中，这种执行能力来自AI就绪的物理路由器、交换机和无线设备。

这些平台提供基于ASIC（专用集成电路）的数据包转发，能够维持太比特级的吞吐量。它们使用硬件实现的质量服务和流量整形来提供微秒级延迟控制。它们支持后量子时代，并在不牺牲速度的情况下处理加密和内联威胁防护。它们还将遥测直接集成到转发平面中，使运营商能够实时监控和优化AI数据流。

## **软件敏捷性与硬件实力相结合**

目标不是用以硬件为中心的网络取代软件定义解决方案，而是确保底层能够支持AI流量的复杂性和强度。这是软件定义网络承诺的自然延伸：将控制与硬件解耦，同时仍然使物理基础设施与工作负载的性能要求保持一致。

想象一个SD‑WAN部署为AI应用程序选择最佳路径，但该路径连接到一个能够以不降低性能的方式转发加密的400 Gbps流量的物理路由器。或者一个软件定义园区网络分割和优先处理AI推理流量，由交换机芯片强制执行，保证这些微秒级的服务级别协议。

软件进行编排和适应；硬件以满足AI全部需求的方式执行。

## **为AI架构：一种混合网络方法**

随着AI从试点走向生产，网络策略将遵循云计算基础设施的模式，变得更加深思熟虑和以工作负载为中心。硬件刷新周期将缩短，以跟上路由和交换芯片的进步，而包括抗量子算法在内的下一代安全性将确保经验证的访问，从设备层面开始。网络设计决策将明确考虑AI工作负载的放置，就像云架构师现在选择代码是在云、边缘还是本地运行一样。

行业方向明确：最强大的AI网络将把软件定义敏捷性与AI优化硬件性能相结合。这种组合将使基础设施能够满足AI前所未有的规模、安全性和延迟要求，从云核心、通过广域网，直到坚固的边缘。

AI正在触发网络领域特有的“回迁思维”，这不是回归过去，而是为了未来进行重新校准。正如云策略已经演变为将工作负载放置在最适合运行的位置一样，AI也需要软件定义网络的灵活性与专用硬件的原始、可预测能力之间的平衡。正确实现这种平衡将使企业能够充分发挥AI的潜力。