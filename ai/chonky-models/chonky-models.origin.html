<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">How do large language models get so large? | Tigris Object Storage</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.tigrisdata.com/blog/chonky-models/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="How do large language models get so large? | Tigris Object Storage"><meta data-rh="true" name="description" content="AI models, comprised mainly of floating-point numbers, function by processing inputs through various components like tokenizers and embedding models. They range in size from gigabytes to terabytes, with larger parameter counts enhancing performance and nuance representation. How do they get so large though?
"><meta data-rh="true" property="og:description" content="AI models, comprised mainly of floating-point numbers, function by processing inputs through various components like tokenizers and embedding models. They range in size from gigabytes to terabytes, with larger parameter counts enhancing performance and nuance representation. How do they get so large though?
"><meta data-rh="true" name="keywords" content="object storage,blob storage,s3,ai,architecture"><meta data-rh="true" property="og:image" content="https://www.tigrisdata.com/blog/assets/images/tiger-ship-bc25048dacd81302f92172bac532377f.webp"><meta data-rh="true" name="twitter:image" content="https://www.tigrisdata.com/blog/assets/images/tiger-ship-bc25048dacd81302f92172bac532377f.webp"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-01-23T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://xeiaso.net"><meta data-rh="true" property="article:tag" content="object storage,reliability,performance"><link data-rh="true" rel="icon" href="/blog/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.tigrisdata.com/blog/chonky-models/"><link data-rh="true" rel="alternate" href="https://www.tigrisdata.com/blog/chonky-models/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.tigrisdata.com/blog/chonky-models/" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Tigris Object Storage RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Tigris Object Storage Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="Tigris Object Storage JSON Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GW2DNH9EW4"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-GW2DNH9EW4",{anonymize_ip:!0})</script>


<link rel="preconnect" href="https://ph.tigrisdata.com">
<script>!function(t,e){var o,p,i,n;e.__SV||(window.posthog=e,e._i=[],e.init=function(r,s,a){function c(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(i=t.createElement("script")).type="text/javascript",i.async=!0,i.src=s.api_host+"/static/array.js",(n=t.getElementsByTagName("script")[0]).parentNode.insertBefore(i,n);var _=e;for(void 0!==a?_=e[a]=[]:a="posthog",_.people=_.people||[],_.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},_.people.toString=function(){return _.toString(1)+".people (stub)"},o="capture identify alias people.set people.set_once set_config register register_once unregister opt_out_capturing has_opted_out_capturing opt_in_capturing reset".split(" "),p=0;p<o.length;p++)c(_,o[p]);e._i.push([r,s,a])},e.__SV=1)}(document,window.posthog||[]),posthog.init("phc_6a2zd9w9hGzIqYl527bL4dXk3Wz8J9pEHyXTwP1hHq4",{api_host:"https://ph.tigrisdata.com",opt_in_site_apps:!0,id:"default"})</script><link rel="stylesheet" href="/blog/assets/css/styles.f0e9b0ee.css">
<script src="/blog/assets/js/runtime~main.2e0f825e.js" defer="defer"></script>
<script src="/blog/assets/js/main.625b88d1.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a href="https://www.tigrisdata.com" target="_self" rel="noopener noreferrer" class="navbar__brand"><div class="navbar__logo"><img src="/blog/logo/light.png" alt="Tigris Blog" class="themedComponent_mlkZ themedComponent--light_NVdE" height="26px"><img src="/blog/logo/dark.png" alt="Tigris Blog" class="themedComponent_mlkZ themedComponent--dark_xIcU" height="26px"></div></a><a href="https://www.tigrisdata.com/docs/" target="_self" rel="" class="navbar__item navbar__link disable-external-icon">Docs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://www.tigrisdata.com/docs/overview/" target="_self" rel="" class="navbar__item navbar__link disable-external-icon">Overview<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://www.tigrisdata.com/docs/about/" target="_self" rel="" class="navbar__item navbar__link disable-external-icon">About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://www.tigrisdata.com/docs/get-started/" target="_self" rel="" class="navbar__item navbar__link disable-external-icon">Get Started<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://www.tigrisdata.com/docs/sdks/fly/" target="_self" rel="" class="navbar__item navbar__link disable-external-icon">Fly.io<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://www.tigrisdata.com/docs/sdks/s3/" target="_self" rel="" class="navbar__item navbar__link disable-external-icon">AWS S3 SDKs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://www.tigrisdata.com/docs/migration/" target="_self" rel="" class="navbar__item navbar__link disable-external-icon">Migration<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog/">Blog</a><a href="https://www.tigrisdata.com/docs/pricing/" target="_self" rel="" class="navbar__item navbar__link disable-external-icon">Pricing<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://twitter.com/TigrisData" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link pseudo-icon twitter-icon"></a><a href="https://console.tigris.dev/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link wc-portal-signup wc-portal-link">Dashboard<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All our posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/chonky-models/">How do large language models get so large?</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/downgrade-py-js/">If you’ve upgraded boto3 or the JavaScript S3 client in the last week, uploading files won’t work. Here’s how to fix it.</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/tigris-filesystem/">Using Tigris as a Filesystem</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/case-study-beam/">How Beam runs GPUs anywhere</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/training-any-cloud/">Training with Big Data on Any Cloud</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/nomadic-compute/">Nomadic Infrastructure Design for AI Workloads</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/tigris-supports-storage-tiers/">Tigris supports Storage Tiers</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/how-we-built-object-notifications/">How we built object notifications in Tigris</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/docker-registry-at-home/">Becoming your own Docker Registry with Tigris</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/availability-metrics-public/">We&#x27;re making our availability metrics public</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/case-study-falai/">How fal.ai offers the fastest generative ai in the world</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/shadow-bucket-thumbnails/">Using Shadow Buckets for Fun and Thumbnails</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/s3-conditional-writes/">What’s the Big Deal with Conditional Writes Support in S3?</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/metadata-quering-with-elixir/">Metadata Querying for Object Storage feat. Elixir</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/fly-tigris-juicefs/">Sharing your Ollama models between Fly Machines using JuiceFS and Tigris</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/eager-and-lazy-caching/">Eager &amp; Lazy Caching feat. Elixir</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/enabling-billing-for-tigris-in-july/">We&#x27;re enabling billing for Tigris in July</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/ai-image-generator-with-stability-and-tigris/">AI Image Generator with Stability and Tigris</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/tigris-vs-s3-cloudfront/">Tigris vs. S3 &amp; Cloudfront</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/a16z-round-press-release/">Announcing Tigris Seed Round led by Andreessen Horowitz</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/object-storage-public-beta/">Tigris, the globally distributed S3-compatible object storage</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/data-layer-foundationdb/">How we built our metadata layer on FoundationDB</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/tigris-authentication-authorization/">Tigris&#x27;s object store&#x27;s authentication &amp; authorization</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/foundationdb-meetup-indexes-talk/">A developer-driven approach to building secondary indexes presentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/client-side-encryption/">Navigating Client-Side Encryption</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/backing-up-foundationdb/">Backing up FoundationDB</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/srp/">SRP Demystified: Strengthening Authentication in the Digital Age</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/transaction-internals-tigris/">Tigris transaction internals</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/building-a-database-using-foundationdb/">Skipping the boring parts of building a storage platform using FoundationDB</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="AI models, comprised mainly of floating-point numbers, function by processing inputs through various components like tokenizers and embedding models. They range in size from gigabytes to terabytes, with larger parameter counts enhancing performance and nuance representation. How do they get so large though?
"><link itemprop="image" href="https://www.tigrisdata.com/blog/assets/images/tiger-ship-bc25048dacd81302f92172bac532377f.webp"><meta itemprop="keywords" content="object storage,blob storage,s3,ai,architecture"><header><h1 class="title_f1Hy" itemprop="headline">How do large language models get so large?</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-01-23T00:00:00.000Z" itemprop="datePublished">January 23, 2025</time> · <!-- -->8 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://xeiaso.net" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://avatars.githubusercontent.com/u/529003?v=4" alt="Xe Iaso" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://xeiaso.net" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Xe Iaso</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Cloud Whisperer</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p><img decoding="async" loading="lazy" alt="A majestic blue tiger riding on a sailing ship. The tiger is very large." src="/blog/assets/images/tiger-ship-bc25048dacd81302f92172bac532377f.webp" width="1280" height="723" class="img_ev3q"></p>
<center><small><em><p>A majestic blue tiger riding on a sailing ship. The tiger is very large.
Image generated using PonyXL.</p></em></small></center>
<p>AI models can get pretty darn large. Larger models seem to perform better than
smaller models, but we don’t quite know why. My work MacBook has 64 gigabytes of
RAM and I’m able to use nearly all of it when I do AI inference. Somehow these
40+ gigabyte blobs of floating point numbers are able to take a question about
the color of the sky and spit out an answer. At some level this is a miracle of
technology, but how does it work?</p>
<p>Today I’m going to cover what an AI model really is and the parts that make it
up. I’m not going to cover the linear algebra at play nor any of the neural
networks. Most people want to start with an off the shelf model, anyway.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-ai-models-made-out-of">What are AI models made out of?<a href="#what-are-ai-models-made-out-of" class="hash-link" aria-label="Direct link to What are AI models made out of?" title="Direct link to What are AI models made out of?">​</a></h2>
<p>At the core an AI model is really just a ball of floating-point numbers that the
input goes through to get an output. There’s two basic kinds of models: language
models and image diffusion models. They’re both very similar, but they have some
different parts.</p>
<p>A text generation model has a few basic parts:</p>
<ul>
<li>A tokenizer model to break input into pieces of words, grammatical separators,
and emoji.</li>
<li>An embedding model to take the frequencies of relationships between tokens and
generate the “concept”, which is what allows a model to see that “hot” and
“warm” are similar.</li>
<li>Token predictor weights, which the embeddings are passed through in order to
determine which tokens are most likely to come next.</li>
</ul>
<p>Note these are really three individual models
<a href="https://bojackhorseman.fandom.com/wiki/Vincent_Adultman" target="_blank" rel="noopener noreferrer">stacked</a> on top of
each other, but they only make sense together. You cannot separate them nor
exchange the parts.</p>
<p>Of all of those, the token predictor weights are the biggest part. The number of
“parameters” a language model has refers to the number of floating point numbers
in the token predictor weights. An 8 billion parameter language has 8 billion
floating point parameters.</p>
<p>An image diffusion model has most of the same parts as a language model:</p>
<ul>
<li>A tokenizer to take your input and break it into pieces of words, grammatical
separators, and emoji.</li>
<li>An embedding model to turn those tokens into a latent space, a kind of
embedding that works better for latent diffusion.</li>
<li>A de-noising model (unet) that gradually removes noise from the latent space
to make the image reveal itself.</li>
<li>A Variational AutoEncoder (VAE) that is used to encode a latent space into an
image.</li>
</ul>
<p>Most of the time, a single model (such as Stable Diffusion XL, PonyXL, or a
finetune) will include all four of these models in one single <code>.safetensors</code>
file.</p>
<p>In the earlier days of Stable Diffusion 1.5, you usually got massive quality
gains by swapping out the VAE model for a variant that works best for you (one
does anime style images better, one was optimized for making hands look correct,
one was optimized for a specific kind of pastel watercolor style, etc). Stable
Diffusion XL and later largely made the VAE that’s baked into the model good
enough that you no longer needed to care.</p>
<p>Of the three stacked models, the de-noising model is the size that&#x27;s cited. The
tokenizer, embedding model, and variational autoencoder are extras on the side.
Stable Diffusion XL has 6.6 billion parameters and Flux [dev] has 12 billion
parameters in their de-noising models, and the other models fit into about 5-10%
of the model size and are not counted by the number of parameters, however they
do contribute to the final model size.</p>
<p>We currently believe that the more parameters a model has allows it to represent
nuance more accurately. This generally means that a 70 billion parameter
language model is able to handle tasks that an 8 billion parameter language
model can’t, or that a 70 billion parameter language model will be able to do
tasks better than an 8 billion parameter language model.</p>
<p>Recently smaller models are catching up,
<a href="https://www.scientificamerican.com/article/when-it-comes-to-ai-models-bigger-isnt-always-better/" target="_blank" rel="noopener noreferrer">bigger isn&#x27;t always better</a>.
Bigger models require more compute and introduce performance bottlenecks. The
reality is that people are going to use large models, so we need to design
systems that can handle them.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="quantization">Quantization<a href="#quantization" class="hash-link" aria-label="Direct link to Quantization" title="Direct link to Quantization">​</a></h2>
<p>If you’re lucky enough to have access to high-vram GPUs on the cheap, you don’t
need to worry about quantization. Quantization is a form of compression where
you take a model’s floating-point weights and convert them to a smaller number,
such as converting a 70 billion parameter model with 140 gigabytes of float16
parameters (16 bit floating numbers) to 35 gigabytes of 4-bit parameters (Q4).
This is a lossy operation, but it will save precious gigabytes from your docker
images and let bigger models fit into smaller GPUs.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>When you read a model quantization level like <code>Q4</code> or <code>fp16</code>/<code>float16</code>, you can
interpret it like this:</p><table><thead><tr><th style="text-align:left">Initial Letter</th><th style="text-align:left">Number</th><th style="text-align:left">What it means</th></tr></thead><tbody><tr><td style="text-align:left"><code>Q</code> or <code>I</code></td><td style="text-align:left"><code>4</code></td><td style="text-align:left">Four bit integers</td></tr><tr><td style="text-align:left"><code>f</code>, <code>fp</code>, or <code>float</code></td><td style="text-align:left"><code>16</code></td><td style="text-align:left">16 bit <a href="https://en.wikipedia.org/wiki/IEEE_754" target="_blank" rel="noopener noreferrer">IEEE754</a> floating-point numbers (half-precision)</td></tr></tbody></table></div></div>
<p>Using quantization is a tradeoff between the amount of video memory (GPU ram)
you have and the desired task. A 70B model at Q4 quantization will have a loss
in quality compared to running it at the full float16 quantization, but you can
run that 70B model on a single GPU instead of needing two to four GPUs to get it
running.</p>
<p>Most of the time you won’t need to quantize image diffusion models to get them
running (with some exceptions for getting Flux [dev] running on low-end
consumer GPUs). This is something that is almost exclusively done with language
models.</p>
<p>In order to figure out how much memory a model needs at float16 quantization,
follow this rule of thumb:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">(Number of parameters * size of each parameter) * 1.25</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This means that an 8 billion parameter model at 16 bit floating point precision
will take about 20 gigabytes of video memory, but can use more depending on the
size of your context window.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="where-to-store-them">Where to store them<a href="#where-to-store-them" class="hash-link" aria-label="Direct link to Where to store them" title="Direct link to Where to store them">​</a></h2>
<p>The bigger your AI model, the larger the weights will be.</p>
<p>AI models are big blobs of data (model weights and overhead) that need to be
loaded into GPU memory for use. Most of the time, the runtimes for AI models
want the bytes for the model to be present on the disk before they load them.
This raises the question of “Where do I store these things?”</p>
<p>There’s several options that people use in production:</p>
<ul>
<li>Git LFS such as with HuggingFace.</li>
<li>Putting the model weights into object storage (like Tigris) and downloading
them when the application starts up.</li>
<li>Putting the model weights into dedicated layers of your docker images (such as
with <a href="https://depot.ai/" target="_blank" rel="noopener noreferrer">depot.ai</a>).</li>
<li>Mounting a remote filesystem that has the models already in them and using
that directly.</li>
</ul>
<p>All of these have their own pros and cons. Git LFS is mature, but if you want to
run it on your own hardware, it requires you to set up a dedicated git forge
program such as Gitea. Using a remote filesystem can lock you into the
provider’s implementation of that filesystem (such as with AWS Elastic
FileSystem). Putting model weights into your docker images can cause extraction
time to increase and can go over the limits of your docker registry of choice.
When using Tigris (or another object store), you&#x27;ll need to either download the
model weights to disk on startup or set up a performant shared filesystem like
<a href="https://www.tigrisdata.com/docs/training/geesefs-linux/" target="_blank" rel="noopener noreferrer">GeeseFS</a>.</p>
<p>Keep all this in mind as you’re comparing options.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="in-summary">In summary<a href="#in-summary" class="hash-link" aria-label="Direct link to In summary" title="Direct link to In summary">​</a></h2>
<p>We’ve spent a lot of time as an industry thinking about the efficiency of Docker
builds and moving code around as immutable artifacts. AI models have the same
classic problems, but with larger artifact size. Many systems are designed under
the assumption that your images are under an undocumented “reasonable” size
limit, probably less than 140 gigabytes of floating-point numbers.</p>
<p>Don’t feel bad if your system is struggling to keep up with the rapid rate of
image growth. It wasn’t designed to deal with the problems we have today, so we
get to build with new tools. However, in a pinch shoving your model weights into
a Docker image will work out just fine if you’re dealing with 8 billion
parameter models at Q4 quantization or less.</p>
<p>Above that threshold, you’ll need to chunk up your models into smaller pieces
<a href="https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-70B/tree/main" target="_blank" rel="noopener noreferrer">like upstream models do</a>.
If that’s a problem, you can store your models in Tigris. We’ll handle any large
files for you without filetype restrictions or restrictive limits. Our filesize
limit is 5 terabytes. If your model is bigger than 5 terabytes, please get in
touch with us. We would love to know how we can help.</p>
<div><div><div class="is--color_gradient_back"><div class="sl_card_m-2 card_static cta-flex"><div class="cta-margin-left"><h1 class="sl_title_m fix-1px">Want to try it out?</h1><p>Make a global bucket with no egress fees and store all your models all over the world.</p></div><div class="cta-flex-item cta-margin-right"><div style="white-space:nowrap"><a href="https://www.tigrisdata.com/docs/get-started/" class="cta-link"><div>Get Started<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="icon-margin iconExternalLink_node_modules-@docusaurus-theme-classNameic-lib-theme-Icon-ExternalLink-styles-module"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></div></a></div></div></div></div></div></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/object-storage/">object storage</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/reliability/">reliability</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/performance/">performance</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/downgrade-py-js/"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">If you’ve upgraded boto3 or the JavaScript S3 client in the last week, uploading files won’t work. Here’s how to fix it.</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-are-ai-models-made-out-of" class="table-of-contents__link toc-highlight">What are AI models made out of?</a></li><li><a href="#quantization" class="table-of-contents__link toc-highlight">Quantization</a></li><li><a href="#where-to-store-them" class="table-of-contents__link toc-highlight">Where to store them</a></li><li><a href="#in-summary" class="table-of-contents__link toc-highlight">In summary</a></li></ul></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="margin-bottom--sm"><a class="footerLogoLink_BH7S" href="/blog/"><img src="/blog/logo/light.png" alt="Tigris Blog" class="footer__logo themedComponent_mlkZ themedComponent--light_NVdE" height="26px"><img src="/blog/logo/dark.png" alt="Tigris Blog" class="footer__logo themedComponent_mlkZ themedComponent--dark_xIcU" height="26px"></a></div><p class="footer__description">Tigris is a globally distributed S3-compatible object storage service that provides low latency anywhere in the world. Tigris enables developers to quickly and easily store and access any amount of data for a wide range of use cases.</p><div class="footer__row"><div class="footer__data"><div class="footer__cta"><a href="https://console.tigris.dev/" target="_blank" rel="noopener noreferrer">Dashboard</a></div></div><div class="links"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.tigrisdata.com/docs/about/" target="_self" rel="" class="footer__link-item disable-external-icon">About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/blog/">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.tigrisdata.com/docs/pricing/" target="_self" rel="" class="disable-external-icon">Pricing<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.tigrisdata.com/docs/legal/service-terms/" target="_self" rel="" class="footer__link-item disable-external-icon">Terms of Service<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.tigrisdata.com/docs/legal/privacy-policy/" target="_self" rel="" class="footer__link-item disable-external-icon">Privacy Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Developers</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.tigrisdata.com/docs/" target="_self" rel="" class="disable-external-icon">Docs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://status.tigris.dev/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Status<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="mailto:help@tigrisdata.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Support<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Tigris Data, Inc. All rights reserved.</div></div></div></footer></div>
</body>
</html>