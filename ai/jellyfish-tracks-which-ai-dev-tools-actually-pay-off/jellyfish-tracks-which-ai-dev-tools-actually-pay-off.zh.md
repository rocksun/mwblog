目前，关于在软件开发中使用人工智能，每个人都在使用它，但似乎没有人真正知道他们花了钱得到了什么。

有一家公司为此提供了一个解决方案。[Jellyfish](https://jellyfish.co/)，它提供了一个[软件工程智能平台](https://thenewstack.io/jellyfish-tracks-ai-impact-across-four-major-coding-tools/)，今天为其 [Jellyfish AI Impact](https://jellyfish.co/platform/jellyfish-ai-impact/) 平台推出了新功能，该平台可提供人工智能对整个[软件开发生命周期 (SDLC)](https://thenewstack.io/ai-agents-are-finally-starting-to-revolutionize-the-software-development-lifecycle/)中的生产力、质量和价值的影响的端到端可见性。

该平台提供关于哪些人工智能工具真正有效以及它们是否物有所值的真实数据。

## 终于有了一些实际数据

因此，Jellyfish 决定使用他们的 AI Impact 平台来解决这个问题，该平台使用户能够摆脱猜测，并实际查看数据。

[Jellyfish AI Impact](https://jellyfish.co/platform/jellyfish-ai-impact/) 的新功能现在支持 Anthropic 的 [Claude Code](https://thenewstack.io/claude-code-user-base-grows-300-as-anthropic-launches-enterprise-analytics-dashboard/) 和 [Windsurf](https://thenewstack.io/windsurf-an-agentic-ide-that-thinks-and-codes-with-you/)，以及 [GitHub Copilot](https://thenewstack.io/github-copilot-a-powerful-controversial-autocomplete-for-developers/)、[Cursor](https://thenewstack.io/using-cursor-ai-as-part-of-your-development-workflow/)、[Gemini](https://thenewstack.io/gemini-cli-googles-challenge-to-ai-terminal-apps-like-warp/) 和 [Amazon Q](https://thenewstack.io/code-in-your-native-tongue-amazon-q-developer-goes-global/)，包括：

*   **多工具比较：** 它将你所有的人工智能工具集中在一个地方，以便你可以并排比较它们。想知道 Claude Code 是否比 Copilot 更适合你的特定用例？现在你可以找到答案，而不是凭直觉。Jellyfish 将关于工具采用、成本和影响的数据整合到一个统一的视图中，因此用户可以对多个 AI 工具进行基准测试，确定特定用例中价值最高的工具，并构建最有效的人工智能工具堆栈。

*   **代码审查代理仪表板：** 随着越来越多的公司使用代码审查工具，Jellyfish 允许团队衡量人工智能代码审查代理（如 [CodeRabbit](https://thenewstack.io/coderabbits-ai-code-reviews-now-live-free-in-vs-code-cursor/)、[Graphite](https://www.graphite.dev/homepage) 和 [Greptile](https://www.greptile.com/)）对整个 SDLC 的影响。

*   **动态人工智能工具支出仪表板：** 借助 Jellyfish 的实时、基于使用情况的团队和项目级别的支出跟踪，公司现在可以将支出直接与结果联系起来，以确定对于特定计划而言，这项投资是否值得。

正如 Jellyfish 联合创始人兼首席执行官 [Andrew Lau](https://www.linkedin.com/in/amlau/) 告诉 The New Stack 的那样，他的公司“让客户能够将细粒度的人工智能支出与交付影响联系起来，从而帮助工程和财务领导者更好地了解这项投资在个人和/或项目层面的价值——所有这些都发生在人工智能成本差异巨大，且对原因几乎没有理解或可见性的时期。”

## 为什么这很重要

Jellyfish 在这里所做的明智之举是保持供应商中立。他们并没有试图向你推销特定的人工智能工具——他们只是在帮助你弄清楚哪些工具对你的团队有效。

Lau 解释说：“随着行业继续进入代理时代，我们为你提供优化当今工具并为未来做好准备所需的洞察力。” 翻译：人工智能工具的前景将继续快速变化，因此你需要一个可以适应的系统。

这可能仅仅是个开始。[人工智能代理](https://thenewstack.io/how-ai-agents-will-change-the-web-for-users-and-developers/) 越来越复杂，定价模式不断发展，并且越来越多的公司将要求证明他们的人工智能投资是值得的。

这就是为什么这种解决方案非常有意义。根据 Jellyfish 的 [2025 年工程管理状况](https://jellyfish.co/resources/2025-state-of-engineering-management-report/) 报告，90% 的工程团队现在正在使用 [AI 编码工具](https://thenewstack.io/ai-coding-tools-create-more-bugs-than-they-fix/)。这比去年仅 61% 有所上升。但是，许多工程团队仍然在盲目地使用人工智能，缺乏构建最有效的人工智能工具堆栈所需的数据。

许多公司基本上是在人工智能工具上砸钱，并希望获得最好的结果。他们这里有 GitHub Copilot，那里有 Claude Code，可能还加入了一些 Cursor，而且他们都在为此付费，但并没有真正理解哪些工具在发挥作用。

## 没有人愿意谈论的问题

Lau 解释说：“人工智能的采用正在加速，成本正在转移，而且我们都面临着使其发挥作用的压力——无论是从代码、产品、商业价值还是采用的角度来看。”“现在有这么多可用的工具都在做创新但不同的事情——通常是为了争夺注意力并共存于同一个工程组织中。”

该公司表示，Jellyfish AI Impact 结合了所有人工智能驱动工具（从编码助手到代码审查代理）的采用指标、动态价值跟踪和交付结果数据，从而清晰、全面地了解人工智能在软件交付中的作用。借助这些整体的见解，工程领导者可以在整个 SDLC 中推动更明智的投资和更好的交付结果。

Lau 补充说：“领导者需要方法来消除噪音，以了解哪些工具和代理适用于哪些团队、代码库和项目，以及原因。” 这种情况不会持续太久，尤其是当这些工具开始花费真金白银，而高管们希望看到真正的回报时。

## 底线

该公司表示，DraftKings 和 Keller Williams 等公司已经在使用 Jellyfish 来更明智地进行人工智能支出。随着市场的成熟，拥有关于什么有效（以及什么无效）的实际数据，将把有效使用人工智能的公司与仅仅是昂贵地使用人工智能的公司区分开来。

新的 Jellyfish 功能现已推出。