
<!--
title: 透明度与社区：人工智能的开源愿景
cover: https://cdn.thenewstack.io/media/2024/05/e7d12269-open.jpg
-->

随着我们探索人工智能和开源的复杂性，培养一个接受坦诚反馈和迭代改进的社区至关重要。

> 译自 [Transparency and Community: An Open Source Vision for AI](https://thenewstack.io/transparency-and-community-an-open-source-vision-for-ai/)，作者 Amanda Kelly。

开源软件是每个人生活的一部分。一项看似平凡的任务，例如发送电子邮件，其神奇之处归功于开发人员的协作贡献，包括对基础技术的贡献者，例如 Linux 操作系统和 Apache Web 服务器应用程序。电子邮件奠定的基础，更广泛地说，互联网展示了开放式开发如何为我们文明的关键基础设施提供动力。

同样，人工智能正在进入我们的日常生活。[人工智能的潜力](https://thenewstack.io/ai/) 突然变得真实——从击败空文档中的闪烁光标，到生成令人眼花缭乱的创意图像，再到使用互联网规模的知识来回答问题。正如我们已经目睹的那样，人工智能的智能程度与其创造者一样。我们在人工智能中看到的偏见、盲点、假设和幻觉只是让我们确信我们确实是人类。

将语言组织成机器可以消费和操作的系统的概念并不新鲜。直到最近，机器才赶上了人类想象力的力量。结果是人工智能快速发展的格局，其中迭代周期变得越来越紧密。GPT-3 的发布及其由此产生的 ChatGPT 界面预示着人工智能的巨大转变。[大型语言模型 (LLM)](https://roadmap.sh/guides/introduction-to-llms) 竞赛已经开始。

几乎每个新的 LLM 竞争者都更快、更智能、更轻量级，但这些模型的围墙花园的钥匙仍然牢牢掌握在它们的主人手中。我们是这些花园产品的消费者，并且在某种程度上是未被承认的贡献者。但这与开源方式——互联网基础、许多这些 LLM 的主要语料库的形成方式——是一种非常不同的契约和开发方式。

尽管硬件和优化技术的进步帮助缩小了 LLM 的计算需求与可用计算机能力之间的差距，但 LLM 并不是很多人可以在其家用计算机上运行的东西——至少现在不行。

复制人类直观理解的语言系统所需的计算能力对大多数人来说是遥不可及的，这引发了一个问题，“即使 LLM 应该是开源的，它们不断增长的硬件需求是否会带来传统开源中不存在的新进入壁垒？”

这可能是求助于其他一些开源原则的地方。你不能在不谈论社区的情况下谈论开源，而且，如果现在普通人无法在他们的家庭实验室中运行 LLM，那么社区可能是人工智能开源的关键。

## 透明度驱动的开发

当我和我的联合创始人决定让 [Streamlit](https://streamlit.io/) 开源时，我们不知道它会如何发展。与决定让项目保持关闭或向世界开放的每一个决定一样，我们都不是轻率做出的。我们知道开源项目创造了机会，但也对社区负有责任。[开源和采用社区战略](https://thenewstack.io/the-open-source-strategy-of-amazon-web-services/) 揭示了一个项目存在的许多边缘案例和问题，这可能会让人筋疲力尽和尴尬，但也是一个项目的优势所在。

这就是开源的风险和美。无论你选择哪种开放程度，你都必须对你做出的决策负责，并说明做出这些决策的原因。这种问责制让你质疑自己的假设，并从不同的角度考虑一切。这是一种推动开发人员职业生涯并推动创新的思维方式。

> 透明度激发信任，进而激发创造力和创新。

社区对 Streamlit 的所作所为和要求总是不停地让我惊讶、鼓舞和谦卑。我们更多地依赖社区的投入，而不是他们对代码的贡献。请求通常来自一群特别热情的人，他们有动力和时间分叉代码，将其拉取下来，启动并运行测试并通过测试，创建一个分支，提交他们的代码进行审查，然后回复评论。我们在 Streamlit 社区中有一些这样的人，但一般来说，我们的社区由不仅使用和喜爱 Streamlit，而且还向他们的朋友和同事推荐它的人组成。这对我来说真的是最高的荣誉，也是让我真正为我的工作感到自豪的原因。

这也是一项重大的责任。我不想让他们失望。我对自己和 Streamlit 要求更高，因为我知道我们有一个真正关心我们的社区。听到你的社区对某个特定决定感到失望并不总是容易的，而审视我自己的偏见和盲点的机会让我成为了一名更好的领导者。这是人工智能可以从开源社区学到的教训。

## 人工智能的开源愿景

开源中的“开源”不仅仅是代码；它还意味着让其他人为你的愿景做出贡献。当涉及到人工智能时，这一点尤其重要。即使它都是开源的，访问障碍也更高，这限制了谁可以使用该技术。这就是我们需要重新定义[开源人工智能的含义](https://thenewstack.io/the-new-stack-what-open-source-means-for-the-github-generation/)并将重点从代码转移到社区的原因。

因此，假设我们有一个开源 LLM，你无法在自己的机器上运行它，但你可以使用 API 访问它，或者至少可以在某个地方演示它。至少，你可以向任何想要查看它们的人提供你的数据集、训练方法、食谱和权重。然后，你可以仔细听取用户提供的反馈和意见，并让这些反馈和意见为路线图提供信息。

透明度激发信任，而信任反过来又激发创造力和创新。当问题确实出现时，如果你拥有不同的技能、观点和经验，则更容易调试和解决问题。开放性和协作加速了进步，最终带来了更多的自由和灵活性。没有什么能像看到别人如何做事那样激发伟大的想法。

此外，正如我在 Streamlit 中发现的那样，公开做所有事情都需要一定程度的标准和责任感。在人工智能方面，这种透明度甚至更为关键。随着人工智能变得越来越复杂，人类和机器之间的界限变得越来越不清晰——我们的个人数据反映出越来越难以辨别的虚假现实，形成了一个衔尾蛇。人工智能中的开源意味着使用该技术的企业和组织将自己置于符合如此强大的工具的标准之下。

## 面向所有人的社区

在人工智能快速发展的时代，我们正在重塑工作场所，甚至可能重塑世界，而这一愿景需要不止一个人。人工智能有一些可怕的现实需要我们面对：它对工作意味着什么，它对安全和隐私意味着什么，谁将成为赢家，谁将成为输家。快速发展和监管都很困难。我们在科技领域一次又一次地看到这种情况发生。在社区中，自治变得更加重要，在开源中，我们有行为准则来帮助确保护栏。

> 由于利害攸关，开发人员必须了解自己的偏见和盲点，以及如何解决这些问题。

可以理解的是，人们对人工智能有很多戒心，这种不信任阻碍了人工智能充分发挥其潜力。任何软件都会有某种偏见，因为我们毕竟只是人类。敏捷开发的一个原则是在我们想清楚所有事情之前发布东西，这样我们就可以测试我们的假设，快速收集数据，并在我们对任何事情做出太多承诺而无法轻易退出之前进行调整。这对人工智能尤其重要。由于利害攸关，开发人员必须了解这些偏见和盲点，以及如何解决这些问题。尽可能多地开源生成式人工智能的各个方面是确保我们识别出广泛的盲点的一种方式，这样我们才能共同实现一个更完整、更诚实的愿景。

当我们驾驭人工智能和开源的复杂性时，培养一个接受坦诚反馈和迭代改进的社区至关重要。除了挑战之外，还有无限的探索、协作和进步机会。我们在人工智能领域的旅程证明了我们突破界限的能力，在培养这种社区精神的过程中，我们为创新和理解的新视野铺平了道路。
