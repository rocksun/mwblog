# Transparency and Community: An Open Source Vision for AI
![Featued image for: Transparency and Community: An Open Source Vision for AI](https://cdn.thenewstack.io/media/2024/05/e7d12269-open-1024x576.jpg)
Open source software is a part of everyone’s life. A task as seemingly mundane as sending an email owes its magic to the collaborative contributions of developers, including contributors to foundational technologies like the Linux operating system and the Apache web server application. The foundation laid by email and, more broadly, the internet, demonstrates how open development can power infrastructure critical to our civilization.
Similarly, AI is finding its way into our daily lives. The
[potential of AI](https://thenewstack.io/ai/) has suddenly become real — from defeating the blinking cursor in an empty document, to generating dazzlingly creative images, to answering questions using internet-scale knowledge. As we’ve already witnessed, AI is only as intelligent as the people who create it. The biases, blind spots, assumptions and hallucinations we see in AI are simply reassurance that we are, indeed, human.
The concept of organizing language into systems that machines can consume and operate on is nothing new. It’s only very recently that the machines have caught up with the power of human imagination. The result is a rapidly evolving landscape of AI in which cycles of iteration have grown tighter and tighter. The release of GPT-3 and its resulting ChatGPT interface heralded a seismic shift in AI. The
[large language model (LLM)](https://roadmap.sh/guides/introduction-to-llms) races have begun.
Nearly every new LLM contender is faster, smarter and more lightweight, but the keys to these walled gardens of models remain firmly in the hands of their proprietors. We are the consumers of the products of these gardens and, by extension, the unacknowledged contributors. But this is a very different contract and way of developing than the open source way — the way in which the foundations of the internet, the primary corpus of many of these LLMs, were forged.
Even though advancements in hardware and optimization techniques have helped close the gap between the computational demands of LLMs and available computer power, an LLM is not something many people can run on their home computer — yet.
The compute power required to replicate the systems of language that humans intuitively understand is out of reach for most people, raising the question, “Even if LLMs should be open source, do their increasing hardware requirements raise new barriers to entry that don’t exist in traditional open source?”
That’s where it may be helpful to turn to some of the other tenets of open source. You can’t talk about open source without talking about community, and if, for now, the average person can’t run an LLM in their home lab, community may be the key to open source in AI.
**Transparency-Driven Development**
When my co-founders and I decided to make
[Streamlit](https://streamlit.io/) open source, we had no idea how it would take off. As with every decision to keep a project closed or to open it up to the world, it was not one we made lightly. We knew that open sourcing the project created opportunity, but also responsibility to the community. [Open sourcing and adopting a community strategy](https://thenewstack.io/the-open-source-strategy-of-amazon-web-services/) lays bare a lot of the edge cases and issues that a project has, which can be exhausting and embarrassing, but also a source of strength for a project.
That’s the risk and beauty of open source. No matter what level of openness you choose to go with, you are forced to be accountable for your decision-making and justify why those decisions were made. That kind of accountability makes you challenge your own assumptions and consider everything from different perspectives. It’s the kind of thinking that propels developers in their careers and pushes innovation forward.
Transparency inspires trust, which in turn empowers creativity and innovation.
What the community does with and asks of Streamlit never ceases to amaze, inspire and humble me. We rely on the community more for their input than their contributions to the code. Pull requests usually come from a select group of particularly passionate people who have the motivation and time to fork the code, pull it down, get the tests up and running and passing, create a branch, submit their code for a review, and then respond to comments. We have some of these people in the Streamlit community, but, generally, our community is composed of people who not only use and love Streamlit, but who also recommend it to their friends and colleagues. That’s really the highest honor for me and what makes me really proud of my work.
It’s also a big responsibility. I don’t want to let them down. I hold myself, and Streamlit, to higher standards because I know we have a community that really cares. It’s not always easy to hear that your community is disappointed with a particular decision, and the opportunity to examine my own biases and blindsides has made me a better leader. This is a lesson that AI can take from the open source community.
**An Open Source Vision for AI**
The “open” in open source is not just about code; it’s also about letting other people contribute to your vision. This is especially important when it comes to AI. Even if it was all open source, the barriers to access are higher, which limits who gets to use the technology. That’s why we need to reframe what
[open source AI means](https://thenewstack.io/the-new-stack-what-open-source-means-for-the-github-generation/) and shift its focus from the code to the community.
So let’s say we have an open source LLM and you can’t run it on your own machine, but you can use an API to access it, or can at least demo it somewhere. At the very least, you can make your datasets, training methods, cookbooks and weights available to anyone who wants to review them. Then you can listen carefully to the feedback and input you receive from users, and let that inform the roadmap.
Transparency inspires trust, which in turn empowers creativity and innovation. And when problems do arise, it’s easier to debug and troubleshoot when you have the advantage of diverse skill sets, perspectives and experiences. Openness and collaboration accelerate progress and ultimately result in a lot more freedom and flexibility. Nothing spurs great ideas like seeing how other people are doing things.
Moreover, as I’ve discovered with Streamlit, doing everything out in the open demands a certain level of standards and accountability. When it comes to AI, this sort of transparency is even more critical. As AI becomes more sophisticated, the boundaries between who is human and who is machine become less defined — an ouroboros of our personal data reflecting back an increasingly indiscernible artificial reality. Open source in AI means that the enterprises and organizations using the technology hold themselves to the kind of standards that befit a tool so potentially powerful.
**Community for Everyone**
In the fast-paced world of AI, we are rewriting the workplace and maybe even the world, and that vision requires more than one person. There are some scary realities to AI we have to confront: what it means for jobs, what it means for security and privacy, who will be the winners and who will be the losers. It’s tough to both evolve quickly and to regulate. Governments are not designed to match this pace of innovation. We’ve seen this happen over and over again in tech. In community, self-governance becomes more important, and in open source, we have codes of conduct to help ensure guardrails.
With so much at stake, developers must understand their biases and blind spots, as well as how to address them.
Understandably, there’s a lot of wariness around AI and this distrust is an impediment to realizing the full potential of AI for good. Any piece of software is going to have some type of bias because we are, after all, only human. A tenet of agile development is releasing things before we think through everything, so we can test our hypotheses, gather data quickly and make adjustments before we are too committed to anything to easily back out of it. This is especially important for AI. With so much at stake, developers must understand these biases and blind spots, as well as how to address them. Open sourcing as many aspects of generative AI as we can is one way to make sure we identify a wide range of blind spots, so that we can achieve together a more complete and honest vision.
As we navigate the complexities of AI and open source, fostering a community that embraces candid feedback and iterative improvement is paramount. Beyond the challenges lie boundless opportunities for exploration, collaboration and advancement. Our journey in AI is a testament to our capacity to push boundaries, and in nurturing this communal spirit, we pave the way for new horizons in innovation and understanding.
[
YOUTUBE.COM/THENEWSTACK
Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.
](https://youtube.com/thenewstack?sub_confirmation=1)