
<!--
title: 开发者：抵御AI风险的最后一道防线
cover: https://cdn.thenewstack.io/media/2025/01/df5e4b89-janilson-furtado-ahagyhoyqb0-unsplash-scaled.jpg
-->

如果每个人都了解最新的安全协议，那么随着 AI 和 ML 技术的发展，每个人都将从中受益。

> 译自 [Developers: The Last Line of Defense Against AI Risks](https://thenewstack.io/developers-the-last-line-of-defense-against-ai-risks/)，作者 Eyal Dyment。

AI/ML和大型语言模型(LLM)技术正在重塑软件开发格局，这已不是秘密。随着大型语言模型的应用越来越普遍，将AI和ML整合到软件产品中的任务日益落到开发者身上。这一创新趋势也带来了重大的安全风险，尤其是在开发者缺乏资源以始终确保安全开发实践的情况下。

安全疏忽可能导致意想不到的错误，例如将恶意代码插入AI/ML模型。无论漏洞多么微小，都可能允许网络罪犯分发受损的开源软件(OSS)模型，然后这些模型可用于入侵公司网络，造成巨大的收入和声誉损失。

开发者也越来越多地使用生成式AI进行代码创建，这带来了风险，因为快节奏工作的开发者可能无法彻底审查生成的代码的安全性。为了应对这些威胁，代码必须从一开始就进行严格的安全检查，从二进制级别开始，以防止软件供应链中潜在的漏洞。

这些安全漏洞带来的挑战是持续存在的，并且预计随着网络罪犯找到利用AI/ML技术的新方法而进一步升级。因此，开发者必须从一开始就在其工作流程中整合安全措施，并采取主动姿态来保护其组织的软件供应链。

除了开发团队的职责外，员工也必须承担一部分责任。在开发者中推广持续的安全最佳实践教育和意识至关重要，并将这些实践传递给更广泛的团队将更好地保护公司。如果每个人都了解最新的安全协议，那么随着AI和ML技术的不断发展，每个人都将从中受益。

## DevOps和DevSecOps界限的模糊

在软件开发生命周期的早期考虑安全问题，传统上并非开发者们的标准做法。当然，这种疏忽对于利用ML模型将有害恶意软件注入软件的网络罪犯来说是一座金矿。开发人员缺乏安全培训使问题更加严重，尤其是在使用可能不安全的开源数据训练的AI生成的代码没有充分筛选漏洞的情况下。

不幸的是，一旦AI/ML模型整合了这样的代码，未检测到的漏洞的可能性只会增加。因此，开发者也必须扮演安全卫士的角色，DevOps和安全不再被视为独立的功能。

投资定期安全培训并提供资源来帮助开发者预测威胁至关重要。加强开发和安全团队之间的协作将确保安全措施的无缝集成，从而形成强大的防御体系，抵御各种威胁。在部署安全的AI/ML解决方案时，在开发的每个阶段嵌入安全措施至关重要。

## 优先考虑早期安全措施：“左移”方法

随着不同团队大规模实施AI，ML模型中的高级安全需求至关重要。“左移”方法应运而生，它提倡在软件生命周期的早期整合安全措施，以领先一步，尽可能防止未来的漏洞，并确保整个开发过程的全面安全。在AI/ML开发中，这种策略至关重要，甚至在部署之前，就能确保代码和模型（通常来自外部来源，有时不可信）的安全性和合规性。

随着AI和ML成为软件开发不可或缺的一部分，健全的安全策略、实践和教育变得至关重要。开发人员必须将他们的编码专业知识与强大的安全理解相结合，以便尽早解决开发过程中的关键漏洞。“左移”方法通过确保在整个软件生命周期中尽早并持续采取安全措施，确保公司能够维护客户和员工的信任，降低风险，并防范复杂的网络威胁。
