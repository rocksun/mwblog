
<!--
title: 企业必须采用专为 IT工作流程定制的AI
cover: https://cdn.thenewstack.io/media/2025/05/848dd931-yannick-pipke-hhik58ic2vi-unsplash-scaled.jpg
summary: 告别通用 LLM！IT 运维拥抱定制 AI 时代：结合 ML 模型、知识图谱，打造 Agent 驱动的自动化决策。自托管开源模型如 DeepSeek、LLaMA 确保数据安全，RAG 保护客户隐私。聚焦 IT 工作流，实现安全、降本、提效！
-->

告别通用 LLM！IT 运维拥抱定制 AI 时代：结合 ML 模型、知识图谱，打造 Agent 驱动的自动化决策。自托管开源模型如 DeepSeek、LLaMA 确保数据安全，RAG 保护客户隐私。聚焦 IT 工作流，实现安全、降本、提效！

> 译自：[Companies Must Embrace Bespoke AI Designed for IT Workflows](https://thenewstack.io/companies-must-embrace-bespoke-ai-designed-for-it-workflows/)
> 
> 作者：Ramprakash Ramamoorthy

尽管大型语言模型（LLM）在过去几年中已经很容易获得，但它们在 IT 领域的进展甚微。我们已经看到生成式人工智能（GenAI）模型成功渗透到 SaaS 解决方案和帮助台等领域；然而，GenAI 成功集成到安全软件中的案例却寥寥无几。

一般来说，重新调整 LLM 以使其在安全领域内工作并不容易。LLM 针对自然语言进行了优化；它们无法立即理解或处理安全元素，例如流数据包、日志、警报和知识图谱。

为了在安全领域构建有效的 GenAI 集成，现在是时候拥抱专为 IT 工作流程定制的基础人工智能了。

## 人工智能模型效率

最近构建更高效的模型（而不是不惜一切代价进行扩展）的趋势是 GenAI 工具在企业领域中的自然发展。尽管对 LLM 进行了大肆宣传，但并非每个业务问题都需要 LLM 解决方案。如果您在基础设施中使用 LLM，最好对其进行适当调整（将其提炼成解决特定业务问题的小型模型），同时关注隐私、安全性和可解释性。

通过适当调整模型的大小，可以将计算量保持在最低限度，从而防止成本转嫁给客户。在调整大小的过程中，重要的是要考虑客户的痛点所在。

**代理式人工智能和上下文集成**

围绕代理式人工智能的炒作是有道理的。其次，最有效的人工智能工具是用户甚至没有注意到的工具，这可以通过跨应用程序的上下文集成来实现。

将推理引擎（解释其输出的 GenAI 模型）与特定数据和上下文相结合，您可以创造巨大的价值。代理可以有效地通过 API 和数据库收集实时数据；他们可以过滤和分类这些数据，将其上下文化，然后自动化工作流程。当然，在 IT 环境中，我们有许多不同的代理来处理各种工作流程。

**将适当大小的 LLM 与用于 IT 的定制模型相结合**

尽管 LLM 针对自然语言进行了优化，并且难以监控元信息和理解流数据包，但可以对其进行适当调整，并与用于 IT 工作流程的定制模型相结合，从而在安全和 IT 运营中创造巨大价值。

**安全性。** 让我们看一个快速的安全示例，以了解这在实践中是如何实现的。一个组织可能有一个机器学习 (ML) 模型，用于检测电子邮件流量中基于历史模式和动态阈值的异常情况。这种异常检测 ML 模型与基于决策树的模型（该模型查找电子邮件标头中的变量以建立上下文）相结合，可以确认一封潜在的可疑电子邮件。
此时，一个小型语言模型会评估可疑电子邮件文本中的“行动号召”。代理会查找电子邮件中的链接并抓取它们以进行进一步处理。然后，一个网络钓鱼检测模型会筛选域名信息、Web 标头和其他变量；在沙箱中对附件执行恶意软件检查；最后，一个庞大的决策树得出结论，该电子邮件是可疑的。

**IT 运维。** 这种定制策略也可以在 IT 运维中使用，以优化服务器成本，而不会影响客户体验。组织可以通过将适当大小的 LLM 与因果知识图谱和用于 IT 的定制模型结合使用，来创建动态的 IT 运维成本管理系统。
例如，一个组织可以利用 ML 模型来预测需求（通过分析使用模式和实时流量数据）。该 ML 模型可能会建议缩减资源并避免过度配置，从而在节省组织云支出的同时保持良好的用户体验。

统计 ML 模型还可以指示 IT 设置中何时会出现问题。此类 ML 模型与在整个 IT 基础设施上构建的知识图谱（随着时间的推移学习因果强度）协同工作。然后，实时推理代理可以帮助 IT 工程师解释知识图谱。

通过使用具有自适应阈值的决策树和跟踪运营流程、分析实时数据、综合见解并提出建议的代理，您的组织可以节省成本、减少 MTTR 并实现业务价值的整体提升。

**使用开源模型并将数据保留在您的生态系统中**

在为 IT 创建定制 AI 模型时，建立强大的治理层至关重要。诚然，如果您拥有整个技术栈，这最容易实现。通过控制堆栈中的所有层，您不依赖于第三方，并且所有数据都保留在您公司的生态系统中。

如果您选择在自托管的开源模型（例如 DeepSeek、LLaMA、Qwen 或 Mistral AI）之上构建，则您的数据永远不必离开您的数据库。同样，由于您拥有整个堆栈，因此您的组织上下文保留在您组织的实例中。敏感数据永远不会在外部共享，并且您的安全权限会将上下文信息保留在您自己的环境中。

通过将检索增强生成 (RAG) 与不包含任何客户数据的 LLM 结合使用，您可以确保客户的数据隐私受到保护。这种方法远胜于具有公共 feed 或匿名客户数据的基础模型。

简而言之，从安全的角度来看，如果您拥有整个技术栈，那么代理将成为一个很好的有机补充——不仅是对权限层，而且对搜索层以及其他访问层（如身份和访问管理 (IAM) 和特权访问管理 (PAM)）。

一般来说，您的 AI 工具应始终处理您在受保护网络中已有的数据；所有权限都应受到尊重，并且应该有代理发出的每个调用的审计跟踪。

## 主要收获

在将 genAI 工具整合到 IT 工作流程中时，公司应采用由代理驱动的定制解决方案。作为一个行业，我们正在从流程自动化转向决策自动化和超定制。

在这样做的同时，我们必须在计算上花费适量的资金，将所有数据处理保留在受保护的环境中，并优先考虑客户数据隐私。我相信这是通过针对 IT 工作流程的定制 AI 模型来实现的最佳方式。