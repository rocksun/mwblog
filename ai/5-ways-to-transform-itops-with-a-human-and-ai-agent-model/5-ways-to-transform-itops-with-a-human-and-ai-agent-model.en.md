A new era of AI operations is here. Research [reveals](https://www.pagerduty.com/blog/ai/agentic-ai-is-here-are-you-keeping-up/) that over half (51%) of global companies have already deployed [AI agents](https://thenewstack.io/ai-agents-a-comprehensive-introduction-for-developers/) in their organization, while more than a third (35%) plan to do so within the next two years. The technology will help them go beyond traditional automation to manage complex, multistep workflows and take the pressure off IT teams.

But AI is not a cure-all. It must be applied to the right use cases in combination with human talent to drive return on investment (ROI). This model allows organizations to harness the speed, scalability and processing power of AI alongside human creativity, context, collaboration and judgment. The key to success will be matching the right resource to the right type of work.

## **How AI Is Changing the Game**

The old ways of doing IT operations (ITOps) are no longer fit for purpose. Static runbooks, [manual triage and reactive incident response](https://thenewstack.io/move-away-from-manual-with-automated-incident-response/) were designed for a simpler world where digital experiences weren’t as critical to the customer experience as they are today. Now, every potential glitch or outage could mean another lost customer.

Increasing business digitization also creates more opportunities for those incidents and outages. Distributed, hybrid cloud environments, microservices, APIs and containerized workloads add tremendous complexity. Updates are shipped almost continuously, and every new service creates new dependencies. It’s no wonder that talented teams are suffering from alert fatigue and declining job satisfaction as they are pulled away from innovation projects and forced to firefight a constant stream of incidents.

AI agents can transform these ITOps processes. Agents work autonomously and intelligently on grunt work to free ITOps teams to focus on innovation and mission-critical resolutions. But agents far surpass traditional automation. We’re talking about context-aware autonomy capable of analyzing real-time telemetry to solve problems, adapt to new conditions and make informed decisions. These agents aren’t just working to complete narrow tasks. They are designed to achieve set outcomes and can manage complex workflows to get there, learning and improving as they go.

Most importantly, agents can collaborate with humans in high-stakes situations. It is this human and [agent combination that has the potential to transform ITOps](https://thenewstack.io/how-ai-agents-will-transform-devops-workflows-for-engineers/).

## **Humans in the Loop**

By combining human talent with AI agents, organizations get the best of both worlds. AI handles repetitive, [data-heavy and time-sensitive tasks like resolving recurring alerts](https://thenewstack.io/smarter-ai-for-critical-operations-why-data-matters/), triaging incidents, adjusting system capacity dynamically and predicting and fixing potential failures. ITOps teams provide the contextual understanding and collaboration, creative problem-solving and strategic oversight that machines cannot match. Humans make judgment calls in ambiguous situations and ensure that any automated action aligns with business priorities.

This new dynamic frees human talent to innovate and [build more resilient architectures](https://thenewstack.io/how-to-build-resilient-it-operations-in-4-steps/). It will also create a new role: AI supervisors tasked with fine-tuning, configuring and integrating agents into workflows. This is the pathway to operational excellence. Faster incident resolution, reduced toil for teams and more time for ITOps to focus on [innovation and operational improvements](https://thenewstack.io/breaking-down-the-barriers-to-operational-innovation/).

## **Five Steps To Start Human-AI Collaboration**

Building a human and agent team requires more than simply flicking a switch. Success demands careful planning, the right governance and guardrails, with continuous feedback looped in. Consider the following five steps:

### **1)** **Deal With Governance**

AI is too important to be treated solely as a technology or engineering initiative. It’s a cross-functional priority that requires clear ownership via a dedicated chief AI officer or governance committee. Agents also need clear parameters. Which tasks require human approval and which can be trusted to the machines? There should be a clear line of accountability if things go wrong. At this stage, it’s also important to align AI initiatives with corporate ethics, security, privacy and compliance policies.

### **2)** **Take a People-Centric Approach**

AI agents should support, not sideline, your ITOps team. This requires a cultural change, so employees feel confident and empowered working alongside agents. To kickstart this change, be clear about how and where human input is required in various incident response scenarios.

AI should handle well-understood incidents with known fixes 100% of the time. It should also lead in familiar incidents that have an element of ambiguity, but only up to a point. Humans should step in to validate AI findings and make the final decision on remediation. When it comes to novel, complex issues that require deep expertise, creativity and strategic thinking, humans should take the lead. AI can be used here in a supporting role to gather context and documentation and handle routine processes.

### **3)** **Build in Guardrails Early**

There’s no point in waiting for something to go wrong before designing safety and control mechanisms. You should build clear boundaries governing what agents can and can’t do from the very start. Permissions and policies will help to keep AI on the right track, and depending on corporate risk appetite, human oversight must be required for certain actions. Output filters and compliance checks will help ensure agents meet internal standards.

### **4)** **Focus on Transparency and Accountability**

AI behavior must be explainable, traceable and auditable to build trust across teams. Log all agent decisions and make the reasoning explainable. Create audit trails for incident reviews. And encourage teams to see the bigger picture of how agent actions slot into accountability frameworks.

### **5)** **Continuously Monitor and Optimize Performance**

Just like any member of your ITOps team, agents should have their performance measured and improved. Use a combination of metrics like incident resolution time, false positives and impact on workflows, as well as qualitative feedback and regular reviews for accuracy. Combine data and team feedback to improve performance and effectiveness.

## **A Colleague, Not a Tool**

Agentic AI is a colleague that can bring the best out of your staff. It’s no surprise [that 44%](https://www.pagerduty.com/blog/ai/agentic-ai-is-here-are-you-keeping-up/) of organizations believe agentic will have an even greater impact than generative AI (GenAI), while 94% expect to adopt the technology even faster than they did GenAI. They also anticipate realizing a greater ROI. But expectations and reality aren’t the same thing. To get the most out of both AI agents and your team, you need the right approach to combine them.

[YOUTUBE.COM/THENEWSTACK

Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.

SUBSCRIBE](https://youtube.com/thenewstack?sub_confirmation=1)

Group
Created with Sketch.

[![](https://thenewstack.io/wp-content/uploads/2021/11/06cb1037-cropped-9d413136-mandiwalls-735x800-1-600x600.jpg)

Mandi Walls is a DevOps advocate at PagerDuty. She is a regular speaker at technical conferences and is the author of the O'Reilly Media white paper "Building a DevOps Culture." She is interested in the emergence of new tools and...

Read more from Mandi Walls](https://thenewstack.io/author/mandi-walls/)