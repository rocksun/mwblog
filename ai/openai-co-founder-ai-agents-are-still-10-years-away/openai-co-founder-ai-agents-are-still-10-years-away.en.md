When OpenAI co-founder [Andrej Karpathy](https://www.linkedin.com/in/andrej-karpathy-9a650716/) speaks, even [Elon Musk reacts](https://x.com/elonmusk/status/1979674580710199447).

Karpathy had just recorded a [two-and-a-half-hour interview](https://www.youtube.com/watch?v=lXUZvyajciY) with podcaster [Dwarkesh Patel](https://www.linkedin.com/in/dwarkesh-sp/). And their wide-ranging discussion challenged conventional wisdom, with Karpathy pointing out roadblocks on any road to artificial general intelligence (AGI), and arguing that we’re 10 years away from AI agents.

Right off the bat, Karpathy said “there’s some over-prediction going on in the industry.” And later, [on X.com](https://x.com/karpathy/status/1979644538185752935), he provided specifics on his own expectations:

“Basically my AI timelines are about 5-10 times [as] pessimistic with regard to what you’ll find in your neighborhood San Francisco AI house party or on your Twitter timeline, but still quite optimistic with regard to a rising tide of AI deniers and skeptics.”

Conversations inevitably continued on social media — starting with Kaparthy’s assertion that early education should include the physics he’d studied, because it’s uniquely good at “booting up” the brain. On the podcast he’d said that whenever confronting a new system — whether it’s AI, physics, or something in between — “I’m trying to find, what is the thing that matters…? How can I simplify it?”

Back on X.com Elon Musk challenged Karpathy, who was also senior director of AI at Tesla, to “an AI coding contest or whatever form of competition you’d like for Andrej vs Grok 5, a la Kasparov vs Deep Blue?”

But that was the moment Musk discovered that when speaking about AI, Karpathy really did have an optimistic streak.

“I’d much rather use and collaborate with Grok 5 than compete against it.”

[![Elon Musk replies to Andrej Karpathy](https://cdn.thenewstack.io/media/2025/10/e76e0a41-elon-musk-replies-to-andrej-karpathy.png)](https://cdn.thenewstack.io/media/2025/10/e76e0a41-elon-musk-replies-to-andrej-karpathy.png)

## Challenging AI Industry Predictions

Karpathy had led Tesla’s self-driving efforts from 2017 to 2022, so he’s experienced the frontiers of AI research. So when podcaster Patel pressed him on what bottlenecks will take a decade to overcome for AI agents, Karpathy answered, “actually making it work!”

Right now, Patel isn’t replacing employees with [Claude](https://thenewstack.io/anthropic-launches-claude-haiku-4-5/) or Codex, Karpathy pointed out, — because “they just don’t work. They don’t have enough intelligence. They’re not multimodal enough, they can’t do computer use and all this stuff … They don’t have continual learning. You can’t just tell them something and they’ll remember it. They’re cognitively lacking and it’s just not working. It will take about a decade to work through all of those issues.”

[![Andrej Karpathy interviewed on Dwarkesh Patel's podcast (screenshot - October 2025)](https://cdn.thenewstack.io/media/2025/10/45a7cca6-andrej-karpathy-interviewed-on-dwarkesh-patels-podcast-screenshot-october-2025.png)](https://cdn.thenewstack.io/media/2025/10/45a7cca6-andrej-karpathy-interviewed-on-dwarkesh-patels-podcast-screenshot-october-2025.png)

Andrej Karpathy (left), co-founder of OpenAI, spoke with podcaster Dwarkesh Patel about the current state of Ai agents.

Why a decade? Karpathy told Patel that’s “a bit of my own intuition, and doing a bit of an extrapolation with respect to my own experience in the field  … I feel like the problems are tractable, they’re surmountable, but they’re still difficult. If I just average it out, it just feels like a decade to me.”

He still predicts there’ll be some seismic shifts that alter the entire field, “because they come with almost surprising regularity.”

In short, Karpathy said, “I still feel there’s so much work to be done” — but he added almost instantly that “they’re going to get better, and it’s going to be wonderful.”

So Karpathy is clearly one of those “yes and no” people — and on X.com, he gave a [clear summation](https://x.com/karpathy/status/1979644538185752935) of where we’re at: “In my opinion we simultaneously 1) saw a huge amount of progress in recent years with LLMs while 2) there is still a lot of work remaining (grunt work, integration work, sensors and actuators to the physical world, societal work, safety and security work (jailbreaks, poisoning, etc.) and also research to get done before we have an entity that you’d prefer to hire over a person for an arbitrary job in the world.

“I think that overall, 10 years should otherwise be a very bullish timeline for” AGI, he said. Adding, “It’s only in contrast to present hype that it doesn’t feel that way.”

## The 10-Year Path to AI Agents

Recalling his work leading Tesla’s self-driving efforts, Karpathy said on the podcast he’s experienced that “very large demo-to-product gap — where the demo is very easy, but the product is very hard.” (Especially in realms where mistakes could be deadly.)

Even today, he said, some self-driving cars have tele-operators, so “there’s more human-in-the-loop than you might expect … In some sense, we haven’t actually removed the person, we’ve moved them to somewhere where you can’t see them.”

And then assuming we reach a world with AGI, Karpathy [noted on X](https://x.com/karpathy/status/1980692376046956961) that “the diffusion of such a system will still take even more time in my mind (e.g. basic technological diffusion stuff as seen with computing/internet, compute constraints, sensors/actuators over the physical world constraints, societal, legal).”

Karpathy believes all of this should be affecting our [timelines for AI’s role in our lives](https://thenewstack.io/whats-next-for-developer-teams-how-to-prepare-now/).

## Bridging the Demo-to-Product Gap

“I think this will work,” Karpathy said on the podcast. “I think it’s tractable. I’m only sounding pessimistic because when I go on my Twitter timeline, I see all this stuff that makes no sense to me …  A lot of it is honestly just fundraising.”

On the podcast, Karpathy even speculated on how superintelligence would feel — “fundamentally automation,” but “extremely foreign.” So what’s concerning about this possibility of [truly autonomous agents](https://thenewstack.io/ai-agents-will-eat-enterprise-software-just-not-in-one-bite/) is also what he sees as the most likely outcome. There’s what he described as “this gradual loss of control and understanding of what’s happening” — a world where we “layer all this stuff everywhere, and there will be fewer and fewer people who understand it.”

If he were writing science-fiction dystopias, Karpathy said, it’d look like “multiple competing entities that gradually become more and more autonomous. Some of them go rogue and the others fight them off. It’s this hot pot of completely autonomous activity that we’ve delegated to. I feel it would have that flavor.”

## Eureka Labs: An AI-Native Approach to Education

But Karpathy has his own answer to those concerns. In July 2024 he [announced](https://x.com/karpathy/status/1813263734707790301) the launch of education company [Eureka Labs](https://eurekalabs.ai/), “a new kind of school that is AI native.”

With pure AI research alone, “I don’t know that I would uniquely improve it,” Karpathy said. So now he’s found a way to tackle those fears that humanity would be “disempowered” by AI.

“I want humans to be well off in the future,” he said, adding, “To me, this is through education that you can achieve this.”

Eureka Labs is currently building its first course, which is about AI — [LLM101n](https://github.com/karpathy/LLM101n). In October, Karpathy released [nanochat](https://github.com/karpathy/nanochat), “a full-stack implementation of an LLM like ChatGPT in a single, clean, minimal, hackable, dependency-lite codebase.”

“You boot up a cloud GPU box, run a single script and in as little as 4 hours later you can talk to your own LLM in a ChatGPT-like web UI,” Karpathy [explained on launch day](https://x.com/karpathy/status/1977755427569111362).

[On X](https://x.com/karpathy/status/1980665134415802554), Karpathy expanded on nanochat. “I wanted to have some fun with it,” he wrote, “so nanochat now refers to me as King Andrej Karpathy (lol) just to illustrate that this is a giant blank canvas — you can infuse completely arbitrarily identity, knowledge or style into your LLM.”

## The Nanochat Project and Its Impact

October’s release of the nanochat LLM implementation will be a big part of Eureka’s first class, its “capstone” project. Its repository on GitHub includes an appropriate quote from the Nobel-winning physicist Richard Feynman: “What I cannot create, I do not understand.”

On the podcast, Karpathy described the nanochat project as “building a ramp to knowledge … It’s the super simplified full-stack thing. If you give this artifact to someone and they look through it, they’re learning a ton of stuff.

“It’s giving you a lot of what I call eurekas per second, which is understanding per second. That’s what I want.” (Maybe that’s why the company is called Eureka Labs.)

[![Screenshot (from GitHub) of Eureka Labs first class, on AI (in development)](https://cdn.thenewstack.io/media/2025/10/0c9c431b-screenshot-from-github-of-eureka-labs-first-class-on-ai-in-development.png)](https://cdn.thenewstack.io/media/2025/10/0c9c431b-screenshot-from-github-of-eureka-labs-first-class-on-ai-in-development.png)

A screenshot from the GitHub repository for Eureka Labs’ first (in-development) AI class.

And even in a future where AI makes many decisions, Karpathy said, “I think there will be a transitional period where we are going to be able to be in the loop and advance things — if we understand a lot of stuff.” (Although, he added, “In the long term, that probably goes away.”)

But ironically, here in the present Karpathy found that today’s “[vibe coding](https://thenewstack.io/how-to-use-vibe-coding-safely-in-the-enterprise/)” AI tools kept misunderstanding the code he was trying to write for nanochat, “because they have too much memory from all the typical ways of doing things on the Internet that I just wasn’t adopting.”

AI coding tools were also “way too over-defensive,” he noted. “They make all these try-catch statements.” And, he added, “They’re using deprecated APIs a bunch of times.” The extra work meant that the experience wasn’t a net gain in productivity.

This might be why Karpathy’s forecasting longer timelines for when AI explodes in popularity, he said. Today, even for AI’s killer use case, “They’re not very good at code that has never been written before … which is what we’re trying to achieve when we’re building these models!”

“I feel like the industry is making too big of a jump and is trying to pretend like this is amazing, and it’s not. It’s slop.”

“They’re not coming to terms with it, and maybe they’re trying to fundraise or something like that.”

VIDEO

[YOUTUBE.COM/THENEWSTACK

Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.

SUBSCRIBE](https://youtube.com/thenewstack?sub_confirmation=1)
[YOUTUBE.COM/THENEWSTACK

Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.

SUBSCRIBE](https://youtube.com/thenewstack?sub_confirmation=1)

Group
Created with Sketch.

[![](https://cdn.thenewstack.io/media/2023/11/82081813-7zddypfe_400x400.jpg)

David Cassel is a proud resident of the San Francisco Bay Area, where he's been covering technology news for more than two decades. Over the years his articles have appeared everywhere from CNN, MSNBC, and the Wall Street Journal Interactive...

Read more from David Cassel](https://thenewstack.io/author/destiny/)