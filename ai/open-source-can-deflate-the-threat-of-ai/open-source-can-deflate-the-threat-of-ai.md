<!-- 
# 开源可以减轻AI的“威胁”
https://cdn.thenewstack.io/media/2023/09/177cf13e-steve-johnson-zpoodqc8ymw-unsplash-scaled-e1695328678635-1024x576.jpg
 -->
 
开源可以帮助处理人工智能。

译自 [Open Source Can Deflate the ‘Threat’ of AI](https://thenewstack.io/open-source-can-deflate-the-threat-of-ai/) 。

西班牙毕尔巴鄂--不仅要限制、控制和封锁AI，依赖生成语言模型的这个革命的开发者还应该依靠开源，最终实现一个我们现在还不敢想象的积极结果。

当然，有很多对这个假设持怀疑态度的人，例子也很多，从具有不同议程的政客，到受惊的公众和其他团体，他们中的一些人可能有好意也可能有坏意。 

正如[Linux基金会](https://training.linuxfoundation.org/training/course-catalog/?utm_content=inline-mention)执行董事[Jim Zemlin](https://www.linkedin.com/in/zemlin/)在[Open Source Summit Europe](https://events.linuxfoundation.org/open-source-summit-europe/)主题演讲中提到的，Elon Musk是1000多名签署者之一，他们在几周前的一封[公开信](https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html)中表达了对这场革命失控的担忧，信中建议在OpenAI发布的ChatGPT之外实施为期六个月的人工智能禁令。

这并不是在轻视AI模型已经存在的偏见和不考虑多样性的问题，这些问题代表了当今和未来真实的风险和可能出现的悲剧后果，但对可能出问题的恐惧引发的不合理反应也很多。

反对者，就像某人说的，需要重新开始思考。Zemlin提出了许多关于加密技术的实质性原因和历史案例，解释为什么试图封锁大语言模型可能是一个代价高昂的错误。

“最近，我们听到来自世界各地的不同人士，主要是那些已经拥有大量资本、大量GPU和良好的基础模型的人士说，我们需要暂停六个月，等弄明白了再说。我们甚至听到一些人说，嘿，这种大语言模型技术和先进的AI技术非常强大，以至于20年内如果落入个人行为者手中，他们可能会做可怕的事情，比如制造暴力武器、发动大网络攻击等。”Zemlin说。

“我今天要告诉你的是，这种对开源大语言模型会产生可怕后果的担忧和恐惧是没有根据的。开源总能带来阳光，围绕代码制造出的平衡的恐惧，因为人们用大语言模型不仅仅是做坏事，也做好事，比如发现新药，提高制造业效率，使用大语言模型来建造更环保的建筑。每个行动都会产生相应的反作用力，我们已经看到开源立即开始解决人们对AI的一些担忧。”
