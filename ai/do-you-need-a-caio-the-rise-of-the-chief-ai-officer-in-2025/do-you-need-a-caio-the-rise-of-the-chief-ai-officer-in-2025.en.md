Not since the smartphone has technology been as truly disruptive as [AI](https://thenewstack.io/ai/).

Which is why there are so many stories about AI changing the workforce. But many organizations are focused on the wrong thing: truncating their talent pipelines by getting rid of junior roles.

This shows a lack of foresight and a big void in leadership, because AI is going to impact every role at every level within an organization. Which means AI adoption has to be a top-down, strategic priority.

In comes the chief AI officer (CAIO).

Just like the creation of the CISO and CDO roles were in response to the 2010s’ need for holistic views of security and data, the CAIO responds to an ever-growing demand for cross-organizational, cross-functional AI leadership, which should include consideration of security and data.

**If you answer yes to any of these questions, you likely need a CAIO or otherwise centralized AI leadership:**

* Are you increasing your investment in AI?
* Are you unsure which teams are using what AI?
* Are you looking for reusable AI use cases or tooling?
* Are you trying to connect technology and business?
* Are you looking for cross-organizational efficiency?

According to a survey by [Pltfrm](https://pltfrmsearch.com/), a tech recruiting company, [48% of the FTSE 100 now have a designated CAIO](https://pltfrmsearch.com/perspectives/) or equivalent AI leadership role. Of these, 67% have been appointed in the last two years, with 42% hired in the past 12 months alone.

So, just what is the role of the CAIO? What should a CAIO be in charge of — or not? Read on to learn from those already doing this multifaceted role and why your company would benefit from AI leadership soon.

## Where Does the CAIO Sit?

AI is already disrupting the corporate hierarchy.

Everyone I interviewed for this piece has taken a different pathway to this AI leadership role. Top AI roles sit within different departments within organizations, at different levels of the org chart, and go by a variety of names.

According to the team at Pltfrm, who ran the aforementioned CAIO survey, the route to this role most often runs through software engineering, data science or consulting. Holding a Ph.D. is common, likely because the CAIO job title has been found in medical, university and other research institutions for about a decade now.

What’s the difference as the role goes mainstream?

“Here the CAIO isn’t building the next rocket; they’re making sure it doesn’t crash on launch. Their job? To manage AI-related risks (such as ethics), as well as adopt, scale and integrate systems responsibly,” the Pltfrm report read.

“The reality is that most CAIOs will require a mix of both offense and defense,” balancing speed of innovation with security and compliance. This role is a balance of staying ahead in the innovation race, along with protecting your organization from becoming the next bad headline.

At tech companies, AI leadership traditionally sat under the CTO. This is no longer advisable because:

* The CTO heads the engineering organization, while AI is being adopted across all departments.
* AI is about a lot more than technology. An AI strategy requires an understanding of people and processes, too.

This chief role includes more strategic vision and governance responsibilities, considering frameworks for ethics, corporate responsibility, data privacy and compliance. It’s risky to bias toward technical stakeholders.

The CAIO is also increasingly a public-facing role, communicating with both the press and customers about an organization’s AI policy.

“As a manager, a VP, a director, C-suite, you can focus on AI as much as you want until you’re given another task,” [Ben Silverman](https://www.linkedin.com/in/ben-silverman-ba76a05/), founder of Seatd IT consultancy, told The New Stack. If you haven’t set up your systems, then any AI transformation strategy will be left behind.

AI leadership, he argued, requires a dedicated C-suite role, with a deep understanding of:

* How to create automation systems.
* How to retain information.
* How to explain information in a way that doesn’t feel overwhelming.

This role that used to report to CIOs or CTOs is now speaking to CEOs, CFOs and full boards, defining return on investment and scaling costs nonlinearly.

## How Do You Prepare for AI Leadership?

More than 10 years ago, [SAP](https://www.sap.com/index.html?utm_content=inline+mention) went through a restructuring to prioritize machine learning (ML). According to [Jared Coyle](https://www.linkedin.com/in/jaredcoyle/), CAIO for the Americas at SAP, this restructuring was 70% focused on the human aspects.

Then, about 18 months ago, SAP moved its CAIO roles from the CIO office to directly within the regional presidents’ offices, as the role evolved from an IT focus to go-to-market and business enablement. IT enablement at SAP is run at the global level, but since AI factors in so many regional and local data privacy regulations, its CAIO roles are inherently regional.

Coyle’s role considers AI additions both within the SAP product suite and in the user experience of more than 100,000 employees.

For him, a great career path to chief AI officer looks similar to his own:

1. **Product:** Sitting where the problems are.
2. **Consulting:** Working close to the customer experience.
3. **Sales:** Understanding financial and operations perspectives.
4. **Leadership:** Bringing a full understanding of an organization to then apply AI to it.

“If you work in just one vertical, it creates this limited view of what the organization actually does,” Coyle said. “AI is a topic that transcends legal, government relations, public relations and our implementations.”

[Naveena Allampalli](https://www.linkedin.com/in/naveena-allampalli/) has spent the last 15 years focused on the intersection of data, AI and product development across well-regulated industries. Two years ago, she joined [CBRE](https://www.cbre.com/), the world’s largest real estate and investment firm, as the global senior director for generative AI for enterprise architecture and AI solutions.

Her role centers on answering the question, “How do we gain efficiencies and productivities through generative AI [GenAI] in business platforms or in AI and the software delivery life cycle?” she told The New Stack. She also identifies “common solutions that we can implement enterprise-wide.”

As at many enterprises, this AI leadership role has shifted from a centralized AI strategy managed by a data science team, Allampalli said, to each of CBRE’s four business units, figuring out where AI could add value within its own product suite.

More and more AI leadership roles are cutting horizontally across departments like this, prioritizing business problems and then working with architecture, data and software teams to implement AI as part of the solution.

“There’s so much space for innovation with AI. We can use it in new and novel ways,” said [Laura Tacho](https://www.linkedin.com/in/lauratacho/), CTO at [DX](https://thenewstack.io/4-north-star-metrics-for-platform-engineering-teams/), at LeadDev’s LDX3 in June. “But, at the end of the day, AI is a tool that needs to help us improve the system. We need to think about using AI at an organizational level if we really want to see the organizational benefits that are being promised.”

This impetus means this role is increasingly elevating to the C-suite.

## A CAIO’s First Task: Governance

Every CAIO is different, but they usually share an early priority: setting up company-wide AI guidelines.

While double the previous year, according to the Traliant HR Report on AI, only [60% of companies have an AI acceptable use policy](https://www.traliant.com/resources/hr-report-on-ai-insights/). A first priority of any AI leadership should be to [create a GenAI policy](https://thenewstack.io/how-to-create-the-generative-ai-policy-you-needed-yesterday/), communicate it across their organization and, more frequently, to customers and other external stakeholders.

“My focus is ensuring we have the right policies, procedure and governance practices in place to develop, procure and operate AI responsibly,” said [Amanda Muller](https://www.linkedin.com/in/amandacmuller/) of her role as chief of responsible AI at [Northrop Grumman](https://www.northropgrumman.com/), the aerospace manufacturer.

In 2020, this led her to create the aerospace manufacturing company’s Responsible AI Working Group. After a few years of research, her team sitting under the chief information and digital office created a set of [responsible AI principles](https://www.northropgrumman.com/what-we-do/mission-solutions/artificial-intelligence-and-machine-learning), which aimed, she told The New Stack, to align customer stakeholders with industry best practices, compliance and legal requirements, and company values.

Muller’s first priority was to identify the potential risks and mitigations of AI use cases. Then, in 2022, with the deluge of generative AI, Northrop Grumman set up the AI governance board, which she chairs. This multidisciplinary team coordinates subject matter experts in law, compliance, global supply chain, human resources, privacy, cyber security and more, in charge of reviewing and approving or disapproving various AI use cases.

As AI can be included in everything, Muller emphasized that her work is very much focused on the AI that Northrop Grumman develops and procures to run the business, to enable employee productivity and job satisfaction. Currently, there isn’t one chief AI officer at the company of about 100,000 people worldwide. Instead, there is a network of AI experts across technology, information, compliance, cybersecurity, privacy, global supply chain and more.

Two months ago, [David Low](https://www.linkedin.com/in/daviddlow/) moved from director of client enablement to the first CAIO at [Waracle](https://waracle.com/), an IT consultancy. His role kicked off with a focus on upskilling his own organization of more than 200 developers, designers and strategists, in order to dogfood processes and develop best practices, so “we’re better equipped to be able to consult other people about it,” he told The New Stack.

While [OpenAI](https://openai.com/) CEO [Sam Altman](https://thenewstack.io/openais-sam-altman-ai-is-now-ready-for-the-enterprise/) is arguing that [AI is ready for the enterprise](https://thenewstack.io/openais-sam-altman-ai-is-now-ready-for-the-enterprise/), most of Low’s well-regulated enterprise clients are still in what he calls the AI discovery phase, skeptical of its compliance and security.

“Most of our clients are now asking about AI that wouldn’t have done three months ago,” he said. “We’re building up their awareness to understand what they can do and what they can’t do.”

For instance, the [European Union’s AI Act](https://artificialintelligenceact.eu/) requires that, if a technology is classified as high risk — including critical infrastructure, education, employment and law enforcement — then organizations must make things audit-safe and explainable around what the AI is actually doing.

> “Everyone goes into the role thinking, *I’m going to bring magical, agentic-powered robots that are going to change my business entirely*. What you’re probably going to do is automated approvals for a while so people get comfortable with that. Be ready for the human aspect, because you will become a salesperson for making people’s lives better.”
>
> **— Jared Coyle, SAP**

Add to this [Dario Amodei](https://www.linkedin.com/in/dario-amodei-3934934/), CEO of [Anthropic](https://www.anthropic.com/), creator of the large language model (LLM) [Claude](https://thenewstack.io/anthropic-launches-claude-opus-4-and-sonnet-4/), who has publicly said his team doesn’t understand its own models because they’ve become too big for humans to comprehend.

If the LLM providers can’t provide provenance, what hope do enterprises have?

“If you take that to the banking space, they wouldn’t accept it because the risks are too high. They can’t explain what the thing is going to do,” Low said. “So what they’re asking us to do is to figure out how to manage that risk, explain the risk and explain the process that AI is actually going through.”

Thankfully, he said, the EU rules have clearly outlined a “template to judge the risk” and how to address it.

Once this awareness and governance is set up, this CAIO role often pivots to advising departments on [running and measuring GenAI experiments](https://thenewstack.io/how-to-run-a-generative-ai-developer-tooling-experiment/), and then helping to facilitate the sharing of lessons learned — and hopefully shared tooling.

## Cross-Functional AI: Start With Boring Use Cases

Are you looking for cross-organizational AI use cases? Start with the boring.

The highest measurable impact use case for GenAI adoption in software development is an [increase in documentation quality](https://thenewstack.io/dora-2024-ai-and-platform-engineering-fall-short/) — despite the much bigger focus and investment into AI code generation. At SAP, the most adopted AI use case is scanning and processing business expense receipts.

“The cool AI use cases that are all shown on keynote stages are not the ones that are going to be used. Be ready to work in the boring,” Coyle advised other CAIOs.

“Everyone goes into the role thinking, *I’m going to bring magical, agentic-powered robots that are going to change my business entirely*. What you’re probably going to do is automated approvals for a while so people get comfortable with that. Be ready for the human aspect, because you will become a salesperson for making people’s lives better.”

It’s human nature for people to be afraid of new systems. The chief role of the CAIO, he said, is to calm nerves and to help people understand how this new technology works.

Leadership should focus on AI use cases that aim to reduce boredom and toil, enabling teammates to focus on problem solving — not to reduce staff.

“I’m more of an ‘enhance with AI’ sort of person,” Silverman said, because AI plus mediocrity will lead to more mediocrity. AI enhancement, he said, is all about “what the person does with that information that matters.”

## How To Scale AI Across an Organization

At organizations with tens of thousands of employees, challenges don’t occur in silos.

One common AI use case has enterprises looking at chat as a way to unlock data insights and to build more customizable dashboards. With such horizontal considerations, Allampalli said, AI leadership helps to understand the problem, determine if it even is an AI problem, and then evaluate third-party tooling — with serious security vetting — versus if a solution should be built internally.

“If we have to build internally, then we work with data teams, we work with AI teams, we work with product development teams, and all these teams come together to form a pod to address those solutions,” she said.

She added, “We try to identify and prioritize the problem and also calculate the return on investment of that specific problem we’re trying to solve. Then we also look into, do we have already that problem addressed, instead of jumping into and building that solution.”

When vetting a solution, its potential for reusability is also key. Then, her team considers if it is “a high-priority use case with high value of efficiency gains and productivity for the organization.”

Once you outline what you can or cannot do, Low said, the CAIO’s job becomes about scaling training and education about how to leverage AI.

“All different disciplines have different ways they’re going to use AI. And then they all have to interact with the software development life cycle that one person’s AI will hand off to another person’s,” he said. “We need to get that right, a mixture of baseline education and thinking about how to implement it across the business.”

Next, it’s time for AI leadership to assess the effort and scope of work, prioritizing data dependencies and how to either build or integrate an existing solution into the end-to-end data flow.

The majority of organizations have spent the last two years focused on their GenAI strategy and now they are pivoting to [agentic AI](https://thenewstack.io/ai-agents/) considerations. As everyone across an organization comes up with agentic AI use cases, Allamalli recommends AI leadership ask:

* Can we build AI agents for this?
* Does this use case already have workflows that agentic AI can follow?
* Are we clear on the inputs and outputs?
* How much time will it take to build?
* Is it really an agentic AI use case or can GenAI solve this?

However, she advised, the focus of AI leadership should remain business first.

Scaling AI is “not just about applying the new technology,” she said. “First, it’s aligning your business problems directly to the AI solution, to the AI value it’s providing. You want to solve the problems for the business, leveraging the technology.”

Then, the role of the CAIO is to prioritize all these potential AI use cases, aligning them with C-suite stakeholder priorities across the enterprise.

## Balancing the AI Budget

Another constant juggle for the chief AI officer is the cost of AI innovation.

“The brilliance in a well-run AI business is understanding the relative ratio of scaling your infrastructure costs to the commercial costs,” Coyle said. “The operational costs. The various infrastructure costs. The human cost, because you have to bring in different talent.”

Right now, the underlying infrastructure at SAP is evolving every six weeks, he said. This rate of change demands a cloud native software development life cycle with templated scalability.

In the face of AI everything, the CAIO helps dictate what’s off the table. For SAP, that’s deciding not to make its own LLMs. SAP has 52 years of highly structured data, Coyle noted — across accounting, customer experience, supply chain and human resources — which means that its financial and environmental costs are much less when training LLMs created by third-party providers.

AI leadership also has to consider how to communicate AI-driven cost changes to existing customers.

No longer is AI relegated to technical teams as it becomes approachable and potentially beneficial to all. This means this new AI role needs to have a unique cross-organizational perspective that only business typically has. The role isn’t easy to fill, but it can help your organization head in the right direction.

As Coyle said, “We have this opportunity, if we do this responsibly, to make the world better.”

[YOUTUBE.COM/THENEWSTACK

Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.

SUBSCRIBE](https://youtube.com/thenewstack?sub_confirmation=1)

Group
Created with Sketch.

[![](https://cdn.thenewstack.io/media/2022/09/24668a31-cropped-cfb880a9-jkriggins-2019-headshot-the-new-stack.jpeg)

Jennifer Riggins is a culture side of tech storyteller, journalist, writer, and event and podcast host, helping to share the stories where culture and technology collide and to translate the impact of the tech we are building. She has been...

Read more from Jennifer Riggins](https://thenewstack.io/author/jennifer-riggins/)