
<!--
title: 用于训练多模态AI模型的5个有用数据集
cover: https://cdn.thenewstack.io/media/2025/01/ea757c99-getty-images-_5j6spykslu-unsplashb.jpg
-->

面向开发者的五大领先多模态数据集，以及这些数据集包含的内容和用途说明。

> 译自 [5 Useful Datasets for Training Multimodal AI Models](https://thenewstack.io/5-useful-datasets-for-training-multimodal-ai-models/)，作者 Kimberley Mok。

多模态AI系统能够跨越文本、图像、音频、视频等多种组合模式执行任务，正变得越来越通用和强大。然而，构建有用的多模态AI模型需要高质量的多模态数据集，这些数据集是训练这些多功能系统的必要燃料——使它们能够超越单一维度或模式，扩展对世界的理解。

例如，图像字幕任务需要一个结合图像和相关描述性文本的训练数据集，这可以用来训练AI模型。训练过程结束后，就可以部署AI模型，利用自然语言处理和计算机视觉技术识别新图像的内容并生成相关的文本。

同样的想法也适用于各种各样的任务，例如视频分析、视听语音识别、跨模态检索、医学诊断等等。这是因为多模态数据集使AI模型能够学习对象及其上下文之间更复杂的语义关系，从而提高模型的性能和准确性。

有如此多的多模态数据集[公开可用](https://github.com/drmuskangarg/Multimodal-datasets)，很难知道从哪里开始。在这篇文章中，我们将介绍目前可用的最著名的一些多模态数据集，并简要描述它们包含的内容以及它们可能被用于什么。

## 1. Flickr30K Entities

作为流行的图像字幕[Flickr30K数据集](https://www.kaggle.com/datasets/adityajn105/flickr30k)的扩展，该数据集包含来自Flickr的超过31,000张图像，每张图像都与五个众包字幕相关联。[Flickr30K Entities](https://bryanplummer.com/Flickr30kEntities/)数据集为原始的158,000个字幕增加了244,000个共指链，此外还为字幕中提到的所有实体（即人或物体）添加了边界框标注。

Flickr30K Entities数据集的一个重要优势是，它为图像文本任务提供了更深入的注释，并帮助模型更好地描述图像的内容——除了定位图像中的实体。

**应用**：实时图像字幕；图像搜索。

**许可证**：图像的使用必须遵守Flickr的[使用条款](http://www.flickr.com/help/terms/)；研究人员和教育工作者可将其用于非商业目的。

![](https://cdn.thenewstack.io/media/2025/01/b9482d75-flickr30-entities.jpg)

*Flickr30 Entities数据集示例。*

## 2. InternVid

[InternVid](https://huggingface.co/datasets/OpenGVLab/InternVid)专为视频相关任务（如视频字幕、视频检索和视频生成）而开发，是一个相对较新的视频文本数据集，包含700万个不同类型物体和活动的视频，时长近76万小时。它包含令人印象深刻的2.34亿个片段，配以丰富的描述性字幕，总计超过41亿字。

该数据集最大的优点之一是其广度，涵盖了16种不同的场景类型和6000多种不同的动作。

**应用**：视频聊天机器人；个性化在线学习。

**许可证**：[Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0)。

## 3. MuSe-CaR (汽车评论中的多模态情感分析)

这个有趣的[文本-图像-音频数据集](https://sites.google.com/view/muse-2021/challenge/data)旨在理解用户生成视频评论中上下文中的情感，以了解产品评论过程中发生的情感参与。MuSe数据集包含超过40小时经过广泛注释的高质量用户生成视频记录，这些记录提供了对可能出现在面部、声音、手势或肢体语言中的情感细微差别的见解。

该数据集的目的是通过提供一个深入的数据集来理解各种复杂的人类情感，从而进一步推进多模态情感分析。

**应用**：心理健康聊天机器人或助手；用于评估客户对产品满意度的自动化情感分析系统。

**许可证**：根据[最终用户许可协议 (EULA)](https://en.wikipedia.org/wiki/End-user_license_agreement)的非商业用途。

![](https://cdn.thenewstack.io/media/2025/01/228bb108-muse-car.jpg)

*MuSe-CaR数据集示例。*

## 4. MovieQA

MovieQA是一个文本-视频-问答多模态数据集，旨在评估故事理解能力和执行视频问答（VideoQA）任务。它包含15000个多项选择题，以及从400多部语义多样性高的电影中截取的带有字幕的电影片段。

正确回答问题需要模型充分理解视频片段中包含的视觉和文本上下文，例如顺序事件、人际互动、意图以及用于描述它们的文本。该数据集的独特之处在于它包含多种信息来源，包括视频片段、剧情、字幕、脚本和描述性视频服务（DVS）。

**应用**：自动化电影分析、摘要和分类。

**许可证**：未指定。

![](https://cdn.thenewstack.io/media/2025/01/36a3b7dc-movieqa.jpg)

*MovieQA数据集示例。*

## 5. MINT-1T

MINT-1T是一个庞大的开源数据集，来自Salesforce AI Research，包含一万亿文本标记和34亿张图像——几乎是下一个最大的开源数据集的十倍。这是一个极其多样化、多模态、交错的数据集，它以模仿现实世界文档（如网页和科学论文，包括PDF和ArXiv论文）的方式整合文本和图像。

该数据集的庞大规模意味着模型可以更广泛地掌握现有的科学和技术研究在线语料库。根据研究团队的说法，目标是创建一个包含“图像和文本的自由形式交错序列”的数据集，适合训练大型多模态AI模型。

**应用**：开发更具上下文感知能力的AI助手；MINT-1T是一个庞大的数据集，它为预算较小的研究人员和企业创造了公平的竞争环境。

**许可证**：CC-BY-4.0


## 结论

新的数据集不断涌现，以下是一些其他值得一提的近期多模态数据集：

* BigDocs：这个开放且“许可宽松”的数据集旨在训练用于从文档中提取信息的模型，使用增强的OCR、布局和图表分析以及表格检测。
* Newsmediabias-plus (NMB+)：该数据集结合了新闻文章中的文本和视觉数据，来自Vector Institute，旨在用于检测和分析媒体偏见和虚假信息。

这些只是大量可用多模态数据集中的少数几个——更不用说也日益受到关注的多语言数据集了。有如此多的选择，找到合适的训练AI模型的数据集相对容易。更多信息，请查看我们关于构建多模态AI应用程序的工具的帖子，以及一些开源和小型多模态AI模型。
