Palantir CEO Alex Karp talks so much that you’d think that he just likes the sound of his own voice—though you wonder if he actually hears what he’s saying.

The subject of the recently published Michael Steinberger book “[The Philosopher in the Valley](https://www.simonandschuster.com/books/The-Philosopher-in-the-Valley/Michael-Steinberger/9781668012956)” popped onto [The Axios Show](https://www.axios.com/2025/11/07/palantir-ceo-alex-karp-interview-axios) this week to talk about all kinds of things, in part because it seems like the wheels in his brain turn faster than his mouth can get the words out. But it’s some of his clearly prepared and repeated lines that are the most eye-roll-inducing.

For instance, when asked by Axios’s Mike Allen, “What the hell is Palantir?” Karp answered, “We are growing the GDP of the US. We are the part of the GDP… of the AI economy where things are useful.” Okay! That is the description of a company, for sure.

Karp’s been hammering the GDP thing lately, considering he brought it up during his [appearance on CNBC’s “Squawk Box”](https://www.youtube.com/watch?v=mqa1yEd891o) earlier this week. There, in a bit of a rambling response to [Michael Burry’s decision to short Palantir](https://gizmodo.com/the-big-short-investor-michael-burry-bets-against-ai-hype-2000681316), Karp suggested that investors should just get on board with his company because “Most of the GDP growth in this country is because of AI.” He’s not wrong, but he also seems to view that as a good thing—that AI is inevitable and essential and everyone should just get on board, rather than there being any chance we’re currently in the middle of a speculative gold rush that is artificially inflating economic growth metrics and will inevitably bottom out.

It’s hard not to read Karp’s view of his own company as essential—to the government, to the world, to pretty much everyone—which has become [something of a theme from AI company executives](https://gizmodo.com/why-is-the-ai-czar-already-saying-openai-wont-get-a-bailout-2000682693) as of late. And there’s no denying he’s a very dedicated hype man for his company. On CNBC, he called it “one of the greatest businesses in the world,” and said it’s “doing a noble task.” On Axios, he chose a slightly different dialect to express that, calling Palantir “the most baller, interesting company on the planet,” with a “baller product” and “baller culture.”

At his core, he seems to feel that Palantir not only can be key to maintaining American exceptionalism, but that it *has* to be. In his [letter to investors](https://www.palantir.com/q3-2025-letter/en/) after the company’s third-quarter earnings were released, he evoked poet William Butler Yeats’ famous poem “The Second Coming,” in which he wrote, “Things fall apart; the center cannot hold.” Karp’s riff on the poem was this: “Today, America is the center, and it must hold.” He went on to argue, “It is and was a mistake to casually proclaim the equality of all cultures and cultural values.” As a reminder, this is supposed to be the head of a software company and not a nationalistic political leader.

To that end, when Karp was asked by Allen to “go dark” and talk about what could go wrong with AI, he didn’t really get to the downside. “It could go wrong in lots of ways, but again, there I would say we need to absorb a lot of risk there because it’s either going to go right and wrong for us or it’s going to go right and wrong for China.”

Asked again, more specifically this time, how AI could impact people, he just can’t get there. “No decision is without risk. And the risk we have to absorb here is going long on this because we’re not doing this in a vacuum. We are going to be the dominant player, or China is going to be the dominant player, and there will just be very different rules depending on who wins,” he said. “So when people are worried about surveillance, of course, there are huge dangers there, but you know, you will have far fewer rights if America’s not in the lead.”

Basically, we might completely destroy our economy, our culture, our sense of privacy and individuality, our sense of pride in contributing to our communities—but we’ll be damned if we let anyone else do it to us.

As a side note, Karp seems to think most people’s concern with surveillance is that they are going to get caught cheating for some reason. For instance, when giving an example of what he thinks is a valid skeptical question to ask about what Palantir is doing, he said, “Is this product being used to take away my right to go have a hot dog with a coworker I’m flirting with while being married? Which, honestly, I think is the god-given right of people in this country.” He later brings this up again, saying that most surveillance technology isn’t determining, “Am I shagging too many people on the side and lying to my partner?” Your guess is as good as any as to what that’s all about.

Anyway, when Karp does finally get to the idea of existential risk brought about by the proliferation of AI, he says the primary risk is “social instability.” Pressed into describing what forms that might take, Karp describes “Pretty crazy populist movements that obviously make no sense, like the government is going to run grocery stores.”

So there are your two paths. You can choose the one where AI is integrated into every part of your life, get forced into increasingly narrow pathways for your education and work, and accept an all-seeing surveillance state as a trade-off for “safety” from an unseen enemy. Or you can have your local government address affordability problems by opening grocery stores in food deserts and selling goods at wholesale prices. Tough call, but it’s clear what side Karp has picked. It happens to be the one he profits from. Go figure.