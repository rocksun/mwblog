
<!--
title: 重新思考人工智能时代的最小权限原则
cover: https://cdn.thenewstack.io/media/2024/07/daed8a14-biometric.jpg
-->

按需部署大型语言模型来决定是否授予访问权限，可以减少所有参与者的摩擦，同时提高安全性。

> 译自 [Rethinking Least Privilege in the Era of AI](https://thenewstack.io/rethinking-least-privilege-in-the-era-of-ai/)，作者 Liam Crilly。

在应用程序安全和访问控制的旧世界中，最小权限是一个美好的理想，但在实践中几乎不可行。每家有一定规模的公司都实施了基于角色的访问控制 (RBAC)。一旦一家公司足够大到可以谈论任何主要形式的合规性（如 SOC2）或构建相当大的技术基础设施，系统锁定就会随之而来。这种锁定可能提高了安全性，但也带来了摩擦，并创建了难以更改和扩展的脆弱系统。

即使访问控制不断改进，[访问控制](https://thenewstack.io/role-based-access-control-five-common-authorization-patterns/) 的核心要求——决定谁可以使用什么——仍然是一种确定性解决方案，扩展性很差。在某种程度上，最小权限已成为问题，而不是解决方案。负责[监管和管理最小权限](https://thenewstack.io/what-is-zero-trust-architecture/) 的系统不仅成为减缓工作速度的摩擦来源，而且变得如此可预测，以至于攻击者学会了利用它们。

例如，攻击者专门针对 Okta 的客户支持系统，该系统本质上对客户数据具有提升的访问权限。他们从工作笔记本电脑上的[员工个人 Google 帐户](https://www.securityweek.com/okta-hack-blamed-on-employee-using-personal-google-account-on-company-laptop/) 中获取数据以访问该系统，他们在该笔记本电脑上保存了帐户凭据，证明了这一原则。

如今，我们正处于对最小权限进行彻底反思的初期阶段。人工智能和[大型语言模型 (LLM)](https://roadmap.sh/guides/introduction-to-llms) 是惊人的预测机器。它们以接近线速的速度运行，可以对请求者（机器或人类）是否应该被授予访问系统的权限做出高度准确的猜测。这正在导致最小权限的新应用，这些应用是动态的和概率性的，不是根据个案，而是根据实际的请求进行决策。

自然地，[构建人工智能](https://thenewstack.io/ai/) 的公司本身就是带头人。来自 OpenAI、Anthropic 和 Deep Mind 的 CISO[在一次深入的播客中讨论了这个问题](https://a16z.com/podcast/securing-the-black-box-openai-anthropic-and-gdm-discuss/)。如果证明有效，这种对最小权限的新方法可能会彻底改变访问控制的工作方式，并加速所有垂直行业和技术孤岛的工作流程。

## 最小权限令人痛苦的诸多原因

最小权限原则是在信息安全领域的基础概念，起源于早期计算和访问控制机制。它由 Jerome Saltzer 和 Michael D. Schroeder 在他们 1975 年的开创性论文“[计算机系统中的信息保护。”](https://www.cs.virginia.edu/~evans/cs551/saltzer/) 中正式阐述。该原则旨在通过确保用户和程序以执行其任务所需的最低访问级别运行来最小化系统内的攻击面。

最小权限的传统方法通常围绕着严格限制用户访问仅与其特定角色相关的资源和信息。虽然这在根本上是合理的，但当用户需要浏览复杂的系统以找到他们所需的精确权限时，它会导致效率低下和沮丧。

- **权限过于严格：** 最小权限有时过于严格，会阻止员工有效地执行工作。这会导致员工因需要频繁请求额外访问权限而感到沮丧，并降低工作效率。如果一家公司拥有更保守的 IT 和安全文化，严格的权限可能会鼓励信息孤岛，并阻碍协作和知识共享。
- **权限过宽：** 另一方面，授予过宽的权限会造成重大的安全风险，用户可以访问其职责范围之外的系统，甚至可以默认访问他们从未接触过的关键系统。这会导致更广泛的攻击面，并增加数据泄露的可能性。
- **权限瓶颈：** 如果权限管理没有至少在一定程度上实现自动化或简化，员工可能需要等待数小时、数天甚至数周才能获得使用工具或系统所需的访问权限。IT 工作流程的中断或人员配备问题会进一步延长排队时间。在许多 IT 服务系统中，员工需要填写特定的请求或工单才能获得访问权限，这些请求或工单必须经过人工审核。这始终会减慢运营速度，降低生产力，并损害员工士气。
- **权限复杂性：** 在拥有更多运营系统的现代云计算环境中，配置和维护权限和控制要复杂得多。微服务运动将应用程序拆分为众多服务，每个服务都有一个 API，每个服务都需要权限。为了应对这种复杂性，许多组织依赖于服务网格，这增加了另一个管理面，并带来了额外的复杂性。多云和混合架构不仅需要跨系统，还需要跨云的权限。权限管理增长最快的领域是机器对机器通信，这引入了额外的协议。所有这些都会导致权限漂移和最小权限问题。
- **动态角色和权限：** 在角色和职责频繁变化的环境中，维护适当的访问级别可能很困难。可能需要临时权限，但如果管理不当，这些权限也会带来风险。传统的 RBAC 系统根据目录服务在组级别启用权限。但在现代跨职能团队和矩阵式组织中，员工无法进行清晰的分类，并且可能在执行集成工作时跨组。此外，当今的工作通常涉及多个企业的人员，这可能需要一个联合的、分层的访问结构，该结构仅限于项目和项目内的功能。

## 使用 LLM 实现动态最小权限

少数公司正在尝试部署 LLM 来提供一种全新的最小权限方法，这种方法更具概率性和上下文性。这种逻辑是合理的。LLM 是概率性决策机器。当存在相对有限的选择和相对容易加强的决策（无论是自主地还是通过人工输入）时，它们的功能最佳。与预测蛋白质如何折叠相比，确定访问请求是否合法相对简单。

这将如何运作？LLM 将根据与请求者相关联的额外信息，对大量 IT 访问控制决策日志进行微调。该系统还可以使用基于最新系统和访问清单的数据嵌入的检索增强生成 (RAG) 来提高准确性。与代码一样，访问控制涉及具有有限表面积的决策——是、否、级别、持续时间、允许的连接类型。在用于访问控制的 LLM 的情况下，人工智能可以在训练期间将人类纳入决策循环，直到他们确信该系统在简单情况下运行良好。所有边缘情况仍然可以路由到人类进行权限决策。

在这个新模型中，最小权限可以在请求级别而不是系统级别发挥作用。新一代经过 IT 流程训练的生成式人工智能系统可以以有趣的方式探索旧的最小权限方法。权限可以动态地降低到秒级，并通过检查系统记录来进行核实。这种新的最小权限方法最终将使完成零信任循环成为可能，不仅验证身份，还提供最小权限访问和授权，这些访问和授权在每次请求甚至每次交易的基础上应用。
在这种情况下，工程师想要更改特定 API，可能只能在有限的时间内访问 API 的治理和代码，直到更改被推送到 CI/CD 系统中，然后在测试完成后失去访问权限。当系统开始出现错误时，工程师可能会获得访问权限，直到修复程序被推送。或者，客户服务代表可能要求与销售团队成员共享对帐户的访问权限，以用于特定目的，并且仅限于查看特定时间段内的记录，并且仅限于特定产品许可证或培训材料。

听起来像是科幻小说吗？OpenAI 已经开始实施其中的一些做法，正如安全主管 Matt Knight 在 [最近的一次播客](https://a16z.com/podcast/securing-the-black-box-openai-anthropic-and-gdm-discuss/) 中所描述的那样。

“想象一下，你是一名开发人员，你需要一些范围狭窄的角色来更改服务。但与其去寻找合适的角色，不如直接请求对整个订阅或租户的广泛管理访问权限，”Knight 说，他将此描述为“简单按钮”。

据 Knight 介绍，LLM 有效地将用户与其想要执行的操作匹配到他们需要的正确内部资源和权限级别。“我们以一种限制它们的方式做到了这一点，如果模型出错，就不会产生影响。仍然需要人工审查，”Knight 解释说。

## LLM 将使最小权限更快但更有效

最终，这种方法不仅会提高效率，让员工得到他们想要的东西，还会提高安全性。虽然攻击者肯定会尝试玩弄系统，但 LLM 的模式匹配能力远远超过人类操作员。

决定是否需要特权是一种模式匹配行为，预测请求来自有效用户，并且用于有效目的。LLM 将能够处理更广泛的上下文窗口，同时仍然局限于特定操作。这也将允许员工进行自然语言请求，并可能让 LLM 建议更好的特权和协作方法。

人类必须参与边缘情况，以提供判断和直觉，但将最小权限从描述性决策架构转移到概率性决策架构将减少所有相关方之间的摩擦，同时改善决策。
