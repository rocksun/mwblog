Gartner 新发布的《企业AI搜索市场指南》提供了一个有价值的视角，阐述了生成式AI如何正在改变[企业知识获取](https://thenewstack.io/why-ai-search-platforms-are-gaining-attention/)。然而，随着焦点仍然停留在内部生产力和治理上，一个关键问题出现了：当搜索是面向客户并直接与互动、转化和收入挂钩时，同样的方法是否适用？

## Gartner 对企业AI搜索的看法

Gartner 的研究侧重于内部、以员工为中心的使用案例，包括数字工作场所助手、IT 支持、人力资源知识管理和合规自动化。目标是使[AI 助手和副驾驶](https://thenewstack.io/ai-coding-assistants-are-reshaping-engineering-not-replacing-engineers/)能够通过整合企业数据孤岛中的信息来提高员工生产力。客户体验 (CX) 场景仅被简要提及，并被视为邻近市场而非核心优先事项。

因此，报告强调了治理、连接器、元数据丰富、安全裁剪和知识图谱。这些能力对于企业环境至关重要，但与实时、面向客户的系统关联性较低。

性能主要根据 AI 助手的可靠性和治理来评估，这与企业 AI 搜索的内部焦点一致。在这些环境中，延迟和吞吐量的重要性低于访问控制和合规性。混合搜索和[检索增强生成 (RAG)](https://thenewstack.io/freshen-up-llms-with-retrieval-augmented-generation/) 被认为是核心能力，但重点仍然是管理跨不同数据孤岛的复杂性，而不是服务高吞吐量、低延迟的工作负载。

Gartner 还预计大型企业将在 Microsoft 365、Salesforce 和 SAP 等 SaaS 套件中运行多个嵌入式搜索平台。这种架构非常适合内部知识管理，但并非为面向客户的系统而设计，在面向客户的系统中，性能、规模和准确性直接影响用户体验和业务成果。

## 面向客户的搜索

这为构建面向客户的 AI 应用的组织创造了一个明显的空白，在这些应用中，搜索性能不仅仅是一个生产力因素，更是一种业务关键能力。无论是电子商务、金融、媒体、社交网络、市场情报还是其他应用，其要求都截然不同。开发人员必须提供高吞吐量、低延迟的检索和排名，通常在严格的服务级别目标下每秒处理数千个查询。

这些系统依赖于多阶段排名管道、复杂的张量计算以及跨文本、图像和结构化数据的多模态检索。它们还必须以机器速度提供生成式或检索增强的结果。索引和特征更新几乎实时发生，以反映库存、行为或内容流的变化，同时还要在大规模环境下保持正常运行时间、成本效率和性能。

与内部企业 AI 搜索系统不同，内部系统的首要任务是治理和政策合规性，而面向客户的 AI 搜索必须优化低延迟相关性、响应速度和个性化。

这些系统直接嵌入到核心产品体验中，不仅影响用户满意度，还影响收入、互动和留存。它们需要一个统一的架构，能够同时处理词法和向量检索，在靠近数据的地方执行学习型排名模型以减少网络带宽，并支持大规模推理工作负载，而无需大量的编排或额外的中间件。

## 结论

Gartner 的报告为在内部生产力和治理背景下理解企业 AI 搜索提供了一个基本框架。然而，同样的假设和架构并不适用于面向客户的应用。

随着市场的发展，将会在为内部知识合成设计的企业 AI 搜索平台与为搜索本身就是产品的生产级、实时环境构建的 AI 搜索平台之间出现更精确的区别。

后者必须满足对性能、规模、准确性和多模态远更高的期望，这些是现代生成式和检索增强系统的决定性特征。

对于构建面向客户的 AI 应用的组织来说，Vespa 提供了一种替代传统“洞察引擎”血统的方案。它是为 AI 原生系统而构建，并非改造过的企业搜索。Vespa 为 Perplexity.ai、Spotify 和 Yahoo 等公司提供大规模高吞吐量、实时检索和排名能力。它的架构支持多阶段排名、张量计算、多模态检索以及以机器速度提供 AI 服务。Vespa 专为以工程为主导的公司设计，在这些公司中，搜索就是产品，性能直接驱动收入。