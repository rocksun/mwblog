
<!--
title: 首次！AI语言分析能力比肩人类专家
cover: https://www.quantamagazine.org/wp-content/uploads/2025/10/Metalinguistics-cr-Robert-Neubecker-Social.jpg
summary: 研究挑战乔姆斯基观点，发现一个大型语言模型能像人类语言学家一样分析复杂语言结构，包括递归和歧义，质疑人类语言能力的独特性。
-->

研究挑战乔姆斯基观点，发现一个大型语言模型能像人类语言学家一样分析复杂语言结构，包括递归和歧义，质疑人类语言能力的独特性。

> 译自：[In a First, AI Models Analyze Language As Well As a Human Expert | Quanta Magazine](https://www.quantamagazine.org/in-a-first-ai-models-analyze-language-as-well-as-a-human-expert-20251031/)
> 
> 作者：Steve Nadis

在人类拥有的无数能力中，哪些是人类独有的？至少自亚里士多德以来，语言一直是首要的候选者，他写道人类是“拥有语言的动物”。即使ChatGPT等大型语言模型在表面上复制了日常言语，研究人员仍想知道人类语言中是否存在其他动物或人工智能设备的通信系统无法比拟的特定方面。

特别是，研究人员一直在探索语言模型对语言本身进行推理的程度。对于语言学界的一些人来说，语言模型不仅*不*具备推理能力，而且*无法*具备。这一观点在2023年由著名语言学家Noam Chomsky和两位合著者总结，当时他们[在《纽约时报》上撰文（在新标签页中打开）](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html)称，“对语言的正确解释是复杂的，不能仅仅通过浸泡在海量数据中来学习。”这些研究人员认为，人工智能模型可能擅长使用语言，但它们无法以复杂的方式分析语言。

![Gašper Beguš的肖像](https://www.quantamagazine.org/wp-content/uploads/2025/10/Gasper-Begus-cr-Jami-Smith-V2.webp)

加州大学伯克利分校语言学家Gašper Beguš。

这一观点最近在一篇[论文（在新标签页中打开）](https://ieeexplore.ieee.org/document/11022724)中受到了挑战，该论文由加州大学伯克利分校的语言学家[Gašper Beguš（在新标签页中打开）](https://vcresearch.berkeley.edu/faculty/gasper-begus)；最近在伯克利获得语言学博士学位的[Maksymilian Dąbkowski（在新标签页中打开）](https://maksymilian-dabkowski.github.io/)；以及罗格斯大学的[Ryan Rhodes（在新标签页中打开）](https://wavyphd.com/about)共同撰写。研究人员让多个大型语言模型（LLM）进行了一系列语言测试——其中一个测试是让LLM概括一种虚构语言的规则。虽然大多数LLM未能像人类一样解析语言规则，但其中一个模型展现出了令人印象深刻的能力，大大超出了预期。它能够以与语言学研究生非常相似的方式分析语言——绘制句子图、解决多重歧义，并利用递归等复杂的语言特征。Beguš表示，这一发现“挑战了我们对人工智能能力的理解”。

耶鲁大学计算语言学家[Tom McCoy（在新标签页中打开）](https://ling.yale.edu/profile/tom-mccoy)表示，这项新工作既及时又“非常重要”，他没有参与这项研究。“随着社会越来越依赖这项技术，理解它在哪里能成功、在哪里会失败变得越来越重要。”他补充说，语言分析是评估这些语言模型在多大程度上能像人类一样推理的理想试验台。

## **无限的复杂性**

对语言模型进行严格语言测试的一个挑战是确保它们不事先知道答案。这些系统通常在大量书面信息上进行训练——不仅是互联网的大部分内容，涉及几十甚至几百种语言，还包括语言学教科书等。理论上，这些模型可能只是简单地记忆和反刍在训练期间输入给它们的信息。

为了避免这种情况，Beguš及其同事创建了一个分为四个部分的语言测试。其中三部分涉及要求模型使用树状图分析专门设计的句子，这些树状图首次出现在Chomsky 1957年的里程碑式著作《句法结构》中。这些图将句子分解为名词短语和动词短语，然后进一步细分为名词、动词、形容词、副词、介词、连词等。

测试的一个部分侧重于递归——即在短语中嵌入短语的能力。“The sky is blue”是一个简单的英语句子。“Jane said that the sky is blue”将原句嵌入到一个稍微复杂的句子中。重要的是，这种递归过程可以无限进行下去：“Maria wondered if Sam knew that Omar heard that Jane said that the sky is blue”也是一个语法正确，尽管有些笨拙的递归句子。

自然界中的递归

**递**归不仅是语言中的一个关键要素，也是自然界的一个特征。例如，在加拿大北部的维多利亚岛上，人们可以发现一个湖中的岛屿，而这个岛屿又在一个岛屿上。但那个岛屿也在一个岛屿上的湖中。这个（未命名的）最内层的岛屿是已知最大的“三阶”岛屿，有时被戏称为“盗梦空间岛”，以2010年克里斯托弗·诺兰执导的电影命名，影片中角色进入梦中梦的梦境世界。

![](https://www.quantamagazine.org/wp-content/uploads/2025/10/Metallinguistics_SideBar-crMarkBelan-Desktopv5-01.svg)

递归被Chomsky和其他人称为人类语言的定义性特征之一——甚至可以说是人类思维的一个定义性特征。语言学家认为，其无限潜力赋予了人类语言从有限词汇和有限规则中生成无限多可能句子的能力。到目前为止，还没有令人信服的证据表明其他动物能够以复杂的方式使用递归。

递归可以发生在句子的开头或结尾，但最难掌握的形式被称为中心嵌入，它发生在句子的中间——例如，从“the cat died”到“the cat *the dog bit* died。”

Beguš的测试给语言模型输入了30个包含复杂递归示例的原创句子。例如：“The astronomy the ancients we revere studied was not separate from astrology.”（我们尊崇的古人研究的天文学与占星术并非泾渭分明。）通过句法树，其中一个语言模型——OpenAI的o1——能够确定该句子的结构如下：

> **我们尊崇的[古人[研究的]]天文学与占星术并非泾渭分明。**

然后，该模型进一步给句子添加了另一层递归：

> **我们尊崇的[居住在我们珍视的土地上的[古人[研究的]]]天文学与占星术并非泾渭分明。**

Beguš等人没有预料到这项研究会发现一个具有更高层次“元语言”能力的人工智能模型——用他的话说，就是“不仅仅是使用语言，而是思考语言的能力”。

卡内基梅隆大学计算语言学家[David Mortensen（在新标签页中打开）](https://www.cs.cmu.edu/~dmortens/)表示，这是他们论文中“引人注目”的方面之一，他没有参与这项工作。关于语言模型是否仅仅是在预测句子中的下一个词（或语言标记），以及这与人类对语言的深刻理解在本质上是否不同，一直存在争议。“语言学界有些人说LLM并非真正地在处理语言，”他说。“这看起来是对这些说法的否定。”

## **你是什么意思？**

McCoy对o1的整体表现感到惊讶，特别是它识别歧义的能力，他称之为“计算语言模型难以捕捉的著名难题”。人类“拥有大量常识性知识，使我们能够排除歧义。但计算机很难拥有这种水平的常识性知识。”

像“Rowan fed his pet chicken”这样的句子，可能描述的是Rowan饲养的宠物鸡，也可能描述的是他喂给他的（大概更传统的）动物伴侣的鸡肉餐。o1模型正确地生成了两种不同的句法树，一个对应句子的第一种解释，另一个对应第二种解释。

研究人员还进行了与音系学相关的实验——音系学是研究声音模式以及最小声音单位（称为音素）组织方式的学科。为了像母语使用者一样流利地说话，人们遵循通过实践习得而从未被明确教授的音系规则。例如，在英语中，在一个以“g”结尾的单词后面加上“s”会产生“z”音，如“dogs”。但在一个以“t”结尾的单词后面加上“s”听起来更像是标准的“s”音，如“cats”。

在音系学任务中，该团队创建了30种新的“迷你语言”（Beguš如此称呼它们），以查明LLM是否能够在没有任何先验知识的情况下正确推断出音系规则。每种语言都由40个虚构单词组成。以下是其中一种语言的一些示例词：

> θalp  
> ʃebre  
> ði̤zṳ  
> ga̤rbo̤nda̤  
> ʒi̤zṳðe̤jo

然后，他们要求语言模型分析每种语言的音系过程。对于这种语言，o1正确地写道：“当一个元音紧接在一个清音且阻塞音的辅音之后时，它会变成一个气声元音”——阻塞音是一种通过限制气流形成的声音，例如“top”中的“t”。

这些语言是新发明的，所以o1在训练期间不可能接触过它们。“我没想到结果会如此强大或令人印象深刻，”Mortensen说。

## **独属于人类还是并非如此？**

这些语言模型能走多远？它们是否会仅仅通过变得更大——叠加更多的计算能力、更多的复杂性和更多的训练数据——而无限地变得更好？或者人类语言的某些特征是仅限于我们物种的进化过程的结果？

最近的结果表明，这些模型原则上可以进行复杂的语言分析。但目前还没有任何模型提出原创的东西，也没有教会我们以前不知道的语言知识。

如果改进仅仅是增加计算能力和训练数据的问题，那么Beguš认为语言模型最终将在语言技能上超越我们。Mortensen说，当前的模型有些局限。“它们被训练做非常具体的事情：给定一段标记（或词）的历史，预测下一个标记，”他说。“由于它们的训练方式，它们在泛化方面遇到了一些麻烦。”

但鉴于最近的进展，Mortensen说他看不出为什么语言模型最终不会展现出比我们自己更好的语言理解能力。“我们能够以更具创造性的方式，从更少的数据中更好地进行泛化的模型，这只是时间问题。”

Beguš表示，新结果表明，曾经被认为是人类语言独有特性的那些属性正在被稳步“削弱”。“我们似乎没有我们以前认为的那么独特。”