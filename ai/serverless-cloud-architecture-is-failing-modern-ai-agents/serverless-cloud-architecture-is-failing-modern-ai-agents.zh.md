近十年来，云架构一直遵循一个简单的规则：保持一切无状态。AWS Lambda 和其他[无服务器](https://thenewstack.io/serverless/)平台鼓励团队将工作负载分解为微小、短命的函数，这些函数不带持久状态，且本地资源占用极少。这种模型扩展性好，成本效益高，并成为现代[微服务](https://thenewstack.io/microservices/)的支柱。

截至 2025 年，[AI 智能体](https://thenewstack.io/ai-agents-a-comprehensive-introduction-for-developers/)已直接被推向金融、医疗保健、能源、电子商务和软件开发等各个领域的生产环境。随着它们开始处理真实的业务工作流程——调查事件、分析文档、协调多步骤任务、运行测试或导航内部系统——一种模式变得不可避免：Lambda 风格的方法无法支持它们。使得无服务器吸引人的那些假设，恰恰是智能体所违背的假设。

随着企业试图安全且可预测地操作化智能体，2025 年定义了两个重要的经验教训。

**经验教训 1**：对于敏感的智能体工作负载，虚拟私有云（VPC）和本地部署成为默认选择。

在高风险环境中，向私有云和本地执行的转变变得尤为明显。早期对公共大语言模型（LLM）API 的实验，让位于风险、合规和安全团队的严峻问题：数据去向何处，谁能看到，记录了什么，以及我们能否强制执行审计要求？对于涉及客户信息、内部 API 或敏感文档的智能体工作流程，公共端点不再被接受。

[Snowflake](https://www.snowflake.com/?utm_content=inline+mention) 在 2025 年持续扩展的 [Cortex](https://thenewstack.io/stack-overflow-on-snowflake-cortex-answers-without-attitude/) 展示了行业如何响应。历史上，Snowflake 采用集中式、云托管模型，计算和存储与 Snowflake 管理的基础设施紧密绑定。Cortex 标志着这一模式的改变。Cortex 不在 Snowflake 的环境中运行模型，而是直接在客户现有的 Snowflake VPC 内部执行。这意味着嵌入、模型推理、日志和智能体驱动的工具调用都保留在企业自己的网络边界内。这一转变不仅仅是为了方便。Snowflake 将其定位为对具有严格审计规则和对外部[数据移动](https://thenewstack.io/agentic-ai-is-coming-but-can-your-data-infrastructure-keep-up/)零容忍的行业至关重要，但智能体风险管理是其隐含的因素。

类似转变在其他行业也可见。Sana 对 2025 年末工业和金融部署的分析强调，企业越来越要求其智能体平台采用 VPC 或本地安装。这些组织需要其智能体使用内部身份提供商进行身份验证，遵守内部权限结构，并完全在预设的云安全边界内运行。任何其他方式都会引入不可接受的操作和监管风险。

这一趋势反映了一个更广泛的认识：一旦智能体获得与敏感数据交互或在生产系统中执行操作的能力，它就成为一个特权软件组件。而特权系统不能存在于企业边界之外。

**重要性**：企业 AI 项目现在[必须假定涉及内部数据的智能体工作负载](https://thenewstack.io/ai-agents-must-learn-from-chatgpts-data-wrongs/)将需要 VPC 原生或本地部署。这一转变影响着供应商选择、成本规划、网络架构、身份设计以及组织如何构建智能体开发和监控的管道。

**经验教训 2**：智能体执行从无状态函数转向持久化云工作站。

2025 年的第二个决定性转变是架构方面的。AI 智能体不是在毫秒级内运行的。它们跨多个步骤序列工作，引用过去的上下文，创建中间文件，运行验证，调用多个工具，并在长时间内返回任务。这种工作流程与无服务器的假设——即一旦调用结束，任何东西都不会持久化——根本不兼容。

传统的无服务器假定函数短暂运行，从不保留本地状态，并且每次都重新加载工具，而智能体工作流程需要更接近于一个长期存在的 Workspace。它们需要稳定地访问其工具。它们必须在不同步骤之间保留上下文。它们不能为每个动作都重建环境。而且它们必须作为连续的工作单元而非一系列孤立事件进行可观测。

领先的模型实验室在 2025 年全年展示了这一转变。OpenAI 和 Anthropic 的公开演示显示，智能体能够编写和执行代码、导航浏览器界面、搜索文档以及协调不同工具。这些工作流程只有在跨步骤保留状态和工具的持久化执行环境中才有意义。基础架构更像是轻量级云工作站，而不是短暂的函数。

Google DeepMind 的研究也反映了相同的模式。其用于调试、代码执行和基于浏览器的任务的工具使用型智能体都依赖于稳定的环境，在这些环境中，依赖项、缓存和测试运行器在重复尝试中保持可用。如果没有连续性，工作流程将失败或变得极其缓慢。

许多企业亲身体验到这一点。试图将[智能体强制纳入无状态架构](https://thenewstack.io/agents-meet-databases-the-future-of-agentic-architectures/)会导致环境重建、缓慢的预热时间、不一致的行为和调试难题。随着团队采纳持久化环境，他们获得了可预测的性能、更简单的故障排除，以及能够观测智能体轨迹而非孤立日志的能力。

**重要性**：转向持久化执行环境改变了组织对编排、资源管理、成本和安全的看法。计算的核心单元不再是微型调用。它是一个会话。企业需要能够调度、暂停、恢复、审计和终止整个智能体会话，同时保持隔离和治理的工具。

## 云架构的发展方向

这两个转变指向了 AI 智能体的新云模式：

1.  部署必须符合数据驻留、可审计性和监管要求。
2.  执行必须支持有状态、多步骤的工作流程。
3.  编排必须将智能体的完整会话——而非单独的提示调用——作为可靠性和控制的单位。

这代表着与过去十年围绕将工作分解为小而无状态的片段的云设计背道而驰。智能体迫使企业接受一个简单的现实：有意义的自动化需要连续性、上下文和控制。

展望未来，适应这种新架构的组织将能够运行可靠、受控且可投入生产的智能体。那些试图将无服务器时代的模式强加于智能体工作负载的组织，将发现他们的基础设施——而非他们的模型——才是真正的瓶颈。