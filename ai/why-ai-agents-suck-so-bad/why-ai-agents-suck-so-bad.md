
<!--
title: 为什么AI Agent如此糟糕
cover: https://cdn.thenewstack.io/media/2025/03/c8db6817-rodion-kutsaiev-l2jpoyf82ne-unsplash.jpg
-->

作者详细描述了与一位支持专员令人沮丧的经历，突显了当前基于 RAG 的 AI 系统在处理复杂的客户支持问题方面的局限性。

> 译自：[Why AI Agents Suck So Bad](https://thenewstack.io/why-ai-agents-suck-so-bad/)
> 
> 作者：Jack Wallen

让我来描述一下背景。

前几天我意识到我的DJI LIDAR坏了。我依靠这个小小的技术来为我的电影摄影机增加自动对焦和自动跟随功能。如果没有这个功能，我就很难拍到我需要的一些镜头。

这个东西大概有一年左右的历史了，但我不知道它是否还在保修期内。无论如何，它必须被修理。

![DJI Lidar (B&H)](https://cdn.thenewstack.io/media/2025/03/e42527db-dji_cp_rn_00000359_01_focus_pro_lidar_1712652359_1816801-300x300.jpg)

*这是一个DJI Lidar (B&H)*

于是，我跳到DJI网站，进入支持页面，我以为我会受到AI Agent的欢迎。

果然。

我跳到Agent上，输入了类似“我的LIDAR不再自动对焦”的内容。AI Agent的回答毫无帮助，所以我跟进了一个问题。同样，[AI Agent](https://thenewstack.io/ai-agents-a-comprehensive-introduction-for-developers/)让我失望了，所以我采取了另一种方法，问了一个问题：“我如何退回我的LIDAR进行维修？”

Agent无法帮助我。

经过30分钟的尝试，我决定必须找一个真人。大约60分钟后，我拿到了LIDAR的退货标签，可以把它打包了。

鉴于如此多的企业都在依靠AI Agent来处理几乎所有事情，这种情况本不应该发生。与AI Agent的对话应该很简单，也许像这样：

*   我：我的LIDAR不再自动对焦。
*   AI Agent：您能给我序列号以便我更好地帮助您吗？
*   我：当然。<输入序列号>
*   AI Agent：谢谢。请稍等。<片刻过去>您的设备仍在保修期内。输入您的电子邮件地址，我将发送一个退货标签，我们将优先处理。
*   我：谢谢。
*   AI Agent：还有什么我可以帮您的吗？
*   我：没有。谢谢。
*   AI Agent：祝您愉快，记得查看您的电子邮件以获取标签。

这应该是交流的*方式*；但不幸的是，事实并非如此，我花了太多的时间安排退货和维修事宜。

就目前而言，唯一享受效率的一方是企业。我尝试用AI Agent解决问题的每一个例子都与我尝试退回我的LIDAR时的经历非常相似，所以这不是DJI的错。

问题在于AI本身。

## AI本应使一切更有效率。

我实际上之前构建过一个[chatbot](https://thenewstack.io/what-we-learned-from-building-a-chatbot/)，并且了解它们的工作原理。AI Agent在构建方式和与用户交互的方式上都非常相似。

问题是，大多数AI Agent都基于[检索增强生成](https://thenewstack.io/how-to-add-rag-to-ai-agents-for-contextual-understanding/) (RAG) 模型，这种模型恰好既廉价又无效。这种基于RAG的系统在世界各地被广泛使用，这是一个问题。为什么？因为公司正在使用这些系统来帮助处理非常复杂的客户支持任务。

仔细想想。

许多大公司可能不这么认为，但客户支持是一个极其复杂的过程。每个用户都有不同的问题，对他们正在使用或试图做的事情有不同的理解水平，说不同的语言，并且处于非常不同的沮丧程度。

当RAG系统用于此目的时，它们无法处理沟通的细微差别，并且通常无法处理问题。

为什么会这样？基于RAG的AI与像[Mistral](https://mistral.ai/about), [Ollama](https://thenewstack.io/how-to-set-up-and-run-a-local-llm-with-ollama-and-llama-2/), 或 [ChatGPT](https://thenewstack.io/how-to-build-web-components-using-chatgpt/) 这样的AI系统不同，因为它没有语言处理、推理或做出决定的能力。当您使用基于RAG的系统时，您会知道的，因为交互远非人性化。基于RAG的AI Agent工作的唯一方式是您知道要问的正确问题。问一些离题或复杂的问题，您会立即明白我的意思，因为Agent要么不知道如何回复，要么会重复自己，要么会重置（我多次经历过）。

基于RAG的系统用于医疗保健、法律咨询服务、房地产经纪人、电子商务助手、企业检索型聊天机器人、会议记录和摘要生成器、预约预订和安排、数据分析Agent等等。

## 如何解决这个问题？
你可能已经使用过 [Google 的 Gemini Live](https://thenewstack.io/gemini-all-you-need-to-know-about-googles-multimodal-ai/)，并体验了与 AI 的全面对话。我用过它，它令人印象深刻。我还经常通过 Msty 使用 Ollama 进行研究，并且很少失望。现在，想象一下，如果一家公司使用像 Gemini Live 这样的东西作为支持代理。事情的完成将达到前所未有的准确性和效率水平。

问题是，大多数公司都不愿意花钱购买变革性的 AI 代理。什么是变革性的 AI 代理？很高兴你问了。

变革性的 AI 代理具有以下特点：

- 自主性
- 学习和适应性
- 决策
- 任务执行
- 协作

这些类型的代理被认为是 AI 发展的“第三次浪潮”（在预测性和生成性 AI 之后），并且可以轻松地彻底改变许多行业。

但是，公司需要愿意花钱才能使它们发挥作用，这既不便宜也不容易。考虑一下：一家公司可以创建一个变革性的 AI 代理，并使其可供各地的企业使用。一旦企业决定采用该代理，他们就必须专门针对自己的需求（针对产品、服务等）对其进行培训。

该培训将要求企业拥有大量关于其产品和流程的文档。最重要的是，为了真正使这些代理有效，它们必须与企业内部的其他系统集成（例如提交工单）；否则，它们将不会非常有效。

为了好玩，我问了 Gemini 这个问题：

为什么 AI 代理在处理支持方面如此糟糕？

Gemini 的回答很有说服力：

> 虽然 AI 代理取得了重大进展，但它们仍然在细微差别、适应性、数据偏差和客户信任方面存在不足。克服这些限制需要持续的研究、更好的数据、改进的算法以及以人为本的 AI 在客户支持中的实施方法。关键是将 AI 视为增强人类代理的工具，而不是完全取代它们。最佳的客户支持体验很可能是那些无缝融合了 AI 和人类智能优势的体验。

Gemini 的回答一针见血，尤其是 AI 是一种增强人类代理的工具，而不是完全取代它们的部分。在公司理解基于 RAG 的代理无法取代人类提供支持之前，客户将继续拥有令人沮丧的体验，甚至可能因为支持太差而放弃他们喜欢的品牌。

这个问题是真实存在的，而且我看不出它会在短期内消失。

为什么？很简单。我问了 [Perplexity](https://thenewstack.io/more-than-an-openai-wrapper-perplexity-pivots-to-open-source/) AI 驱动的搜索引擎以下问题：

公司部署变革性 AI 代理需要多少成本？

答案应该会告诉你原因：

*   公司部署变革性 AI 代理的成本可能因项目的复杂性和范围而异。截至 2025 年，以下是潜在成本的概述：
    *   对于小规模或基本的 AI 代理开发，公司预计花费在 50,000 美元到 80,000 美元之间 1。
    *   中等规模的 AI 代理开发通常在 80,000 美元到 150,000 美元之间 1。
    *   大规模或高级的 AI 代理开发可能花费 150,000 美元或更多。
    *   对于具有深度学习、实时决策和持续学习等高级功能的、高度专业化的智能代理，成本可能超过 300,000 美元。

因此，部署一个变革性的 AI 代理需要花费 50,000 美元到 300,000 美元不等。这是一大笔钱，尤其是与基于 RAG 的系统相比，后者（根据 Perplexity 的说法）起价为 7,000 美元，并随着复杂性的增加而增加。

最终，基于 RAG 的 AI 代理比变革性 AI 便宜得多，因此你可以肯定大多数企业都会选择前者。在他们最终为变革性选项投入更多资金之前，大多数客户都会感到不太满意。
