Friday, May 31st 2024
[AMD, Broadcom, Cisco, Google, HPE, Intel, Meta and Microsoft Form Ultra Accelerator Link (UALink) Promoter Group to Combat NVIDIA NVLink](/322978/amd-broadcom-cisco-google-hpe-intel-meta-and-microsoft-form-ultra-accelerator-link-ualink-promoter-group-to-combat-nvidia-nvlink)
AMD, Broadcom, Cisco, Google, Hewlett Packard Enterprise (HPE), Intel, Meta and Microsoft today announced they have aligned to develop a new industry standard dedicated to advancing high-speed and low latency communication for scale-up AI systems linking in Data Centers.
Called the Ultra Accelerator Link (UALink), this initial group will define and establish an open industry standard that will enable AI accelerators to communicate more effectively. By creating an interconnect based upon open standards, UALink will enable system OEMs, IT professionals and system integrators to create a pathway for easier integration, greater flexibility and scalability of their AI-connected data centers.
As the demand for AI compute grows, it is critical to have a robust, low-latency and efficient scale-up network that can easily add computing resources to a single instance. Creating an open, industry standard specification for scale-up capabilities will help to establish an open and high-performance environment for AI workloads, providing the highest performance possible.
This is where UALink and an industry specification becomes critical to standardize the interface for AI and Machine Learning, HPC, and Cloud applications for the next generation of AI data centers and implementations. The group will develop a specification to define a high-speed, low-latency interconnect for scale-up communications between accelerators and switches in AI computing pods.
The 1.0 specification will enable the connection of up to 1,024 accelerators within an AI computing pod and allow for direct loads and stores between the memory attached to accelerators, such as GPUs, in the pod. The UALink Promoter Group has formed the UALink Consortium and expects it to be incorporated in Q3 of 2024. The 1.0 specification is expected to be available in Q3 of 2024 and made available to companies that join the Ultra Accelerator Link (UALink) Consortium.
Ultra Accelerator Link (UALink) is a high-speed accelerator interconnect technology that advances next-generation AI/ML cluster performance. AMD, Broadcom, Cisco, Google, HPE, Intel, Meta and Microsoft are forming an open industry standard body to develop technical specifications that facilitate breakthrough performance for emerging usage models while supporting an open ecosystem for data center accelerators.
"The work being done by the companies in UALink to create an open, high performance and scalable accelerator fabric is critical for the future of AI. Together, we bring extensive experience in creating large scale AI and high-performance computing solutions that are based on open-standards, efficiency and robust ecosystem support. AMD is committed to contributing our expertise, technologies and capabilities to the group as well as other open industry efforts to advance all aspects of AI technology and solidify an open AI ecosystem." - Forrest Norrod, executive vice president and general manager, Data Center Solutions Group, AMD
"Broadcom is proud to be one of the founding members of the UALink Consortium, building upon our long-term commitment to increase large-scale AI technology implementation into data centers. It is critical to support an open ecosystem collaboration to enable scale-up networks with a variety of high-speed and low-latency solutions." - Jas Tremblay, vice president and general manager of the Data Center Solutions Group, Broadcom
"Ultra-high performance interconnects are becoming increasingly important as AI workloads continue to grow in size and scope. Together, we are committed to developing the UALink which will be a scalable and open solution available to help overcome some of the challenges with building AI supercomputers." - Martin Lund, Executive Vice President, Common Hardware Group, Cisco
"Open standards are important to HPE as we innovate in supercomputing and increase access to systems. As a founding member of the UALink industry consortium, we look forward to contributing our expertise in high performance networking and systems, and collaborating to develop a new open standard for accelerator interconnects for the next generation of supercomputing." - Trish Damkroger, senior vice president and general manager, HPC & AI Infrastructure Solutions, HPE
"UALink is an important milestone for the advancement of Artificial Intelligence computing. Intel is proud to co-lead this new technology and bring our expertise in creating an open, dynamic AI ecosystem. As a founding member of this new consortium, we look forward to a new wave of industry innovation and customer value delivered though the UALink standard. This initiative extends Intel's commitment to AI connectivity innovation that includes leadership roles in the Ultra Ethernet Consortium and other standards bodies." - Sachin Katti, SVP & GM, Network and Edge Group, Intel Corporation
"In a very short period of time, the technology industry has embraced challenges that AI and HPC have uncovered. Interconnecting accelerators like GPUs requires a holistic perspective when seeking to improve efficiencies and performance. At UEC, we believe that UALink's scale-up approach to solving pod cluster issues complements our own scale-out protocol, and we are looking forward to collaborating together on creating an open, ecosystem-friendly, industry-wide solution that addresses both kinds of needs in the future." - J Metz, Ph.D., Chair, Ultra Ethernet Consortium
Called the Ultra Accelerator Link (UALink), this initial group will define and establish an open industry standard that will enable AI accelerators to communicate more effectively. By creating an interconnect based upon open standards, UALink will enable system OEMs, IT professionals and system integrators to create a pathway for easier integration, greater flexibility and scalability of their AI-connected data centers.
**Driving Scale-Up for AI Workloads**
As the demand for AI compute grows, it is critical to have a robust, low-latency and efficient scale-up network that can easily add computing resources to a single instance. Creating an open, industry standard specification for scale-up capabilities will help to establish an open and high-performance environment for AI workloads, providing the highest performance possible.
This is where UALink and an industry specification becomes critical to standardize the interface for AI and Machine Learning, HPC, and Cloud applications for the next generation of AI data centers and implementations. The group will develop a specification to define a high-speed, low-latency interconnect for scale-up communications between accelerators and switches in AI computing pods.
The 1.0 specification will enable the connection of up to 1,024 accelerators within an AI computing pod and allow for direct loads and stores between the memory attached to accelerators, such as GPUs, in the pod. The UALink Promoter Group has formed the UALink Consortium and expects it to be incorporated in Q3 of 2024. The 1.0 specification is expected to be available in Q3 of 2024 and made available to companies that join the Ultra Accelerator Link (UALink) Consortium.
**About Ultra Accelerator Link**
Ultra Accelerator Link (UALink) is a high-speed accelerator interconnect technology that advances next-generation AI/ML cluster performance. AMD, Broadcom, Cisco, Google, HPE, Intel, Meta and Microsoft are forming an open industry standard body to develop technical specifications that facilitate breakthrough performance for emerging usage models while supporting an open ecosystem for data center accelerators.
**Supporting Quotes**
"The work being done by the companies in UALink to create an open, high performance and scalable accelerator fabric is critical for the future of AI. Together, we bring extensive experience in creating large scale AI and high-performance computing solutions that are based on open-standards, efficiency and robust ecosystem support. AMD is committed to contributing our expertise, technologies and capabilities to the group as well as other open industry efforts to advance all aspects of AI technology and solidify an open AI ecosystem." - Forrest Norrod, executive vice president and general manager, Data Center Solutions Group, AMD
"Broadcom is proud to be one of the founding members of the UALink Consortium, building upon our long-term commitment to increase large-scale AI technology implementation into data centers. It is critical to support an open ecosystem collaboration to enable scale-up networks with a variety of high-speed and low-latency solutions." - Jas Tremblay, vice president and general manager of the Data Center Solutions Group, Broadcom
"Ultra-high performance interconnects are becoming increasingly important as AI workloads continue to grow in size and scope. Together, we are committed to developing the UALink which will be a scalable and open solution available to help overcome some of the challenges with building AI supercomputers." - Martin Lund, Executive Vice President, Common Hardware Group, Cisco
"Open standards are important to HPE as we innovate in supercomputing and increase access to systems. As a founding member of the UALink industry consortium, we look forward to contributing our expertise in high performance networking and systems, and collaborating to develop a new open standard for accelerator interconnects for the next generation of supercomputing." - Trish Damkroger, senior vice president and general manager, HPC & AI Infrastructure Solutions, HPE
"UALink is an important milestone for the advancement of Artificial Intelligence computing. Intel is proud to co-lead this new technology and bring our expertise in creating an open, dynamic AI ecosystem. As a founding member of this new consortium, we look forward to a new wave of industry innovation and customer value delivered though the UALink standard. This initiative extends Intel's commitment to AI connectivity innovation that includes leadership roles in the Ultra Ethernet Consortium and other standards bodies." - Sachin Katti, SVP & GM, Network and Edge Group, Intel Corporation
"In a very short period of time, the technology industry has embraced challenges that AI and HPC have uncovered. Interconnecting accelerators like GPUs requires a holistic perspective when seeking to improve efficiencies and performance. At UEC, we believe that UALink's scale-up approach to solving pod cluster issues complements our own scale-out protocol, and we are looking forward to collaborating together on creating an open, ecosystem-friendly, industry-wide solution that addresses both kinds of needs in the future." - J Metz, Ph.D., Chair, Ultra Ethernet Consortium
17 Commentson AMD, Broadcom, Cisco, Google, HPE, Intel, Meta and Microsoft Form Ultra Accelerator Link (UALink) Promoter Group to Combat NVIDIA NVLink
InfiniBand is more of an off-the-board communication protocol for supercomputers. Its pretty different than NVLink / UPI / Infinity Fabric.
The title should read:
"Listed companies finally understood open standards benefit everyone. Only after they've been s****** over by someone elses dominiting design".
Doesn't mean they won't do the same as nVidia in the future. Of course they will.
Another thing is many of these companies have huge data centers and cost savings is very important for them.
Edit: picture implies the answer is "Yes."
Meta and Microsoft to buy AMD's new AI chip as alternative to Nvidia (cnbc.com)
If only they did the same thing and embraced FSR and ROCm and pushed them so we would be free of the other Ngreedia lock-in techs.
The big players and real money owners (Meta, Google, Microsoft, Tesla, Oracle, etc.) who support Nvidia's market control practices with proprietary technologies. It's funny that they say something like that now.
It's not laughable, it's business as usual.
extremely jealousabout success of NVIDIA. All These companies, unfortunately for them, missed a GPU-train. AMD and Intel could be considered as an exception but both failed to compete with NVIDIA.
Ben Dover
Betty Humpter
I touch myself