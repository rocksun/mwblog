Strap in, the AI revolution has hit overdrive!!!
Except, of course, that it hasn’t, and it won’t anytime soon, despite what you’ve read in countless breathless editorials. It’s not that AI isn’t important, or that it doesn’t have the potential to change everything. It is and it does, but it’s simply not going to happen as fast as we think.
The reason is people. It’s always people.
## The hubris of forecasts
*The Wall Street Journal* columnist Christopher Mims reminds us of this in [his latest column](https://www.wsj.com/tech/personal-tech/what-i-got-wrong-in-a-decade-of-predicting-the-future-of-tech-06420bba). He says that we all fall prey to the “all-too-common error of technological determinism—the fallacy that all it takes for the next big thing to transform our lives is for it to be invented.”
I think back to articles I’ve written about
[how the desktop is dead](https://asay.blogspot.com/2005/09/commentary-desktop-is-dead.html?m=1) (because why wouldn’t we just use our smartphones for everything?), or how Linux was going to completely eradicate Windows. I suspect I’ve gotten more things wrong than right, at least in terms of big forecasts about the future.
The problem with that future is that people live there, and we slow things down.
Mims says, “What’s most often holding back mass adoption of a technology is our humanity” because “a new technology has to fit with the quirky, unpredictable, and far-from-rational set of predilections, needs, and biases resident in all of us.” Stop by any enterprise these days and they’ll
*all* tell you that they’re “data driven” and operate on “actionable insights” from that data. Meanwhile, in the real world, we tend to be data driven right up until the data conflicts with our gut instinct, which [studies have uncovered for years](https://www.techrepublic.com/article/85-of-big-data-projects-fail-but-your-developers-can-help-yours-succeed/).
This past week
[Jan Lieke quit OpenAI](https://x.com/janleike/status/1791498187313963308) because, among other things, he worried that “safety culture and processes have taken a back seat to shiny products” at OpenAI, even as risks loom large. “Building smarter-than-human machines is an inherently dangerous endeavor,” he warns. Those of us who have used OpenAI’s ChatGPT recently can perhaps share some words of comfort: Don’t worry. We’re nowhere near artificial general intelligence (AGI) whereby machines are capable of real thought. And even if we were, we’re decades away from a world where people trust AI enough to let it do much of anything for us. Heck, most of us will barely allow AI-powered voice assistants like Siri or Alexa to do much more than set cooking timers for us.
Those who worry the machines are going to take over soon should spend more time with people. People slow things down. That’s also probably a key factor behind Mims’ first point: Disruption is overrated.
## Slow revolutions
As Mims notes, “The most-worshiped idol in all of tech—the notion that any sufficiently nimble upstart can defeat bigger, slower, sclerotic competitors—has proved to be a false one.” I have spent decades arguing that open source was going to topple proprietary software (it hasn’t) and that this or that startup
[would up-end big tech](https://www.infoworld.com/article/3056637/nosql-chips-away-at-oracle-ibm-and-microsoft-dominance.html) (they haven’t). Yes, we’ve seen real change in things like the database market, but never at the speed that I and others have hoped or expected.
Again, the reason is people.
Also, the processes behind those people. Within enterprise IT, for example, change happens slowly because every technology decision is ultimately a people decision. For example, we can write all the blogs we want about how devops has merged development and operations, but it’s still true that most enterprises, most of the time, have different teams performing these tasks. We can talk about the end of various programming languages (Cobol!), but so long as applications run on that code, there’s going to be someone employed to maintain the system—forever.
Consider the reality that AWS is now a $100 billion-a-year business but still a rounding error in the overall IT market. Cloud represents hundreds of millions of IT spend, yet the vast majority of enterprise IT dollars service on-premises workloads. That’s changing, but slowly. Why? Because people implemented those on-premises applications and will continue to maintain them for many years. Next time you think AI will change things overnight, remember that cloud kicked off with the launch of AWS in 2006, yet here we are 18 years later, and most applications are still on-premises.
All of which is not to say that things like AI aren’t changing the world. They are. But the speed of that change takes time because people are involved. That’s not bad. It’s just a matter of making technology work for humanity.