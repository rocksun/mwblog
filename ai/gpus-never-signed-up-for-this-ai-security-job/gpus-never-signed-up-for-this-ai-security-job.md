<!--
title: GPU：AI安全防线上的错位英雄
cover: https://cdn.thenewstack.io/media/2025/09/2a7905f1-gpus.jpg
summary: GPU 在 AI 领域至关重要，但其安全措施落后于 CPU。与 CPU 相比，GPU 缺乏权限分离、虚拟内存和运行时可观测性等保护措施，这在多租户环境中构成风险。企业需认识到 GPU 架构的局限性，并开发保护 AI 基础设施所需的措施。
-->

GPU 在 AI 领域至关重要，但其安全措施落后于 CPU。与 CPU 相比，GPU 缺乏权限分离、虚拟内存和运行时可观测性等保护措施，这在多租户环境中构成风险。企业需认识到 GPU 架构的局限性，并开发保护 AI 基础设施所需的措施。

> 译自：[GPUs Never Signed Up for This AI Security Job](https://thenewstack.io/gpus-never-signed-up-for-this-ai-security-job/)
> 
> 作者：Jed Salazar

AI 正在飞速发展，重塑软件模式、商业模式和基础设施。但有一块关键硬件却难以跟上步伐。曾经在“Quake III Arena”等游戏中为我们带来逼真阴影效果，在“Counter-Strike”中带来流畅运动效果的 GPU，现在正在为机器学习 (ML) 和云 AI 平台提供动力。最初旨在高速渲染像素和光照效果，[GPU 擅长并行处理](https://thenewstack.io/the-critical-role-of-gpu-data-orchestration-in-ai-success/)。这使得它们非常适合沉浸式游戏，现在也使得它们成为神经网络的必需品。

但 [GPU 安全](https://thenewstack.io/ai-clouds-are-flying-blind-the-illusion-of-runtime-protection/) 却没有跟上步伐。

虽然 CPU 已经发展到包含诸如权限分离、虚拟内存和运行时可观测性等保护措施，但 GPU 仍然停留在为受信任的单用户环境构建的设计理念中。这种不匹配在现代基础设施中造成了危险的盲点。今年 6 月，[Wiz 披露了另一个 GPU 隔离缺陷](https://www.wiz.io/blog/nvidia-ai-vulnerability-cve-2025-23266-nvidiascape)，进一步强调了 GPU 缺乏基本的多租户安全措施。这些处理器从未被设计为[在工作负载之间强制执行严格的边界](https://thenewstack.io/what-we-wish-we-knew-about-container-security/)，也无法支持现代 [AI 安全](https://thenewstack.io/ai-security-needs-better-infrastructure-not-more-tools/) 所需的遥测和可审计性。

然而，现在 GPU 被部署在共享的、高风险的环境中，就好像它们是加固的基础设施一样。这种错误的信心正是使这种新兴威胁如此紧迫的原因。

## **GPU 和 CPU 的构建目的截然不同**

CPU 的制造商们花费了数十年时间来开发保护措施，包括权限级别、虚拟内存、进程隔离和可观测性。GPU 设计仍然基于为单用户、单用途环境所做的假设。GPU 从来没有打算在工作负载之间共享，也没有打算保护一个客户的数据免受另一个客户的侵害。

在架构层面上，GPU 和 CPU 完全不同。CPU 专为通用计算而构建，对执行和内存具有强大的控制能力。它们通过少量内核处理各种任务，每个内核都能够在进程之间切换，并通过虚拟内存和严格的权限级别来保持隔离。

[GPU 针对吞吐量进行了优化](https://thenewstack.io/revolutionizing-storage-the-role-of-gpus-in-modern-infrastructure/)。它们包含数千个简单的内核，旨在跨大型数据集执行相同的指令。这使得它们非常适合渲染和矩阵数学，但也引入了上下文切换和内存隔离方面的盲点。一个工作负载的内存可能在其结束后很长时间仍然存在，这在共享环境中会构成风险。如果没有页表、内存随机化或系统调用边界，GPU 的暴露程度会比 CPU 高。

GPU 安全问题传统上侧重于这种隔离的缺失。许多编程模型都假设驱动程序可以安全地管理内存，并且用户是受信任的。这种假设在云中是不成立的。一个容器或虚拟机 (VM) 可能会留下数据痕迹，而另一个容器或虚拟机可能会访问这些数据。GPU 执行的不透明性加剧了这些风险。没有成熟的工具来进行运行时检查或行为审计，这限制了可见性和控制。

## **更多隐藏的风险和安全的错觉**

虽然这些传统问题仍然存在，但更深层次的故事更加紧迫。企业正在将 AI 工作负载部署到 GPU 加速集群中，同时假设 CPU 隔离模型仍然适用。但事实并非如此。

首先，GPU 驱动程序代表着一个巨大的攻击面。这些驱动程序通常以提升的权限运行，并管理跨工作负载的硬件访问。单个漏洞可能会危及主机系统。与 CPU 的驱动程序更小且通常由操作系统抽象不同，GPU 驱动程序直接处理调度、内存和指令分派。它们庞大、复杂且通常是专有的，因此难以审计和修补。

其次，来自 GPU 的遥测数据有限。大多数工具报告利用率和内存吞吐量等性能指标，而不是行为信号。没有等效的系统调用跟踪或内核审计。恶意活动（例如密钥泄露或数据抓取）可能完全发生在 GPU 内核中，并且仍然不可见。

第三，共享 GPU 在多租户环境中造成盲点。工作负载通常背靠背运行，不能强烈保证一个租户的数据不会暴露给另一个租户。认为 GPU 只运行无害数学运算的观点掩盖了这样一个事实，即这种数学运算通常包括敏感的嵌入、权重和令牌。随着 AI 系统变得越来越复杂，临时存在于 GPU 上的数据的价值也会增加。忽视这些风险只会延缓针对这些漏洞的真实攻击的出现。

## **Linux 和容器教会了我们关于成长的什么**

Linux 从未被设计为保护在云环境中运行的数十亿个容器。它最初是一个通用操作系统，旨在用于单台机器和受信任的用户。随着它成为现代基础设施的支柱，围绕隔离、可见性和多租户的假设不再成立。随之而来的是安全工具的快速发展，包括命名空间、cgroups、seccomp 和高级可观测性。生态系统不得不在最初并非旨在承担云负担的内核周围构建保护层。

GPU 也出现了同样的模式。这些处理器是为了渲染图形和加速本地计算而创建的，而不是在共享硬件上运行来自多个租户的敏感 AI 工作负载。然而，这正是现在对它们的期望。就像早期容器时代的 Linux 一样，GPU 的架构还没有赶上现代使用需求。我们越早认识到这一差距，就能越早开发出保护 AI 基础设施所需的保护措施。否则，我们将继续加速发展，而没有避免后果所需的保障措施。

如果您不了解 GPU 级别发生的事情，您真的可以信任您的 AI 安全态势吗？