
<!--
title: AI即将来到边缘，但它看起来会有所不同
cover: https://cdn.thenewstack.io/media/2025/03/03da3105-ai-edge.jpg
summary: 边缘AI来袭！企业如何抓住机遇？文章剖析边缘计算优势：低延迟、高安全、高效数据处理。关注SLM在边缘的角色，NVIDIA等专用芯片，及ZEDEDA等平台如何助力企业部署AI，应对资源限制挑战，构建气隙模型，迎接超大规模边缘计算市场爆发！
-->

边缘AI来袭！企业如何抓住机遇？文章剖析边缘计算优势：低延迟、高安全、高效数据处理。关注SLM在边缘的角色，NVIDIA等专用芯片，及ZEDEDA等平台如何助力企业部署AI，应对资源限制挑战，构建气隙模型，迎接超大规模边缘计算市场爆发！

> 译自：[AI Is Coming to the Edge, but It Will Look Different](https://thenewstack.io/ai-is-coming-to-the-edge-but-it-will-look-different/)
> 
> 作者：Damir Mujezinovic

首批可用的 AI 程序大约在 70 年前开发出来，但直到 ChatGPT 等基于云的工具进入市场，AI 才真正开始引起商业界和公众的想象。

2024 年，麦肯锡报告称，[72% 的企业](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai)已经采用了 AI。到 2025 年初，该分析公司发现，在未来三年内，[92% 的公司](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)计划增加其 AI 投资，其中许多公司都在寻求从 AI 预计带来的 4.4 万亿美元的生产力增长中分一杯羹。这些数据点表明 AI 已经变得多么普遍——但挑战依然存在，从[数据泄露](https://thenewstack.io/llm-integration-pitfalls-protecting-sensitive-data-in-the-ai-age/)的风险、对供应商锁定的担忧、对基础设施的有限控制，到数据传输速度的问题。

边缘 AI 以一种完全不同的方法实现许多相同的目标：在更靠近数据源的地方处理数据，而不是使用遥远的云服务器。

但是，在更靠近数据生成地点处理数据如何改变 AI 的运作方式，哪些行业将从这种方法中受益最多？[小型语言模型](https://thenewstack.io/the-rise-of-small-language-models/) (SLM) 将在边缘发挥什么作用？在本文中，我将探讨在边缘部署 AI 的主要优势和潜在缺点，以及对可能影响其未来采用的新兴趋势的专家分析。

## 在边缘部署 AI 的主要优势

当通过[边缘计算](https://thenewstack.io/edge-computing/what-is-edge-computing/)将数据处理移到更靠近源头的位置时，会产生四个主要优势：改进的连接性、减少的延迟、更高效的数据处理和更好的安全性。

**1. 更好的连接性**

当 AI 部署在边缘时，连接性很少成为问题，正是因为数据处理在更靠近源头的地方进行，从而减少了对互联网带宽的依赖以及与云持续通信的需求。

**2. 减少的延迟**

由于边缘 AI 在更靠近源头的地方处理数据，因此响应时间大大缩短，这在快速决策可能对效率和安全产生重大影响时至关重要。

**3. 更高效的数据处理**

对于处理大量数据的组织来说，在许多情况下，边缘 AI 是更优越的解决方案，因为它减少了将数据传输到云和从云传输数据的需求。

通过在更靠近数据源头的地方处理数据，组织可以过滤信息并将精炼的见解发送到中央系统，而不是用无关数据淹没它们。这种类型的数据收集和处理减少了瓶颈、网络拥塞和带宽成本，同时提高了性能和效率。

**4. 改进的隐私和合规性**

Capital One 在 2019 年遭受了一次大规模的[云相关漏洞](https://cert.europa.eu/publications/threat-intelligence/threat-memo-190802-1/pdf)，暴露了超过 1 亿人的敏感信息。该银行依赖 [Amazon Web Services (AWS)](https://aws.amazon.com/?utm_content=inline+mention) 进行云存储和计算，攻击者利用这些服务来访问客户的财务和个人数据。

边缘 AI 通过在气隙或断开连接的模式下运行，在某些环境中提供了安全优势。在这种配置中，系统未连接到外部网络，从而大大降低了网络攻击和恶意软件的风险。这种方法在能源和制造业等领域尤其有价值。

## 企业如何利用边缘 AI 技术的优势

边缘管理和编排平台可以帮助企业充分利用边缘 AI，从而更轻松地支持边缘 AI 部署并更有效地实现运营目标。为了探讨这是如何运作的，我与 ZEDEDA 产品和工程高级副总裁 Padraig Stapleton 进行了交谈。

![边缘与云端的推理。](https://cdn.thenewstack.io/media/2025/03/78eb43f1-inference-edge-vs-cloud.jpeg)

边缘与云端的推理。
作为一种基于云原生软件即服务（SaaS）的边缘管理和编排平台，ZEDEDA 为在偏远地区运营的公司提供服务，例如在斯堪的纳维亚半岛、北美、中东和拉丁美洲从事石油和天然气行业的公司。它使用 ZEDEDA 的边缘计算平台在边缘设备上运行应用程序。

“这些应用程序包括传统的业务应用程序，还包括直接从边缘提取数据的机器学习应用程序，无论是在石油钻井现场还是在太阳能发电场。它们在现场处理数据，并提出建议，其速度远远快于在数据中心传输和处理数据的速度，”Stapleton 说。

Stapleton 说，安全性是 ZEDEDA 在与潜在客户的对话中首先解决的问题。“在很多情况下，我们的客户处理的是非常敏感的客户数据，他们不愿意通过互联网将其传输回云端。因此，对他们来说，推理和所有 AI 都必须在边缘完成，”他说。

降低延迟是选择边缘计算的另一个主要因素，正如 Stapleton 解释的那样：“您需要能够查看数据并在几乎实时的情况下做出决策，如果您必须将其发送回云端、进行处理并获得响应，您就无法做到这一点。”

## 在边缘部署 AI 的缺点

当然，在边缘部署 AI 也有一些缺点。它们主要与有限的计算能力和资源约束有关，这会影响处理效率，并使处理资源密集型任务具有挑战性。

“如果您在云端拥有一个 AI 模型，您通常可以更好地访问、更好地控制，并且更好地更新模型。与边缘相比，您可能拥有更大的数据集，并且您拥有更多的工具来重新训练、更新和测试模型的效率和准确性，”Stapleton 指出。

与更集中化的[云计算](https://thenewstack.io/how-to-choose-the-right-cloud-cpu-for-your-workload/)相比，在边缘部署 AI 可能是一个手动且耗时的过程。理想情况下，边缘 AI 部署应该像按下按钮一样简单。获得两全其美的一种方法是在云端开发模型并在边缘部署它，但这并不总是容易实现。

像 ZEDEDA 这样的平台可能有助于组织达到这一点，但边缘 AI 部署的固有局限性（从有限的硬件资源到可扩展性问题和数据管理挑战）不容忽视。相反，它们需要被接受和处理。

一般来说，边缘 AI 和传统云 AI 之间的选择取决于具体的用例和需求。适用于某些组织和行业的方案可能不适用于其他组织和行业。

## 新兴趋势：边缘 AI 的未来形态

到 2028 年，预计[50% 的 AI 工作负载](https://www.techopedia.com/50-percent-ai-data-computing-on-edge)将在边缘发生，高于 2023 年的 5%。与此同时，[超大规模边缘计算市场](https://www.thebusinessresearchcompany.com/report/hyperscale-edge-computing-global-market-report#:~:text=It%20will%20grow%20to%20%2419.49,autonomous%20vehicles%20and%20smart%20cities.)预计将以 34.2% 的复合年增长率增长，到 2029 年预计将达到 194.9 亿美元。

硬件开发也取得了[重大进展](https://www.microchipusa.com/industry-news/semiconductor-industry/the-intersection-of-ai-and-semiconductors-advancements-implications-and-future-opportunities/)。像 [NVIDIA 这样的公司正在创建专用芯片](https://thenewstack.io/after-deepseek-nvidia-puts-its-focus-on-inference-at-gtc/)，例如 Jetson 系列，以向更小、更节能的边缘设备提供巨大的计算能力。神经形态芯片（旨在模仿人脑中的神经网络）也正在涌现，以及硅光子技术和现场可编程门阵列 (FPGA)。

> 这种积极主动的方法有助于加强安全协议，使企业能够实时应对潜在风险。

根据 Stapleton 的说法，许多行业对边缘 AI 都有着浓厚的兴趣，尤其是在石油、天然气和制造业领域。这主要是由于制造业流程的持续数字化和自动化，公司希望使用边缘 AI 来取代以前在云端处理的手动任务和流程。

“想想通过制造过程的东西。您有一个应用程序，基本上检查小部件的尺寸、颜色、形状和密度是否正确。您希望能够当场做出决定，并检测它是否有效，”Stapleton 说。

ZEDEDA 的一些客户使用边缘 AI 和计算机视觉来验证工作场所的安全性，利用 AI 系统来监控员工是否佩戴了防护设备。例如，如果发现员工未佩戴必要的装备，系统可以检测到这一点并触发立即响应。这种积极主动的方法有助于执行安全协议，使企业能够实时解决潜在风险。

## 塑造边缘 AI 未来的两大生态系统

展望未来，有两种潜在的生态系统将塑造边缘的计算机视觉和 AI 的未来。

第一种是混合模型，其中边缘系统保持与云的连接，允许组织利用云资源来训练 AI 模型、更新它们，然后将它们部署在边缘。这提供了灵活性，因为业务应用程序往往保持静态，而运行和处理数据的模型会经常更新。

Stapleton 指出：“我们的客户希望从这种整体式架构演变，在这种架构中，应用程序和模型紧密耦合，转变为一种松散耦合的架构，并在实际更新模型的方式上具有更大的灵活性。”

第二种新兴的生态系统更以垂直领域为中心。例如，能源和关键系统领域的公司由于担心安全和数据隐私，不愿将其网络向互联网开放。这种生态系统围绕气隙解决方案展开，从而可以在安全的环境中进行本地训练和部署。

他解释说：“在这种情况下，我们正在创建一个完整的生态系统，您可以在本地解决方案中训练模型，部署这些模型，监控它们的输出，然后将所有内容反馈到一个循环中。”

这两种模型都有意义，因为它们满足了特定行业的需求。混合模型适合那些乐于利用云进行训练和模型更新并希望保持一定灵活性的组织。对于具有更明显的安全和数据隐私问题的行业来说，本地部署的[气隙模型](https://thenewstack.io/the-ultimate-guide-to-software-distribution/)可能是一个更好的选择。

## SLM 将在边缘计算中发挥的作用

SLM 很可能在边缘发挥作用，尤其是在运营技术以及制造业、石油和天然气以及汽车和运输行业。这些模型通常源自[大型语言模型 (LLM)](https://thenewstack.io/llm/)，可能会在不同的垂直领域中使用，主要侧重于在边缘提供当今不易获得的知识和专业知识。

目前，这些行业中 AI 的应用方式有些保守，机器学习确定性模型被用于计算机视觉和预测性维护。然而，随着越来越多的组织探索劳动力增强，这种情况可能在不久的将来发生变化。

Stapleton 说：“一些行业将面临劳动力老龄化的问题，或者需要在对人们来说不一定最适宜工作的地点部署设备。”

“我看到这些模型有助于增强他们的劳动力，减少对大量人工干预或在具有挑战性的地点参与的需求。针对特定垂直用例训练的 SLM 等技术将使他们能够做更多的事情，因为知识将构建到模型中以协助员工，即使在偏远环境中也是如此。我相信这是我们将在未来几年看到的另一种趋势，”他继续说道。

> 利用边缘 AI 技术的最佳方式是退后一步，确定实际用例，专注于特定的、可管理的项目，并从中推断知识。

Stapleton 认为，新的颠覆性技术大约每 10 年出现一次。在 2000 年代，是互联网；在 2010 年代，是云；现在，在 2020 年代，AI 似乎是推动各个行业进行重组的力量。

问题在于，将现实从炒作中分离出来并不总是那么容易。对于希望利用边缘 AI 技术的组织来说，最好的方法是退后一步，确定实际用例，专注于特定的、可管理的项目，并从中推断知识。ZEDEDA 在 Llama 3.1 8B 模型等模型中所做的基本上就是这样，据 Stapleton 称，它已将该模型集成到自己的内部知识共享应用程序中。

“通过这样做，我们能够创建第一个基于 LLM 的应用程序，我们正在公司内部使用它。我们将使用它作为一个模型，开始构建其他用例，无论是用于我们内部开展业务的方式，还是用于我们可以作为我们生态系统的一部分提供给客户的东西。因此，这在很大程度上是一个从小团队和一个特定用例开始，然后在此基础上积累知识，以发展这些技术在您组织中的使用的案例，”他说。

## 解决边缘的实际问题

边缘 AI 代表了企业处理数据方式的变革性转变，与传统的基于云的 AI 相比，它具有明显的优势，例如降低延迟、提高安全性以及更有效地利用带宽。

尽管如此，挑战依然存在，尤其是在资源限制和边缘 AI 管理的复杂性方面。像 ZEDEDA 这样的公司可以通过提供边缘管理解决方案来支持企业应对这些挑战，这些解决方案可以帮助促进边缘 AI 的部署和编排。

ZEDEDA 旨在消除手动流程，缩短部署时间，通过实时监控保护设备健康，简化维护和大规模部署，并通过集中式平台帮助管理分布式系统。

ZEDEDA 致力于将云体验带到边缘，努力通过可扩展且通用的平台来加速[计算机视觉](https://zededa.com/solutions/enabling-computer-vision-at-the-edge/)部署，该平台简化了管理，同时利用零信任安全模型来提供强大的保护，以抵御潜在威胁。

要了解有关 ZEDEDA 解决方案的更多信息，请[申请演示](https://zededa.com/request-a-demo/)。