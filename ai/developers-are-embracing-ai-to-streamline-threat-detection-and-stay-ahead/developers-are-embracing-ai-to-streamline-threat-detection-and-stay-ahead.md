
<!--
title: 开发者们正在拥抱AI以简化威胁检测并保持领先
cover: https://cdn.thenewstack.io/media/2025/02/0c5109a9-nubelson-fernandes-gts2w7bu3qo-unsplash-1-scaled.jpg
-->

AI 驱动的安全工具可以更快地检测威胁，同时减少开发人员的工作量。

> 译自：[Developers Are Embracing AI To Streamline Threat Detection and Stay Ahead](https://thenewstack.io/developers-are-embracing-ai-to-streamline-threat-detection-and-stay-ahead/)
> 
> 作者：Ainsley Lawrence

安全威胁的演变速度对传统的检测和响应方法提出了挑战。在许多方面，开发者是[网络安全的第一道防线](https://thenewstack.io/developers-the-first-line-of-defense-in-cybersecurity/)，为更精细的措施奠定了基础。随着开发周期加速和基础设施变得更加复杂，开发者需要先进的工具来识别和消除潜在的攻击。人工智能为安全工作流程带来了新的能力，实现了精确的威胁检测，同时[降低了开发团队的认知负荷](https://thenewstack.io/platform-engineering-reduces-cognitive-load-and-raises-developer-productivity/)。

现代安全实践需要速度和准确性——这是 AI 擅长的两个领域。集成 AI 驱动的安全工具的开发团队能够处理大量的安全数据，检测细微的攻击模式，并[自动响应新兴威胁](https://thenewstack.io/automated-threat-enrichment-an-overview/)。AI 驱动的安全工具加强了防御，同时让开发者能够专注于他们的核心任务：创建和维护高质量的应用程序。

## AI 和自动化在网络安全中的优势

AI 安全工具以人类分析师无法达到的速度处理数据，识别数百万事件中的模式和关联。该技术擅长同时扫描网络日志、API 调用和用户行为，从而发现可能表明安全漏洞的异常情况。安全运营的成功取决于[平衡](https://www.xantrion.com/article/ai-and-automation-in-cybersecurity-a-balancing-act)机器效率和人类判断，其中每个组成部分都加强了另一个。这种协同作用体现在两个关键领域：增强人类专业知识的智能模式识别和优化分析师工作负载的精确威胁评估。

现代安全工具以空前的细节分析行为模式，捕捉通常预示着新兴威胁的细微异常。先进的机器学习模型通过不断学习传入的数据来适应新的攻击媒介，从而在没有明确编程的情况下改进其检测能力。

[团队越来越依赖 AI 自动化](https://thenewstack.io/platform-teams-automate-infrastructure-requirement-gathering/)来处理重复的监控任务，而人类分析师则专注于战略决策和复杂的调查。这种伙伴关系创建了一个更有效的安全运营，其中机器擅长快速模式匹配，而人类则将上下文理解应用于潜在威胁。
AI 系统擅长通过在标记潜在威胁之前关联多个数据点来减少误报。这些工具在其完整上下文中评估安全事件，考虑时间模式、用户角色和典型工作流程行为等因素来确定风险级别。

如此高水平的精确威胁评估能够实现更有效的资源分配，因为安全团队将其专业知识集中在已验证的威胁上，而不是追逐虚假警报。[机器学习模型](https://thenewstack.io/machine-learning-models-to-predict-the-next-stranger-things/)创建了一个积极的反馈循环，其中人类的见解提高了 AI 的准确性，从而为分析师提供了越来越可靠的威胁情报。

## AI 和伦理考量

AI 安全系统会做出无数影响用户隐私、数据访问和威胁响应的决策。安全团队必须仔细考虑自动化决策对个人隐私权和组织安全需求的影响。在保护敏感检测方法的同时，保持 AI 安全运营的透明度提出了独特的挑战。负责任地实施 AI 安全工具取决于两个关键方面：为 AI 决策建立明确的责任制，并在整个安全监控过程中保护用户隐私。

当安全团队为自动化决策建立监督机制，让人类掌握主动权时，[符合伦理的 AI 就能服务于共同利益](https://onlinesoe.tufts.edu/blog/be-an-engine-for-good-in-the-age-of-ethical-ai/)。开发团队需要记录在案的流程来审查 AI 安全警报并保持对关键安全运营的人工监督。
安全架构师必须为 AI 驱动的安全决策建立透明的责任链。为此，监控系统应跟踪哪些 AI 模型标记了潜在威胁，哪些团队成员审查了警报，以及[自动化响应如何影响系统用户和运营](https://thenewstack.io/automate-routine-tasks-with-an-ad-hoc-ansible-script/)。

机器学习模型需要大量数据才能有效地进行威胁检测，这给用户和组织带来了严重的隐私问题。每次安全扫描和分析都需要在全面监控和敏感信息保护之间取得谨慎的平衡。

安全团队可以通过战略性的数据收集策略来解决隐私问题，同时保持防御能力。限制收集到必要的安全指标，并对 AI 训练数据强制执行严格的访问控制，有助于在日常操作中保护个人信息。精心设计的隐私保护措施可以在不牺牲安全有效性的前提下建立用户信任。

## 自动化威胁搜寻

AI 驱动的威胁搜寻将手动安全流程转变为系统化的检测程序。安全团队通过自动化监控和标准化搜寻程序来增强其能力，从而扩展其识别潜在漏洞的能力。[自动化搜寻计划的成功依赖于两个关键](https://thenewstack.io/crawl-walk-run-the-key-to-successful-automation/)组件：工作流程自动化和模板驱动的检测。

安全团队使用 EDR 和 SIEM 查询来[自动化跨多个平台的威胁检测](https://thenewstack.io/5-ways-to-automate-threat-hunting/)。这种集成连接了 XDR 系统，共享模板并触发工作流程，以实现跨安全工具的一致监控。

自定义工作流程会根据特定的安全事件或基于时间的计划触发自动搜索。安全平台之间的集成使团队能够关联来自不同数据源的发现，从而更全面地了解潜在威胁。

可重用的搜寻模板标准化了跨安全工具和团队的检测流程。这些模板编纂了经过验证的搜索模式和检测逻辑，使所有安全团队成员都可以使用高级搜寻技术。

安全团队根据新的威胁情报和成功的搜寻结果共享和改进模板。标准化的模板有助于保持检测方法的一致性，同时允许根据特定的环境需求和威胁配置文件进行自定义。

## 最后的想法

AI 安全工具为开发团队提供了显著的威胁检测速度和准确性优势，前提是团队实施适当的监督和隐私控制。随着检测模型通过[持续](https://thenewstack.io/continuous-improvement-metrics-for-scaling-engineering-teams/)学习和反馈得到改进，开发人员可以构建日益复杂的自动化响应，同时保持安全有效性和运营稳定性之间的关键平衡。将 AI 安全工具集成到开发工作流程中，并密切关注道德考量和系统化的威胁搜寻，使团队能够有效地应对新兴的安全挑战。
