
<!--
title: 为什么开源与人工智能的结合如此混乱
cover: https://cdn.thenewstack.io/media/2025/02/6eafc9df-state-of-opencon-panel-2.jpg
-->

即使是专家也难以将开源和人工智能完美地结合在一起，这是State of Open Con会议上的一个小组讨论中提到的。

> 译自 [Why Fitting Open Source and AI Together Is So Messy](https://thenewstack.io/why-fitting-open-source-and-ai-together-is-so-messy/)，作者 Steven J Vaughan-Nichols。

伦敦 — 在第三届年度 [State of Open Con (SOOCon25)](https://stateofopencon.com/) 的一个由领先的开源 AI 专家组成的小组讨论会上，一件事很快变得清晰：即使是专业人士也在努力拼凑开源 AI 的拼图。

主持人 [Alex Williams](https://thenewstack.io/author/alex/)，The New Stack 的创始人兼出版人，通过询问 [Sam Johnston](https://www.linkedin.com/in/samjohnston/)，[Open Source Alliance (OSA)](https://opensourcealliance.org/#link=%7B) 的创始人，来定义开放性和 AI 的含义，特别是关于成本和可重复性。

“[开源 AI] 的核心是可重复性，” Johnston 说，他的团队制作了 [Open Weight Definition (OWD)](https://openweight.org/)。“你需要所有的软件和非软件组件来重现它。”

他继续说，“如果你想改变给定输入的输出，你需要改变数据。” 当训练数据包括受版权保护的材料或在法律上不能公开分享的敏感个人信息时，这会带来独特的挑战。

这不是事实吗？“[Open Source Initiative](https://opensource.org/) 我们想直接使用传统软件的定义，但我们在开源方面遇到了麻烦，”开源安全公司 [Tidelift](https://tidelift.com/?utm_content=inline+mention) 的联合创始人兼总法律顾问 [Luis Vilas](https://www.linkedin.com/in/luisv/) 说。

“这个品牌的价值变得如此之大，以至于人们需要使用这个品牌，即使实际上没有传统意义上的源代码，或者至少源代码只是这个价值中很小的一部分。我认为这是让每个人都感到困惑的部分原因。”

的确，开源原则、AI 和数据治理的交叉点正在引发关于如何使数十年历史的框架适应现代机器学习 (ML) 系统的存在性问题。例如，Vlas 继续说，虽然开源传统上侧重于源代码，“数据行业在开放性方面的成熟度落后了 15 年……我们需要将数据专家纳入这些对话。”

另一个例子是：每个人都知道，尽管有保障措施，AI 模型仍有重复私人医疗记录或受版权保护的文本的风险，这使得传统的开放许可模式变得复杂。但是，还有许多更微妙的开放数据问题，很少有人考虑过，更不用说针对开源 AI 用途解决了。

## 对企业影响发出警报

但是，当我们担心完善 OSI 的 [Open Source AI Definition (OSAID)](https://thenewstack.io/the-open-source-ai-definition-is-out/) 时，[Amanda Brock](https://thenewstack.io/author/amanda-brock/)，[OpenUK](https://openuk.uk/) 的 CEO，并且不喜欢 OSIAD，对不断演变的立法和企业影响发出了警报。

“欧盟的 [EU’s AI Act](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai) 使用了 ‘free and open source AI’，但没有定义它……这让大公司可以通过赔偿条款和保险壁垒来声称开放性，同时保持控制，”她在小组讨论会上说。

小组中的每个人都警告说，如果没有明确的标准，只有科技巨头才能承担 AI 部署的法律风险 — 可能会形成监管护城河。例如，这就是为什么 [Meta](https://about.meta.com/?utm_content=inline+mention) 的 CEO [Mark Zuckerberg is bound and determined to define open source AI](https://www.zdnet.com/article/why-mark-zuckerberg-wants-to-redefine-open-source-so-badly/) 以他的方式。如果 Zuckerberg 发号施令，Meta 和其他 AI 巨头将受益，而其他较小的 AI 公司和组织将被冷落。

随着训练最先进的 AI 模型的成本现在达到 5 亿美元，Brock 做出了一个严峻的预测：“如果没有真正的开放性，只有美国和中国才能控制 AI 的未来……其他所有人都会被排除在外。”

前进的道路似乎需要为数据取代代码成为关键组件的时代重新发明开放性 — 赶在企业和法律力量巩固新的数字鸿沟之前。

当然，如果新的 DeepSeek 大语言模型（LLM）被证明比 Meta、Google、OpenAI 及其他科技巨头创建的 LLM 便宜数个数量级，那么一切都会改变。请继续关注。人工智能商业模式的普遍认知可能被证明是愚蠢的。

不过，开源的保护和适应之间的紧张关系贯穿于所有这些挑战。正如 Johnston 观察到的那样，“我们冒着通过相互冲突的定义，不仅破坏开源 AI，而且破坏开源本身的风险。”

与此同时，Villa 提倡灵活性：“我们需要摒弃许可证总是答案的想法……某些组件需要的治理模式超出了版权范围。”

## “开放”现在意味着什么？

简而言之，软件开发中传统的开放概念需要为 AI 系统重新定义。 小组成员指出，仅仅拥有开源代码对于 AI 来说是不够的； 用于训练模型的数据同样至关重要。 这种转变需要对 AI 系统中“开放性”的构成要素有一个新的理解。

小组成员一致认为，我们需要应对混合和合并开源原则、开放数据和 AI 技术所带来的挑战，以促进行业中更公平和更具创新性的发展。

然而，需要仔细考虑法律、伦理和实践方面的问题，以确保这些技术的益处得到广泛应用，同时保护个人权利，并防止权力集中在少数大型公司手中。

各位，请系好安全带； 我们将面临一段颠簸的旅程。
