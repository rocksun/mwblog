# 进攻性安全领域的革命：Agentic AI 的新纪元

![Featued image for: Revolutionizing Offensive Security: A New Era With Agentic AI](https://cdn.thenewstack.io/media/2025/02/687c35ee-testing123-1024x576.png)

回顾过去十年[安全领域](https://thenewstack.io/security/)的发展，我对安全升级到现代 DevOps、CI/CD 和云实践所做的出色工作感到无比钦佩和自豪。但仔细观察后，我发现进攻性安全（[渗透测试](https://thenewstack.io/introduction-to-software-testing/)、红队演练、道德黑客），长期以来被认为是发现具有业务影响的真正可利用漏洞的最有效方法之一，实际上还停留在远古时代。

它几乎完全是手动的，主要以服务而非产品的形式提供。虽然我们今天所知的这些服务可以提供有价值的见解，但它们也受到以下问题的困扰：

- 时间点
- 昂贵
- 难以扩展

大多数进攻性安全服务侧重于数量而非质量，通常依赖于初级测试人员或外包团队。对于试图[跟上快速发展](https://thenewstack.io/ai-is-evolving-rapidly-heres-how-developers-can-keep-pace/)的威胁形势的企业来说，目前的方法还远远不够。

**产品化进攻性安全的局限性**

进攻性安全的内在价值在于能够摆脱管理数百万未经证实的漏洞，而只关注那些真正可利用且可能对业务产生实际影响的漏洞。这是最终的现实检验。

没有猜测或理论上的风险管理。进攻性安全会准确地告诉你，如果攻击者今天以你的业务为目标，他们可能会取得什么成果。

以基础设施为中心的进攻性安全工具在自动化网络渗透测试方面取得了进展，但对于 Web 应用程序和其他面向客户的资产，产品化解决方案始终无法满足需求。

这又回到了每个系统和领域中众所周知的最后一英里问题，无论是 DevOps、DevSecOps 还是 AppSec。这是因为每个应用程序都不同，每个企业都面临着独特的风险，而历史上不可能复制导航这些细微差别所需的人类般的推理能力。工具最终依赖于硬编码的用例，这些用例是肤浅的，并且主要迎合了最低的共同点。但对于现代系统和应用程序的复杂性而言，根本没有一种万能的方法。

这反映了 DAST（动态应用程序安全测试）类别的失败，该类别难以提供深度、适应独特的场景或提供可操作的后续步骤。

结果呢？

公司仍然依赖于进攻性安全服务，不是因为他们想这样做，而是因为他们不得不这样做。无论是为了 SOC2 等合规性要求、面向客户的报告，还是为了更深入地了解可利用的漏洞，都没有可行的替代方案。

**为什么进攻性安全会失效**

如前所述，一些已知的进攻性[安全](https://thenewstack.io/security-testing-must-be-part-of-software-development-life-cycle/)限制被转移到渗透测试的自动化变体中，而这些变体根本经不起时间的考验。

这些包括：

**时间点评估**：渗透测试提供了一个快照，但任何新版本、功能或更新都会使结果过时。

**可扩展性问题**：高质量的渗透测试成本高昂，而且经验丰富的专业人员的稀缺使得扩展这些服务变得不切实际。

**缺乏真正的价值**：许多服务的运作方式类似于工厂，优先考虑吞吐量而不是量身定制的见解。初级测试人员和外包工作很常见，这会降低发现的深度和质量。

**合规性高于安全性**：通常，进攻性安全被视为审计的勾选框练习，而不是真正改善组织防御的工具。

**游戏规则改变者：惊喜……Agentic AI**

多年来，进攻性安全的艺术一直由人类的创造力来定义，这是一把双刃剑。虽然这有助于进攻性安全的情境感知思维、适应性推理以及模拟攻击者心态的能力，从而使这些服务如此有效，但最终它变得难以扩展。

然后，生成式 AI (GenAI) 出现了，它改变了许多领域。安全也不例外。

随着[大型语言模型 (LLM)](https://roadmap.sh/guides/introduction-to-llms)的兴起，我们进入了一个机器可以以模仿甚至超越人类智能的方式进行思考、推理和适应的时代。这种转变开启了新的可能性。

借助 Agentic AI，我们已经能够大规模地复制最佳进攻性安全专业人员的深度、创造力和适应性。
**进攻性安全在哪些方面可以分解 Agentic AI 的步骤**

如果我们审视人类和自动化进攻性安全方面的局限性，我们就会开始对 agentic AI 带来的范式转变感到兴奋。

以前该领域不可能实现的功能已经出现。它具有以下特点：

**持续性**：不再是过时的即时快照。持续测试与您的系统和应用程序一同发展。
**上下文感知**：与传统工具不同，agentic AI 了解每个应用程序的独特结构、逻辑和业务环境，以及每个企业面临的独特风险。
**可操作性**：它不会用大量无法管理的漏洞积压来压垮团队，而是提供一份简短的、优先排序的、具有实际业务影响的可利用问题列表。
这不仅仅是合规驱动的安全，而是真实的保护。

**没那么快。还有工作要做**

需要明确的是：这项技术还不完善。LLM 可能会产生幻觉，它们的输出并不总是确定性的，并且监管问题仍然悬而未决。这就是为什么人为因素仍然至关重要，并且（尚未）可以完全被机器取代。

通过将 AI 与人工监督相结合，我们可以实现两全其美。这种未来主义的进攻性安全会是什么样子？智能、学习、自适应的 LLM 与以下各项相结合：

- 值得信赖的专业人员，他们确保测试是安全且非破坏性的。
- 专家，他们验证发现结果，提供可操作的见解并指导补救工作。
- 合规性报告，其中包含人工问责制的保证。

这种混合模型弥合了 AI 驱动的可扩展性与企业所依赖的、并且尚未准备好完全放弃的（并且有充分的理由！）值得信赖的专业知识之间的差距。

**进攻性安全的未来**

随着越来越多的法规、标准和其他繁文缛节，安全常常变得以合规性为导向，而不是实用。

网络安全的未来不是关于被动防御或合规驱动的测试。而是关于真正主动、智能和可扩展的保护。进攻性安全一直是了解风险的最有效方法，但直到现在，它的实施过于繁琐，使得许多企业无法充分利用它并遥不可及。

Agentic AI 的定位是彻底重置该领域。通过将日益成熟的新技术与值得信赖的人工专业知识相结合，我们正在努力使数字世界对每个人都更安全。

[
YOUTUBE.COM/THENEWSTACK
技术发展迅速，不要错过任何一集。订阅我们的 YouTube
频道，即可观看我们所有的播客、访谈、演示等。
](https://youtube.com/thenewstack?sub_confirmation=1)