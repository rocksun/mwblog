Most AI coding agents use similar large language models (LLMs) under the hood. Where they differentiate is in their context engineering. Early on, agents focused on adding the right parts of a project’s codebase into their ever-expanding context windows or by using Retrieval-Augmented Generation (RAG). But those techniques have their limits, and with their sole focus on the codebase, they do miss out on much of the additional context that engineers generate in tools like GitHub, [GitLab](https://about.gitlab.com/?utm_content=inline+mention) and Bitbucket.

With [Qodo Aware](https://www.qodo.ai/products/qodo-aware/), Qodo aims to bring enhanced context awareness to virtually any agentic coding tool, no matter whether that’s Qodo itself of a coding agent like Claude Code that can access the service through a Model Context Protocol (MCP) server.

Qodo Aware features three main agents. The first is for context retrieval and uses semantic search (across multiple repositories, if needed) to find relevant code snippets for a given task. The second is called Deep Research, and as the name implies, it is meant to answer complex queries about a codebase by analyzing the code structure. Deep issues, the third agent, focuses on looking at code diffs and analyzing breaking changes.

[![](https://cdn.thenewstack.io/media/2025/09/baad05c7-qodo-aware.jpeg)](https://cdn.thenewstack.io/media/2025/09/baad05c7-qodo-aware.jpeg)

Image credit: Qodo.

There’s also a free open source version of this, [Open Aware](https://github.com/qodo-ai/open-aware), that indexes popular open source libraries.

As Qodo CEO and co-founder [Itamar Friedman](https://www.linkedin.com/in/itamarf/) told me, as the team built its code quality agents, it quickly realized that having access to the codebase alone wasn’t enough to get the best results. What these systems were missing, he argued, was a “second brain” where all of the context was aggregated and stored.

“The thing is, we need reasoning on that 1 million [token] context, and so the idea is twofold. One, even if you do want to exploit that context, reorganizing and serving that context in an organized way to the LLM is very critical,” he said. “There is a difference between just shoving everything unorganized into the context, and doing a proper prompt engineering where you’re saying: Hey, this is the code. It’s connected to that. And here is the relevant comment that is relevant for this. … And the second thing: Even then, you want to make sure that you’re providing the most relevant context and not providing it with too much context either.”

[![](https://cdn.thenewstack.io/media/2025/09/30f8b913-qodo-aware-1.jpeg)](https://cdn.thenewstack.io/media/2025/09/30f8b913-qodo-aware-1.jpeg)

Image credit: Qodo.

The code itself is the basis for this context, but what Qodo Aware can now pull in is how that code came to be, which can add useful information around how a bug came to be (and how to fix it). That may be encapsulated in the discussions around a pull request in GitHub and other metadata, for example. Friedman acknowledged that not all of these discussions happen in pull requests, so the team is also looking at adding additional sources, including emails and chat messages, over time.

One interesting architectural decision the team made is that it pre-processes all of the context data, making it faster and more efficient for the agents to recall this data and use it for any given task. (Friedman likened this to training LLMs.)

In Qodo’s benchmarks, this system, which uses a combination of the [Language Server Protocol](https://microsoft.github.io/language-server-protocol/) (LSP), knowledge graphs and vector embeddings, easily beats coding agents like OpenAI’s Codex, Claude Code and  [Google](https://cloud.google.com/?utm_content=inline+mention)‘s Gemini CLI when it comes to code comprehension and retrieval accuracy.

[![](https://cdn.thenewstack.io/media/2025/09/206b4982-qodo-benchmark.jpeg)](https://cdn.thenewstack.io/media/2025/09/206b4982-qodo-benchmark.jpeg)

Image credit: Qodo.

Friedman noted that he agrees with the likes of Anthropic CEO and co-founder [Dario Amodei](https://www.linkedin.com/in/dario-amodei-3934934/) and OpenAI CEO [Sam Altman](https://x.com/sama) that in a few years from now, the vast majority of code will be generated by AI. But to be able to trust this code, the focus has to be on quality and review — and it will take a new generation of tools to do so. Unsurprisingly, Qodo plans to launch additional expert agents to help with code reviews, too. He also believes that while the terminal and IDE work well for generating code, the user interface paradigm will shift as developers interact more with agents than the code itself.

“There’s a new paradigm of how this needs to look — and that’s what we’ve been working on for a while,” he said. In his view, this means going from an integrated development experience to what he called a “review development experience.” The company plans to say more about this new experience in the coming months.

[YOUTUBE.COM/THENEWSTACK

Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.

SUBSCRIBE](https://youtube.com/thenewstack?sub_confirmation=1)

Group
Created with Sketch.

[![](https://thenewstack.io/wp-content/uploads/2025/03/15a7eb12-cropped-4e88ac40-frederic-profile-2-600x600.jpg)

Before joining The New Stack as its senior editor for AI, Frederic was the enterprise editor at TechCrunch, where he covered everything from the rise of the cloud and the earliest days of Kubernetes to the advent of quantum computing....

Read more from Frederic Lardinois](https://thenewstack.io/author/frederic-lardinois/)