<!--
title: 构建基于事件的GenAI应用
cover: https://cdn.thenewstack.io/media/2023/12/3763b70d-chatbot-1024x498.jpg
-->

将GenAI应用推向市场最终需要一个通用的运营模式和数据集成平台。

> 译自 [4 Steps for Building Event-Driven GenAI Applications](https://thenewstack.io/4-steps-for-building-event-driven-genai-applications/)，作者 Andrew Sellers 领导 Confluent 的技术战略团队，支持战略发展、竞争分析和思想领导力。他曾以技术领导者的身份将几个基于 AI 的商业产品推向市场。他是十几项与机器学习和企业数据相关的专利的共同发明人。

我从事人工智能工作近 20 年，应用的技术涵盖预测建模、知识工程和符号推理。AI 的巨大潜力一直感觉十分明显，但其广泛应用似乎总是还有几年才能到来。然而，以当前的生成式 AI(GenAI)技术作为体现，这一次感觉不同。

过去的一个重大障碍是，设计和训练模型需要非常稀缺的专业知识。现在，我们有了像 [LLM](https://www.techtarget.com/whatis/definition/large-language-model-LLM) 这样为 GenAI 提供动力的基础模型，这些模型是可复用和通用的，使得这项技术的应用比以往任何时候都更加民主化。

全球各地的公司正在尝试构建 GenAI 驱动的应用和工具，以提高效率和创新。[IDC 的新预测显示](https://www.idc.com/getdoc.jsp?containerId=prUS51310423)，面向 GenAI 的支出将在 2023 年达到 159 亿美元。但这些投资不会像过去的 AI 迭代那样只让少数公司受益。

虽然使用[零样本学习或小样本学习](https://www.techopedia.com/definition/34949/zero-shot-one-shot-few-shot-learning)来构建基于 GenAI 的应用程序的方法前景广阔，可以生成更好的输出，但大多数非平凡的用例都需要使用[模型训练时](https://roadmap.sh/guides/free-resources-to-learn-llms)不可用的特定领域的数据来[建立提示的上下文](https://www.confluent.io/blog/chatgpt-and-streaming-data-for-real-time-generative-ai/)。从语义搜索到推荐引擎，GenAI 应用程序大多数有价值的用例都需要将提示与相关、及时和准确的企业数据配对，以生成可用的输出，通常应用一种常称为[检索增强生成(RAG)](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)的模式。

构建这些数据驱动的 GenAI 应用需要开发跨越多项技能的复杂应用程序。此外，目标不是构建单一的基于 GenAI 的应用程序。要真正使 GenAI 转变您的业务，您的团队将随着时间推移交付成十上百的专门应用程序，这些应用程序可能使用相同的基础模型，但从企业中的不同真实来源中提取数据。

大多数现代企业会发现构建和部署基于 AI 的应用程序具有挑战性，因为它们的数据被锁定在孤立的、异构的操作数据存储中。最终，推出 GenAI 应用程序到市场需要一个通用的操作模式和数据集成平台。

根据我们团队与数百名正在构建 GenAI 应用程序的客户的讨论获得的见解，我们发现构建 GenAI 应用程序的最佳方式是采用[事件驱动模式](https://thenewstack.io/the-rise-of-event-driven-architecture/)。我们确定了这些应用程序往往具有的四个一般步骤。接下来我们将描述，每一步最好以事件驱动的应用程序来实现。

## 使用事件流构建 LLM 驱动应用程序的关键步骤

LLM 驱动的应用程序通常有四个步骤：数据增强、推理、工作流和后处理。对每个步骤采用事件驱动方法可大大简化开发和运营。

我们来看看:

### 步骤 1. 数据增强

此步骤通过诸如以下活动准备数据以建立 LLM 查询的上下文:

- **分块**，其中将数据分割成语义上有意义的碎片
- 创建**嵌入**，这是保留含义和关系的信息的数学表示，使 AI 模型能够理解和推理否则仅供人类消费的信息
- 存储在**向量存储**中用于检索支持大型语言模型(LLM)所需的高维向量表示

此步骤使用源连接器或本机集成的帮助，从企业中的各种运营数据源(例如 Amazon S3 和 Salesforce)中提取非结构化数据，然后将非结构化数据嵌入组织到向量存储中，然后可以将其设计成提示。我们利用数据流传递实时整合企业异构运营数据的优势之一，进行可靠的信任使用。

采用事件驱动方法的好处是，运营数据存储中的更改与向量存储暂存信息一致，以后在 LLM 启用的应用程序中建立提示的上下文。脆弱的 ETL(提取、转换、加载)流水线可能具有级联的批处理操作，这意味着 LLM 正在处理过时的数据。向量存储是持久缓存，去规范化企业知识，以提供消费者已经期待的复杂、反应迅速的体验。

下图显示了这种模式，其中 [Apache Kafka](https://thenewstack.io/apache-kafka-primer/) 消费者组从连接器接收端拉取数据，处理数据并创建嵌入，通过连接器接收端或本机集成传递到[适当的向量存储](https://thenewstack.io/vector-databases-long-term-memory-for-artificial-intelligence/)。

![放大](https://cdn.thenewstack.io/media/2023/12/49660b8d-image1a.png)

### 步骤 2. 推理

下一步涉及推理，其中包括使用前面步骤准备的数据工程提示，以及处理 LLM 的响应。

当用户的提示输入时，应用程序可以从增强的向量存储或类似的企业服务收集相关上下文，以生成最佳提示。

现在，让我们看看事件驱动方法如何提供帮助。

如果您看下面的图像，您会在左边看到一个 Web 应用程序。Web 应用程序通常由一个全栈团队构建，他们主要关注数据如何进出对象关系(ORM)[映射](https://www.theserverside.com/definition/object-relational-mapping-ORM)以及管理会话。通过这种模式，他们可以独立于您在右边看到的消费者组工作，后者可以由专门从事 AI 应用程序开发的后端团队完成。消费者组调用向量存储对提示进行工程化处理，然后调用 LLM 服务。

![放大](https://cdn.thenewstack.io/media/2023/12/e49853fe-image2a.png)

当您使用类似 ChatGPT 的东西时，想一想 LLM 调用，这些调用可能需要几秒钟，对于分布式系统来说这是永恒的。有了这种方法，您的 Web 应用程序团队不需要管理这个问题。团队可以将所有这些都视为异步通信，这对组织团队并独立扩展它们是一个非常棒的模式。

此外，通过具有分解的、专用的服务而不是单体，这些应用程序可以独立部署和扩展。考虑到新的推理步骤是消费者组，以及组织可以为快速实例化这些模板化基础架构，这可以帮助缩短上市时间。

### 步骤 3. 工作流

工作流是一种常见的概念模型(例如 [LangChain](https://www.langchain.com/) 中的链)，用于组合推理代理和推理步骤以形成 GenAI 驱动的应用程序。代理的直观之处在于，我们通常需要一些东西来根据前一个响应自动执行操作，例如下一个 LLM 调用。LLM 可以是某些用途的合适的智能代理，但这些通常是依赖特定领域知识的专业化、更传统的模型。

考虑设计保险承保应用程序：GenAI 模型通常(还)不做承保决定。相反，LLM 提供了一个自然语言接口，调用传统模型根据特定风险建模提供预测。我们通常将 LLM 代理分解为调用链的另一个原因是，最先进的 LLM(在撰写本文时)在我们提出多个简单的问题而不是更大的复合问题时，往往会返回更好的结果，尽管这种特征正在迅速发展。

现在我们来看下面的图像。如前所述，Web 应用程序开发人员可以独立工作。全栈工程师可以构建 Web 应用程序，后端系统工程师可以构建可以对运营数据(如关系数据库管理系统)执行自然语言搜索的消费者组。这是 SQLBuilder 和 LangChain 所允许的。它可以使用推理代理并根据向量存储中的内容建立提示的上下文。它可以根据 Web 应用程序所需查询的需要，对 LLM 进行尽可能多的后续调用。

![放大](https://cdn.thenewstack.io/media/2023/12/0b3fd886-image3.png)

### 步骤 4. 后处理

幻觉确实会发生，企业必须独立验证 LLM 输出并执行业务逻辑，以防止应用程序适得其反。

拥抱事件驱动方法在这里如何提供帮助?如果您查看下面的图像，您会看到一个独立的后处理消费者组。同样，这将后处理与应用程序的其他部分分离。

![放大](https://cdn.thenewstack.io/media/2023/12/71458761-image4.png)

随着 LLM 工作流和依赖性的发展远远快于确定可接受性的业务逻辑，这种方法很有用。

通常，不同的业务组(例如合规团队)将定义这些规则并构建这些应用程序。事件驱动的微服务消除了不必要的带外协调，因为每个微服务只产生和消费管控良好的事件。

归根结底，GenAI 应用程序依赖于数据驱动，为这些应用程序提供生成可靠结果所需的数据量和质量对大多数公司来说是一个挑战。这正是数据流平台可以提供帮助的地方。这样的平台可以通过利用不断丰富、可信赖和建立上下文的数据流，帮助您快速构建和扩展这些数据密集型实时应用程序。

## 拥抱数据流平台

数据流的一个核心[价值主张是您不受数据所在位置的限制](https://www.confluent.io/blog/chatgpt-and-streaming-data-for-real-time-generative-ai/)。数据流使企业能够在实时将相关的数据流路由到需要的任何位置，使数据轻松可用于生成 AI 驱动的应用程序。

数据流平台通过以下方式实现大规模实时生成应用程序:

- 实时整合企业中的各种运营数据，进行可靠、可信赖的使用
- 使用嵌入将非结构化企业数据组织到向量存储中，然后可以帮助工程化提示
- 将面向客户的应用程序与 LLM 调用管理分离开来，提供可靠、响应迅速、横向扩展的体验
- 使 LLM、向量存储和嵌入模型可以被视为模块化组件，随着技术的改进可以被替换

归根结底，数据流帮助解耦系统、团队和技术。它促进建立良好上下文、可信赖和可发现的数据产品，以便团队可以自信和独立地扩展其应用程序，这对于基于 GenAI 的应用程序至关重要。

数据流平台确保您可以将实时、格式良好和高度管理的数据流带来驱动 GenAI 应用程序，并促进数据重用性、工程敏捷性和更高的信任度。这允许企业快速交付消费者已经期待的响应迅速、复杂的体验。访问我们的 AI 资源中心以了解 Confluent 如何为您的 GenAI 之旅提供支持。
