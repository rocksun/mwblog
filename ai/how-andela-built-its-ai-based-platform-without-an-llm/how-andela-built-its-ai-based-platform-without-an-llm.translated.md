# Andela 如何在没有 LLM 的情况下构建其基于 AI 的平台

![Andela 如何在没有 LLM 的情况下构建其基于 AI 的平台的特色图片](https://cdn.thenewstack.io/media/2024/05/9f8e81f1-talent-1024x576.jpg)

根据 Gartner 的说法，熟练的 IT 人员的搜索已走向全球，一些组织中近四分之一的人员现在被定义为“无国界”——在海外采购和工作。

然而，撒下如此广泛的网，使得很难找到你想要的人，更重要的是，快速、可靠且安全地将他们纳入其中。

这是一项为机器智能构建的工作：寻找和分析具有不同技能和期望的人员，并将他们与数量无限的职位相匹配，同时受多种要求的约束。人员和职位都缺乏任何接近可能有所帮助的通用语法。此外还有语言和时区等挑战。

这是一项巨大的数据分析工作，但我们构建了我们的 AI 驱动的招聘平台 Andela Talent Cloud (ATC)，而没有使用 [大型语言模型 (LLM)](https://roadmap.sh/guides/introduction-to-llms)。事实上，我们从我们的管道中移除了 ChatGPT，[并构建了一个基于结构化数据的系统：](https://thenewstack.io/7-tips-for-building-fast-scalable-cost-efficient-streaming-data-pipelines/) 我们的工程师开发了一个专门针对招聘流程细微差别而设计的分类法。

**引擎解构**

我们的 Talent Decision Engine (TDE) 使用 AI 和数据驱动的匹配算法将人员与职位配对，分析从技能和经验到位置和语言能力的数千个数据点。此引擎由许多相关服务提供支持：人才响应服务，以优先考虑最有可能快速响应的人员；推荐引擎，根据人员对角色的总体匹配度进行匹配和排名；以及 AutoMatch，它针对成功进行尽可能多的匹配进行优化，同时避免竞标战。

TDE 提供高质量的匹配，这是 ChatGPT 无法提供的。首先，LLM 无法很好地处理表格数据，并且可能 [难以从](https://thenewstack.io/machine-learning-still-struggles-to-extract-meaning-from-language/) 此类数据表示中提取有意义的见解。ChatGPT 还缺乏足够的数值处理能力。LLM 主要处理文本数据，可能无法推断包含数值的数据（例如人才的时区和工作时间如何与多个工作要求相匹配，每个要求来自不同的时区和独特的最低工作时间）之间的关系。

此外，LLM 面临可解释性挑战，这对决策至关重要：虽然它们可以生成文本输出，但理解它们对结构化数据预测背后的推理具有挑战性，并且与专注于表格数据的技术（如 [XGBoost](https://www.nvidia.com/en-us/glossary/xgboost/) 或类似技术）相比，这是一个显着的缺点，例如，可以使用 SHAP（Shapley Additive exPlanations 值）轻松解释它们的预测。

第四个缺点是 LLM 通常具有有限的上下文窗口，这意味着它们在生成文本时只能考虑固定数量的前置标记。此限制使得它们难以捕获结构化数据中存在的远程依赖关系和复杂关系。

这些只是我们选择不将 LLM 用于我们面临的表格类型问题的原因中的四个。基本上，与专门为结构化数据处理设计的模型（例如图神经网络或传统的机器学习算法，如决策树或支持向量机）相比，它们在这些场景中无法以同样有效或高效的方式执行。

因此，我们创建了基于表格数据的模型，该模型遵循结构化分类法来解决此问题。我们的人工智能驱动方法对我们业务领域固有的特质元素进行建模。例如，它根据技能的必要性（关键、强制性和可选）对技能进行分类，以微调自动匹配过程。接下来，它分析人才技能与工作要求之间的一致性。

然后，它仔细评估其他工作先决条件与我们人才库中特征的一致性，包括时间限制和时区兼容性、以往经验、候选人的首选角色等方面的考虑因素。此外，我们的方法还纳入了对维持我们的培训管道至关重要的数据库进行整理和注释的强大协议。当面临数据稀缺的工作类别时，这种细致的过程至关重要。
**另一个挑战：质量**

我们如何确保 ATC 的算法能够找到最合适的候选人？我们与招聘人员和人才匹配人员合作，以找出需要寻找的品质。这帮助我们开发了我们称之为匹配适应度评分的东西，它使用超过 10,000 人和大约 800 项技能的信息。该评分基于 50 项属性，例如时区、经验年数、技能和薪水。

**处理不完整数据**

建立可信的匹配适应度评分意味着我们还必须克服人们个人资料中的漏洞——缺少基本数据。例如，有些人没有具体说明他们希望赚取多少，这对于匹配人员和设定符合客户预算预期的费率都很重要。在这种具体情况下，我们

[开发了一项人才费率推荐服务](https://thenewstack.io/hbcus-can-become-a-key-source-of-software-development-talent/)，该服务通过识别具有类似技能的人员来生成某人可能根据其技能寻求多少的近似值。

构建和完善 ATC 的不同组件需要使用多种不同的技术，包括降维、词嵌入、独热编码和数据标准化。我们经常使用多种技术来解决一个具体问题——比较结果并选择最有效的方法。

我们发现不乏有用的机器学习技术和方法可用于解决技术问题。真正的挑战是确保项目参与者充分掌握并阐明了招聘中涉及的业务和流程。有如此多的细微差别，即使是最小的细节出错也可能导致搜索结果有缺陷。

为了向面向客户的应用程序交付匹配适应度，我们开发了可扩展推荐服务 (ERS)，这是一个由 Python 驱动的框架，旨在提供端点来评估人才对各种工作角色的适用性。通过 ERS，我们的面向客户的应用程序获得了洞察力，包括基于技能的匹配适应度、人才响应可能性、估计的人才费率等等。这使我们的平台能够高效地识别、参与并与每个职位最合格的候选人展开对话。

**接下来是什么？**

LLM 将出现在产品路线图中，尽管它们可能支持 ATC 而不是成为基石。例如，我们正在考虑是否可以将 LLM 与人才档案结合在技能等领域，以帮助改善向潜在招聘人员展示候选人的方式。我们还使用 LLM 来解析职位描述以获取技能，以便映射到我们的分类法，从而简化职位创建过程。

**从结构化数据中生成见解**

LLM 获得了很多宣传。虽然许多人急于提升技能，但值得注意的是，人工智能的成功并非来自技术，而是来自理解你试图解决的业务问题。根据我们的经验，对于其他行业来说，要从数据中生成见解，他们应该：

* **认识到语言模型 (LLM) 的局限性**，例如 ChatGPT 在处理结构化数据方面的局限性。通过投资专门设计用于结构化数据处理的专业模型，例如决策树等传统机器学习算法，你可以开发出高准确度可解释的模型。
* **了解业务细微差别**：确保项目参与者充分理解并阐明任何特定领域任务中涉及的业务和流程。注意细微差别，因为即使是很小的细节也会显著影响数据驱动解决方案的有效性。
* **制定策略来解决数据质量问题**，例如开发与你的业务领域相关的结构化分类法的可能性。这可以生成有见地的新的数据类型，例如分类信息，这些信息在原始文本格式中原本会是嘈杂的、缺失的或不完整的。我们领域中的一些好例子包括工作角色、技能和口语等等。当它们被正确提取和组合时，可以构建更强大的机器学习模型。
* **使用较小的模型**来估计缺失的关键信息，以馈送其他相关模型或服务。在我们的领域，我们这样做是为了估计人才特征，例如响应能力或费率。
* **与领域专家密切合作**，以识别开发评分机制（例如匹配适应度评分）所需的相关品质。结合人类专业知识来克服数据中的差距，并确保算法决策所需的特征的相关性。
* **探索各种机器学习技术和方法**来解决具体问题，并比较结果以选择[最有效的方法](https://thenewstack.io/how-solving-the-multi-armed-bandit-problem-can-move-machine-learning-forward/)。

通过结合这些策略，寻求利用结构化数据获取见解的行业可以
[开发针对其特定需求量身定制的稳健数据驱动解决方案](https://thenewstack.io/ai-engineering-what-developers-need-to-think-about-in-2024/)，改善决策流程和结果。

[YOUTUBE.COM/THENEWSTACK](https://youtube.com/thenewstack?sub_confirmation=1)
技术发展迅速，不要错过任何一集。订阅我们的 YouTube
频道以流式传输我们所有的播客、访谈、演示等。