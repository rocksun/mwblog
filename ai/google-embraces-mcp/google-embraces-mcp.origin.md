# Google Embraces MCP
![Featued image for: Google Embraces MCP](https://cdn.thenewstack.io/media/2025/05/2c1306b6-google-io-1024x768.jpg)
Anthropic’s [Model Context Protocol](https://thenewstack.io/tutorial-set-up-an-mcp-server-with-net-and-github-copilot/) (MCP) has quickly become the standard for connecting AI agents to tools and data sources. Google, at its I/O developer conference, today announced that it, too, will now support MCP as a built-in part of its Gemini API and [SDK](https://ai.google.dev/gemini-api/docs/migrate).

The company also says that it is looking to make it easier for developers to deploy MCP servers and other hosted tools for AI agents, but it did not provide any details about what this would look like.

Google itself also recently announced the [Agent2Agent protocol](https://thenewstack.io/googles-agent2agent-protocol-helps-ai-agents-talk-to-each-other/) (A2A), and while there has been some confusion about the relationship between MCP and A2A, Google always stressed that the two were complementary. A2A, as the name implies, is meant to enhance how agents interact with each other, while MCP is about connecting agents to data.

![](https://cdn.thenewstack.io/media/2025/05/8f5c907a-img_0917-scaled.jpg)
Image credit: The New Stack.

“Protocols like Agent2Agent and Model Context Protocol are important steps in building more capable agents. […] These technologies will work together to make agents even more useful,” Google CEO Sundar Pichai said in a press briefing ahead of today’s announcement.

Until now, developers had to use third-party libraries to call MCP servers from their applications.

The protocol has become so popular, with seemingly every SaaS service exposing an MCP server now, that even Microsoft Windows is getting [local MCP servers now](https://thenewstack.io/microsoft-brings-mcp-local-ai-models-and-post-quantum-security-to-windows/), so that desktop-based AI apps can access them.

It’s worth noting that Google Deepmind CEO Demis Hassabis already [hinted](https://techcrunch.com/2025/04/09/google-says-itll-embrace-anthropics-standard-for-connecting-ai-models-to-data/) that MCP support was coming to Gemini in April, but at the time, he did not provide a timeline.

![](https://cdn.thenewstack.io/media/2025/05/3c0dfa0b-d017a051-b7eb-4eb7-aa5c-3e8f01589ffa-scaled.jpg)
Image credit: The New Stack.

MCP support is only one of many updates to Google’s Gemini ecosystem, which range from adding a computer-use tool to the Gemini API and its Vertex AI service, which will be able to automate browser-based tasks, for example, as well as updated models, an even deeper “Deep Think” deep thinking mode for the popular Gemini 2.5 Pro model, an updated generative video model and more (as well as a new $249/month subscription service that will be needed to access many of these high-end features).

[
YOUTUBE.COM/THENEWSTACK
Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.
](https://youtube.com/thenewstack?sub_confirmation=1)