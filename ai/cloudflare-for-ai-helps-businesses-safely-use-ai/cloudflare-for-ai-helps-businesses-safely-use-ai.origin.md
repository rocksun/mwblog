# Cloudflare for AI Helps Businesses Safely Use AI
![Featued image for: Cloudflare for AI Helps Businesses Safely Use AI](https://cdn.thenewstack.io/media/2025/03/36e838c5-aicloudfordevelopers-1024x543.jpg)
[Cloudflare](https://cloudflare.com), the content delivery and security service, today announced the launch of Cloudflare for AI, a new suite of security tools that aims to address some of the most pressing security concerns that businesses have around the use of AI models and services.
These include tools to monitor how employees use these tools, discover when they use unauthorized services, and stop information leakage to these models. The new service can also detect when inappropriate or toxic [prompts are submitted to a model](https://thenewstack.io/beyond-prompt-engineering-governing-prompts-and-ai-models/).

As Cloudflare explains in today’s announcement, the idea here is to help businesses feel more confident about the AI workloads they enable for their employees and users.

“Over the next decade, an organization’s AI strategy will determine its fate — innovators will thrive, and those who resist will disappear. The adage ‘move fast, break things’ has become the mantra as organizations race to implement new models and[ experiment with AI to drive](https://thenewstack.io/improving-developer-experience-drives-profitability/) innovation,” said Matthew Prince, co-founder and CEO at Cloudflare. “But there is often a missing link between experimentation and safety. Cloudflare for AI allows customers to move as fast as they want in whatever direction, with the necessary safeguards in place to enable rapid deployment and usage of AI. It is the only suite of tools today that solves customers’ most pressing concerns without putting the brakes on innovation.”

The overall suite consists of a number of services. There is the Firewall for AI, for example, which allows businesses to discover which AI applications employees actually use. The age-old problem of shadow IT persists. As employees clamor to use these new AI tools, security teams often have no insights into what they are doing. Now, they will get reports on which tools are in use and the ability to block them if necessary.

Similarly, the Cloudflare AI Gateway, which the company launched back in 2023, provides insights into the models being used inside of a company and the kind of prompts submitted, which in turn means the firewall can then block prompts that may expose personally identifiable information and other data leaks from reaching the model.

Few tools in the market today focus on stopping toxic prompts. To detect these, Cloudflare is using Llama Guard, [Meta’s tool for safeguarding LLM](https://thenewstack.io/why-open-source-developers-are-using-llama-metas-ai-model/) conversations. This, Cloudflare says, will help keep models in line with their intended usage.

Cloudflare is not alone in seeing a market for these tools, of course. There are API-centric offerings from [Kong](https://konghq.com/products/kong-ai-gateway?utm_source=google&utm_medium=cpc&utm_campaign=ai&utm_term=kong%20ai%20gateway&utm_content=kong-ai-gateway_landing-page_search&gad_source=1&gbraid=0AAAAAD3UpvSnUSJsx_bwhPYxViTt0CMGC&gclid=Cj0KCQjws-S-BhD2ARIsALssG0byTYS6UyfExkqLrvfg3zA6vqhXA4EpU7ALoC67E3nAqRKbALsb0T8aAk7CEALw_wcB) and [IBM](https://www.ibm.com/products/api-connect/ai-gateway), for example, as well as solutions from [F5 ](https://www.f5.com/products/ai-gateway)and [Databricks](https://www.databricks.com/product/ai-gateway).

[
YOUTUBE.COM/THENEWSTACK
Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.
](https://youtube.com/thenewstack?sub_confirmation=1)