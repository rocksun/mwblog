# Pinecone 升级其向量数据库平台的检索功能

![Pinecone 升级其向量数据库平台的检索功能的特色图片](https://cdn.thenewstack.io/media/2024/12/247ba1a3-aws-reinvent-1024x576.png)

今天在 AWS re:Invent 大会上，Pinecone 公布了其[AI检索平台](https://thenewstack.io/vector-databases-are-having-a-moment-a-chat-with-pinecone/) 的重大改进。作为其所谓的“级联搜索”方法的一部分，该公司的向量数据库搜索系统现在包括用于搜索结果重新排序的模型、专有的稀疏向量嵌入模型用于词汇搜索，以及一个新的稀疏向量索引。

该供应商还公布了一些安全升级，包括[基于角色的访问控制](https://thenewstack.io/7-expert-strategies-for-managing-rbac-on-openshift/) (RBAC)、客户管理的加密密钥、审计日志以及 AWS PrivateLink 私有端点的普遍可用性。使用 AWS PrivateLink 的私有端点，用户可以连接到向量数据库，而无需从其虚拟私有云传输数据到公共互联网。

通过将其重新排序功能与并行实现密集和稀疏向量搜索的方法相结合，Pinecone 旨在改进搜索结果，使其超越传统混合搜索的结果。通常，向量数据库设置中的混合搜索将稀疏向量搜索（词汇或基于关键字的搜索的术语）的结果与密集向量搜索（涉及向量嵌入的检索）的结果相结合。

Pinecone 的级联搜索技术在此组合中添加了重新排序器，并以不同于传统混合搜索的方式合成结果，同时仍然证明关键字搜索的持续相关性。

“Pinecone 一直认为向量数据库的功能超越了语义搜索，许多公司都在寻找更广泛的工具来实现检索，这并不令人惊讶，”Pinecone 产品经理评论道。“你不仅仅需要密集向量和语义搜索。你需要关键字搜索和重新排序器来合并关键字结果。”

## 级联搜索

新提供的重新排序模型包括[Cohere Rerank](https://cohere.com/rerank) 3.5 和 Pinecone 的专有模型 pinecone-rerank-v0。重新排序模型通常是神经网络，它们使用实际查询来评估查询的响应（例如文档）。它们使组织能够“运行更强大的比较，说明此文档特定于此查询，并为每个查询-文档对生成分数，”解释道。

尽管混合搜索可能涉及重新排序模型，但这种范式与称为级联搜索的范式之间的区别在于密集和稀疏向量搜索的结果的组合方式。

Pinecone 旨在改进搜索结果，使其超越传统混合搜索的结果。

据介绍，混合搜索通常将密集向量搜索的搜索结果分数与稀疏向量搜索的搜索结果分数结合起来，“并使用某种通常基于启发式的技术来组合它们，例如倒排秩融合”。使用级联搜索，密集向量索引可能会有 100 个结果，稀疏向量索引也可能有 100 个结果，并且这两个检索都是并行完成的。

“但是，这些不会相互加权，因此您使用重新排序器，”补充道。“通常，这只会产生 10 到 20 个重新排序器另一侧的结果，这些结果会传递给 LLM 进行总结。因此，我们认为这是一个从关注召回、顶部大量结果的级联，到基本上提供给 LLM 的最小上下文量。”

## 单个 API 调用

尽管向量搜索引擎结合重新排序模型（以及其他重新排序搜索结果的技术）并非罕见，但 Pinecone 对它们的打包方式因其提供的用户体验而值得关注。在其云原生、无服务器计算产品中，用户不仅可以访问重新排序模型，还可以访问 Pinecone 的专有稀疏嵌入模型 — [pinecone-sparse-english-v0](https://docs.pinecone.io/models/pinecone-sparse-english-v0) — 和一个新的稀疏向量索引。

“我们正在托管和优化用于推理的模型，”说道。“例如，在这个与 Cohere 的新版本中，您无需提供您的 Cohere API 密钥，Pinecone 也不会调用 Cohere 来运行重新排序器或嵌入模型。这些模型完全托管在 Pinecone 的基础设施上。我们端到端地管理它们，并为客户处理账单和所有事务。”
这种简化的用户体验旨在普及大型语言模型的使用，以及实现这一目标所需的大量架构和基础设施方面。新提供的稀疏向量索引类型（据Jones所说，它不是混合索引，并且在许多用例中都优于BM25），以及Pinecone专有的稀疏嵌入模型，强调了在语言模型时代词汇搜索的持续相关性。

这些功能对Pinecone提供用户体验方面具有影响力，在该用户体验中，客户可以向供应商发送文本，它将“在一个API调用中处理嵌入和重新排序”，Jones说。

## 重新排序模型的优势

使用重新排序技术来细化搜索结果并使其更贴合组织的特定数据、查询和用例，是稀疏和密集向量搜索的最佳实践。当组织不[微调或训练嵌入模型](https://thenewstack.io/the-secret-sauce-for-vector-search-training-embedding-models/)时，它们对于密集向量搜索尤其有价值。“当你嵌入文档时，你不知道查询，”Jones说。“文档在不知道查询的情况下被嵌入，因此它们没有针对特定问题进行调整。”重新排序模型通过将查询与文档或嵌入内容进行比较来缓解这种情况。它们还产生其他优势，例如：

**改进上下文：**重新排序模型对语言模型接收到的查询上下文产生积极影响。“研究表明，它提高了上下文窗口的质量，”Jones提到。“你可以使用分数来删除或切断不相关的文档，即使召回步骤，嵌入模型……可能是相关的。”

**降低成本：**一些模型专门减少发送到语言模型的标记数量——而不会影响内容的含义——用于RAG和其他应用程序。重新排序模型还可以减少发送到语言模型的标记数量，从而降低成本。“如果你传递较少的上下文作为输入，标记数量就会减少，”Jones说。

**缓解中间丢失问题：**中间丢失问题是一种现象，其中语言模型（包括为适应更长的提示和更大数量的上下文而设计的新模型）在相关信息不在其解析内容的开头时会产生较差的响应。“即使你给LLM正确的答案，你也希望包含答案的那一部分文本在上下文窗口中尽可能靠上，”Jones说。“如果它更靠中间，LLM就较不可能关注它。”

## 一步向前

Pinecone在整合重新排序模型和开发自己的模型以重新排序和嵌入稀疏向量方面的进步，是对其平台的重要补充。由于重新排序模型适用于词汇搜索，因此这两项工作都强调了需要将密集和稀疏向量搜索配对以最大限度地利用向量数据库信息检索的必要性。

然而，该供应商的资本价值主张可能是其以单一方式向客户提供这些模型的能力，其中许多使用这些模型所需的维护和工作都转移到了Pinecone。“这是第一次尝试，是我们自己名义下发布并自己训练的第一个模型，”Jones说。“这是为了解决一个非常大的问题，那就是，稀疏模型真的不多，当然也没有很多可用于托管的模型。”

[YOUTUBE.COM/THENEWSTACK 技术发展迅速，不要错过任何一集。订阅我们的YouTube频道，收看我们所有的播客、访谈、演示等等。](https://youtube.com/thenewstack?sub_confirmation=1)