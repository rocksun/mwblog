无论是训练还是推理，数据都是人工智能应用的基础。如今，由于聊天机器人领域的爆炸式增长，推理工作负载获得了最多的关注，但推理对于物联网 (IoT) 设备、移动应用程序、智能传感器等领域的实时决策也至关重要。

为现代人工智能工作负载提供动力绝非易事，它需要超低延迟、[高可用性](https://thenewstack.io/distributed-postgres-high-availability-for-mission-critical-apps/)以及实时数据处理和同步。在分布式环境中，这项艰巨的任务变得更具挑战性，因为在不同的地理位置维护模型需要无缝的数据复制和冲突解决。

这正是传统的、基于集中式云的人工智能推理的不足之处。

在集中式系统之间发送数据会消耗大量的带宽。它还会引入延迟，从而减慢响应速度，进而影响从搜索到实时分析的方方面面。在计算和数据在物理上分离的分布式世界中，集中式推理是一个瓶颈。对于需要立即响应的应用程序（例如，自动驾驶汽车、医疗保健、公用事业），即使是很小的延迟也很重要。

但是，推理不必是集中式的。通过将人工智能推理转移到[边缘](https://thenewstack.io/edge-computing/)，可以解决许多这些挑战。通过将模型和计算都更靠近数据源，并在边缘节点上分配人工智能工作负载，可以显著减少延迟、提高数据隐私、降低带宽成本并提高系统效率。

但是，有一个问题：边缘的人工智能推理只有在底层架构能够支持它的情况下才有效。

## 为分布式推理构建架构

[Antony Pegg](https://www.linkedin.com/in/antonypegg/) 是 [pgEdge](https://www.pgedge.com/) 的产品管理总监，他在一次采访中解释说：“边缘的全部意义在于，你正在分配工作负载，使其尽可能靠近需要完成工作的地方。这意味着计算本身需要移到那里。”

除非你的数据和写入操作也在那里，否则你无法在边缘运行推理。这需要从集中式架构转变为 [多主主动-主动架构](https://www.pgedge.com/solutions/benefit/multi-master)。

Pegg 解释了两者之间的区别：“在传统架构中，你有一个节点接受所有写入，然后你有获得更新的副本，但它们仅用于读取——直到主节点出现问题……然后需要将另外两个只读节点之一提升为写入节点并接管。”

多主主动-主动架构则相反——正如 Pegg 所说的，“从设计上就是分散式的”。读取和写入操作可以在任何节点上进行，并且更改会自动复制到整个网络——不需要单个主节点。这种设置允许边缘位置在本地读取和写入，确保数据在所有节点之间保持同步，即使在出现连接问题时也是如此。

通过这种方式，多主主动-主动架构保证了高可用性、更快的响应时间以及无缝的数据复制和同步——这些都是维护人工智能模型及其推理完整性的关键要素。

尽管如此，一些组织对放弃集中式现状而采用分布式方法仍持保留态度。

## 对边缘人工智能的误解仍然存在

尽管使用多主主动-主动架构将人工智能推理转移到边缘具有明显的优势，但常见的误解使一些组织不愿加入：

### 误解 #1：边缘硬件无法处理人工智能工作负载

有些人认为边缘设备根本无法满足人工智能工作负载的需求。特别是硬件要求似乎是一个障碍：“很多人仍然认为边缘硬件太弱[并且没有]将更新分发到底层模型本身的能力，”Pegg 说。

但实际上，现代芯片已经能够有效地运行复杂的模型，即使是量化或提炼的版本——Pegg 说这不应该令人惊讶：“几十年来，我们一直在几何级数上增加能力和小型化……这一切都是为了缩小尺寸以提高效率。”

### 误解 #2：边缘推理仅适用于低风险用例

另一个过时的观点是，边缘推理仅对低风险或小众用例有用。Pegg 再次巧妙地驳斥了这种观点，他指出了实际部署：“它已经被用于关键任务系统，如医疗保健、制造业、国防、自动驾驶汽车。很多东西已经在开发中，我可以说，已经有几十年了。”

一个例子：[电信提供商](https://aws.amazon.com/blogs/industries/distributed-inference-with-collaborative-ai-agents-for-telco-powered-smart-x/?utm_source=chatgpt.com) 已经在边缘、区域和云层使用具有协作 [人工智能代理](https://thenewstack.io/ai-agents-a-comprehensive-introduction-for-developers/) 的分布式推理，以为网络优化和智能基础设施监控等实时应用程序提供支持。

### 误解 #3：你仍然需要单一的事实来源

也许采用边缘人工智能推理的最大心理障碍是仍然相信你仍然需要单一的事实来源。

Pegg 认为这是最难改变的心态，因为我们一直被教导相信云意味着“我们需要单一的事实来源。由此产生的实施模式是编写所有内容的单一位置。”

到目前为止，他说，大多数组织已经接受了分布式读取的概念——但这只是成功了一半。现在，人们需要理解“编写和实际计算必须从中心架构中移开，这意味着你的架构需要是模块化的、紧凑的和可复制的。”

而这正是多主主动-主动架构所实现的。

事实上，一旦团队克服了心理障碍，缺乏单一的事实来源就会成为一种优势：“当你没有单一的事实来源时，”Pegg 说，“你就没有单一的故障点。”

因为每个节点都是活动的，所以系统具有容错能力。如果一个区域暂时离线，其他区域将继续运行；当离线区域恢复在线时，其他节点可以立即赶上它，从而确保即使在意外中断期间也能持续提供数据——这是需要不间断访问数据以进行实时处理和决策的人工智能应用程序的关键要求。

### 误解 #4：计算必须保持集中式

与对单一事实来源的依恋类似，许多组织仍然坚持需要一个集中式堆栈来进行计算（无论是训练还是推理）的想法。

Pegg 坚持认为这种心态需要改变：“你需要将两者[训练和推理]分开，然后重新构建你的系统以分解和分发推理——然后相信推理本身可以从多个位置协调以创建共享的一致性。”

对于 Pegg 来说，这不是一个技术问题；这是一个信任问题：“这些都是需要克服的信任和改变的步骤——相信它不仅*可以*完成，而且相信它*已经*在完成。”

## 为什么这种转变现在很重要

正如技术拐点经常发生的那样，要么现在适应——要么被抛在后面。

采用分布式推理的团队将以更低的延迟、更快的洞察时间、更高的可靠性、更低的成本以及更大的数据来源和主权脱颖而出。

在许多方面，这都归结为速度。正如 Pegg 所说：“速度为王。任何可以减少延迟的事情都可以改善你用来衡量业务的几乎所有指标。” 对于边缘人工智能工作负载，“它离你越近，你就可以越快地进行计算，并立即为你提供所需的决策信息。”

同样的逻辑也适用于成本。集中式系统带来了大量的带宽、硬件和云费用——但边缘推理可以降低成本：“你发送的越少，发送的时间越短[它]，你的成本就越低。你需要部署来运行它的硬件和基础设施越小，你的成本就越低。”

这不是一个小问题。对于许多组织来说，超预算的云支出是一个长期存在的问题，[84% 的组织难以有效地管理它](https://www.flexera.com/about-us/press-center/new-flexera-report-finds-84-percent-of-organizations-struggle-to-manage-cloud-spend)。而且，[麦肯锡预测，到 2030 年，计算需求将达到 7 万亿美元](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers)（主要由人工智能和带宽密集型工作负载驱动），现在是重新思考架构的最佳时机——也是最紧迫的。

分布式推理还有助于数据来源和主权。当你可以分割哪些数据保留在本地以及哪些数据被共享时，就可以更轻松地遵守不同的法规，例如 GDPR 和《加州消费者隐私法案》(CCPA)。

## 用于边缘人工智能的分布式 PostgreSQL

性能、速度和弹性优势都为将人工智能推理转移到边缘提供了强有力的理由——但前提是数据层能够跟上。

这就是为什么许多[使用 PostgreSQL](https://roadmap.sh/postgresql-dba) 的公司正在转向具有多主主动-主动架构的[分布式 PostgreSQL](https://www.pgedge.com/solutions/benefit/ai-inference-at-the-edge)，以减少延迟、确保数据一致性并消除单点故障——而这正是 pgEdge 的优势所在。

[Enquire AI](https://www.pgedge.com/solutions/benefit/ai-inference-at-the-edge) 就是一家将多主架构付诸行动的公司。

Enquire AI 是一家集成了人工智能和人类智能的数字专家网络。其国际客户群意味着该公司面临着严格的数据驻留和响应时间要求——高延迟是一个棘手的挑战，它会导致过度的应用程序响应时间并降低客户体验。尽管该公司已经在使用 [AWS](https://aws.amazon.com/?utm_content=inline+mention) 关系数据库服务 (RDS)，但它选择过渡到 pgEdge Cloud 而不是 AWS Aurora，并在美国东部和孟买地区部署了一个双节点集群。现在，通过跨两个区域设置的分布式数据库，Enquire AI 可以依靠 [更高的可用性](https://www.pgedge.com/solutions/benefit/postgresql-high-availability)、更低的延迟和更轻松的数据驻留合规性。

[pgEdge 提供了一种专为边缘构建的分布式 PostgreSQL 架构](https://www.pgedge.com/products/what-is-pgedge)。其多主主动-主动设置允许每个节点处理读取和写入，并在整个网络中自动复制更改。这意味着没有主节点，也没有单点故障——只有一致的数据。

对于人工智能工作负载，这种数据邻近性至关重要。Pegg 解释说：“如果你仍然集中进行推理，那么你就将收益减半了。” 虽然主动-主动复制可确保一致性，但推理仍然需要数据来执行操作。“没有它，你就错过了计算所需的，”Pegg 解释说。通过在本地存储数据，pgEdge 允许人工智能系统立即对其执行推理或决策。“没有我们，”Pegg 补充说，“你无法真正分配计算，因为计算需要数据来支持它。”

根据 Pegg 的说法，多主主动-主动概念是 pgEdge 的与众不同之处。“我们支持分布式、小型化、缩小尺寸并使其在本地运行的整个范式转变——然后让共享的事实分布、容错和低延迟。此外，我们是完全开源且完全标准的 PostgreSQL。”

这种组合意味着更快的更新、更低的延迟、更低的带宽成本和更快的决策——这是在边缘构建可扩展的智能系统的基础。

[了解更多](https://www.pgedge.com/landing-pages/multi-master-whitepaper) 关于完全开放、完全标准的多主分布式 Postgres 方法如何解决各个行业边缘人工智能推理的高可用性和低延迟挑战。