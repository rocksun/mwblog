
<!--
title: 开源AI定义将解决百万个难题
cover: https://cdn.thenewstack.io/media/2024/09/72157605-virginia-johnson-qmnnzj_ok-m-unsplash-scaled.jpg
-->

语言很重要。如果没有真正开放的人工智能开发精神和社区，将会失去很多。

> 译自 [Defining Open Source AI Will Solve a Million Headaches](https://thenewstack.io/defining-open-source-ai-will-solve-a-million-headaches/)，作者 Mark Surman。

几周前发布了一份 500 字的文件，它将对互联网的未来产生重大影响。[开源倡议](https://opensource.org/) (OSI) 发布了 [开源 AI](https://opensource.org/open-source-ai-definition-draft-v-0-0-9) 的近乎最终定义，这将解放 AI 开发者的广泛社区，为 AI 创新创造蓬勃发展的运动，就像互联网本身的创建一样。[开源软件](https://thenewstack.io/open-source/) 支撑着当今使用的互联网基础设施和大多数应用程序。之所以会这样，是因为开源先驱将其定义为 [始终可以免费使用和修改](https://thenewstack.io/the-future-of-open-source-needs-more-give-and-less-take/) 的软件。这使得开源软件得到广泛采用，并为我们的数字生活提供动力的创新。

现在是最佳时机。我们看到一波 AI 模型——许多来自最大的科技公司——被“
[开源](https://thenewstack.io/open-source-is-at-a-crossroads/)”所吹捧，但未能反映 [原始开源软件定义](https://thenewstack.io/how-should-we-define-open-ai/) 的精神。虽然这可能感觉像是语义，但 [语言很重要](https://thenewstack.io/open-source-has-a-definition-lets-get-serious-about-defending-it/)。围绕开源 AI 的粗心语言可能会破坏未来数万亿美元的创新，并将 AI 条款留给少数几家大公司。

如果没有真正开放的 AI 开发精神和社区，将会有很多损失。哈佛大学最近的一项研究表明，开源软件创造了约 [8 万亿美元](https://www.hbs.edu/ris/Publication%20Files/24-038_51f8444f-502c-4139-8bf2-56eb4b65c58a.pdf)的经济价值。所有这些创新都基于 1998 年编写的原始开源定义中的保证：任何自称为开源的软件都将始终可以免费使用、研究、修改和共享。这意味着你可以在开源软件之上构建一个企业、一项政府服务——实际上是任何东西——而不用担心有人可能会向你收费或在未来更改该软件的使用条款。

我们将在 AI 中看到同样的好处，但前提是开发人员可以自由地使用、研究、修改和共享 AI 系统的所有元素。这里的“AI 系统的所有元素”这个短语至关重要。AI 和软件有一些关键差异。AI 系统包括由工作 AI 模型构建的软件代码和用于创建模型的基础训练数据。OSI 的新定义断言代码和模型必须是开放的，并且数据必须是透明且可复制的。假设我们想要开启另一个创造力和创新的时代。在这种情况下，我们需要 AI 实验室——包括大型商业参与者——在称他们发布的内容为“开源”之前接受此定义。如果没有这一点，开发人员可能会避开开放模型，整个开源生态系统可能会在早期陷入停滞。

来自最大科技公司的巨型语言模型 (LLM) 激增——Meta 的 Llama 最为显着——它们被吹捧为开源。这些模型可以轻松构建 AI 应用程序，而无需从头开始构建它们所需的过高成本。我们已经看到了有价值的 AI 应用程序，从[药物发现](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/megamolbart)到[医学教育](https://arxiv.org/pdf/2304.08247)，建立在这些模型之上。这绝对是朝着正确方向迈出的一步，但有一个警告：这些 AI 模型并不是真正的开放。

在*经济学家*本周早些时候发表的一篇观点文章中，马克·扎克伯格和 Spotify 首席执行官丹尼尔·埃克将开源 AI 定义为“其权重以宽松许可证公开发布的模型”，并以 Llama 为例。这种狭隘的定义为 Meta 等公司改变路线并停止发布其 AI 模型的某些部分留下了空间，如果这些部分不再符合其利益。如果发生这种情况，在这些模型之上构建的开发人员可能会发现他们的产品无法操作，或者至少受到严重限制——想想中断的服务和受阻的创新。这引发了对建立在这些模型之上的应用程序的长期可行性以及对充满活力的开源 AI 生态系统的可行性的真正担忧。

2 月份，Mozilla 和哥伦比亚大学[召集了领先专家](https://blog.mozilla.org/en/mozilla/ai/introducing-columbia-convening-openness-and-ai/)，探讨开放性在人工智能时代应有何含义。最终的论文指出了在人工智能中狭隘和草率使用“开源”一词的风险。它还对“开放式”许可证提出了警告，例如 Llama 许可证，该许可证仅对每月用户少于 7 亿的产品授予免费使用权。你能想象在开放软件上建立你的初创公司，一旦你的业务成功就会被锁定吗？这就是这样的许可证会做的事情。

该草案定义旨在解决这些风险——围绕开源人工智能的定义划清界限，以便开发人员知道他们可以依赖什么。这将为构建开源人工智能模型的人工智能实验室注入动力，这些模型不会消失或最终关闭。

示例包括 EleutherAI 的 GPT-NeoX-20B，在 Apache 2.0 许可证下发布，允许任何人使用该模型。同样，艾伦研究所的 OLMo 模型提供了对用于开发它的代码、数据、权重和评估套件的完全访问权限，使研究人员能够对其进行研究和改进。与 Meta 的 Llama 不同，这些模型允许研究人员充分研究和测试人工智能系统的内部运作，并将其调整为自己的需求。

同样值得注意的是，像 Eleuther 和 AI2 这样的实验室是非营利组织，这让开发人员相信这些资源将保持可用和最新，确保建立在这些模型之上的产品的可持续性。这种持续支持的原则使 Linux 和 Apache 等开源项目在全球服务器中如此普遍。开发人员知道并相信 Linux 和 Apache 基金会将继续让他们的软件以公共利益运营。

这些非营利组织的工作有可能创造一个人工智能未来，既有助于更广泛的公共利益，又为人工智能时代提供了一个真正开放的工具箱。政策制定者、慈善家和更广泛的技术社区应该加大支持力度，支持此类举措。更知名的商业参与者应以这些项目为榜样，改变他们的方法，使其更符合新的 OSI 定义。如果我们做对了，我们就可以让任何人——和任何社区——塑造、享受和信任人工智能。我们的数字基础设施的未来和我们创新的能力取决于此。
