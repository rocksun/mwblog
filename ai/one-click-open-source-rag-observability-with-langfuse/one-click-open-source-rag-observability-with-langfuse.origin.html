<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>One-click Open Source RAG Observability with Langfuse — LlamaIndex, Data Framework for LLM Applications</title><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><meta name="title" content="One-click Open Source RAG Observability with Langfuse — LlamaIndex, Data Framework for LLM Applications"/><meta name="description" content="LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models (LLMs)."/><meta property="og:title" content="One-click Open Source RAG Observability with Langfuse — LlamaIndex, Data Framework for LLM Applications"/><meta property="og:description" content="LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models (LLMs)."/><meta property="og:image" content="https://cdn.sanity.io/images/7m9jw85w/production/2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="One-click Open Source RAG Observability with Langfuse — LlamaIndex, Data Framework for LLM Applications"/><meta property="twitter:description" content="LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models (LLMs)."/><meta property="twitter:image" content="https://cdn.sanity.io/images/7m9jw85w/production/2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png"/><meta name="next-head-count" content="19"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-C2Y84HJY3F"></script><script></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-C2Y84HJY3F');
            </script><link rel="preload" href="/_next/static/css/0cb365ebab2cca42.css" as="style"/><link rel="stylesheet" href="/_next/static/css/0cb365ebab2cca42.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a1043a3085919747.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a1043a3085919747.css" data-n-p=""/><link rel="preload" href="/_next/static/css/e66dc315d65925fe.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e66dc315d65925fe.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-28c7c894f2275c52.js" defer=""></script><script src="/_next/static/chunks/framework-f21ad92cd7cbda96.js" defer=""></script><script src="/_next/static/chunks/main-e9a4e4ae37deaffb.js" defer=""></script><script src="/_next/static/chunks/pages/_app-0e2e3fe906643661.js" defer=""></script><script src="/_next/static/chunks/d9067523-4985945b21298365.js" defer=""></script><script src="/_next/static/chunks/41155975-60c12da9ce9fa0b2.js" defer=""></script><script src="/_next/static/chunks/cb355538-cee2ea45674d9de3.js" defer=""></script><script src="/_next/static/chunks/1180-7eeee2fc8118ec7a.js" defer=""></script><script src="/_next/static/chunks/1554-8ee2118cbdad6208.js" defer=""></script><script src="/_next/static/chunks/5814-28d698d1c25c41ad.js" defer=""></script><script src="/_next/static/chunks/5575-3d548bca7cc3c6c0.js" defer=""></script><script src="/_next/static/chunks/4478-7a50854e95958c26.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-075bb751d8036614.js" defer=""></script><script src="/_next/static/pGBlFmtqp0g680plY_OVM/_buildManifest.js" defer=""></script><script src="/_next/static/pGBlFmtqp0g680plY_OVM/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="__variable_aaf875 __variable_770839 __variable_29b269"><div class="page"><header class="Header_header__hO3lJ"><button class="Hamburger_hamburger__17auO Header_hamburger__lUulX"><svg width="28" height="28" viewBox="0 0 28 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 14H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" id="hamburger-stroke-top" class="Hamburger_hamburgerStrokeMiddle__I7VpD"></path><path d="M3.5 7H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeTop__oOhFM"></path><path d="M3.5 21H24.5" stroke="#212121" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="Hamburger_hamburgerStrokeBottom__GIQR2"></path></svg></button><a aria-label="Homepage" href="/"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" class="Header_logo__e5KhT" style="color:transparent" src="/llamaindex.svg"/></a><nav class="Nav_nav__bbBYX Header_nav__3fHSH"><ul><li><a href="/enterprise">Enterprise</a></li><li><a href="/open-source">Open source</a></li><li><a href="/community">Community</a></li><li><a href="/careers">Careers</a></li><li><a class="Nav_active__0wSiM" href="/blog">Blog</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6 Header_button__1HFhY"><div class="Button_buttonBorderWrapper__IFJjJ"><span class="Button_buttonBorder__RPy5q"></span></div><div class="Button_buttonColorWrapper__DoWTh"><span class="Button_buttonColor__2AcCn"> <!-- -->Talk to us</span></div></a><div class="MobileMenu_mobileMenu__g5Fa6"><nav class="MobileMenu_nav__EmtTw"><ul><li><a href="/enterprise">Enterprise</a></li><li><a href="/open-source">Open source</a></li><li><a href="/community">Community</a></li><li><a href="/careers">Careers</a></li><li><a href="/blog">Blog</a></li></ul></nav><a href="/contact" class="Button_button-variant-ghost__o2AbG Button_button__aJ0V6"><div class="Button_buttonBorderWrapper__IFJjJ"><span class="Button_buttonBorder__RPy5q"></span></div><div class="Button_buttonColorWrapper__DoWTh"><span class="Button_buttonColor__2AcCn"> <!-- -->Talk to us</span></div></a><ul class="Socials_socials__8Y_s5 Socials_socials-theme-dark__Hq8lc MobileMenu_socials__JykCO"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul><p class="Text_text__zPO0D Text_text-size-16__PkjFu MobileMenu_copyright__nKVOs">© 2024 LlamaIndex</p></div></header><main><section class="BlogPost_post__JHNzd"><img alt="" loading="lazy" width="800" height="659.5" decoding="async" data-nimg="1" class="BlogPost_featuredImage__KGxwX" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1920&amp;q=75"/><p class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-600__fKYth BlogPost_date__6uxQw"><a class="BlogPost_author__mesdl" href="/blog/author/langfuse">Langfuse</a> <!-- -->•<!-- --> <!-- -->Mar 18, 2024</p><h1 class="Text_text__zPO0D Text_text-size-32__koGps BlogPost_title__b2lqJ">One-click Open Source RAG Observability with Langfuse</h1><ul class="BlogPost_tags__13pBH"><li><a class="Badge_badge___1ssn" href="/blog/tag/llm"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">LLM</span></a></li><li><a class="Badge_badge___1ssn" href="/blog/tag/observability"><span class="Text_text__zPO0D Text_text-size-16__PkjFu Text_text-weight-500__f2npw">Observability</span></a></li></ul><div class="BlogPost_htmlPost__Z5oDL"><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><em>This is a guest post from the team at Langfuse</em></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">There are so many different ways to make RAG work for a use case. What vector store to use? What retrieval strategy to use? LlamaIndex makes it easy to try many of them without having to deal with the complexity of integrations, prompts and memory all at once.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Initially, we at Langfuse worked on complex RAG/agent applications and quickly realized that there is a new need for observability and experimentation to tweak and iterate on the details. In the end, these details matter to get from something cool to an actually reliable RAG application that is safe for users and customers. Think of this: if there is a user session of interest in your <em>production</em> RAG application, how can you quickly see whether the retrieved context for that session was actually relevant or the LLM response was on point?</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Thus, we started working on <a href="http://langfuse.com" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">Langfuse.com</a> (<a href="https://github.com/langfuse/langfuse" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">GitHub</a>) to establish an open source LLM engineering platform with tightly integrated features for tracing, prompt management, and evaluation. In the beginning we just solved our own and our friends’ problems. Today we are at over 1000 projects which rely on Langfuse, and 2.3k stars on GitHub. You can either <a href="https://langfuse.com/docs/deployment/self-host" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">self-host</a> Langfuse or use the <a href="https://cloud.langfuse.com" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">cloud instance</a> maintained by us.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We are thrilled to announce our new integration with LlamaIndex today. This feature was <a href="https://github.com/orgs/langfuse/discussions/828" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">highly requested</a> by our community and aligns with our project&#x27;s focus on native integration with major application frameworks. Thank you to everyone who contributed and tested it during the beta phase!</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">The challenge</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We love LlamaIndex, since the clean and standardized interface abstracts a lot of complexity away. Let’s take this simple example of a VectorStoreIndex and a ChatEngine.</p><pre><code><span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> SimpleDirectoryReader
<span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> VectorStoreIndex

documents = SimpleDirectoryReader(<span class="hljs-string">&quot;./data&quot;</span>).load_data()

index = VectorStoreIndex.from_documents(documents)

chat_engine = index.as_chat_engine()

<span class="hljs-built_in">print</span>(chat_engine.chat(<span class="hljs-string">&quot;What problems can I solve with RAG?&quot;</span>))
<span class="hljs-built_in">print</span>(chat_engine.chat(<span class="hljs-string">&quot;How do I optimize my RAG application?&quot;</span>))</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">In just 3 lines we loaded our local documents, added them to an index and initialized a ChatEngine with memory. Subsequently we had a stateful conversation with the chat_engine.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This is awesome to get started, but we quickly run into questions like:</p><ul><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><em>“What context is actually retrieved from the index to answer the questions?”</em></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><em>“How is chat memory managed?”</em></li><li class="Text_text__zPO0D Text_text-size-16__PkjFu"><em>“Which steps add the most latency to the overall execution? How to optimize it?”</em></li></ul><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">One-click OSS observability to the rescue</h2><div style="height:auto;width:auto" data-ntpc="YouTubeEmbed"><lite-youtube videoid="4PZbb9XwG2o" style="max-width: none"></lite-youtube></div><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We integrated Langfuse to be a one-click integration with LlamaIndex using the global callback manager.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Preparation</p><ol><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Install the community package (pip install llama-index-callbacks-langfuse)</li><li class="Text_text__zPO0D Text_text-size-16__PkjFu">Copy/paste the environment variables from the Langfuse project settings to your Python project: &#x27;LANGFUSE_SECRET_KEY&#x27;, &#x27;LANGFUSE_PUBLIC_KEY&#x27; and &#x27;LANGFUSE_HOST&#x27;</li></ol><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Now, you only need to set the global langfuse handler:</p><pre><code><span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> set_global_handler

set_global_handler(<span class="hljs-string">&quot;langfuse&quot;</span>)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">And voilá, with just two lines of code you get detailed traces for all aspects of your RAG application in Langfuse. They automatically include latency and usage/cost breakdowns.</p><figure><img alt="" loading="lazy" width="999.5" height="659.5" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=2048&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=2048&amp;q=75"/></figure><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Group multiple chat threads into a session</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Working with lots of teams building GenAI/LLM/RAG applications, we’ve continuously added more features that are useful to debug and improve these applications. One example is <a href="https://langfuse.com/docs/tracing/sessions" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">session tracking</a> for conversational applications to see the traces in context of a full message thread.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">To activate it, just add an id that identifies the session as a trace param before calling the chat_engine.</p><pre><code><span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> global_handler

global_handler.set_trace_params(
  session_id=<span class="hljs-string">&quot;your-session-id&quot;</span>
)

chat_engine.chat(<span class="hljs-string">&quot;What did he do growing up?&quot;</span>)
chat_engine.chat(<span class="hljs-string">&quot;What did he do at USC?&quot;</span>)
chat_engine.chat(<span class="hljs-string">&quot;How old is he?&quot;</span>)</code></pre><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Thereby you can see all these chat invocations grouped into a session view in Langfuse Tracing:</p><figure><img alt="" loading="lazy" width="999.5" height="629" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89c4bc95018b0441487cc0f48d8f1b42e5d008e6-1999x1258.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=1080&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89c4bc95018b0441487cc0f48d8f1b42e5d008e6-1999x1258.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=2048&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F89c4bc95018b0441487cc0f48d8f1b42e5d008e6-1999x1258.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=2048&amp;q=75"/></figure><p class="Text_text__zPO0D Text_text-size-16__PkjFu">Next to sessions, you can also track individual users or add tags and metadata to your Langfuse traces.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Trace more complex applications and use other Langfuse features for prompt management and evaluation</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">This integration makes it easy to get started with Tracing. If your application ends up growing into using custom logic or other frameworks/packages, all Langfuse integrations are fully interoperable.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We have also built additional features to version control and collaborate on prompts (langfuse <a href="https://langfuse.com/docs/prompts/get-started" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">prompt management</a>), track <a href="https://langfuse.com/docs/experimentation" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">experiments</a>, and <a href="https://langfuse.com/docs/scores/overview" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">evaluate</a> production traces. For RAG specifically, we collaborated with the RAGAS team and it’s easy to run their popular eval suite on traces captured with Langfuse (see <a href="https://langfuse.com/docs/scores/model-based-evals/ragas" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">cookbook</a>).</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Get started</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">The easiest way to get started is to follow the <a href="https://docs.llamaindex.ai/en/stable/examples/callbacks/LangfuseCallbackHandler.html" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">cookbook</a> and check out the <a href="https://langfuse.com/docs/integrations/llama-index/get-started" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">docs</a>.</p><h2 class="Text_text__zPO0D Text_text-size-48__A2f8Q">Feedback? Ping us</h2><p class="Text_text__zPO0D Text_text-size-16__PkjFu">We’d love to hear any feedback. Come join us on our <a href="https://langfuse.com/discord" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">community discord</a> or add your thoughts to this <a href="https://github.com/orgs/langfuse/discussions/828" rel="noreferrer noopener" class="SanityPortableText_link__QA4Ze">GitHub thread</a>.</p><p class="Text_text__zPO0D Text_text-size-16__PkjFu"><br/></p></div><div class="BlogPost_relatedPosts__0z6SN"><h2 class="Text_text__zPO0D Text_text-align-center__HhKqo Text_text-size-16__PkjFu Text_text-weight-400__5ENkK Text_text-family-spaceGrotesk__E4zcE BlogPost_relatedPostsTitle___JIrW">Related articles</h2><ul class="BlogPost_relatedPostsList__uOKzB"><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/one-click-open-source-rag-observability-with-langfuse">One-click Open Source RAG Observability with Langfuse</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-18</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4419e1afaa5eab8c15eb7b3ba750166298158a67-853x480.gif%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4419e1afaa5eab8c15eb7b3ba750166298158a67-853x480.gif%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2F4419e1afaa5eab8c15eb7b3ba750166298158a67-853x480.gif%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/pii-detector-hacking-privacy-in-rag">PII Detector: hacking privacy in RAG</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-13</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fb5404df39ca9c68da96a69a72cb877ec6c22ab1a-6426x1688.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fb5404df39ca9c68da96a69a72cb877ec6c22ab1a-6426x1688.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fb5404df39ca9c68da96a69a72cb877ec6c22ab1a-6426x1688.png%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/launching-the-first-genai-native-document-parsing-platform">Launching the first GenAI-native document parsing platform</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-13</p></div></li><li><div class="CardBlog_card__mm0Zw"><div class="CardBlog_thumbnail__XCu_R"><img alt="" loading="lazy" width="400" height="280" decoding="async" data-nimg="1" class="CardBlog_image__I2Asd" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fcf42b2ac43a6b3900a54b3c706d73e4a07b1b4b9-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=640&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fcf42b2ac43a6b3900a54b3c706d73e4a07b1b4b9-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F7m9jw85w%2Fproduction%2Fcf42b2ac43a6b3900a54b3c706d73e4a07b1b4b9-1024x1024.webp%3Ffit%3Dmax%26auto%3Dformat&amp;w=828&amp;q=75"/></div><p class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth CardBlog_title__qC51U"><a href="/blog/llamaindex-newsletter-2024-03-12">LlamaIndex Newsletter 2024-03-12</a></p><p class="Text_text__zPO0D Text_text-size-16__PkjFu">2024-03-12</p></div></li></ul></div></section></main><footer class="Footer_footer__eNA9m"><div class="Footer_navContainer__7bvx4"><div class="Footer_logoContainer__3EpzI"><img alt="LlamaIndex" loading="lazy" width="213" height="42" decoding="async" data-nimg="1" style="color:transparent" src="/llamaindex.svg"/><div class="Footer_socialContainer__GdOgk"><ul class="Socials_socials__8Y_s5"><li><a href="https://github.com/run-llama/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a></li><li><a href="https://twitter.com/llama_index"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/91154103/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></li></ul></div></div><div class="Footer_nav__BLEuE"><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/">LLamaIndex</a></h3><ul><li><a href="/blog"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Blog</span></a></li><li><a href="/careers"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Careers</span></a></li><li><a href="/contact"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Contact</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/enterprise">Enterprise</a></h3><ul><li><a href="https://cloud.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LLamaCloud</span></a></li><li><a href="https://cloud.llamaindex.ai/parse"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaParse</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/open-source">Open Source</a></h3><ul><li><a href="https://pypi.org/project/llama-index/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python package</span></a></li><li><a href="https://docs.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Python docs</span></a></li><li><a href="https://www.npmjs.com/package/llamaindex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript package</span></a></li><li><a href="https://ts.llamaindex.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">TypeScript docs</span></a></li><li><a href="https://llamahub.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaHub</span></a></li><li><a href="https://github.com/run-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">GitHub</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e"><a href="/community">Community</a></h3><ul><li><a href="/community#newsletter"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Newsletter</span></a></li><li><a href="https://discord.com/invite/eN6D2HQ4aX"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Discord</span></a></li><li><a href="https://twitter.com/llama_index"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Twitter/X</span></a></li><li><a href="https://www.linkedin.com/company/91154103/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LinkedIn</span></a></li><li><a href="https://www.youtube.com/@LlamaIndex"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">YouTube</span></a></li></ul></div><div><h3 class="Text_text__zPO0D Text_text-size-20__LNa6Q Text_text-weight-600__fKYth Footer_navHeader__9o83e">Starter projects</h3><ul><li><a href="https://www.npmjs.com/package/create-llama"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">create-llama</span></a></li><li><a href="https://secinsights.ai"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">SEC Insights</span></a></li><li><a href="https://chat.llamaindex.ai/"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">Chat LlamaIndex</span></a></li><li><a href="https://github.com/run-llama/llamabot"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">LlamaBot</span></a></li><li><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html"><span class="Text_text__zPO0D Text_text-size-16__PkjFu">RAG CLI</span></a></li></ul></div></div></div><p class="Text_text__zPO0D Text_text-size-14__6Qc26 Footer_copyright__vFlrA">© 2024 LlamaIndex</p></footer></div></div><svg xmlns="http://www.w3.org/2000/svg" class="flt_svg" style="display:none"><defs><filter id="flt_tag"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="2"></feGaussianBlur><feColorMatrix in="blur" result="flt_tag" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="flt_tag" operator="atop"></feComposite></filter><filter id="svg_blur_large"><feGaussianBlur in="SourceGraphic" result="blur" stdDeviation="8"></feGaussianBlur><feColorMatrix in="blur" result="svg_blur_large" values="1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 19 -9"></feColorMatrix><feComposite in="SourceGraphic" in2="svg_blur_large" operator="atop"></feComposite></filter></defs></svg></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"page":{"_updatedAt":"2024-03-18T18:05:43Z","slug":{"current":"one-click-open-source-rag-observability-with-langfuse","_type":"slug"},"author":{"_createdAt":"2024-03-18T17:57:51Z","_rev":"jlRkt7ZLIy764pfMnLNNn5","_type":"people","name":"Langfuse","_id":"7634ad30-ab9b-4336-a62f-47d8b2a187a7","_updatedAt":"2024-03-18T17:57:51Z","slug":{"current":"langfuse","_type":"slug"}},"tags":[{"_createdAt":"2024-02-22T20:19:11Z","_rev":"jbUo4a8sS9GhVRG46mMVHT","_type":"blogTag","_id":"aa7d304e-787e-4a6c-80cb-8911afd4c788","title":"LLM","_updatedAt":"2024-03-13T16:00:26Z","slug":{"current":"llm","_type":"slug"}},{"_id":"c777ce15-86a7-4d8e-8a64-8025e652dfd5","title":"Observability","_updatedAt":"2024-02-22T20:19:14Z","slug":{"current":"observability","_type":"slug"},"_createdAt":"2024-02-22T20:19:14Z","_rev":"9mLWnJtMvL1OgKPLcXbz07","_type":"blogTag"}],"mainImage":"https://cdn.sanity.io/images/7m9jw85w/production/2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319.png","publishedDate":"Mar 18, 2024","title":"One-click Open Source RAG Observability with Langfuse","_id":"45799345-c81d-477c-9e70-87671f541864","featured":false,"image":{"_type":"image","asset":{"_ref":"image-2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319-png","_type":"reference"}},"_rev":"jlRkt7ZLIy764pfMnLNr0D","_type":"blogPost","relatedPosts":[{"title":"One-click Open Source RAG Observability with Langfuse","featured":false,"image":{"asset":{"_ref":"image-2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319-png","_type":"reference"},"_type":"image"},"publishedDate":"2024-03-18","slug":"one-click-open-source-rag-observability-with-langfuse"},{"title":"PII Detector: hacking privacy in RAG","featured":false,"image":{"_type":"image","asset":{"_ref":"image-4419e1afaa5eab8c15eb7b3ba750166298158a67-853x480-gif","_type":"reference"}},"publishedDate":"2024-03-13","slug":"pii-detector-hacking-privacy-in-rag"},{"title":"Launching the first GenAI-native document parsing platform","featured":false,"image":{"_type":"image","asset":{"_ref":"image-b5404df39ca9c68da96a69a72cb877ec6c22ab1a-6426x1688-png","_type":"reference"}},"publishedDate":"2024-03-13","slug":"launching-the-first-genai-native-document-parsing-platform"},{"featured":false,"image":{"asset":{"_ref":"image-cf42b2ac43a6b3900a54b3c706d73e4a07b1b4b9-1024x1024-webp","_type":"reference"},"_type":"image"},"publishedDate":"2024-03-12","slug":"llamaindex-newsletter-2024-03-12","title":"LlamaIndex Newsletter 2024-03-12"}],"_createdAt":"2024-03-18T18:05:43Z","text":[{"markDefs":[],"children":[{"_type":"span","marks":["em"],"text":"This is a guest post from the team at Langfuse","_key":"d63fe7bffaaa0"}],"_type":"block","style":"normal","_key":"a7f9461d800c"},{"children":[{"_type":"span","marks":[],"text":"","_key":"97341f38ba6b"}],"_type":"block","style":"normal","_key":"e09ad67d6d60","markDefs":[]},{"children":[{"_type":"span","marks":[],"text":"There are so many different ways to make RAG work for a use case. What vector store to use? What retrieval strategy to use? LlamaIndex makes it easy to try many of them without having to deal with the complexity of integrations, prompts and memory all at once.","_key":"f74fa242e38d"}],"_type":"block","style":"normal","_key":"310366d2224a","markDefs":[]},{"markDefs":[],"children":[{"marks":[],"text":"","_key":"41cce38de3cc0","_type":"span"}],"_type":"block","style":"normal","_key":"0b8d6c6de0d7"},{"_key":"750fe9226f3f","markDefs":[],"children":[{"_type":"span","marks":[],"text":"Initially, we at Langfuse worked on complex RAG/agent applications and quickly realized that there is a new need for observability and experimentation to tweak and iterate on the details. In the end, these details matter to get from something cool to an actually reliable RAG application that is safe for users and customers. Think of this: if there is a user session of interest in your ","_key":"9a4307f50d1f0"},{"_type":"span","marks":["em"],"text":"production","_key":"9a4307f50d1f1"},{"_type":"span","marks":[],"text":" RAG application, how can you quickly see whether the retrieved context for that session was actually relevant or the LLM response was on point?","_key":"9a4307f50d1f2"}],"_type":"block","style":"normal"},{"children":[{"_type":"span","marks":[],"text":"","_key":"b9d76bfc0d580"}],"_type":"block","style":"normal","_key":"dbf1c718d688","markDefs":[]},{"children":[{"_type":"span","marks":[],"text":"Thus, we started working on ","_key":"07810ccf58180"},{"marks":["bae0aa6eecf6"],"text":"Langfuse.com","_key":"07810ccf58181","_type":"span"},{"_type":"span","marks":[],"text":" (","_key":"07810ccf58182"},{"_type":"span","marks":["833e1b6b824e"],"text":"GitHub","_key":"07810ccf58183"},{"_type":"span","marks":[],"text":") to establish an open source LLM engineering platform with tightly integrated features for tracing, prompt management, and evaluation. In the beginning we just solved our own and our friends’ problems. Today we are at over 1000 projects which rely on Langfuse, and 2.3k stars on GitHub. You can either ","_key":"07810ccf58184"},{"_type":"span","marks":["3bfdded0a187"],"text":"self-host","_key":"07810ccf58185"},{"_type":"span","marks":[],"text":" Langfuse or use the ","_key":"07810ccf58186"},{"_key":"07810ccf58187","_type":"span","marks":["f9eddee90251"],"text":"cloud instance"},{"_type":"span","marks":[],"text":" maintained by us.","_key":"07810ccf58188"}],"_type":"block","style":"normal","_key":"c839d24db3f6","markDefs":[{"href":"http://langfuse.com","_key":"bae0aa6eecf6","_type":"link"},{"_type":"link","href":"https://github.com/langfuse/langfuse","_key":"833e1b6b824e"},{"href":"https://langfuse.com/docs/deployment/self-host","_key":"3bfdded0a187","_type":"link"},{"_type":"link","href":"https://cloud.langfuse.com","_key":"f9eddee90251"}]},{"_type":"block","style":"normal","_key":"feece2a06c61","markDefs":[],"children":[{"_key":"cf37d58775bd0","_type":"span","marks":[],"text":""}]},{"style":"normal","_key":"8cca98e91538","markDefs":[{"_type":"link","href":"https://github.com/orgs/langfuse/discussions/828","_key":"cf7d833b8c2f"}],"children":[{"text":"We are thrilled to announce our new integration with LlamaIndex today. This feature was ","_key":"d8e3193a91ae0","_type":"span","marks":[]},{"_type":"span","marks":["cf7d833b8c2f"],"text":"highly requested","_key":"d8e3193a91ae1"},{"_type":"span","marks":[],"text":" by our community and aligns with our project's focus on native integration with major application frameworks. Thank you to everyone who contributed and tested it during the beta phase!","_key":"d8e3193a91ae2"}],"_type":"block"},{"markDefs":[],"children":[{"_type":"span","marks":[],"text":"The challenge","_key":"3ca342b6e6e50"}],"_type":"block","style":"h2","_key":"516c2fc2e5ae"},{"markDefs":[],"children":[{"marks":[],"text":"We love LlamaIndex, since the clean and standardized interface abstracts a lot of complexity away. Let’s take this simple example of a VectorStoreIndex and a ChatEngine.","_key":"8482bc3205080","_type":"span"}],"_type":"block","style":"normal","_key":"631aecfb6a83"},{"code":"from llama_index.core import SimpleDirectoryReader\nfrom llama_index.core import VectorStoreIndex\n\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\nindex = VectorStoreIndex.from_documents(documents)\n\nchat_engine = index.as_chat_engine()\n\nprint(chat_engine.chat(\"What problems can I solve with RAG?\"))\nprint(chat_engine.chat(\"How do I optimize my RAG application?\"))","_type":"codeBlock","language":"python","_key":"817fbc47f926"},{"style":"normal","_key":"1c88bb4a04ba","markDefs":[],"children":[{"marks":[],"text":"In just 3 lines we loaded our local documents, added them to an index and initialized a ChatEngine with memory. Subsequently we had a stateful conversation with the chat_engine.","_key":"cdf0d46286b70","_type":"span"}],"_type":"block"},{"_key":"f1bab819946c","markDefs":[],"children":[{"_type":"span","marks":[],"text":"","_key":"2e280f55298a0"}],"_type":"block","style":"normal"},{"_key":"46f9a9fc238f","markDefs":[],"children":[{"_type":"span","marks":[],"text":"This is awesome to get started, but we quickly run into questions like:","_key":"5959d5604a230"}],"_type":"block","style":"normal"},{"style":"normal","_key":"607ebff39238","listItem":"bullet","markDefs":[],"children":[{"_type":"span","marks":["em"],"text":"“What context is actually retrieved from the index to answer the questions?”","_key":"1f8f598586540"}],"level":1,"_type":"block"},{"_key":"1c4a8c3c98f0","listItem":"bullet","markDefs":[],"children":[{"_key":"900b4b4814040","_type":"span","marks":["em"],"text":"“How is chat memory managed?”"}],"level":1,"_type":"block","style":"normal"},{"markDefs":[],"children":[{"_type":"span","marks":["em"],"text":"“Which steps add the most latency to the overall execution? How to optimize it?”","_key":"aa28b5e32a210"}],"level":1,"_type":"block","style":"normal","_key":"6669d05c85ae","listItem":"bullet"},{"children":[{"_key":"548875927cbb0","_type":"span","marks":[],"text":"One-click OSS observability to the rescue"}],"_type":"block","style":"h2","_key":"9a614e2e3b66","markDefs":[]},{"_type":"youtubeVideo","videoId":"4PZbb9XwG2o","_key":"16dc787ef86c"},{"children":[{"_type":"span","marks":[],"text":"We integrated Langfuse to be a one-click integration with LlamaIndex using the global callback manager.","_key":"98bf7227925b0"}],"_type":"block","style":"normal","_key":"12b97ed88884","markDefs":[]},{"style":"normal","_key":"fb40e1687c0c","markDefs":[],"children":[{"_key":"f6f3dae157c80","_type":"span","marks":[],"text":""}],"_type":"block"},{"markDefs":[],"children":[{"_type":"span","marks":[],"text":"Preparation","_key":"fd98aa7475130"}],"_type":"block","style":"normal","_key":"929a9611e01a"},{"listItem":"number","markDefs":[],"children":[{"_type":"span","marks":[],"text":"Install the community package (pip install llama-index-callbacks-langfuse)","_key":"e0442ac40b480"}],"level":1,"_type":"block","style":"normal","_key":"5d4a4acb9434"},{"markDefs":[],"children":[{"_type":"span","marks":[],"text":"Copy/paste the environment variables from the Langfuse project settings to your Python project: 'LANGFUSE_SECRET_KEY', 'LANGFUSE_PUBLIC_KEY' and 'LANGFUSE_HOST'","_key":"60cf4ec8fcb80"}],"level":1,"_type":"block","style":"normal","_key":"8948884ac868","listItem":"number"},{"children":[{"_key":"b7172622cebd0","_type":"span","marks":[],"text":""}],"_type":"block","style":"normal","_key":"36c1bb4503ea","markDefs":[]},{"style":"normal","_key":"743952b060c4","markDefs":[],"children":[{"marks":[],"text":"Now, you only need to set the global langfuse handler:","_key":"295a647cea870","_type":"span"}],"_type":"block"},{"code":"from llama_index.core import set_global_handler\n\nset_global_handler(\"langfuse\")","_type":"codeBlock","language":"python","_key":"4993f102afba"},{"_type":"block","style":"normal","_key":"3b0893cc0786","markDefs":[],"children":[{"_type":"span","marks":[],"text":"And voilá, with just two lines of code you get detailed traces for all aspects of your RAG application in Langfuse. They automatically include latency and usage/cost breakdowns.","_key":"83f06bb52b450"}]},{"_type":"image","_key":"3debd5813c02","asset":{"_ref":"image-2e38fd76d589eed1dd66af785879e73b22eb7877-1999x1319-png","_type":"reference"}},{"children":[{"_type":"span","marks":[],"text":"Group multiple chat threads into a session","_key":"2f5832d9e95d0"}],"_type":"block","style":"h2","_key":"8271fa4c30a2","markDefs":[]},{"_key":"645c9038bc07","markDefs":[{"href":"https://langfuse.com/docs/tracing/sessions","_key":"1bf6dd6bccba","_type":"link"}],"children":[{"_type":"span","marks":[],"text":"Working with lots of teams building GenAI/LLM/RAG applications, we’ve continuously added more features that are useful to debug and improve these applications. One example is ","_key":"d72fc7f7eeec0"},{"marks":["1bf6dd6bccba"],"text":"session tracking","_key":"d72fc7f7eeec1","_type":"span"},{"_type":"span","marks":[],"text":" for conversational applications to see the traces in context of a full message thread.","_key":"d72fc7f7eeec2"}],"_type":"block","style":"normal"},{"_key":"1a0c4424e86e","markDefs":[],"children":[{"_type":"span","marks":[],"text":"","_key":"53e3b89411460"}],"_type":"block","style":"normal"},{"markDefs":[],"children":[{"marks":[],"text":"To activate it, just add an id that identifies the session as a trace param before calling the chat_engine.","_key":"6f04a155d5fb0","_type":"span"}],"_type":"block","style":"normal","_key":"1e35fc160f7d"},{"language":"python","_key":"9e7d4e04506d","code":"from llama_index.core import global_handler\n\nglobal_handler.set_trace_params(\n  session_id=\"your-session-id\"\n)\n\nchat_engine.chat(\"What did he do growing up?\")\nchat_engine.chat(\"What did he do at USC?\")\nchat_engine.chat(\"How old is he?\")","_type":"codeBlock"},{"_type":"block","style":"normal","_key":"1f7249646346","markDefs":[],"children":[{"_type":"span","marks":[],"text":"Thereby you can see all these chat invocations grouped into a session view in Langfuse Tracing:","_key":"ba058c48e9f50"}]},{"_type":"image","_key":"5313655f5522","asset":{"_ref":"image-89c4bc95018b0441487cc0f48d8f1b42e5d008e6-1999x1258-png","_type":"reference"}},{"_type":"block","style":"normal","_key":"bbd1242fb49a","markDefs":[],"children":[{"marks":[],"text":"Next to sessions, you can also track individual users or add tags and metadata to your Langfuse traces.","_key":"08db2c82a1360","_type":"span"}]},{"_key":"585a8f02c391","markDefs":[],"children":[{"_type":"span","marks":[],"text":"Trace more complex applications and use other Langfuse features for prompt management and evaluation","_key":"5e186a5e77230"}],"_type":"block","style":"h2"},{"_type":"block","style":"normal","_key":"94928f97b5d1","markDefs":[],"children":[{"_type":"span","marks":[],"text":"This integration makes it easy to get started with Tracing. If your application ends up growing into using custom logic or other frameworks/packages, all Langfuse integrations are fully interoperable.","_key":"1fee7e6363640"}]},{"markDefs":[],"children":[{"_type":"span","marks":[],"text":"","_key":"d9c5fba828ce0"}],"_type":"block","style":"normal","_key":"2f48b153c55a"},{"_key":"9da13d1f5352","markDefs":[{"_type":"link","href":"https://langfuse.com/docs/prompts/get-started","_key":"3b7b0a196b66"},{"_type":"link","href":"https://langfuse.com/docs/experimentation","_key":"fd765c7d7679"},{"_key":"aaa9f489e1a1","_type":"link","href":"https://langfuse.com/docs/scores/overview"},{"_key":"51ede0d2fbce","_type":"link","href":"https://langfuse.com/docs/scores/model-based-evals/ragas"}],"children":[{"_key":"623395edb8460","_type":"span","marks":[],"text":"We have also built additional features to version control and collaborate on prompts (langfuse "},{"_type":"span","marks":["3b7b0a196b66"],"text":"prompt management","_key":"623395edb8461"},{"text":"), track ","_key":"623395edb8462","_type":"span","marks":[]},{"_type":"span","marks":["fd765c7d7679"],"text":"experiments","_key":"623395edb8463"},{"_type":"span","marks":[],"text":", and ","_key":"623395edb8464"},{"_type":"span","marks":["aaa9f489e1a1"],"text":"evaluate","_key":"623395edb8465"},{"_type":"span","marks":[],"text":" production traces. For RAG specifically, we collaborated with the RAGAS team and it’s easy to run their popular eval suite on traces captured with Langfuse (see ","_key":"623395edb8466"},{"_type":"span","marks":["51ede0d2fbce"],"text":"cookbook","_key":"623395edb8467"},{"_type":"span","marks":[],"text":").","_key":"623395edb8468"}],"_type":"block","style":"normal"},{"style":"h2","_key":"70f4e951660e","markDefs":[],"children":[{"_type":"span","marks":[],"text":"Get started","_key":"550fd694cd6b0"}],"_type":"block"},{"children":[{"_type":"span","marks":[],"text":"The easiest way to get started is to follow the ","_key":"223c9ebe68430"},{"_key":"223c9ebe68431","_type":"span","marks":["8b315027176f"],"text":"cookbook"},{"_key":"223c9ebe68432","_type":"span","marks":[],"text":" and check out the "},{"text":"docs","_key":"223c9ebe68433","_type":"span","marks":["2869cb43aa87"]},{"_type":"span","marks":[],"text":".","_key":"223c9ebe68434"}],"_type":"block","style":"normal","_key":"8f94808a9a2a","markDefs":[{"_type":"link","href":"https://docs.llamaindex.ai/en/stable/examples/callbacks/LangfuseCallbackHandler.html","_key":"8b315027176f"},{"_type":"link","href":"https://langfuse.com/docs/integrations/llama-index/get-started","_key":"2869cb43aa87"}]},{"style":"h2","_key":"54c8327c032e","markDefs":[],"children":[{"marks":[],"text":"Feedback? Ping us","_key":"9300659ddd330","_type":"span"}],"_type":"block"},{"children":[{"_type":"span","marks":[],"text":"We’d love to hear any feedback. Come join us on our ","_key":"57cb181133460"},{"_type":"span","marks":["5fac86b91965"],"text":"community discord","_key":"57cb181133461"},{"text":" or add your thoughts to this ","_key":"57cb181133462","_type":"span","marks":[]},{"_type":"span","marks":["bfef4a5a959a"],"text":"GitHub thread","_key":"57cb181133463"},{"_type":"span","marks":[],"text":".","_key":"57cb181133464"}],"_type":"block","style":"normal","_key":"512a62bc478f","markDefs":[{"_type":"link","href":"https://langfuse.com/discord","_key":"5fac86b91965"},{"_key":"bfef4a5a959a","_type":"link","href":"https://github.com/orgs/langfuse/discussions/828"}]},{"_key":"077cfb91083c","markDefs":[],"children":[{"_type":"span","marks":[],"text":"\n","_key":"b3c0736411180"}],"_type":"block","style":"normal"}]},"params":{"slug":"one-click-open-source-rag-observability-with-langfuse"},"draftMode":false,"token":""},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"one-click-open-source-rag-observability-with-langfuse"},"buildId":"pGBlFmtqp0g680plY_OVM","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>