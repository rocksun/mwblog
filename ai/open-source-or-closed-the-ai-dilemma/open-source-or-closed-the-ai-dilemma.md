
<!--
title: 开源还是闭源？人工智能的困境
cover: https://cdn.thenewstack.io/media/2024/07/6219faea-landscape-4701725_1280.jpg
-->

在一个公平的世界里，开源和开放模型应该仍然是一种选择，而闭源应该仍然是一种权利。

> 译自 [Open Source or Closed? The AI Dilemma](https://thenewstack.io/open-source-or-closed-the-ai-dilemma/)，作者 Keith Pijanowski。

[人工智能](https://thenewstack.io/ai/) 正在软件行业掀起一场完美风暴，现在 [马克·扎克伯格呼吁](https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/) 开源人工智能。三种强大的观点正在碰撞，关于如何控制人工智能：

1. 所有人工智能都应该开源，以实现共享和透明。
2. 保持人工智能闭源，并允许大型科技公司控制它。
3. 制定人工智能使用法规。

这场辩论之所以棘手，是因为存在一些事实。首先，即使你拥有模型的源代码，你也完全不知道模型的行为方式。[人工智能的开放性](https://thenewstack.io/open-source-ai-osi-wrestles-with-a-definition/) 需要的不仅仅是提供 [源代码](https://thenewstack.io/back-to-the-basics-understanding-source-code/)。其次，人工智能有多种形式，可以用来解决各种各样的问题。

从用于欺诈检测和目标广告的传统人工智能到用于创建聊天机器人的生成式人工智能，这些聊天机器人在表面上产生类似人类的结果，将我们越来越接近最终（也是可怕的）目标——人工通用智能（AGI）。最后，上面列出的控制人工智能的想法都已被证明可以改善软件的整体发展。

## 了解不同的观点

让我们更详细地讨论上面列出的不同观点。

**观点 #1 — 所有人工智能都应该开源，以实现共享和透明：** 这源于对人工智能透明度的推动。开源是一种经过验证的共享和改进软件的方法。当用于传统软件时，它提供了完全的透明度。开源软件推动了软件行业飞速发展。

**观点 #2 — 保持人工智能闭源，并允许大型科技公司控制它：** 闭源或专有软件是指一项发明可以保密，远离竞争对手，以最大限度地提高经济收益。对于开源理想主义者来说，这听起来简直是邪恶的；然而，这更多是一种哲学选择，而不是存在于善恶谱系上的选择。大多数软件都是专有的，这本身并不坏——它是竞争和健康生态系统的基础。任何创造新事物的发明者都有权选择闭源路径。问题是，如果你在没有透明度的情况下运作，如何保证负责任的人工智能？

**观点 #3 — 制定人工智能使用法规：** 这来自立法者和民选官员推动监管。基本理念是，如果一项公共功能或技术过于强大，以至于不良行为者或不负责任的管理可能会损害公众利益，那么应该任命一个政府机构来制定控制措施并执行这些控制措施。有一种观点认为，人工智能领域的现有领导者也希望进行监管，但他们的理由并不那么纯粹——他们希望冻结竞争环境，让他们处于领先地位。我们将主要关注公共利益领域。

## 开源的本质

在生成式人工智能出现之前，数据中心运行的大多数软件都是传统的。如果你拥有传统软件的源代码，你可以准确地确定它的功能。精通相应编程语言的工程师可以审查代码并确定其逻辑。你甚至可以修改它并改变它的行为。开源（或开源代码）是另一种说法——我将提供确定行为和改变行为所需的一切。简而言之，开源软件的本质是提供理解软件行为并改变它的所有必要信息。

为了使模型完全开放，你需要训练数据、模型的源代码、训练期间使用的超参数，当然还有训练后的模型本身，它包含数十亿（很快将是数万亿）个参数，这些参数存储着模型的知识——也称为参数记忆。现在，一些组织只提供模型，将其他所有东西都保留给自己，并声称它是“开源”。这种做法被称为“开源洗白”，通常被开源和闭源社区视为不诚实。我希望看到一个新的术语用于部分共享的人工智能模型。也许是“部分开放模型”或“来自开源洗白公司的模型”。

关于完全共享模型，还有一个最终的难题。假设一个组织想要做正确的事情，并分享模型的全部内容——训练数据、源代码、超参数和训练后的模型。你仍然无法准确地确定它的行为，除非你对其进行广泛的测试。决定行为的参数化内存不是人类可读的。同样，行业需要一个不同的术语来描述完全开放的模型。这个术语应该不同于“开源”，后者只应该用于非人工智能软件，因为模型的源代码无助于确定模型的行为。也许“开放模型”更合适。

## 常规论点
让我们看看一些支持只使用前面描述的其中一种观点的常见论点。这些观点的拥护者都充满热情，但这种热情可能会影响判断。

论点：封闭式人工智能的支持者声称，大型科技公司有能力防范潜在的危险和滥用。因此，人工智能应该保持私密，不要进入开源社区。

反驳：大型科技公司有能力防范潜在的滥用，但这并不意味着他们会明智地或完全做到这一点。此外，还有其他目标需要考虑。他们的主要目的是为股东赚钱，这将永远优先于其他目标。

论点：那些认为人工智能可能像人类一样构成威胁的人喜欢问：“你会开源曼哈顿计划吗？”

反驳：这是一个关于治理的论点。然而，这是一个不公平且不正确的类比。曼哈顿计划的目的是在战时利用放射性材料进行核聚变来制造炸弹。核聚变不是一种可以应用于不同任务的通用技术。你可以制造炸弹和发电——仅此而已。其成分和结果对公众构成危险，因此所有方面都应该受到监管。人工智能则大不相同。如上所述，它有各种各样的形式，风险也各不相同。

论点：支持开源人工智能的人说，开源有利于科学共享，提供透明度，并防止少数人垄断一项强大的技术。

反驳：这在很大程度上是正确的，但并不完全正确。开源确实提供了共享。对于人工智能模型来说，它只会提供一定程度的透明度。最后，是否“开放模型”能够防止少数人垄断他们的权力还有待商榷。要像 ChatGPT 一样大规模运行模型，你必须进行计算，而只有少数公司能够获得这种计算能力。

## 多数人的需求胜过少数人的需求

在《星际迷航 II：可汗的愤怒》中，史波克死于辐射中毒。史波克意识到必须修理飞船的主引擎才能逃生，但引擎室被致命的辐射淹没。尽管有危险，史波克还是进入充满辐射的舱室进行必要的修理。他成功地恢复了曲速引擎，使企业号能够到达安全距离。不幸的是，瓦肯人对辐射并不免疫。他临死前对柯克船长解释了他行动背后的逻辑：“多数人的需求胜过少数人或个人的需求。”

这完全是合理的逻辑，必须用来控制人工智能。某些模型对公众构成风险。对于这些模型，公众的需求胜过创新者的权利。

## 所有人工智能都应该开源吗？'

让我们回顾一下迄今为止确立的公理：

- 开源应该仍然是一种选择。
- 开放模型不像开源的非人工智能软件那样透明。
- 闭源是创新者的权利。
- 无法保证大型科技公司会正确控制他们的 AI。
- 公众的需求必须优先于所有其他需求。

以上五个要点代表了我试图阐明关于开源、闭源和监管的所有内容。如果你认为它们是准确的，那么“所有人工智能都应该开源吗？”这个问题的答案是否定的，因为这既不能控制人工智能，也不能控制闭源。此外，在一个公平的世界里，开源和开放模型应该仍然是一种选择，而闭源应该仍然是一种权利。

我们可以更进一步，谈谈整个行业可以采取的行动，以朝着有效控制人工智能的方向发展：

- 确定对公众构成风险的模型类型。由于它们控制信息（聊天机器人）或危险资源（自动驾驶汽车），因此具有高风险的模型应该受到监管。
- 应该鼓励组织将他们的模型作为完全开放的模型进行共享。开源社区需要站出来，要么阻止要么标记那些只部分共享的模型。开源社区还应该制定测试，用于对模型进行评级。
- 如果封闭模型不构成对公众的风险，则应允许其继续存在。大型科技公司应开发其控制措施和测试，并为其提供资金和共享。这可能是大型科技公司与开源社区密切合作解决共同问题的机会。

