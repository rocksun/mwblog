# 数据尊严：开发者必须解决 AI 归属问题

翻译自 [Data Dignity: Developers Must Solve the AI Attribution Problem](https://thenewstack.io/data-dignity-developers-must-solve-the-ai-attribution-problem/) 。

人工智能正在欺骗我们。本文研究归属问题以及开发人员社区如何通过元数据解决方案来解决这个问题。

![](https://cdn.thenewstack.io/media/2023/05/ab145ca4-lion-g812430828_1280-1024x682.jpg)
*图片来自Pixabay*

人类提供的数据可以被视为为人工智能提供动力的一种劳动形式;[《经济学人》](https://www.economist.com/the-world-if/2018/07/07/data-workers-of-the-world-unite)。

除了对人工智能接管世界的略微非理性的恐惧之外，还有一个更具体的问题是人工智能欺骗你；这篇文章着眼于归因问题以及开发社区可能参与解决这些问题的方式。

现在有三个问题汇合在一起，可能迫使我们改变使用网络的方式：

1. 相信我们的个人数据和创建的媒体已被大公司滥用；
2. 新的 GPT 风格的 AI，可以从网络上拖网大量用户数据；和
3. 事实上，我们目前没有一致的数字化方式来记载谁写了什么。

你的社交关系网在为公司提供燃料已经有一段时间了，但现在的新问题是文本、图像和视频很快就可以被 AI “混合”使用，而原作者几乎没有机会得到署名。与此相比，看看音乐行业如何对待 80 年代的少数嘻哈艺术家“借鉴”现有音轨。他们偶尔会遭受谴责，甚至被起诉。但这些轻罪是以人类的速度，在少数情况下，在聚光灯下发生的。 [Midjourney](https://www.midjourney.com/) 可以每小时使用 [ArtStation](https://www.artstation.com/) 上发现的图像产生数百个新图像，而艺术家甚至不知道。如今， Dr. Dre 这样的人物已经被公认为体制的一部分——他支付任何应得的版税。

## 什么是数据尊严？

“数据尊严”是一场运动，产生于生成式 AI 出现之前，与著名技术评论家 [Jaron Lanier](https://www.newyorker.com/science/annals-of-artificial-intelligence/there-is-no-ai) 密切相关。该理论认为，当使用关于个人的数据或重组个人创造的数据时，经济体应该作出调整以补偿这些人。这些想法的驱动力在于“免费”在线经济在认可或报酬方面已经是一个灾难。很明显，生成式 AI 将使这个立场变得更加糟糕。

在本文中，我们关注的不是信息自由流动，而是有关那些信息的信息(元数据)-以及防止它成为失物。所以我提倡的是，为保留这种旅行主题，给信息加上行李标签。还有一些可靠的行李搬运工。

以网络上的任何文档为例；以及文档中的一段引言。如果这段引言后来出现在其他地方，没有简单的自动化方式可以获取该文档的作者，或确保该引言被正确归属于作者。因此,当 GPT AI 将两个不同的段落合并在一起时，原文的来源就彻底丢失了。

相比之下，Twitter 的结构旨在记载发推人的作者，甚至转推人转推的推文的作者。与推文关联的元数据(除词语外与推文创作相关的所有内容)不仅仅是作者；它还包括时间、位置、语言和唯一的 Id 。既然 Twitter 可以工作，我们为什么让网络走错路?

在 2000 年代， Semantic Web 被提议作为万维网的改进版本。目标是创建一个网络，智能代理能够使用注入的元数据来理解网页的内容，为人类提供有用的服务或与其他智能代理进行交互。

不幸的是， Semantic Web 项目本质上一直是学术性的。拟议的向网页添加元数据的语言难以使用。2000 年代初的推理引擎很慢。正如我们将在下面看到的，元数据通常是搜索引擎优化（SEO）的武器，而不是真理之剑。元数据本身不是静态的——它可能会老化，需要维护。另一个问题来自 JSON 的诞生和令人眩晕的崛起。对于 Semantic Web 来说，这有点太晚了，所以使用了 JSON 的较旧（也更丑陋）的继姐 XML 。但我们应该接受该项目的目的是好的。

## 如何解决问题

有三种基本途径可以将意义注入网络，并帮助解决归属问题：

1. 让 AI 创建和维护元数据。
2. 使用更好的工具和协议将有用且一致的元数据重新注入 Web。
3. 将元数据透明地粘贴到云中。

这些都不是相互排斥的。我们知道，目前，ChatGPT 不喜欢使用网络来增强其训练数据，尽管我希望如果它理解自己的建议，它将很容易找到给定文档的作者：

![](https://cdn.thenewstack.io/media/2023/05/ed6e8714-untitled-1024x434.png)

谷歌似乎已经可以做到这一点，即使它没有吹嘘解决方案：

![](https://cdn.thenewstack.io/media/2023/05/62aac49c-untitled-1-1024x420.png)

请注意，作者显然是以粗体选择的，就像搜索结果一样。

如果我们只是让几家大公司形成大量关于一切的元数据，以便他们的 LLM 可以正确训练，那么我们可以要求这些公司使用人工智能来跟踪归属。这似乎是一件合理的事情，但如果没有监督，我们将永远无法确定在实现这一目标时存储了多少元数据。

##  文档中的元数据

网页具有以标记形式免费存储元数据的内置功能，而不会扭曲它们呈现的信息。事实上， HTML 的目的是使用元数据来增强信息。在您现在正在阅读的文档内，您可能会找到以下标签：

```html
<meta name="author" content="David Eastman" class="yoast-seo-meta-tag">
```

此元数据指向（在本例中）我自己是作者。这就是为什么人工智能不必太聪明就能知道这篇文章是谁写的。但是我们立即被提醒，我们目前添加元数据的原因几乎总是为了服务于 SEO 。

在 Jaron 的文章中寻找相同的信息怎么样？问题是不存在共同的模型或“牛路径”。因此，我们发现的元数据并不完全符合我们的预期：

```html
<meta name="author" content="Condé Nast">
```

幸运的是，在同一文档中，我们还可以找到：

```html
<meta property="article:author" content="Jaron Lanier">
```

因此，即使在提供相同服务的平台之间也存在流沙。这些结果来自非常负责任和稳定的出版物。这里的解决方案是让开发人员进行更多的沟通，就类似行业的通用标准达成一致，并在可能的情况下将网络的稳定性置于其他考虑因素之前。当然，这说起来容易。

## API 解决方案

一个简单的 REST 解决方案可以在大多数内容平台中实现。您可以在 HTML 中查询此站点以获取作者；例如，此查询将使用 “https://thenewstack.io/author/david-eastman/” 生成我的文章。虽然，你需要知道我名字的表述，并接受一些早期的文章不会出现。更有用的是以 RESTful 的方式提取任何给定文章的作者（以及其他元数据）。

```
https://thenewstack.io/how-to-software/query?metadata=author
```

上面只是使用自然的 REST 查询接口，尽管它可以在一个更简洁的公式中实现——我们想要的只是“返回名为 how-to-software 的帖子的作者”。

因此，如果您正在为任何内容平台设计 REST API，请确保用户可以在他们有权访问的任何页面上获取元数据。

## 将信息存储在其他位置

元数据也可以收集并放置在中立的存储库中。这将允许第三方处理元数据，同时允许适当的公众访问元数据。

例如，有许多公司将使用 AI 来进行内容审核——它们可能会试图向现有的可疑媒体添加元数据上下文。提出 AI 视频审核的一家初创公司的例子是 [unitary.ai](https://www.notion.so/What-has-AI-ever-done-for-us-7c5fb6b772af4d079244ba077bf3c77a) 。讽刺的是，这是反过来的问题——不是确保媒体保留归属，而是向原本希望留在暗处的媒体添加元数据。如果元数据位于中立位置，用户不必接受平台对所有审核问题的最终定夺。

同样，试图使用生成 AI 的受监管行业可能会与合规中间件互动，以避免在用户响应中损害已认可的合规标准。似乎有理由将规则和生成的元数据以开放和可访问的方式保留。很明显，这里的开发挑战是设计架构和标准来解决这些问题。

因此，公平生成人工智能的未来确实取决于开发社区是否愿意提供大量方法来保留归属，否则人工智能将花费大部分时间与法律系统聊天。
