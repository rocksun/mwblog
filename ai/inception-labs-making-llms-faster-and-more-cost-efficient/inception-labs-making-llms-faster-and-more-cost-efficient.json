{"url":"https://thenewstack.io/inception-labs-making-llms-faster-and-more-cost-efficient/","title":"Inception Labs: Making LLMs Faster and More Cost-Efficient","author":"Alex Williams","summary":"","cover":"https://cdn.thenewstack.io/media/2025/12/97f308b5-mercury-speed-2.jpg","zh_title":"始源实验室：大模型极速提效，成本锐减！","zh_summary":"Karpathy 赞誉 Inception 扩散模型。它并行生成词元，比传统 LLM 快 5-10 倍。尤其适用于编码和语音等实时应用，Inception 提供 API 且具成本效益。"}