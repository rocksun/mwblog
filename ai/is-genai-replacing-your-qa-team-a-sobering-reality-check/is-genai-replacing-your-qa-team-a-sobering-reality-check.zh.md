围绕生成式人工智能（GenAI）的炒作声浪震耳欲聋，尤其是在软件开发生命周期（SDLC）和质量保证（QA）领域。供应商们承诺将带来革命性的变化，声称 AI 代理将取代整个团队。但作为开发者和技术领导者，我们需要以一种务实的态度来对待这股浪潮，专注于建立信任和寻找真正的价值，而不是追逐那些最终沦为昂贵摆设的炒作周期。

说实话：尽管演示令人惊叹，但 GenAI 尚未*从根本上*改变诸如测试用例生成、测试数据管理、缺陷分类或脚本维护等核心 QA 流程——至少目前还没有。许多工具过度承诺，难以应对 LLM 固有的挑战，如幻觉和非确定性结果。这些不是小 bug；它们是可靠回归测试的致命缺陷，尤其是在受监管的环境中。任何声称他们的工具今天可以完全取代人工测试人员的人，坦率地说，都是在兜售庸医的药。

围绕 Agentic AI 的最新炒作周期已将泡沫推向了新的高度，承诺提供更多的功能，而没有认识到 Agent 并不能改变 LLM 的根本局限性。如果说 LLM 就像和一个拥有百科全书的蹒跚学步的孩子交谈，那么 AI Agent 实际上是让这个孩子可以使用整个工具棚（包括电锯和草叉）。这个流行语具有催眠作用，这些功能也很酷，但这些协议太新了，甚至没有围绕安全性的基本保护措施。

当涉及到集成[任何新技术](https://thenewstack.io/3-benefits-of-technology-integrations-in-cloud-security/)时，尤其是像 GenAI 这样具有颠覆性的技术时，信任是关键——尤其是对于天生持怀疑态度的 QA 团队（这是他们的工作！）。忽视他们的担忧或无视当前 AI 工具的局限性会适得其反，并削弱信任。相反，要坦诚地说明风险、收益和缺点。承认 LLM 已知的问题，并让你的团队自由地探索、实验，并找出如何使用这些强大但有缺陷的工具。让他们在定义与 AI 的关系中拥有自主权。

## 建立信任：AI 集成的基础

建立信任也需要严格的道德准则。首要任务是：除非你的雇主明确授权，否则不要在向云托管 LLM 发出的查询中使用客户数据。客户数据受到非常具体的条款和条件的保护，并且大型 AI 供应商被视为第三方子处理者（需要披露）。数据暴露和不准确、虚构的洞察力的风险太高。生成定制的测试数据（也许使用由模式引导的 LLM）或使用经过彻底匿名处理的数据（需经过严格审查）来代替。发布明确的 AI 使用政策，维护批准的工具和子处理者列表，并提供定期培训以加强负责任的做法。

那么，GenAI *现在*可以在哪里提供价值呢？忘记取代 QA 核心的批判性思维和风险分析。相反，专注于消除苦差事和增强人类的能力。我的指导原则一直是：[“首先自动化那些无聊的事情。”](https://thenewstack.io/automate-the-boring-stuff-with-kubernetes/) 考虑一下那些会分散注意力并导致上下文切换延迟的繁琐任务：生成项目脚手架、编写样板配置、总结大量的测试结果、创建错误报告的初稿（带有屏幕截图、视频和日志），甚至帮助解读复杂的遗留测试脚本。

[氛围编程是真实存在的](https://thenewstack.io/vibe-coding-in-a-post-ide-world-why-agentic-ai-is-the-real-disruption/)，但在某个时候，我运行的每个会话都更多地是关于与 LLM 正在做的疯狂事情作斗争，而不是构建你的软件。对于初级开发人员来说，这可能是一个冒险的主张：如果你不知道好代码和坏代码之间的区别，你就无法审查和纠正它所犯的错误。

我最近使用氛围编程编写了一个 [Python 脚本来桥接 GitLab 的 GraphQL API](https://thenewstack.io/getting-started-with-the-deepl-language-translation-api-in-python/) 和 Snowflake——通过迭代提示和改进，这项原本需要数天才能完成的任务在数小时内变得可以管理。它可以成为一个出色的头脑风暴伙伴，帮助克服创建测试计划时的写作障碍，或者迫使人们更周到地考虑风险。[开发人员正在成功地](https://thenewstack.io/mindset-refactor-evolving-for-developer-success/)使用 GenAI 来生成单元测试、组件测试和 API 测试——在这些领域，测试通常更具确定性和独立性。从理论上讲，Agentic AI 可以为我创建和执行这些脚本，而[无需知道它们是如何工作的](https://thenewstack.io/vector-databases-what-devs-need-to-know-about-how-they-work/)。我还不愿意对这些工具投入如此多的信任。

但该项目是一个一次性脚本，而不是需要长期维护的软件。为了使用氛围编程来编写测试自动化项目，你需要确保你了解你正在使用的 LLM 的局限性和优势，并且你进行定期提交，以防出现问题。测试[自动化代码往往需要](https://thenewstack.io/platform-teams-automate-infrastructure-requirement-gathering/)抽象和仔细的规划，以实现低维护脚本。氛围编程仍然无法胜任为你完成这种程度的工作——它更适合一次性的工作。

这种“增强，而非自动化”的方法改变了我们整合工具的方式：不要要求 AI 成为测试人员，而是要求它：

* 分析测试结果并查明测试失败的原因（UI 更改？API 错误？性能滞后？）
* 帮助根据风险和过去的结果优化测试执行策略。
* 识别测试覆盖率的差距和重叠。
* 促进更好的跨团队沟通，也许通过 [API 契约测试](https://thenewstack.io/reining-in-the-api-wild-west-5-api-testing-best-practices/) 来及早发现重大变更，从而支持协作而不是指责。

## 生成式 AI 在质量保证中的真正 ROI

GenAI 在 QA 中的真正 ROI 可能不会来自人员缩减，尽管一些管理人员可能希望或供应商可能承诺的那样。它将来自使团队能够通过消除苦差事、提供更好的洞察力以及释放人类专家专注于解决复杂问题和战略风险管理来更快地交付更高质量的软件。

GenAI 的前景尚不成熟，尤其是在其与 SDLC 的集成方面。许多工具将会失败。准备好批判性地评估并丢弃那些无法在初始演示之外提供持续价值的工具。注意供应商锁定，并寻找遵循标准的工具（代理的 MCP，生态系统的 A2A）。如果可能，首选开源。不要让采用 AI 的冲动导致你低估了 QA 不可替代的工艺。

通过欣然接受 GenAI 的局限性以及它的能力，专注于信任，并针对正确的问题——苦差事、乏味、耗时——我们可以利用它的能力来真正增强，而不仅仅是颠覆我们构建和交付软件的方式。