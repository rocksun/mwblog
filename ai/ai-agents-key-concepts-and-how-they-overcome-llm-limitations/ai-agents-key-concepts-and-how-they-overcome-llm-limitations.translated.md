# AI 代理：关键概念及如何克服 LLM 限制

![AI 代理：关键概念及如何克服 LLM 限制的特色图片](https://cdn.thenewstack.io/media/2024/06/504e8243-allison-saeng-burzgf1rio8-unsplash-1024x768.jpg)

随着大型语言模型 (LLM) 变得更加强大，一种被称为“代理”的新型软件应运而生，以增强和提升 LLM 的能力。本文介绍了代理的关键概念以及它们如何补充 LLM。

自基于 GPT 3.5 的 ChatGPT 初次发布以来，[大型语言模型](https://thenewstack.io/what-is-a-large-language-model/) 已经发展成熟。一些最近发布的版本（如 [GPT-4o](https://openai.com/index/hello-gpt-4o/)、[Gemini Pro](https://deepmind.google/technologies/gemini/pro/) 和 [Claude Opus](https://www.anthropic.com/news/claude-3-family) 模型）甚至展示了高级推理能力。[开放语言模型](https://thenewstack.io/large-language-models-open-source-llms-in-2023/) 领域近年来也一直在快速发展。这些 LLM 的多个变体已发布，可用于私有环境中。在推理和回答复杂问题方面，一些开放语言模型（如 [Mistral](https://docs.mistral.ai/getting-started/models/) 和 [Llama 3](https://llama.meta.com/llama3/)）与商业模型不相上下。所有这些都是 AI 代理趋势的驱动力。

## 什么是 AI 代理？

代理是一种自主软件实体，它利用 LLM 的语言处理能力来执行超出简单文本生成和理解的广泛任务。这些代理通过纳入与数字环境交互、基于从 LLM 得出的语言理解做出决策和执行操作的机制来扩展 LLM 的功能。

在操作系统环境中，将 LLM 视为内核，将代理视为程序。

代理在很大程度上依赖 LLM 进行推理，同时通过添加新功能来增强 LLM 的功能。

LLM 有几个限制，代理试图克服这些限制。我们来看看其中的一些限制。

## LLM 的限制

**LLM 没有记忆**

类似于 REST API 调用，调用 LLM 完全是无状态的。与 LLM 的每次交互都是独立的，这意味着该模型本质上不会记住先前的交流或建立在先前的对话之上。此限制影响了长期交互的连续性和连贯性，因为该模型无法利用历史背景来为未来的响应提供信息。LLM 的无状态特性要求每个输入都必须完全自包含，从而导致在扩展用例中重复或不连贯的交互。

**LLM 调用是同步的**

LLM 以同步方式运行，这意味着它们一次顺序地处理和响应每个输入。此同步操作意味着该模型必须完成对给定输入的响应，然后才能处理下一个输入。这种顺序处理在需要实时交互或同时处理多个查询的场景中可能是一个限制，因为它不能固有地并行处理不同的输入。

**LLM 可能产生幻觉**

LLM 可能会产生[幻觉](https://thenewstack.io/how-to-reduce-the-hallucinations-from-large-language-models/)，即模型生成的事实上不正确或荒谬的信息的实例。这种现象发生是因为 LLM 是在包含互联网文本的庞大数据集上进行训练的，它们学习的是模式和相关性，而不是事实准确性。因此，它们可以捏造细节或自信地提供虚假信息，营造出知识的错觉。

**LLM 无法访问互联网**

LLM 无法浏览网络或调用网络服务，因此它们仅限于其接受训练的数据，并且没有能力实时从实时网络源检索或验证信息。此限制意味着它们的响应仅基于嵌入其中的现有知识，这些知识对于实时查询可能不是最新的或在上下文中不相关的。因此，LLM 无法提供当前新闻更新、访问最新研究或从动态在线数据库中提取数据，这使得它们在需要最新信息的任务中的使用效果较差。

**LLM 在数学方面很差**
### 大型语言模型的局限性

大型语言模型在处理数学任务时往往表现不佳，尤其是那些需要精确计算或复杂问题解决的任务。这种限制的出现是因为大型语言模型主要被设计为基于从大量文本数据集中学习到的模式来理解和生成自然语言。虽然它们可以执行简单的算术运算并遵循基本的数学规则，但它们解决更复杂的数学问题或确保多步骤计算准确性的能力是有限的。它们通常缺乏执行高级数学运算所需的结构化逻辑推理。

**大型语言模型具有非确定性输出**

大型语言模型在数据格式和结构方面表现出非确定性输出，这意味着相同的输入每次处理时都会产生不同的输出。这种可变性源于支撑大型语言模型的算法的概率性质，该算法根据学习到的模式而不是确定性规则从一系列可能的响应中进行选择。因此，输出的格式和结构可能不同，这使得难以获得一致的结果，特别是对于需要响应格式统一的应用程序，例如自动报告生成、表单填写或数据提取。

## 代理如何增强大型语言模型？

代理弥合了传统软件开发工具和大型语言模型之间的差距，这有助于解决或缓解上述一些限制。

例如，通过集成诸如网络浏览和代码执行环境之类的工具，代理可以在大型语言模型分析和生成详细响应之前将真实世界数据与复杂计算相结合。

在操作系统上下文中，将大型语言模型视为内核，将代理视为程序。外壳由代理执行任务所需的工具和支持服务组成。代理通过将大型语言模型与完成任务所需的工具和外部服务连接起来来增强其功能。

让我们了解代理在增强大型语言模型能力中的作用。

**记忆和上下文保留**

与无状态且不保留先前交互记忆的大型语言模型不同，代理可以合并记忆机制来记住过去的交互并在其基础上进行构建。这使代理能够在长期参与中保持连续性和连贯性，利用历史背景为未来的响应提供信息。此功能通过创建更个性化和与上下文相关的交互来增强用户体验。

**异步和并行处理**

虽然大型语言模型同步且顺序地处理输入，但代理可以同时管理多个任务并异步操作。这种并行化进程的能力使代理能够更有效地处理实时交互，提高在需要同时处理多个查询或任务的场景中的效率和响应能力。

**事实核查和实时信息访问**

代理可以通过合并实时数据验证和访问外部信息源来减轻大型语言模型中的幻觉问题。通过连接到互联网或特定数据库，代理可以验证大型语言模型生成的信息，确保准确性并减少虚假或误导性输出的发生。这使得代理在需要最新且精确信息的应用程序中特别有价值。

**增强的数学能力**

代理可以集成专门的数学引擎或软件来处理复杂的计算和问题解决任务，弥补大型语言模型的数学弱点。这种集成允许代理执行精确且可靠的数学运算，扩展它们在技术和科学领域的实用性。

**一致的输出格式**

为了解决大型语言模型输出的非确定性，代理可以实施后处理步骤来标准化响应的格式和结构。例如，它们可以强制大型语言模型的输出始终以 JSON 或 XML 格式化。通过确保数据呈现的一致性，代理可以提高在需要统一性的应用程序（例如报告生成和数据提取）中的输出可靠性。

**角色驱动的交互**

代理通过利用记忆和个性化功能来增强与大型语言模型的角色驱动交互，从而创造出更定制化和引人入胜的用户体验。通过在多个交互中保持上下文，代理可以调整响应以符合用户的偏好、历史和会话风格——有效地模拟一个一致的角色。这种个性化方法不仅提高了用户满意度，还允许代理提供更相关和与上下文相关的帮助。代理可以根据用户反馈和过去的交互动态调整其行为，使对话感觉更自然和更像人类。

## 摘要
**更正后的 Markdown 格式：**

大型语言模型已显著发展，GPT-4o 和 Gemini 1.5 等模型就是例证。然而，它们仍然是无状态的，按顺序处理输入，可能出现幻觉，缺乏实时数据访问，难以处理复杂的数学问题，并且产生非确定性输出。

人工智能代理通过整合用于上下文保留的记忆机制、异步管理任务和实时验证信息来增强大型语言模型，从而提高准确性和连贯性。它们还集成了专门的数学引擎并标准化了输出格式，使其在各种应用程序中更可靠、更高效。

[YouTube.com/TheNewStack](https://youtube.com/thenewstack?sub_confirmation=1)

技术发展迅速，不要错过任何一集。订阅我们的 YouTube 频道以流式传输我们所有的播客、访谈、演示等。