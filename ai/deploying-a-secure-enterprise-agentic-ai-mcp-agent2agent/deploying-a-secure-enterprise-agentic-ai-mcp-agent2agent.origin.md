# Deploying A Secure Enterprise Agentic AI: MCP + Agent2Agent
![Featued image for: Deploying A Secure Enterprise Agentic AI: MCP + Agent2Agent](https://cdn.thenewstack.io/media/2025/06/ad46897a-teodor-skrebnev-x9qktlqucco-unsplash-1-1024x683.jpg)
[Teodor Skrebnev](https://unsplash.com/@teodor__pl?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)on
[Unsplash](https://unsplash.com/photos/a-laptop-computer-sitting-on-top-of-a-desk-X9qKtLqucCo?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash).
The introduction of LLMs, AI agents, and their evolving ecosystem of tooling like [Model Context Protocol (MCP)](https://www.anthropic.com/news/model-context-protocol) has opened the doors to a variety of new use cases. Still, they present unique challenges to secure in production, leaving us with many unanswered questions about how we will create safe and secure applications for our users.

I encountered some of those questions when our team first began exploring MCP and its applications. We asked ourselves questions like, “The MCP spec doesn’t say exactly what we should do for auth… so how should we think about it?” We wondered about the best way to provide API keys, what a remote server would look like in the future, and how different clients and their LLMs would interpret and utilize the tools we provide through our server.

This article explores the key risks inherent in using LLMs, how we perceive those risks changing with the introduction of new standards like MCP, and how we are thinking about secure and scalable agentic architectures with even newer ones, such as [Agent2Agent (A2A)](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/).

## How Did We Get Here?
In security evaluations, we often consider two concepts: **Attack Surface, **the number of places in your system that are vulnerable to exploitation by attackers and **Blast Radius**, the impact a successful attack can have on your system. LLMs have exploded in popularity recently with flexibility and promises of an automated world, but they also bring vulnerable attack surfaces when added to our applications. Basic chatbots broaden our attack surface by accepting and reasoning over untrusted natural language provided by the user. Because of the non-deterministic nature of LLMs, there is a lack of predictability of output and limited ability to reproduce issues for diagnostics. Thus, we also cannot fully be sure of the potential harm created by its answers, increasing our blast radius. As early adopters building our own agentic platform, the team faced a variety of new security challenges, with the most well-known being [Prompt Injections](https://genai.owasp.org/llmrisk/llm01-prompt-injection/) and [Jailbreaks](https://www.bugcrowd.com/blog/ai-deep-dive-llm-jailbreaking/), both facilitated by untrusted content fed to the LLM, designed to cause unintended actions or responses.

Then came agents. Agentic AI ramps up the complexity and risk factor by introducing more privileged interactions with APIs and data. Now, we can introduce more intelligent systems that use tools and knowledge sources. Agents work with APIs, connect with data sources (some from the public internet), maybe even talk to other [agents or be managed by another AI](https://thenewstack.io/agentic-ai-for-enterprises-4-key-benefits-driving-innovation/) agent supervisor. However, if you extend our logic of attack surface and blast radius, you can see how the problem compounds as we add more untrusted content passed between components. [Indirect prompt injections](https://cetas.turing.ac.uk/publications/indirect-prompt-injection-generative-ais-greatest-security-flaw) can be passed through websites crawled for the LLMs knowledge, lying in wait for just the right user query to activate it. DNS records for a tool’s domain could [trick a host machine](https://github.blog/security/application-security/localhost-dangers-cors-and-dns-rebinding/) into accessing services on its own local network. Unfortunate targets may experience data exfiltration or remote code execution.

Not that we haven’t seen similar vulnerabilities before, but the change in architectural landscape can be disorienting at first, requiring new ways of thinking about security. To make this vision of a more secure agentic flow possible, we have MCP and Agent2Agent frameworks. While MCP focuses on creating access to tools, A2A focuses on interoperability between agents.

## What Can We Do About It?
Below, we highlight three key vulnerabilities we think are important through our work with MCP and how to address them (details follow below):

**Cross-Server Leakage and Sensitive Data Exposure:**One of the benefits of MCP is that your application/agent/client can gather up everything it needs to complete a request, maybe from more than one MCP server, and pass those off to the LLM(s) (single or multiple vendors) for processing. This implicitly risks the exposure of resources within one server to another. We suggest that enterprises that want to expose their tools to these clients leverage agents to do so instead of MCP servers directly so that they can maintain control and protect themselves from data exposure.**Authentication and Authorization:**MCP lacks a mechanism for common authentication of users such as OIDC or SSO and makes it possible to bypass authorization requirements across resources (aka:[The Confused Deputy](https://en.wikipedia.org/wiki/Confused_deputy_problem)). Hence, we suggest separating the authentication and authorization layer such that you can use your existing control plane infrastructure to identify users and agents, ensuring they always have proper credentials for the data they are acting upon. A2A conveniently helps here as a client agent implementing the protocol can discover the other agent’s authentication scheme through the agent card. This allows enterprises to make progress while exploring alternative approaches for maintaining and[managing agent identities](https://thenewstack.io/ai-agents-are-redefining-the-future-of-identity-and-access-management/).**Prompt Injections and Jailbreaks:**MCP clients and their LLMs are susceptible to prompt injection and jailbreak attacks from other connected MCP servers. For both clients and servers, knowing that your tools and resources are trustworthy is critically important. Detection strategies at the A2A server layer to decrease the likelihood of these attacks being successful would work well. A2A isn’t the only architecture choice here, any agent pattern that is protected from direct inputs and outputs will provide the space for implementing detection strategies.
As you have read through the above, it has probably become obvious to you that, in essence, a mesh of agent architecture could address a lot of these challenges versus having to leverage MCP servers or A2A specifically.

We further elaborate on these risks and our recommendations below for those who want to understand them with examples. Our guiding principle in this exploration was to ensure that we can build [secure systems for our customers](https://thenewstack.io/customer-facing-incidents-on-the-rise-it-leaders-say/) without making the architecture too complex to scale. As enterprises look to adopt these frameworks to accelerate their own AI innovations, we are hoping that we will collectively do this without risking the security of our users.

### 1. Cross-Server Leakage and Sensitive Data Exposure
MCP is magic the first time you use it. Watching your agent figure out how to interact with an API and use it to achieve the task is pretty cool, it really does give vibes of the future. Should we expand our agent and give it access to more servers? Well, unfortunately, there’s a risk of one server [interacting](https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks) with another. The problem here is the agent can mix together components from each server, [allowing them to potentially see into and access things](https://thenewstack.io/10-things-to-consider-when-allowing-access-to-production/) they shouldn’t. This cross-server access also [opens up our attack surface and our blast radius](https://thenewstack.io/how-supply-chain-attackers-maximize-their-blast-radius/).

![](https://cdn.thenewstack.io/media/2025/06/db60787c-image3-1024x484.png)
Multiple MCP servers create a potentially dangerous mixing of privileged access to data.

A2A helps address this problem by introducing a layer of abstraction between your application and connected MCP servers. It introduces an agent interface that exposes Tasks, acting as a trusted delegate by hiding its own access to MCP servers, protecting you from exposing privileged data to other connected servers within your application. This does not completely eliminate the risk, as you could always theoretically encounter malicious activity hidden behind an agent, but it helps prevent eavesdropping and unintended resource usage from other MCP servers.

![](https://cdn.thenewstack.io/media/2025/06/4d66c8b8-image1-1024x852.png)
A2A agents delegate access to MCP resources, limiting the direct exposure to other agents and servers.

### 2. Authentication and Authorization
[MCP servers are mostly run locally](https://thenewstack.io/how-to-access-local-mcp-servers-through-a-secure-tunnel/) today but will be remote over time such that your agent can connect to it over standard HTTPS. MCP currently suggests using OAuth for authorization, but lacks authentication commonly used by enterprises for identification such as OpenID Connect, Single Sign-On, or SAML. A2A allows for this missing authentication and enables flexible authorization architectures to ensure our users and agents are acting in a trusted manner.
A2A servers provide authentication and authorization options through standard exchanges and expect the client and server to negotiate this on their own. The agent card provides fields for what type of authentication is required for access, with authorization fields planned for addition into the spec. With A2A, we don’t need to make that many changes with how we do things today to broaden our options from what MCP offers. Maybe your company uses OpenID for employee logins and you want to make sure that they authenticate with this system before allowing any agents to perform authorized actions on their behalf. MCP on its own can’t help you there much today.

Regarding identity, one specific addition we should make is separating the agent identity from user identity. A user should authenticate with your system, but the agent representing that user should also be uniquely identified for authorization purposes. There may be differences in authorization permissions between a user and their authorized agent. The A2A server should verify every request for authorization requirements on the tools and resources it selects for the task, ensuring that unauthorized access is not possible through permission abuse and that both the agent and the user it represents have the correct scope of permissions.

[Abstractions](https://developers.cloudflare.com/agents/model-context-protocol/authorization/#3-bring-your-own-oauth-provider) are already being built and offered as a service to circumvent some of these limitations with MCP, but they are still experimental. A more straightforward path forward may be the standard flows you’re already using.
### 3. Prompt Injection and Jailbreaks
We can’t really have a security discussion about LLMs without running into [prompt injections](https://genai.owasp.org/llmrisk/llm01-prompt-injection/) and jailbreaks. They are the two most talked about vulnerabilities within agentic applications and are often involved in facilitating other attacks. LLMs are impressionable and relatively easy to trick. Unless guarded by systems that can inspect untrusted inputs and outputs, applications run the risk of performing unintended actions through altered instructions that will be interpreted by the LLM.

Because prompt injections are so prevalent, isolating and inspecting any untrusted input to the LLM is critical. With MCP, our attack surface and blast radius increase quite a bit compared to bespoke agents with predictable tools and resources. We can’t really trust that multiple connected MCP servers won’t update a safe looking tool to include injections later without you knowing or that they won’t provide resources that include prompt injection instructions that attempt cross-server access.

It is possible to mitigate this issue through scanning of tools, runtime verification and implementing injection detection on any untrusted input before sending it to the LLM.

With A2A though, our agent server can act as the first and last line of defense against injections. Our interface with the outside world in this architecture limits the attack surface presented by injections from other servers. We can employ standard input and output guardrails at the entry point to our agent server or wherever it makes sense in the request flow. We also protect our users from being compromised by other servers, as the A2A server controls the tools and resources the agent will be exposed to for completing its task.

*Vinnie Giarrusso, Principal Full Stack Developer at Twilio also contributed to this article.*
[
YOUTUBE.COM/THENEWSTACK
Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.
](https://youtube.com/thenewstack?sub_confirmation=1)