<!--
title: 面对AI灭世主义：智能并非全部
cover: https://cdn.thenewstack.io/media/2023/12/26cf79a9-oxides-bryan-cantrill-speaking-at-monktoberfest-2023-intelligence-is-not-enough-1024x581.png
-->

AI灭世主义者早就迷失在一种伪装成贝叶斯分析的宗教当中。这是Oxide公司CTO在接受TNS采访时说的。

> 译自 [Bryan Cantrill on AI Doomerism: Intelligence Is Not Enough](https://thenewstack.io/bryan-cantrill-on-ai-doomerism-intelligence-is-not-enough/)，作者 David Cassel 是旧金山湾区的自豪居民，他已在那里报道技术新闻二十多年。多年来，他的文章出现在从 CNN、MSNBC 和华尔街日报互动版等地方......

当历史学家回顾我们这个时代时，他们会看到一个面临新技术的物种。他们会看到新的关注点，甚至有人会提出存在主义的恐惧——AI 可能会灭绝人类。

但是，他们可能也会记住其他的事情。一个人[站在缅因州波特兰的舞台上](https://www.youtube.com/watch？v=bQfJi7rjuEk)，捍卫人类的荣誉，因为人类拥有 AI 永远无法复制的独特属性。

就像威廉·福克纳（William Faulkner）[曾说过](https://www.nobelprize.org/prizes/literature/1949/faulkner/speech/)的那样，人性不仅会持续，还会获胜。

这种防御来自 [Bryan Cantrill](https://thenewstack.io/joyent-historical-perspective-future-containers/)，[Oxide 计算机公司](https://thenewstack.io/oxide-launches-the-worlds-first-commercial-cloud-computer/)的联合创始人兼首席技术官。在第 11 届年度“[Monktoberfest](https://monktoberfest.com/faq/)” 开发者大会上——一个“检查社会趋势和技术交叉点”的开发者大会上，Cantrill 针对高度假设的“存在主义威胁”场景吐露了自己的强烈感受。在一次电子邮件采访中，Cantrill 告诉我们：“我的演讲不是针对 AI 灭世主义者的。”

“他们早已经消失在一种伪装成贝叶斯分析的宗教中。”

在缅因州的波特兰，他告诉他的听众，这次演讲是被“一大群互联网垃圾煽动的，我被它们让人难以置信的激怒的......”

## AI 将如何灭绝人类

AI 将如何确切地灭绝人类？Cantrill 摒弃了一些常见的建议场景，因为它们的依据荒谬莫名，甚至可笑。(“你不能说一个计算机程序将会控制核武器。”)

好吧，但是如果 AI 以某种方式开发出了新型生物武器呢？“我认为这反映了对生物武器有多复杂的某种误解。”要是一个超级智能 AI 开发出了新型分子纳米技术呢？

“我不好意思说，在意识到所有的东西都没有被简化为实践之前，我读完了一整本关于纳米技术的书......所有这些实际上都是假设的。”

> “正如每当涉及到 AI 接管世界的时候，我女儿喜欢说的：‘它没有手臂或腿。'”

Cantrill 然后对他认为荒谬的假说做出了更简短的反应：“天啊。纳米技术又回来了。”

Cantrill 乐于展示他对灭绝人类的 AI 的怀疑态度，并指出即使作为一个假说，它也提出了“数以亿计的问题”。例如，为什么那会是 AI 的动机？它从哪里获得生产手段？ “正如每当涉及到 AI 接管世界的时候，我女儿喜欢说的：‘它没有手臂或腿。'”

Cantrill 详细阐述，逗乐了观众。“当你想杀死所有人类时，缺乏手臂和腿变得真正关键。”

那么 AI 到底如何应对人类反抗的威胁？“老实说，幻想一下有点好玩......” Cantrill 说。“你能想象如果我们都联合起来与计算机程序作斗争会怎么样吗？”想一想，如果全人类集中各种力量挫败一段单一的软件故障，那将是什么景象。

“那会很棒!”

## 软件是核武器吗？

AI 灭世主义的一个例子是一位善意的人，根据 Cantrill 的描述，他“不情愿地支持暂停所有 AI——AI 令人恐惧，我们必须暂停所有 AI 研究”。

9月，AI 助手公司 [Lindy](https://www.lindy.ai/) 的创始人 [Flo Crivello](https://www.linkedin.com/in/florentcrivello) 在一条推文中论证说，“智能是世界上最强大的力量......而我们正要在不太过思考的情况下向地球上的每一个人提供核武器......”

Crivello 还认为“没有提供任何实质性的反对存在主义风险的论证”，并嘲笑AI 支持者是“不慎重的人”。

首先，Cantrill 对这种场景中的慎重的人上推特发帖“将计算机程序与核武器等同”感到冒犯。而这些所谓认真的人士已经走得如此之远，以至于扔掉了自己对我们“灭亡概率”的评估——也就是对全人类的完全湮灭。

“我们能对我们共同的祖先有点更多的敬畏吗？”

但是 Cantrill 认为，这种“夸张”和无依据的假设本身可能会导致可怕的场景。例如，AI 开发的暂停将是“目中无人的权威主义。这是必须的。” Cantrill 首先指出，即使是“限制计算机程序能做什么也相当吓人，违反了许多人认为的自然权利”。

在这条向下的滑坡路上，就像一个幻灯片指出的，“伴随着的言论往往令人不安地暴力”。一些认为 AI 对人类构成存在主义威胁的人然后可以证明实际的人类保护暴力行为。

在 Cantrill 看来，认为人类存在存在主义威胁会导致人们说“我们应该控制 GPU。那些违反 GPU 国际禁运的人呢？是的，我们应该轰炸他们的数据中心。事实上，我们应该先发制人地打击他们的数据中心。”

Cantrill 嘲笑这是一种反应过度，全部是“因为一个计算机程序”。如果这个辩论中需要一个“严肃的”反驳，Cantrill 自己就提出了一个。

“请不要轰炸数据中心。”

## AI 无法做到的事情

Cantrill 的演讲题目是“智力还不够：工程的人性化”。

这里听众意识到他们正在聆听一家刚推出[全新服务器架构的公司](https://thenewstack.io/oxide-launches-the-worlds-first-commercial-cloud-computer/)自豪的 CTO 的演讲。“我想关注实际进行工程所需要的......我确实有一些最近构建某些非常大和非常难的集体工程实践的经验......”

分享一个来自现实世界的故事，Cantrill 铺上了他们完成的服务器的图片，然后讲述了来自所有可怕故事中最可怕的反乌托邦：生产。

- 他们花了几周时间调试一个拒绝重置的 CPU——最后发现问题是他们供应商固件中的一个错误。
- 另一个星期花在一个也不会重置的网络接口控制器上。同样，他们的供应商出了错——这涉及到其一个关键电阻器的规格。
- 甚至有一个时间期间他们后来称为“数据损坏周”——当损坏开始零星出现在他们的操作系统引导镜像中。(一张幻灯片解释了难以置信的晦涩原因：他们的微处理器“通过一个搭便车的早期引导中的映射进行投机性加载”)。Cantrill 说只有一个孤独的人类通过直觉知道该往哪看。“正是他们的好奇心引领他们找到了表面下燃烧的煤火。”

重要的是，这些错误的共同点是“新出现”的属性——实际上不是设计到部件中的东西，而是把它们组合在一起时出现的。“对于每一个，都没有任何文档。事实上，对于其中几个，文档是积极不正确的。文档会误导你......突破往往是一些不应该工作的东西。

“一些超级智能存在不会建议的东西。”

Cantrill 放上一张幻灯片，写着“仅有智力并不能解决这样的问题”，展示了他在 Oxide 的团队拥有某些独特的人性。“我们解决这些问题的能力与我们作为一个团队的集体智慧无关......”他告诉他的听众。“我们必须调动我们性格的要素。不是我们的智力——我们的韧性。”

“我们的团队精神。我们的严谨。我们的乐观主义。”

Cantrill 说他确信你(人类)的工程师也一样......

他强调了他演讲的关键点。“这些是人的属性。” 当我们招聘时，我们不仅考虑智力——而是寻求协作和团队精神，最重要的是共同的价值观。“这种对智力的着迷来自那些诚实地说不太外出的人。”

“他们需要多动手做事，比如照顾孩子，远足......”

## 一个深刻的真理

Cantrill 得出了他所说的一个深刻的真理：“智力很伟大；但它不是全部。这里有人性。”

需要澄清 AI 对工程师而言仍然有用，但缺乏三个关键属性：意志力、欲望和驱动力。“当我们假装它们可以自主工程时，我们是在损害我们自己的人性。” Cantrill说。

“它们不能。我们人类可以......”

虽然 Cantrill 认为人类灭绝的风险太小，不值得担心，但他承认确实存在真正的风险。但是“坏消息，” Cantrill 说。“这是你已经知道的风险......是种族主义。是经济失业。是阶级——就是我们作为人类永恒以来一直在应对的所有问题。”

“AI 是这些问题的力量乘数，我们需要非常非常认真地对待它。因为 AI 将被滥用——已经在被滥用。AI 伦理非常重要。”

Cantrill 指出，这里有一线希望。已经有关于核武器、生物武器研究甚至自动驾驶汽车等事物的现成法律法规和整个监管体系。“让我们执行它们......” Cantrill说。“用你的恐惧来推动执行法规。”

但这使得反对他认为过度炒作的“AI 悲观主义”变得更加重要。正如 Cantrill 在[最近的一篇博文](https://bcantrill.dtrace.org/2023/11/26/what-punch-cards-teach-us-about-ai-risk/)中所说，“AI 会自主地毁灭人类的恐惧比无稽之谈更糟，因为它们会使我们忽视 AI 可能被滥用的非常实际的可能性。”

在他的演讲中，Cantrill 甚至暗示人们秘密上更喜欢思考一个夸大的反乌托邦，“我们反正都会灭绝......所以像‘我们都会在奇点之后......我们实际上不在乎这个世界。'”

“我们中有些人确实在乎这个星球、这生活和这个世界。这就是我们生活的世界。

“我们不应该让恐惧——未指定的、非具体的恐惧——阻止我们使这个世界变得更好。”
