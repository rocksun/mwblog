
<!--
title: AI重塑科技，微软等公司重新调整开发架构
cover: https://cdn.thenewstack.io/media/2025/01/cfd53e53-curated-lifestyle-zgye7fcyk38-unsplash.jpg
-->

微软将AI和开发者团队整合到新的CoreAI部门，标志着这家科技巨头在人工智能时代软件开发方法的根本转变。

> 译自 [As AI Reshapes Tech, Microsoft, Others Refocus Dev Structure](https://thenewstack.io/as-ai-reshapes-tech-microsoft-others-refocus-dev-structure/)，作者 Darryl K Taft。

AI对软件组织的影响巨大，以至于微软等大型公司正在进行组织变革以跟上[AI革命](https://thenewstack.io/how-the-genai-revolution-reminds-us-of-1990s-computing/)的步伐。

微软本周宣布了一项重大的组织变革，创建了一个名为“[CoreAI——平台和工具](https://blogs.microsoft.com/blog/2025/01/13/introducing-core-ai-platform-and-tools/)”的新工程部门，以应对AI技术的快速发展。

在一份[致微软员工的备忘录](https://blogs.microsoft.com/blog/2025/01/13/introducing-core-ai-platform-and-tools/)中，微软董事长兼首席执行官[Satya Nadella](https://www.linkedin.com/in/satyanadella/)表示，他认为2025年将成为[AI应用](https://thenewstack.io/top-7-tools-for-building-multimodal-ai-applications/)的关键一年，并指出：“与以往任何平台转变相比，应用堆栈的每一层都将受到影响。这就像同时将GUI、互联网服务器和云原生数据库引入应用程序堆栈一样。三十年的变化被压缩到三年内！”

## 整合团队

Nadella写道，新的组织将整合几个现有团队，包括微软的开发者部门、AI平台以及来自首席技术官办公室的一些关键团队（AI超级计算机、AI自主运行时和工程发展）。

微软正在应对一种在过去一年中持续发展的趋势，这种趋势已从将AI视为一项科学努力转变为将其视为一项工程机遇。

Omdia的分析师[Brad Shimmin](https://www.linkedin.com/in/bradshimmin/)表示：“由于像微软Azure OpenAI服务这样的AI服务的成本和复杂性都非常低，数据科学家和企业应用程序开发人员都一直在强烈要求通过API访问AI成果。”

他补充说：“鉴于像微软自己的[AutoGen](https://thenewstack.io/microsoft-builds-autogen-studio-for-ai-agent-prototyping/)这样的支持框架的快速成熟以及与[.NET](https://thenewstack.io/herodevs-throws-net-6-users-a-post-deprecation-lifeline/)的直接连接，开发人员现在可以导入和调用AI API服务来执行命名实体提取或图像识别等任务，而无需了解这些服务背后的任何科学知识。”

## 新使命

新的微软Core AI和工具团队的使命是为客户构建端到端的Copilot和AI堆栈，以构建和运行AI应用程序和代理。Nadella说，该团队还将负责构建[GitHub Copilot](https://thenewstack.io/github-copilot-a-powerful-controversial-autocomplete-for-developers/)，“从而在领先的AI优先产品和AI平台之间形成紧密的反馈循环，以推动堆栈及其路线图”。

此外，微软“将构建具有内存、权限和动作空间的自主应用程序，这些应用程序将继承强大的模型能力，”Nadella写道。他还写道：“此外，我们为这些AI应用程序构建、部署和维护代码的方式也正在发生根本性的变化，并变得自主。”

Nadella表示，此次重组反映了微软对新的“AI优先应用程序堆栈”的愿景，该堆栈将具有新的UI/UX模式、基于代理的运行时以及重新设计的管理和可观察性层，并以Azure作为基本的AI基础设施。

“……Azure必须成为AI的基础设施，而我们将在此基础上构建我们的AI平台和开发者工具——涵盖Azure AI Foundry、GitHub和[VS Code](https://thenewstack.io/microsoft-makes-github-copilot-free-in-vs-code/)。换句话说，我们的AI平台和工具将共同创建代理，而这些代理将共同改变每个SaaS应用程序类别，并且自定义应用程序的构建将由软件驱动（即‘服务即软件’），”Nadella写道。

## 代理的力量

Arcjet首席执行官[David Mytton](https://www.linkedin.com/in/davidmytton/)告诉The New Stack，代理是他认为此次重组中最重要的方面。

他说：“[GitHub Copilot Workspace](https://githubnext.com/projects/copilot-workspace)已经这样做了一段时间了，它也通过[Copilot Edits](https://code.visualstudio.com/docs/copilot/copilot-edits)进入了VS Code。”“这就是他们正在准备的——2025年是多步骤代理的一年。先从Copilot入手，然后扩展到其他微软应用程序是有意义的。”

此外，Mytton指出，Meta首席执行官预测2025年代理将成为中级工程师同事，“所以微软改变其组织结构听起来像是这类结构变化的领先指标，”他说。


## AI无处不在

“AI无处不在。AI存在于开发工具中，所以它在GitHub中。AI拥有自己的工具，它存在于应用程序中，以及与API对话的代理中，所以它存在于Visual Studio和VS Code中。AI无处不在，并非孤岛，”Blue Badge Insights首席执行官告诉The New Stack。“因此，AI平台和开发部门走到一起是合情合理的。”

然而，“最终，如果微软正确地使用AI，它将不那么离散，而更像堆栈每个部分的元素。我认为我们还没有达到那个阶段，而且我确信还会有更多重组，但这一个是有道理的。它使AI摆脱了孵化期的隔离，使其成为开发人员主流的一部分，这反映了整个行业最终的发展方向。”


## 主要参与者

将领导这个团队，担任CoreAI——平台和工具的执行副总裁（EVP）。AI平台的企业副总裁；AI基础设施的企业副总裁兼首席技术官副手；开发部门总裁；以及开发基础设施的企业副总裁，以及他们各自的团队将向Parikh汇报。“在过去几年中，我们将GitHub Copilot集成到Visual Studio系列和Azure中，我们已经看到AI将如何颠覆应用程序和开发人员体验，”在LinkedIn帖子中写道。“将所有这些整合到一个集中的努力中将加速我们在这一领域的能量。”

此外，Parikh将与云+AI集团执行副总裁、体验+设备执行副总裁；安全执行副总裁；微软AI首席执行官；以及微软首席技术官密切合作，以优化整个微软技术堆栈，Nadella说。

Nadella补充说，Guthrie将继续领导云+AI，专注于云基础设施的增长，使其成为微软最大的业务部门。

“微软意识到AI正在改变一切并相应地进行重组，这是一个好兆头，”Constellation Research的分析师告诉The New Stack。“AI正在改变软件开发，因此AI平台和开发工具的合并是有意义的。但是，各部门之间需要大量的协调，因此Satya Nadella将其称为‘一个微软’也就不足为奇了。组织结构的转折点在于，这是Scott Guthrie第一次放弃产品责任。”


## 怀疑论的观点

微软对重组以利用技术创新并不陌生，此举也不例外，Intellyx的分析师告诉The New Stack。

“对于微软这样规模的任何供应商来说，将AI——特别是生成式AI——整合到产品线中都是有意义的。为了完成这项任务而进行重组是完全合理的，”他说。

然而，“戴上我的怀疑主义者的帽子，我想知道这里是否有更多炒作而不是实际内容，”Bloomberg说。“毕竟，微软之前已经走过‘代理AI’的道路了。还记得Clippy吗？你可以说此举的重点是构建‘加强版的Clippy’。真的有人想要那样吗？”


## 一个全新的软件开发时代

Omdia的Shimmin表示，他认为我们正在进入企业应用程序开发的新时代，这个时代将整个软件堆栈重新构想为一个功能更强大、更灵活的工具集，该工具集日益建立在代理系统之上。

“与其通过硬编码的命令式方法构建纯粹的确定性系统，我们似乎正在进入一个新的阶段，在这个阶段，开发人员使用更声明式的方法，专注于定义结果，而不是编写达到该结果所需的线性步骤。

他说：“总而言之，我认为我们从微软看到的是AI在企业软件开发堆栈中广泛应用的反映，我们认为这是必要的步骤，Salesforce去年年底通过其AgentForce平台的增强功能在某种程度上已经证明了这一点。”


## AI对其他企业供应商的影响

Meta的扎克伯格在[ Joe Rogan播客](https://www.youtube.com/watch?v=7k1ehaE0bdU&t=7687s)中提到，他觉得可以开始[使用自主式AI系统来替代他的中层工程师](https://www.businessinsider.com/mark-zuckerberg-meta-ai-replace-engineers-coders-joe-rogan-podcast-2025-1)。Salesforce的领导者[Marc Benioff](https://www.linkedin.com/in/marcbenioff/)在去年12月底也曾说过，出于同样的原因，他[不打算在2025年招聘“任何”工程师](https://www.windowscentral.com/software-apps/work-productivity/salesforce-is-seriously-debating-software-engineer-hires-in-2025)。

Shimmin说：“老实说，我认为这些大型科技公司有点操之过急。像[Cline](https://github.com/cline/cline)和[Aider](https://aider.chat/)这样的相对先进的自主编码助手当然可以构建可用的应用程序‘起点’，但我还没有看到它们积极地用于执行维护非常庞大、成熟的代码库的典型工作流程，这些工作流程超出了基本的文档、单元测试等等。”

他补充道：“如果这些系统确实能够帮助我们以接近Meta和Salesforce让我们相信的任何规模生成代码，那么我非常肯定，我们将面临巨大的补充需求，因为公司将争先恐后地招聘能够胜任的工程师，这些人不是为了取代被AI取代的人，而是为了维护AI构建的代码。让我们拭目以待。”


## Red Hat的方法

作为其应对AI新进展战略的一部分，[Red Hat](https://www.openshift.com/try?utm_content=inline+mention)本周[完成了对Neural Magic的收购](https://www.redhat.com/en/about/press-releases/red-hat-completes-acquisition-neural-magic-fuel-optimized-generative-ai-innovation-across-hybrid-cloud)，后者是加速GenAI推理工作负载的软件和算法的先驱。通过Neural Magic，Red Hat增加了推理性能工程和模型优化的专业知识。

该公司表示，借助Neural Magic的技术，Red Hat的目标是突破大规模企业AI的挑战，利用开源创新进一步普及AI的变革力量。

Neural Magic的功能将被整合到Red Hat AI中，Red Hat AI是Red Hat的生成式AI平台组合。Red Hat AI 考虑到混合云而构建，包含：

* [Red Hat Enterprise Linux AI (RHEL AI)](https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux/ai)，一个基础模型平台，可以更无缝地在Linux服务器部署中开发、测试和运行IBM Granite系列开源许可的LLM，用于企业应用程序；
* [Red Hat OpenShift AI](https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-ai)，一个AI平台，提供工具可在本地、公共云或边缘的分布式Kubernetes环境中快速开发、训练、服务和监控机器学习模型；以及
* [InstructLab](https://www.redhat.com/en/topics/ai/what-is-instructlab)，一个由Red Hat和IBM创建的易于使用的开源AI社区项目，使任何人都可以通过使用InstructLab的微调技术协作改进开源许可的Granite LLM来塑造生成式AI的未来。

IDC分析师Dave McCarthy在一份声明中表示：“Red Hat收购Neural Magic是对其AI能力的战略增强，通过利用Neural Magic在模型优化和推理加速方面的专业知识，促进了AI在混合云中的部署。此举不仅符合Red Hat对开源创新的承诺，而且使公司能够提供更具成本效益、可扩展的AI解决方案，从而减少对专用硬件的依赖。”
