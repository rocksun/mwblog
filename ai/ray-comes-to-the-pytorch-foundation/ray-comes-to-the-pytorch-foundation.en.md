The [PyTorch Foundation](https://pytorch.org/foundation/), the Linux Foundation-based open source AI organization, today announced that it will become the host of [Ray](https://github.com/ray-project/ray), the popular open source distributed computing framework for scaling AI and Python applications. The Ray project will join existing projects like PyTorch itself, the vLLM inference engine and deep learning optimization library DeepSpeed.

Ray was originally incubated in UC Berkeley’s [RISELab](https://rise.cs.berkeley.edu/people/). [Robert Nishihara](https://www.linkedin.com/in/robert-nishihara-b6465444/) and [Philipp Moritz](https://www.linkedin.com/in/philipp-moritz-61419682/), who were graduate students at the time, launched the project in 2016. Together with their professor (and Databricks co-founder) [Ion Stoica](https://www.linkedin.com/in/ionstoica/), they then decided to [found Anyscale](https://www.anyscale.com/press/founders-of-open-source-project-ray-launch-anyscale-with-usd-20-6m-in-funding-to-democratize-distributed-programmingfounders-of-open-source-project-ray-launch-anyscale-with-usd-20-6m-in-funding-to-democratize-distributed-programming) to commercialize their work. Since then, Anyscale has raised over $250 million and launched various products around Ray, and like most open source companies, it also offers a hosted platform that combines many of these services into an enterprise-ready platform.

The [core Ray project](https://docs.ray.io/en/latest/ray-core/walkthrough.html) itself provides the primitives (called tasks, actors and objects) for building distributed Python-based applications. It’s worth noting that the core piece of Ray isn’t limited to AI applications but can be used to scale any Python workload. But the Ray project also includes the AI-specific libraries for managing machine learning (ML) data sets and handling distributed training, as well as libraries for tuning and serving models. Ray also includes a library for [scaling reinforcement learning workloads](https://docs.ray.io/en/latest/rllib/index.html).

“At Ray, our goal is to make distributed computing as straightforward as writing Python code,” said Anyscale co-founder Nishihara. “Joining the PyTorch Foundation helps us stay true to that mission, ensuring Ray continues to be an open, community-driven backbone for developers and their organizations.”

Since its launch, Anyscale has independently maintained the Ray open source project (though it has occasionally been mislabeled “Apache Ray”).

[![](https://cdn.thenewstack.io/media/2025/10/b898508a-ray-stack.png)](https://cdn.thenewstack.io/media/2025/10/b898508a-ray-stack.png)

Image credit: Anyscale.

For the PyTorch Foundation, the addition of Ray means it now offers some of the most foundational open source projects for the AI ecosystem. There is PyTorch for model development, vLLM for inference and Ray for distributed execution, the Foundation argues.

“By bringing Ray under the PyTorch Foundation umbrella, alongside projects like vLLM and DeepSpeed, we are uniting the critical components needed to build next-generation AI systems. Ray’s inclusion strengthens our collective mission to support developers with the tools to efficiently train, serve, and deploy AI models at scale,” said [Matt White](https://www.linkedin.com/in/mdwdata/), the GM of AI at the Linux Foundation and executive director of the PyTorch Foundation.

[YOUTUBE.COM/THENEWSTACK

Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.

SUBSCRIBE](https://youtube.com/thenewstack?sub_confirmation=1)

Group
Created with Sketch.

[![](https://thenewstack.io/wp-content/uploads/2025/03/15a7eb12-cropped-4e88ac40-frederic-profile-2-600x600.jpg)

Before joining The New Stack as its senior editor for AI, Frederic was the enterprise editor at TechCrunch, where he covered everything from the rise of the cloud and the earliest days of Kubernetes to the advent of quantum computing....

Read more from Frederic Lardinois](https://thenewstack.io/author/frederic-lardinois/)