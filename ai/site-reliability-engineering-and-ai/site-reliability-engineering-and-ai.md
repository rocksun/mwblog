<!-- 
# SRE与AI
https://cdn.thenewstack.io/media/2023/11/dd9cb2d1-rope-1274372_1280-1024x682.jpg
 -->

译自 [Site Reliability Engineering and AI](https://thenewstack.io/site-reliability-engineering-and-ai/) 。

AI能够根据业务目标推荐更加贴合的标准和优先级，比任何一个人类团队都要快速高效。

当思考Site Reliability Engineering(SRE)以及使软件可靠的一般概念时，很容易看到AI可以发挥重要作用。像ChatGPT这样的大型语言模型已经可以在许多事件管理步骤中被利用。从更长远的角度来看，[更定制化的AI解决方案](https://thenewstack.io/embrace-ai-acceleration-by-investing-in-reliability/)可以彻底改变监控工具和服务水平目标的使用和解释方式。当然，从本质上讲，实践者的弹性才是可靠性的核心，而不是任何算法。但我们将探讨未来的AI如何增强这一核心优势。

让我们探讨这三个未来使用案例，同时深入研究在实施过程中您将面临的风险和挑战。

## 大型语言模型增强事件响应

当前AI工具中最强大的一类是[大语言模型](https://thenewstack.io/6-reasons-private-llms-are-key-for-enterprises/)(LLM)，如ChatGPT。LLM利用大量人类编写的文本来生成针对任何提示的有用响应。在快节奏、高压力的事件响应环境中，LLM可以用来消除苦差事和困惑的来源。

例如，假设一个故障服务生成了错误日志。看起来不错，但是日志可能有成千上万行，您并不确定要查找什么。在还有其他问题需要解决的时候，您真的没有时间手动扫描整个文档。只需要将数据提交给LLM，简单地要求它“突出显示和总结任何异常”，几秒钟内就可以得到结果。这可能不会给您整个故事，但会给您一个起点。

以下是LLM可以减少事件响应人员认知负荷的其他一些快速示例:

- 总结冗长的Slack对话，显示尝试了什么以及获得了什么结果，以帮助新响应人员快速上手。
- 分析代码库以回答自然语言请求，如“指出处理用户登录的所有代码行”。
- 快速创建临时脚本以帮助测试错误原因，如“制作一个尝试这些选项的所有排列组合的表单A的脚本”。

## 基于AI的事件响应存在风险

使用大型语言模型(LLM)加速敏感流程如事件响应将总伴随一定风险。LLM倾向于“幻视”，生成貌似合理但没有事实根据的数据。您越依赖它们，这些错误数据的影响就越隐蔽。但是如果您花费时间逐一验证AI的所有输出，就失去了速度和便捷性的优势。

关键是在AI辅助和事件管理流程之间取得平衡。在所有操作之上建立健全的流程可以最大限度减少潜在危害。事件管理平台为与AI工具实验提供了良好基础。

## AI视角提升监控和服务指标

现有AI模型利用海量人类生成的数据集如文本、图像和音频来创造每类数据的新示例。未来AI研究可能打开AI总结这些数据集知识(不仅内容)的潜力，以对新情况做出判断。这种“通用AI”的可能性在AI界存在很大争议。不管您的立场，不难想象新类型专用AI运用更有限的“视角”。

以[系统监控和服务指标](https://thenewstack.io/a-new-definition-of-reliability/)(SLO)为例，这是SRE领域两个常见难题。概念上它们很简单。系统监控就是观察系统输出以确保正常运行。SLO就是跟踪与客户满意度相关的服务组件指标，如“用户能否足够快、频繁、准确地搜索我们数据库以达成预期？”

实际上回答这些简单问题非常复杂。现有工具可以通过自动收集和跟踪相关数据来减少这一过程的繁琐。但是仍有主观成分需要有意义的人工参与。什么样算“足够快”？什么样算“足够健康”？得出这些答案需要对系统和用户有全面的整体视角，既了解业务需求又不受个人偏见影响。

AI可以帮助达到这个全面、客观的视角。不同于人类要克服对最熟悉系统领域的偏见，AI可以客观看待整个系统。它们可以在没有对用户“应该”做什么的预设的情况下分析大量用户数据。有了这种视角，它们可以比任何人类团队用更少时间和精力提出更符合业务目标的标准和优先级。

## 依赖AI视角的风险

归根结底，期望是一个可以分析大量业务数据和目标并提出建议的AI模型。拥有一个像有经验的人类一样出色且没有偏见的AI将是巨大成就。但人类仍可能出错。

降低这种风险的方法与现有的人为风险相同，即持续评估和学习。没有AI能准确预测一切，总会有改变“正确”答案的意外因素。制定明确目标如客户留存率或系统正常运行时间，然后评估标准和优先级是否达成目标，将永远是商业成功的必要组成部分。每次学习新知识也要传授给AI助手。

## AI助力人类适应力

工程师对AI的反应自然存在分歧。的确，短期来看，我们已经看到它减轻了许多任务的繁琐和认知负荷。但随之而来的是，许多组织目光短浅地试图裁员，希望剩下的工程师依靠AI弥补损失提高效率。看到未来AI可能承担更多战略和意义重大的工作，对职业不安全感和无目的感的担忧完全合理。

最坏情况，拥抱AI的组织可能面临大规模离职。这显然很糟，对服务可靠性影响可能灾难性。损失实践者的适应力远大于AI带来的任何益处。人类在可靠性工作中的适应力、灵活性和顽强精神无法被任何算法取代。

管理者需要明确，AI是可靠性解决方案的助力，不是替代品。重点应始终是赋能人类从事更有影响力和趣味的工作，AI则在后台处理繁琐任务。即使AI可能接手目前有影响力和趣味的工作，也要向工程师保证，他们将担任发挥人类独特优势的更具战略性和指导性的职位。工程师应被带到个人为组织做出贡献的最大潜力，而不是可以被优化掉的具体工作职能。

一旦工程师觉得自己作为人而不是统计指标或代码行的集合受到重视，他们就会真正具备适应力。AI学习工具可以帮助跨团队欣赏和对整个系统有更全面的视角。想象“请求每个服务领域的PowerPoint摘要，并按使用数据细分”并在几分钟内得到结果。工程师可以以更大的战略视角应对逆境，提高留存率和满意度。

总之，我们才刚刚开始发掘AI在可靠性领域的应用价值。在几年内，即使这些预测可能过于保守。重要的是投资于人和流程以降低AI革命带来的风险。就像过去的云迁移、微服务拆分、上线等改变游戏规则的举措，拥抱AI同样将带来挑战和机遇。我们希望您能积极面对。
