在这篇博文中，我们将探讨如何使用 [Ent](https://entgo.io), [Atlas](https://atlasgo.io), 和 [pgvector](https://github.com/pgvector/pgvector) 构建一个 [RAG](https://en.wikipedia.org/wiki/Retrieval-augmented_generation) (检索增强生成) 系统。

RAG 是一种通过结合检索步骤来增强生成模型能力的技术。我们不再仅仅依赖于模型内部的知识，而是可以从外部来源检索相关文档或数据，并使用这些信息来生成更准确、更符合上下文的响应。这种方法在构建诸如问答系统、聊天机器人或任何需要最新或特定领域知识的应用程序时特别有用。

### 设置 Ent schema{#setting-up-our-ent-schema}

让我们从初始化 Go 模块开始我们的教程，该模块将用于我们的项目：

```go
go mod init github.com/rotemtam/entrag # Feel free to replace the module path with your own
```

在这个项目中，我们将使用 [Ent](/), 一个 Go 的实体框架，来定义我们的数据库 schema。数据库将存储我们想要检索的文档（分块为固定大小）和表示每个块的向量。通过运行以下命令来初始化 Ent 项目：

```go
go run -mod=mod entgo.io/ent/cmd/ent new Embedding Chunk
```

此命令为我们的数据模型创建占位符。我们的项目应该如下所示：

```
ent
├── generate.go
├── schema
│   ├── chunk.go
│   └── embedding.go
├── go.mod
└── go.sum
```

接下来，让我们定义 `Chunk` 模型的 schema。打开 `ent/schema/chunk.go` 文件并按如下方式定义 schema：

```go
package schema

import (
	"entgo.io/ent"
	"entgo.io/ent/schema/edge"
	"entgo.io/ent/schema/field"
)

// Chunk holds the schema definition for the Chunk entity.
type Chunk struct {
	ent.Schema
}

// Fields of the Chunk.
func (Chunk) Fields() []ent.Field {
	return []ent.Field{
		field.String("path"),
		field.Int("nchunk"),
		field.Text("data"),
	}
}

// Edges of the Chunk.
func (Chunk) Edges() []ent.Edge {
	return []ent.Edge{
		edge.To("embedding", Embedding.Type).StorageKey(edge.Column("chunk_id")).Unique(),
	}
}
```

这个 schema 定义了一个 `Chunk` 实体，具有三个字段：`path`、`nchunk` 和 `data`。`path` 字段存储文档的路径，`nchunk` 存储块号，`data` 存储分块的文本数据。我们还定义了一个到 `Embedding` 实体的边，它将存储块的向量表示。

在继续之前，让我们安装 `pgvector` 包。`pgvector` 是一个 PostgreSQL 扩展，它提供对向量运算和相似性搜索的支持。我们将需要它来存储和检索我们块的向量表示。

```go
go get github.com/pgvector/pgvector-go
```

接下来，让我们定义 `Embedding` 模型的 schema。打开 `ent/schema/embedding.go` 文件并按如下方式定义 schema：

```go
package schema

import (
	"entgo.io/ent"
	"entgo.io/ent/dialect"
	"entgo.io/ent/dialect/entsql"
	"entgo.io/ent/schema/edge"
	"entgo.io/ent/schema/field"
	"entgo.io/ent/schema/index"
	"github.com/pgvector/pgvector-go"
)

// Embedding holds the schema definition for the Embedding entity.
type Embedding struct {
	ent.Schema
}

// Fields of the Embedding.
func (Embedding) Fields() []ent.Field {
	return []ent.Field{
		field.Other("embedding", pgvector.Vector{}).
			SchemaType(map[string]string{
				dialect.Postgres: "vector(1536)",
			}),
	}
}

// Edges of the Embedding.
func (Embedding) Edges() []ent.Edge {
	return []ent.Edge{
		edge.From("chunk", Chunk.Type).Ref("embedding").Unique().Required(),
	}
}

func (Embedding) Indexes() []ent.Index {
	return []ent.Index{
		index.Fields("embedding").
			Annotations(
				entsql.IndexType("hnsw"),
				entsql.OpClass("vector_l2_ops"),
			),
	}
}
```

这个 schema 定义了一个 `Embedding` 实体，它有一个类型为 `pgvector.Vector` 的字段 `embedding`。`embedding` 字段存储块的向量表示。我们还定义了一个到 `Chunk` 实体的边，以及一个在 `embedding` 字段上的索引，使用 `hnsw` 索引类型和 `vector_l2_ops` 运算符类。这个索引将使我们能够对嵌入执行高效的相似性搜索。

最后，让我们通过运行以下命令来生成 Ent 代码：

```go
go mod tidy
go generate ./...
```

Ent 将根据 schema 定义为我们的模型生成必要的代码。

### 设置数据库{#setting-up-the-database}

接下来，让我们设置 PostgreSQL 数据库。我们将使用 Docker 在本地运行 PostgreSQL 实例。由于我们需要 `pgvector` 扩展，我们将使用 `pgvector/pgvector:pg17` Docker 镜像，该镜像预装了该扩展。

```go
docker run --rm --name postgres -e POSTGRES_PASSWORD=pass -p 5432:5432 -d pgvector/pgvector:pg17
```

我们将使用 [Atlas](https://atlasgo.io), 一个与 Ent 集成的数据库 schema 即代码工具，来管理我们的数据库 schema。通过运行以下命令来安装 Atlas：

```go
curl -sSfL https://atlasgo.io/install.sh | sh
```
更多安装选项，请参阅 [Atlas 安装文档](https://atlasgo.io/getting-started#installation)。

由于我们将要管理扩展，因此我们需要一个 Atlas Pro 帐户。您可以通过运行以下命令注册免费试用版：

```
atlas login
```

如果您想跳过使用 Atlas，您可以直接使用[此文件](https://github.com/rotemtam/entrag/blob/e91722c0fbe011b03dbd6b9e68415547c8b7bba4/setup.sql#L1)中的语句将所需的模式直接应用于数据库。

现在，让我们创建 Atlas 配置，该配置将 `base.pg.hcl` 文件与 Ent 模式组合在一起：

```
data "composite_schema" "schema" {
  schema {
    url = "file://base.pg.hcl"
  }
  schema "public" {
    url = "ent://ent/schema"
  }
}
env "local" {
  url = getenv("DB_URL")
  schema {
    src = data.composite_schema.schema.url
  }
  dev = "docker://pgvector/pg17/dev"
}
```

此配置定义了一个复合模式，其中包括 `base.pg.hcl` 文件和 Ent 模式。我们还定义了一个名为 `local` 的环境，该环境使用我们将用于本地开发的复合模式。`dev` 字段指定了 [Dev Database](https://atlasgo.io/concepts/dev-database) URL，Atlas 使用该 URL 来规范化模式并进行各种计算。

接下来，让我们通过运行以下命令将模式应用于数据库：

```
export DB_URL='postgresql://postgres:pass@localhost:5432/postgres?sslmode=disable'
atlas schema apply --env local
```

Atlas 将从我们的配置中加载数据库的所需状态，将其与数据库的当前状态进行比较，并创建一个迁移计划以使数据库达到所需状态：

```
Planning migration statements (5 in total):
-- create extension "vector":
-> CREATE EXTENSION "vector" WITH SCHEMA "public" VERSION "0.8.0";
-- create "chunks" table:
-> CREATE TABLE "public"."chunks" (
"id" bigint NOT NULL GENERATED BY DEFAULT AS IDENTITY,
"path" character varying NOT NULL,
"nchunk" bigint NOT NULL,
"data" text NOT NULL,
PRIMARY KEY ("id")
);
-- create "embeddings" table:
-> CREATE TABLE "public"."embeddings" (
"id" bigint NOT NULL GENERATED BY DEFAULT AS IDENTITY,
"embedding" public.vector(1536) NOT NULL,
"chunk_id" bigint NOT NULL,
PRIMARY KEY ("id"),
CONSTRAINT "embeddings_chunks_embedding" FOREIGN KEY ("chunk_id") REFERENCES "public"."chunks" ("id") ON UPDATE NO ACTION ON DELETE NO ACTION
);
-- create index "embedding_embedding" to table: "embeddings":
-> CREATE INDEX "embedding_embedding" ON "public"."embeddings" USING hnsw ("embedding" vector_l2_ops);
-- create index "embeddings_chunk_id_key" to table: "embeddings":
-> CREATE UNIQUE INDEX "embeddings_chunk_id_key" ON "public"."embeddings" ("chunk_id");
-------------------------------------------
Analyzing planned statements (5 in total):
-- non-optimal columns alignment:
-- L4: Table "chunks" has 8 redundant bytes of padding per row. To reduce disk space,
the optimal order of the columns is as follows: "id", "nchunk", "path",
"data" https://atlasgo.io/lint/analyzers#PG110
-- ok (370.25Âµs)
-------------------------
-- 114.306667ms
-- 5 schema changes
-- 1 diagnostic
-------------------------------------------
? Approve or abort the plan:
â¸ Approve and apply
Abort
```

除了规划更改之外，Atlas 还将提供诊断和建议，以优化模式。在这种情况下，它建议重新排序 `chunks` 表中的列以减少磁盘空间。由于在本教程中我们不关心磁盘空间，因此我们可以通过选择 `Approve and apply` 来继续迁移。

最后，我们可以验证我们的模式是否已成功应用，我们可以重新运行 `atlas schema apply` 命令。Atlas 将输出：

```
Schema is synced, no changes to be made
```

### 搭建 CLI[â](#scaffolding-the-cli)

现在我们的数据库模式已经设置好，让我们搭建我们的 CLI 应用程序。在本教程中，我们将使用 [alecthomas/kong](https://github.com/alecthomas/kong) 库来构建一个小应用程序，该应用程序可以加载、索引和查询数据库中的文档。

首先，安装 `kong` 库：

```
go get github.com/alecthomas/kong
```

接下来，创建一个名为 `cmd/entrag/main.go` 的新文件，并按如下方式定义 CLI 应用程序：

```go
package main

import (
	"fmt"
	"os"

	"github.com/alecthomas/kong"
)

// CLI holds global options and subcommands.
type CLI struct {
	// DBURL is read from the environment variable DB_URL.
	DBURL     string   `kong:"env='DB_URL',help='Database URL for the application.'"`
	OpenAIKey string   `kong:"env='OPENAI_KEY',help='OpenAI API key for the application.'"`
	// Subcommands
	Load  *LoadCmd  `kong:"cmd,help='Load command that accepts a path.'"`
	Index *IndexCmd `kong:"cmd,help='Create embeddings for any chunks that do not have one.'"`
	Ask   *AskCmd   `kong:"cmd,help='Ask a question about the indexed documents'"`
}

func main() {
	var cli CLI
	app := kong.Parse(&cli,
		kong.Name("entrag"),
		kong.Description("Ask questions about markdown files."),
		kong.UsageOnError(),
	)
	if err := app.Run(&cli); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %s\n", err)
		os.Exit(1)
	}
}

```
创建一个名为 `cmd/entrag/rag.go` 的额外文件，内容如下：

```go
package main

type (
	// LoadCmd loads the markdown files into the database.
	LoadCmd struct {
		Path string `help:"path to dir with markdown files" type:"existingdir" required:""`
	}
	// IndexCmd creates the embedding index on the database.
	IndexCmd struct {
	}
	// AskCmd is another leaf command.
	AskCmd struct {
		// Text is the positional argument for the ask command.
		Text string `kong:"arg,required,help='Text for the ask command.'"`
	}
)
```

通过运行以下命令验证我们搭建的 CLI 应用程序是否正常工作：

```bash
go run ./cmd/entrag --help
```

如果一切设置正确，您应该看到 CLI 应用程序的帮助输出：

```text
Usage: entrag <command> [flags]
Ask questions about markdown files.
Flags:
  -h, --help             Show context-sensitive help.
      --dburl=STRING     Database URL for the application ($DB_URL).
      --open-ai-key=STRING OpenAI API key for the application ($OPENAI_KEY).
Commands:
  load --path=STRING [flags]
    Load command that accepts a path.
  index [flags]
    Create embeddings for any chunks that do not have one.
  ask <text> [flags]
    Ask a question about the indexed documents
Run "entrag <command> --help" for more information on a command.
```

### 将文档加载到数据库 {#load-the-documents-into-the-database}

接下来，我们需要一些 markdown 文件来加载到数据库中。创建一个名为 `data` 的目录，并向其中添加一些 markdown 文件。对于此示例，我下载了 [ ent/ent](https://github.com/ent/ent) 仓库并使用了 `docs` 目录作为 markdown 文件的来源。现在，让我们实现 `LoadCmd` 命令以将 markdown 文件加载到数据库中。打开 `cmd/entrag/rag.go` 文件并添加以下代码：

```go
const (
	tokenEncoding = "cl100k_base"
	chunkSize     = 1000
)

// Run is the method called when the "load" command is executed.
func (cmd *LoadCmd) Run(ctx *CLI) error {
	client, err := ctx.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}
	tokTotal := 0
	return filepath.WalkDir(ctx.Load.Path, func(path string, d fs.DirEntry, err error) error {
		if filepath.Ext(path) == ".mdx" || filepath.Ext(path) == ".md" {
			chunks := breakToChunks(path)
			for i, chunk := range chunks {
				tokTotal += len(chunk)
				client.Chunk.Create().
					SetData(chunk).
					SetPath(path).
					SetNchunk(i).
					SaveX(context.Background())
			}
		}
		return nil
	})
}

func (c *CLI) entClient() (*ent.Client, error) {
	return ent.Open("postgres", c.DBURL)
}
```

此代码定义了 `LoadCmd` 命令的 `Run` 方法。该方法从指定的路径读取 markdown 文件，将它们分成 1000 个 token 的块，并将它们保存到数据库中。我们使用 `entClient` 方法来使用 CLI 选项中指定的数据库 URL 创建一个新的 Ent 客户端。

有关 `breakToChunks` 的实现，请参见 [完整代码](https://github.com/rotemtam/entrag/blob/93291e0c8479ecabd5f2a2e49fbaa8c49f995e70/cmd/entrag/rag.go#L157) 在 [ entrag 仓库](https://github.com/rotemtam/entrag) 中，它几乎完全基于 [Eli Bendersky's intro to RAG in Go](https://eli.thegreenplace.net/2023/retrieval-augmented-generation-in-go/)。

最后，让我们运行 `load` 命令以将 markdown 文件加载到数据库中：

```bash
go run ./cmd/entrag load --path=data
```

命令完成后，您应该看到块已加载到数据库中。要验证，请运行：

```bash
docker exec -it postgres psql -U postgres -d postgres -c "SELECT COUNT(*) FROM chunks;"
```

您应该看到类似以下内容：

```text
 count
-------
    276
(1 row)
```

### 索引嵌入 {#indexing-the-embeddings}

现在我们已经将文档加载到数据库中，我们需要为每个块创建嵌入。我们将使用 OpenAI API 为块生成嵌入。为此，我们需要安装 `openai` 包：

```bash
go get github.com/sashabaranov/go-openai
```

如果您没有 OpenAI API 密钥，您可以在 [OpenAI Platform](https://platform.openai.com/signup) 上注册一个帐户并[生成一个 API 密钥](https://platform.openai.com/api-keys)。

我们将从环境变量 `OPENAI_KEY` 中读取此密钥，因此让我们设置它：

```bash
export OPENAI_KEY=<your OpenAI API key>
```

接下来，让我们实现 `IndexCmd` 命令以创建块的嵌入。打开 `cmd/entrag/rag.go` 文件并添加以下代码：

```go
// Run is the method called when the "index" command is executed.
func (cmd *IndexCmd) Run(cli *CLI) error {
	client, err := cli.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}
	ctx := context.Background()
	chunks := client.Chunk.Query().
		Where(
			chunk.Not(
				chunk.HasEmbedding(),
			),
		).
		Order(ent.Asc(chunk.FieldID)).
		AllX(ctx)
	for _, ch := range chunks {
		log.Println("Created embedding for chunk", ch.Path, ch.Nchunk)
		embedding := getEmbedding(ch.Data)
		_, err := client.Embedding.Create().
			SetEmbedding(pgvector.NewVector(embedding)).
			SetChunk(ch).
			Save(ctx)
		if err != nil {
```

return fmt.Errorf("error creating embedding: %v", err)
		}
	}
	return nil
}

// getEmbedding invokes the OpenAI embedding API to calculate the embedding
// for the given string. It returns the embedding.
func getEmbedding(data string) []float32 {
	client := openai.NewClient(os.Getenv("OPENAI_KEY"))
	queryReq := openai.EmbeddingRequest{
		Input: []string{data},
		Model: openai.AdaEmbeddingV2,
	}
	queryResponse, err := client.CreateEmbeddings(context.Background(), queryReq)
	if err != nil {
		log.Fatalf("Error getting embedding: %v", err)
	}
	return queryResponse.Data[0].Embedding
}

我们已经为 `IndexCmd` 命令定义了 `Run` 方法。该方法查询数据库中没有 embedding 的 chunks，使用 OpenAI API 为每个 chunk 生成 embeddings，并将 embeddings 保存到数据库。

最后，让我们运行 `index` 命令来为 chunks 创建 embeddings：

```bash
go run ./cmd/entrag index
```

你应该会看到类似的日志：

```
2025/02/13 13:04:42 Created embedding for chunk /Users/home/entr/data/md/aggregate.md 0
2025/02/13 13:04:43 Created embedding for chunk /Users/home/entr/data/md/ci.mdx 0
2025/02/13 13:04:44 Created embedding for chunk /Users/home/entr/data/md/ci.mdx 1
2025/02/13 13:04:45 Created embedding for chunk /Users/home/entr/data/md/ci.mdx 2
2025/02/13 13:04:46 Created embedding for chunk /Users/home/entr/data/md/code-gen.md 0
2025/02/13 13:04:47 Created embedding for chunk /Users/home/entr/data/md/code-gen.md 1
```

### 提问[â](#asking-questions)

现在我们已经加载了文档并为 chunks 创建了 embeddings，我们可以实现 `AskCmd` 命令来提问关于索引文档的问题。打开 `cmd/entrag/rag.go` 文件并添加以下代码：

```go
// Run is the method called when the "ask" command is executed.
func (cmd *AskCmd) Run(ctx *CLI) error {
	client, err := ctx.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}
	question := cmd.Text
	emb := getEmbedding(question)
	embVec := pgvector.NewVector(emb)
	embs := client.Embedding.
		Query().
		Order(func(s *sql.Selector) {
			s.OrderExpr(sql.ExprP("embedding <-> $1", embVec))
		}).
		WithChunk().
		Limit(5).
		AllX(context.Background())
	b := strings.Builder{}
	for _, e := range embs {
		chnk := e.Edges.Chunk
		b.WriteString(fmt.Sprintf("From file: %v\n", chnk.Path))
		b.WriteString(chnk.Data)
	}
	query := fmt.Sprintf(`Use the below information from the ent docs to answer the subsequent question.
Information:
%v
Question: %v`, b.String(), question)
	oac := openai.NewClient(ctx.OpenAIKey)
	resp, err := oac.CreateChatCompletion(
		context.Background(),
		openai.ChatCompletionRequest{
			Model: openai.GPT4o,
			Messages: []openai.ChatCompletionMessage{
				{
					Role:    openai.ChatMessageRoleUser,
					Content: query,
				},
			},
		},
	)
	if err != nil {
		return fmt.Errorf("error creating chat completion: %v", err)
	}
	choice := resp.Choices[0]
	out, err := glamour.Render(choice.Message.Content, "dark")
	fmt.Print(out)
	return nil
}
```

这就是所有部分组合在一起的地方。在使用文档及其 embeddings 准备好数据库后，我们现在可以提问关于它们的问题。让我们分解 `AskCmd` 命令：

```go
emb := getEmbedding(question)
embVec := pgvector.NewVector(emb)
embs := client.Embedding.
	Query().
	Order(func(s *sql.Selector) {
		s.OrderExpr(sql.ExprP("embedding <-> $1", embVec))
	}).
	WithChunk().
	Limit(5).
	AllX(context.Background())
```

我们首先使用 OpenAI API 将用户的问题转换为向量。使用这个向量，我们希望在数据库中找到最相似的 embeddings。我们查询数据库中的 embeddings，使用 `pgvector` 的 `<->` 运算符按相似度排序，并将结果限制为前 5 个。

```go
for _, e := range embs {
	chnk := e.Edges.Chunk
	b.WriteString(fmt.Sprintf("From file: %v\n", chnk.Path))
	b.WriteString(chnk.Data)
}
query := fmt.Sprintf(`Use the below information from the ent docs to answer the subsequent question.
Information:
%v
Question: %v`, b.String(), question)
```

接下来，我们准备来自前 5 个 chunks 的信息，以用作问题的上下文。然后，我们将问题和上下文格式化为单个字符串。

```go
oac := openai.NewClient(ctx.OpenAIKey)
resp, err := oac.CreateChatCompletion(
	context.Background(),
	openai.ChatCompletionRequest{
		Model: openai.GPT4o,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleUser,
				Content: query,
			},
		},
	},
)
if err != nil {
	return fmt.Errorf("error creating chat completion: %v", err)
}
choice := resp.Choices[0]
out, err := glamour.Render(choice.Message.Content, "dark")
fmt.Print(out)
```

然后，我们使用 OpenAI API 生成对问题的响应。我们将问题和上下文传递给 API 并接收响应。然后，我们使用 `glamour` 包渲染响应，以在终端中显示它。

在运行 `ask` 命令之前，让我们安装 `glamour` 包：

```bash
go get github.com/charmbracelet/glamour
```

最后，让我们运行 `ask` 命令来提问关于索引文档的问题：


`go run ./cmd/entrag ask "tl;dr What is Ent?"`

And our RAG system responds:

`Ent is an open-source entity framework (ORM) for the Go programming language. It`
allows developers to define data models or graph-structures in Go code. Ent
emphasizes principles such as schema as code, a statically typed and explicit
API generated through codegen, simple queries and graph traversals, statically
typed predicates, and storage agnosticism. It supports various databases,
including MySQL, MariaDB, PostgreSQL, SQLite, and Gremlin-based graph databases,
and aims to enhance productivity in Go development.
太棒了！我们已经成功地使用 Ent、Atlas 和 pgvector 构建了一个 RAG 系统。我们现在可以询问有关加载到数据库中的文档的问题，并获得具有上下文感知的响应。

以下是我们的 RAG 系统的一些问答：

## `go run ./cmd/entrag ask "how to define order field in entgql"`

选择一个可比较的字段：在您的 schema 中选择您想要排序的字段。这可以是一个文本字段、一个时间戳、一个整数、一个枚举等。

注释字段：在所选字段上使用 entgql.OrderField 注释。排序字段名称应为大写，并与其在 GraphQL schema 中的相应枚举值匹配。

更新您的 Schema：以下是如何在 ent/schema 中注释您的字段的示例：

```go
func (Todo) Fields() []ent.Field {
	return []ent.Field{
		field.Text("text").
			NotEmpty().
			Annotations(
				entgql.OrderField("TEXT"),
			),
		field.Time("created_at").
			Default(time.Now).
			Immutable().
			Annotations(
				entgql.OrderField("CREATED_AT"),
			),
		field.Enum("status").
			NamedValues(
				"InProgress", "IN_PROGRESS",
				"Completed", "COMPLETED",
			).
			Default("IN_PROGRESS").
			Annotations(
				entgql.OrderField("STATUS"),
			),
		field.Int("priority").
			Default(0).
			Annotations(
				entgql.OrderField("PRIORITY"),
			),
	}
}
```

或者，多个排序字段：如果要启用按多个字段排序，可以使用 entgql.MultiOrder() 注释：

```go
func (Todo) Annotations() []schema.Annotation {
	return []schema.Annotation{
		entgql.MultiOrder(),
	}
}
```

生成 GraphQL 类型：确保 GraphQL 类型与您的 GraphQL schema 中的设置匹配，例如：

```graphql
enum OrderDirection {
  ASC
  DESC
}
enum TodoOrderField {
  CREATED_AT
  PRIORITY
  STATUS
  TEXT
}
input TodoOrder {
  direction: OrderDirection!
  field: TodoOrderField
}
```

将 orderBy 参数添加到查询：在您的 GraphQL 查询中包含 orderBy 参数，以允许客户端对项目进行排序：

```graphql
type Query {
  todos(
    after: Cursor
    first: Int
    before: Cursor
    last: Int
    orderBy: TodoOrder
  ): TodoConnection!
}
```

通过执行这些步骤，您可以确保基于 Ent 的应用程序可以在 GraphQL API 中支持基于各种字段的排序。

## `go run ./cmd/entrag ask "what's the difference between privacy rules and interceptors"`

- 隐私规则：
  - 目的：隐私规则主要关注于对数据查询和变更强制执行访问控制策略。它们根据预定义的规则确定是否允许操作。
  - 实现：它们作为隐私策略的一部分实现，使用 ent.Policy 接口，其中包括 EvalQuery 和 EvalMutation 方法。
  - 操作：隐私规则评估是否满足特定条件，然后允许或拒绝访问数据。它们可以返回诸如 privacy.Allow 、 privacy.Deny 或 privacy.Skip 之类的决策来控制评估流程。
  - 用例：非常适合通过确保用户只有在满足指定条件时才能执行某些操作来管理访问控制。
- 拦截器：
  - 目的：拦截器充当 Ent 查询的中间件，允许修改和自定义查询行为。它们可用于在查询生命周期的不同阶段增强或修改查询。
  - 实现：实现为接口或使用 ent.InterceptFunc 适配器。它们通过在读取路径上工作来拦截并可能修改查询。
  - 操作：拦截器修改或增强查询，通常没有隐私规则中固有的访问控制逻辑。它们提供钩子来执行自定义逻辑，在查询执行前后。
  - 用例：适用于对查询进行通用转换或修改，例如添加默认过滤器、查询限制或日志记录操作，而无需关注访问控制。

总而言之，虽然隐私规则侧重于访问控制，但拦截器侧重于管理和修改查询执行过程。

### 总结[â](#wrapping-up)

在这篇博文中，我们探讨了如何使用 Ent、Atlas 和 pgvector 构建 RAG 系统。特别感谢 [Eli Bendersky](https://eli.thegreenplace.net/2023/retrieval-augmented-generation-in-go/) 的内容丰富的博文以及多年来他出色的 Go 写作！