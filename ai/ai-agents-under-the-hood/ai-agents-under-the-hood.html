<html lang="en" data-theme="light" class=""><__hrp__ data-ext-id="eanggfilgoajaocelnaflolkadkeghjp" style="position: relative !important; z-index: 2147483647 !important;"><link href="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/nj.css" rel="stylesheet"><div class="HrpQab HrpQab_normal" style="inset: auto 0px 130px auto; opacity: 1;"><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/close.svg"><div class="HrpQab__tooltip HrpQab__tooltip_close"><div class="HrpQab__message">CLOSE SELECTION BAR<br>• ALT → Disable for website<br>• SHIFT → Disable globally</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/general-search-refraction.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>S</b></div><div class="HrpQab__message">Search the web</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/education-atom-02.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>E</b></div><div class="HrpQab__message">Explain</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/files-file-search-04.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>U</b></div><div class="HrpQab__message">Summarize</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/files-file-check-02.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>G</b></div><div class="HrpQab__message">Fix grammar</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/editor-magic-wand-02.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>P</b></div><div class="HrpQab__message">Rephrase</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/editor-pencil-02.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>W</b></div><div class="HrpQab__message">Rewrite</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/maps-flag-05.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>F</b></div><div class="HrpQab__message">Finish writing</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/general-translate-01.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>T</b></div><div class="HrpQab__message">Translate</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_option" style="order: 1;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/arrows-flip-backward.svg"><div class="HrpQab__tooltip HrpQab__tooltip_command"><div class="HrpQab__hotkey"><b><span class="HrpQab__hotkeyPrefix">//</span>R</b></div><div class="HrpQab__message">Write a reply</div><div class="HrpQab__triangle"></div></div></div><div class="HrpQab__button HrpQab__button_main" style="order: 2;"><img src="chrome-extension://eanggfilgoajaocelnaflolkadkeghjp/img/commands/main.svg"><div class="HrpQab__tooltip HrpQab__tooltip_main"><div class="HrpQab__hotkey"><span class="HrpQab__hotkeyPrefix">//</span>/</div><div class="HrpQab__message">AI CHAT<br>Drag to move</div><div class="HrpQab__triangle"></div></div></div></div></__hrp__><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="image" property="og:image" content="https://blog.surkar.in/api/og/post?og=eyJ0aXRsZSI6IkFJJTIwQWdlbnRzJTIwVW5kZXIlMjBUaGUlMjBIb29kIiwiYXV0aG9yIjoiTWFudGhhbiUyMFN1cmthciIsImRvbWFpbiI6ImJsb2cuc3Vya2FyLmluIiwicGhvdG8iOiJodHRwczovL2Nkbi5oYXNobm9kZS5jb20vcmVzL2hhc2hub2RlL2ltYWdlL3VwbG9hZC92MTcyMTY2ODg3MTYwNi9lNDIzMWYwNC0yYjkxLTQ0ZDYtYmJiNy1hMzQzNGZkMTQ4MTkuanBlZyIsInJlYWRUaW1lIjoyMywicmVhY3Rpb25zIjo0LCJjb21tZW50cyI6MX0="><link rel="canonical" href="https://blog.surkar.in/ai-agents-under-the-hood"><title>AI Agents Under The Hood</title><meta name="description" content="Simplifying AI Agents - What They Are and How They Work"><meta property="og:title" content="AI Agents Under The Hood"><meta property="og:description" content="Simplifying AI Agents - What They Are and How They Work"><meta property="og:site_name" content="Manthan Surkar"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.surkar.in/ai-agents-under-the-hood"><meta name="author" content="Manthan Surkar"><meta property="article:author" content="https://hashnode.com/@surkar"><link rel="author" href="https://hashnode.com/@surkar"><link rel="icon" type="image/png" href="https://cdn.hashnode.com/res/hashnode/image/upload/v1751198022133/1c8c4430-333f-4491-9e43-465d6dcb65c0.png?auto=compress,format&amp;format=webp&amp;fm=png"><meta name="theme-color" content="#f6f7fb"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:title" content="AI Agents Under The Hood"><meta property="twitter:description" content="Simplifying AI Agents - What They Are and How They Work"><meta property="twitter:image" content="https://blog.surkar.in/api/og/post?og=eyJ0aXRsZSI6IkFJJTIwQWdlbnRzJTIwVW5kZXIlMjBUaGUlMjBIb29kIiwiYXV0aG9yIjoiTWFudGhhbiUyMFN1cmthciIsImRvbWFpbiI6ImJsb2cuc3Vya2FyLmluIiwicGhvdG8iOiJodHRwczovL2Nkbi5oYXNobm9kZS5jb20vcmVzL2hhc2hub2RlL2ltYWdlL3VwbG9hZC92MTcyMTY2ODg3MTYwNi9lNDIzMWYwNC0yYjkxLTQ0ZDYtYmJiNy1hMzQzNGZkMTQ4MTkuanBlZyIsInJlYWRUaW1lIjoyMywicmVhY3Rpb25zIjo0LCJjb21tZW50cyI6MX0="><style>/* Monkai theme */
          .hljs{display:block;overflow-x:auto;padding:.5em;background:#23241f}.hljs,.hljs-subst,.hljs-tag{color:#f8f8f2}.hljs-emphasis,.hljs-strong{color:#a8a8a2}.hljs-bullet,.hljs-link,.hljs-literal,.hljs-number,.hljs-quote,.hljs-regexp{color:#ae81ff}.hljs-code,.hljs-section,.hljs-selector-class,.hljs-title{color:#a6e22e}.hljs-strong{font-weight:700}.hljs-emphasis{font-style:italic}.hljs-attr,.hljs-keyword,.hljs-name,.hljs-selector-tag{color:#f92672}.hljs-attribute,.hljs-symbol{color:#66d9ef}.hljs-class .hljs-title,.hljs-params{color:#f8f8f2}.hljs-addition,.hljs-built_in,.hljs-builtin-name,.hljs-selector-attr,.hljs-selector-id,.hljs-selector-pseudo,.hljs-string,.hljs-template-variable,.hljs-type,.hljs-variable{color:#e6db74}.hljs-comment,.hljs-deletion,.hljs-meta{color:#75715e}
            /* Monkai theme ends */</style><link rel="alternate" type="application/rss+xml" title="RSS Feed for AI Agents Under The Hood" href="https://blog.surkar.in/ai-agents-under-the-hood/rss.xml"><meta name="next-head-count" content="22"><style>#nprogress{pointer-events:none}#nprogress .bar{background:#29d;position:fixed;z-index:1031;top:0;left:0;width:100%;height:2px}#nprogress .peg{display:block;position:absolute;right:0;width:100px;height:100%;box-shadow:0 0 10px #29d,0 0 5px #29d;opacity:1;-webkit-transform:rotate(3deg) translate(0,-4px);-ms-transform:rotate(3deg) translate(0,-4px);transform:rotate(3deg) translate(0,-4px)}#nprogress .spinner{display:block;position:fixed;z-index:1031;top:15px;right:15px}#nprogress .spinner-icon{width:18px;height:18px;box-sizing:border-box;border:solid 2px transparent;border-top-color:#29d;border-left-color:#29d;border-radius:50%;-webkit-animation:nprogress-spinner .4s linear infinite;animation:nprogress-spinner .4s linear infinite}.nprogress-custom-parent{overflow:hidden;position:relative}.nprogress-custom-parent #nprogress .bar,.nprogress-custom-parent #nprogress .spinner{position:absolute}@-webkit-keyframes nprogress-spinner{0%{-webkit-transform:rotate(0)}100%{-webkit-transform:rotate(360deg)}}@keyframes nprogress-spinner{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}</style><script src="/js/iframe-resizer.js" async="" defer=""></script><script async="" src="https://ping.hashnode.com/gtag/js?id=G-72XG3F8LNJ"></script><script type="text/javascript">
    window.dataLayer = window.dataLayer || [];
    function gtag(){window.dataLayer.push(arguments);}
    gtag('js', new Date());
  </script><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"><link rel="preload" href="/_next/static/css/883f46e254373107.css" as="style"><link rel="stylesheet" href="/_next/static/css/883f46e254373107.css" data-n-g=""><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script defer="" src="/_next/static/chunks/8820-56721d947d773244.js"></script><script defer="" src="/_next/static/chunks/3364-87c2ffca7936c855.js"></script><script defer="" src="/_next/static/chunks/8226.64bcf70d809f2c9f.js"></script><script defer="" src="/_next/static/chunks/5950-ac4ab424aa3bdc31.js"></script><script defer="" src="/_next/static/chunks/7179.58a3a6a905ed3c5b.js"></script><script src="/_next/static/chunks/webpack-21840d9d34b4ca26.js" defer=""></script><script src="/_next/static/chunks/framework-ce84985cd166733a.js" defer=""></script><script src="/_next/static/chunks/main-7636331dc094a8a9.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9b7e51f28796fc05.js" defer=""></script><script src="/_next/static/chunks/0b5ea8d6-208c5eca82a94965.js" defer=""></script><script src="/_next/static/chunks/6365-3d0e1852af604b43.js" defer=""></script><script src="/_next/static/chunks/6933-f312215db97b5535.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...slug%5D-0670863b9e4a6e11.js" defer=""></script><script src="/_next/static/NQCZqh8ei5oJzgkpVggZD/_buildManifest.js" defer=""></script><script src="/_next/static/NQCZqh8ei5oJzgkpVggZD/_ssgManifest.js" defer=""></script><style id="__jsx-668768712">@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Book-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Book-WebXL.woff")format("woff");font-weight:450;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Medium-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Medium-WebXL.woff")format("woff");font-weight:500;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-SemiBold-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-SemiBold-WebXL.woff")format("woff");font-weight:600;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Bold-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Bold-WebXL.woff")format("woff");font-weight:700;font-style:normal;font-display:block}html{--font-inter:__Inter_a184c8;--font-suisse-intl:'Suisse Intl';--font-mermaid:var(--font-inter)}</style><style type="text/css">html[dir=ltr],[data-sonner-toaster][dir=ltr]{--toast-icon-margin-start: -3px;--toast-icon-margin-end: 4px;--toast-svg-margin-start: -1px;--toast-svg-margin-end: 0px;--toast-button-margin-start: auto;--toast-button-margin-end: 0;--toast-close-button-start: 0;--toast-close-button-end: unset;--toast-close-button-transform: translate(-35%, -35%)}html[dir=rtl],[data-sonner-toaster][dir=rtl]{--toast-icon-margin-start: 4px;--toast-icon-margin-end: -3px;--toast-svg-margin-start: 0px;--toast-svg-margin-end: -1px;--toast-button-margin-start: 0;--toast-button-margin-end: auto;--toast-close-button-start: unset;--toast-close-button-end: 0;--toast-close-button-transform: translate(35%, -35%)}[data-sonner-toaster]{position:fixed;width:var(--width);font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;--gray1: hsl(0, 0%, 99%);--gray2: hsl(0, 0%, 97.3%);--gray3: hsl(0, 0%, 95.1%);--gray4: hsl(0, 0%, 93%);--gray5: hsl(0, 0%, 90.9%);--gray6: hsl(0, 0%, 88.7%);--gray7: hsl(0, 0%, 85.8%);--gray8: hsl(0, 0%, 78%);--gray9: hsl(0, 0%, 56.1%);--gray10: hsl(0, 0%, 52.3%);--gray11: hsl(0, 0%, 43.5%);--gray12: hsl(0, 0%, 9%);--border-radius: 8px;box-sizing:border-box;padding:0;margin:0;list-style:none;outline:none;z-index:999999999}[data-sonner-toaster][data-x-position=right]{right:max(var(--offset),env(safe-area-inset-right))}[data-sonner-toaster][data-x-position=left]{left:max(var(--offset),env(safe-area-inset-left))}[data-sonner-toaster][data-x-position=center]{left:50%;transform:translate(-50%)}[data-sonner-toaster][data-y-position=top]{top:max(var(--offset),env(safe-area-inset-top))}[data-sonner-toaster][data-y-position=bottom]{bottom:max(var(--offset),env(safe-area-inset-bottom))}[data-sonner-toast]{--y: translateY(100%);--lift-amount: calc(var(--lift) * var(--gap));z-index:var(--z-index);position:absolute;opacity:0;transform:var(--y);touch-action:none;will-change:transform,opacity,height;transition:transform .4s,opacity .4s,height .4s,box-shadow .2s;box-sizing:border-box;outline:none;overflow-wrap:anywhere}[data-sonner-toast][data-styled=true]{padding:16px;background:var(--normal-bg);border:1px solid var(--normal-border);color:var(--normal-text);border-radius:var(--border-radius);box-shadow:0 4px 12px #0000001a;width:var(--width);font-size:13px;display:flex;align-items:center;gap:6px}[data-sonner-toast]:focus-visible{box-shadow:0 4px 12px #0000001a,0 0 0 2px #0003}[data-sonner-toast][data-y-position=top]{top:0;--y: translateY(-100%);--lift: 1;--lift-amount: calc(1 * var(--gap))}[data-sonner-toast][data-y-position=bottom]{bottom:0;--y: translateY(100%);--lift: -1;--lift-amount: calc(var(--lift) * var(--gap))}[data-sonner-toast] [data-description]{font-weight:400;line-height:1.4;color:inherit}[data-sonner-toast] [data-title]{font-weight:500;line-height:1.5;color:inherit}[data-sonner-toast] [data-icon]{display:flex;height:16px;width:16px;position:relative;justify-content:flex-start;align-items:center;flex-shrink:0;margin-left:var(--toast-icon-margin-start);margin-right:var(--toast-icon-margin-end)}[data-sonner-toast][data-promise=true] [data-icon]>svg{opacity:0;transform:scale(.8);transform-origin:center;animation:sonner-fade-in .3s ease forwards}[data-sonner-toast] [data-icon]>*{flex-shrink:0}[data-sonner-toast] [data-icon] svg{margin-left:var(--toast-svg-margin-start);margin-right:var(--toast-svg-margin-end)}[data-sonner-toast] [data-content]{display:flex;flex-direction:column;gap:2px}[data-sonner-toast] [data-button]{border-radius:4px;padding-left:8px;padding-right:8px;height:24px;font-size:12px;color:var(--normal-bg);background:var(--normal-text);margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end);border:none;cursor:pointer;outline:none;transition:opacity .4s,box-shadow .2s}[data-sonner-toast] [data-button]:focus-visible{box-shadow:0 0 0 2px #0006}[data-sonner-toast] [data-button]:first-of-type{margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end)}[data-sonner-toast] [data-cancel]{color:var(--normal-text);background:rgba(0,0,0,.08)}[data-sonner-toast][data-theme=dark] [data-cancel]{background:rgba(255,255,255,.3)}[data-sonner-toast] [data-close-button]{position:absolute;left:var(--toast-close-button-start);right:var(--toast-close-button-end);top:0;height:20px;width:20px;display:flex;justify-content:center;align-items:center;padding:0;background:var(--gray1);color:var(--gray12);border:1px solid var(--gray4);transform:var(--toast-close-button-transform);border-radius:50%;opacity:0;cursor:pointer;z-index:1;transition:opacity .1s,background .2s,border-color .2s}[data-sonner-toast] [data-close-button]:focus-visible{box-shadow:0 4px 12px #0000001a,0 0 0 2px #0003}[data-sonner-toast] [data-disabled=true]{cursor:not-allowed}[data-sonner-toast]:hover [data-close-button]{opacity:1}[data-sonner-toast]:focus [data-close-button]{opacity:1}[data-sonner-toast]:focus-within [data-close-button]{opacity:1}[data-sonner-toast]:hover [data-close-button]:hover{background:var(--gray2);border-color:var(--gray5)}[data-sonner-toast][data-swiping=true]:before{content:"";position:absolute;left:0;right:0;height:100%}[data-sonner-toast][data-y-position=top][data-swiping=true]:before{bottom:50%;transform:scaleY(3) translateY(50%)}[data-sonner-toast][data-y-position=bottom][data-swiping=true]:before{top:50%;transform:scaleY(3) translateY(-50%)}[data-sonner-toast][data-swiping=false][data-removed=true]:before{content:"";position:absolute;inset:0;transform:scaleY(2)}[data-sonner-toast]:after{content:"";position:absolute;left:0;height:calc(var(--gap) + 1px);bottom:100%;width:100%}[data-sonner-toast][data-mounted=true]{--y: translateY(0);opacity:1}[data-sonner-toast][data-expanded=false][data-front=false]{--scale: var(--toasts-before) * .05 + 1;--y: translateY( calc(var(--lift-amount) * var(--toasts-before)) ) scale(calc(-1 * var(--scale)));height:var(--front-toast-height)}[data-sonner-toast]>*{transition:opacity .4s}[data-sonner-toast][data-expanded=false][data-front=false][data-styled=true]>*{opacity:0}[data-sonner-toast][data-visible=false]{opacity:0;pointer-events:none}[data-sonner-toast][data-mounted=true][data-expanded=true]{--y: translateY(calc(var(--lift) * var(--offset)));height:var(--initial-height)}[data-sonner-toast][data-removed=true][data-front=true][data-swipe-out=false]{--y: translateY(calc(var(--lift) * -100%));opacity:0}[data-sonner-toast][data-removed=true][data-front=false][data-swipe-out=false][data-expanded=true]{--y: translateY( calc(var(--lift) * var(--offset) + var(--lift) * -100%) );opacity:0}[data-sonner-toast][data-removed=true][data-front=false][data-swipe-out=false][data-expanded=false]{--y: translateY(40%);opacity:0;transition:transform .5s,opacity .2s}[data-sonner-toast][data-removed=true][data-front=false]:before{height:calc(var(--initial-height) + 20%)}[data-sonner-toast][data-swiping=true]{transform:var(--y) translateY(var(--swipe-amount, 0px));transition:none}[data-sonner-toast][data-swipe-out=true][data-y-position=bottom],[data-sonner-toast][data-swipe-out=true][data-y-position=top]{animation:swipe-out .2s ease-out forwards}@keyframes swipe-out{0%{transform:translateY(calc(var(--lift) * var(--offset) + var(--swipe-amount)));opacity:1}to{transform:translateY(calc(var(--lift) * var(--offset) + var(--swipe-amount) + var(--lift) * -100%));opacity:0}}@media (max-width: 600px){[data-sonner-toaster]{position:fixed;--mobile-offset: 16px;right:var(--mobile-offset);left:var(--mobile-offset);width:100%}[data-sonner-toaster] [data-sonner-toast]{left:0;right:0;width:calc(100% - 32px)}[data-sonner-toaster][data-x-position=left]{left:var(--mobile-offset)}[data-sonner-toaster][data-y-position=bottom]{bottom:20px}[data-sonner-toaster][data-y-position=top]{top:20px}[data-sonner-toaster][data-x-position=center]{left:var(--mobile-offset);right:var(--mobile-offset);transform:none}}[data-sonner-toaster][data-theme=light]{--normal-bg: #fff;--normal-border: var(--gray4);--normal-text: var(--gray12);--success-bg: hsl(143, 85%, 96%);--success-border: hsl(145, 92%, 91%);--success-text: hsl(140, 100%, 27%);--info-bg: hsl(208, 100%, 97%);--info-border: hsl(221, 91%, 91%);--info-text: hsl(210, 92%, 45%);--warning-bg: hsl(49, 100%, 97%);--warning-border: hsl(49, 91%, 91%);--warning-text: hsl(31, 92%, 45%);--error-bg: hsl(359, 100%, 97%);--error-border: hsl(359, 100%, 94%);--error-text: hsl(360, 100%, 45%)}[data-sonner-toaster][data-theme=light] [data-sonner-toast][data-invert=true]{--normal-bg: #000;--normal-border: hsl(0, 0%, 20%);--normal-text: var(--gray1)}[data-sonner-toaster][data-theme=dark] [data-sonner-toast][data-invert=true]{--normal-bg: #fff;--normal-border: var(--gray3);--normal-text: var(--gray12)}[data-sonner-toaster][data-theme=dark]{--normal-bg: #000;--normal-border: hsl(0, 0%, 20%);--normal-text: var(--gray1);--success-bg: hsl(150, 100%, 6%);--success-border: hsl(147, 100%, 12%);--success-text: hsl(150, 86%, 65%);--info-bg: hsl(215, 100%, 6%);--info-border: hsl(223, 100%, 12%);--info-text: hsl(216, 87%, 65%);--warning-bg: hsl(64, 100%, 6%);--warning-border: hsl(60, 100%, 12%);--warning-text: hsl(46, 87%, 65%);--error-bg: hsl(358, 76%, 10%);--error-border: hsl(357, 89%, 16%);--error-text: hsl(358, 100%, 81%)}[data-rich-colors=true] [data-sonner-toast][data-type=success],[data-rich-colors=true] [data-sonner-toast][data-type=success] [data-close-button]{background:var(--success-bg);border-color:var(--success-border);color:var(--success-text)}[data-rich-colors=true] [data-sonner-toast][data-type=info],[data-rich-colors=true] [data-sonner-toast][data-type=info] [data-close-button]{background:var(--info-bg);border-color:var(--info-border);color:var(--info-text)}[data-rich-colors=true] [data-sonner-toast][data-type=warning],[data-rich-colors=true] [data-sonner-toast][data-type=warning] [data-close-button]{background:var(--warning-bg);border-color:var(--warning-border);color:var(--warning-text)}[data-rich-colors=true] [data-sonner-toast][data-type=error],[data-rich-colors=true] [data-sonner-toast][data-type=error] [data-close-button]{background:var(--error-bg);border-color:var(--error-border);color:var(--error-text)}.sonner-loading-wrapper{--size: 16px;height:var(--size);width:var(--size);position:absolute;inset:0;z-index:10}.sonner-loading-wrapper[data-visible=false]{transform-origin:center;animation:sonner-fade-out .2s ease forwards}.sonner-spinner{position:relative;top:50%;left:50%;height:var(--size);width:var(--size)}.sonner-loading-bar{animation:sonner-spin 1.2s linear infinite;background:var(--gray11);border-radius:6px;height:8%;left:-10%;position:absolute;top:-3.9%;width:24%}.sonner-loading-bar:nth-child(1){animation-delay:-1.2s;transform:rotate(.0001deg) translate(146%)}.sonner-loading-bar:nth-child(2){animation-delay:-1.1s;transform:rotate(30deg) translate(146%)}.sonner-loading-bar:nth-child(3){animation-delay:-1s;transform:rotate(60deg) translate(146%)}.sonner-loading-bar:nth-child(4){animation-delay:-.9s;transform:rotate(90deg) translate(146%)}.sonner-loading-bar:nth-child(5){animation-delay:-.8s;transform:rotate(120deg) translate(146%)}.sonner-loading-bar:nth-child(6){animation-delay:-.7s;transform:rotate(150deg) translate(146%)}.sonner-loading-bar:nth-child(7){animation-delay:-.6s;transform:rotate(180deg) translate(146%)}.sonner-loading-bar:nth-child(8){animation-delay:-.5s;transform:rotate(210deg) translate(146%)}.sonner-loading-bar:nth-child(9){animation-delay:-.4s;transform:rotate(240deg) translate(146%)}.sonner-loading-bar:nth-child(10){animation-delay:-.3s;transform:rotate(270deg) translate(146%)}.sonner-loading-bar:nth-child(11){animation-delay:-.2s;transform:rotate(300deg) translate(146%)}.sonner-loading-bar:nth-child(12){animation-delay:-.1s;transform:rotate(330deg) translate(146%)}@keyframes sonner-fade-in{0%{opacity:0;transform:scale(.8)}to{opacity:1;transform:scale(1)}}@keyframes sonner-fade-out{0%{opacity:1;transform:scale(1)}to{opacity:0;transform:scale(.8)}}@keyframes sonner-spin{0%{opacity:1}to{opacity:.15}}@media (prefers-reduced-motion){[data-sonner-toast],[data-sonner-toast]>*,.sonner-loading-bar{transition:none!important;animation:none!important}}
</style><style id="_goober"> @keyframes go2264125279{from{transform:scale(0) rotate(45deg);opacity:0;}to{transform:scale(1) rotate(45deg);opacity:1;}}@keyframes go3020080000{from{transform:scale(0);opacity:0;}to{transform:scale(1);opacity:1;}}@keyframes go463499852{from{transform:scale(0) rotate(90deg);opacity:0;}to{transform:scale(1) rotate(90deg);opacity:1;}}@keyframes go1268368563{from{transform:rotate(0deg);}to{transform:rotate(360deg);}}@keyframes go1310225428{from{transform:scale(0) rotate(45deg);opacity:0;}to{transform:scale(1) rotate(45deg);opacity:1;}}@keyframes go651618207{0%{height:0;width:0;opacity:0;}40%{height:0;width:6px;opacity:1;}100%{opacity:1;height:10px;}}@keyframes go901347462{from{transform:scale(0.6);opacity:0.4;}to{transform:scale(1);opacity:1;}}.go4109123758{z-index:9999;}.go4109123758 > *{pointer-events:auto;}</style><style type="text/css">.___Latex___1nfc2_1 ._latex_1nfc2_1 {
  font: inherit
}
</style><link as="script" rel="prefetch" href="/_next/static/chunks/5772-330b7829e95060dd.js"><link as="script" rel="prefetch" href="/_next/static/chunks/4960-b70b6f04f379686e.js"><link as="script" rel="prefetch" href="/_next/static/chunks/pages/index-77bcfcca4712573b.js"><script type="text/javascript" async="" src="https://googleads.g.doubleclick.net/pagead/viewthroughconversion/344963816/?random=1751601126737&amp;cv=11&amp;fst=1751601126737&amp;bg=ffffff&amp;guid=ON&amp;async=1&amp;gtm=45he5710v893467680za204&amp;gcd=13l3l3l3l1l1&amp;dma=0&amp;tag_exp=101509157~103116026~103200004~103233427~103351869~103351871~104684208~104684211~104718208~104839054~104839056~104885889~104885891~104908321~104908323&amp;u_w=1920&amp;u_h=1080&amp;url=https%3A%2F%2Fblog.surkar.in%2Fai-agents-under-the-hood&amp;ref=https%3A%2F%2Fwww.inoreader.com%2F&amp;hn=www.googleadservices.com&amp;frm=0&amp;tiba=AI%20Agents%20Under%20The%20Hood&amp;npa=0&amp;auid=2001752842.1751601025&amp;uaa=x86&amp;uab=64&amp;uafvl=Not.A%252FBrand%3B99.0.0.0%7CChromium%3B136.0.7103.94&amp;uamb=0&amp;uam=&amp;uap=Windows&amp;uapv=19.0.0&amp;uaw=0&amp;fledge=1&amp;_tu=BA&amp;data=event%3Dgtag.config&amp;rfmt=3&amp;fmt=4"></script><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-toast {
  display: flex;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  right: 0;
  top: 1%;
  width: fit-content;
  padding: 12px 20px;
  margin: auto;
  overflow: auto;
  background: #fef6f9;
  box-shadow: 0px 4px 10px 0px rgba(0, 10, 30, 0.06);
  font-size: 15px;
  border-radius: 8px;
  color: #333;
}

.immersive-translate-toast-content {
  display: flex;
  flex-direction: row;
  align-items: center;
}

.immersive-translate-toast-hidden {
  margin: 0 20px 0 72px;
  text-decoration: underline;
  cursor: pointer;
}

.immersive-translate-toast-close {
  color: #666666;
  font-size: 20px;
  font-weight: bold;
  padding: 0 10px;
  cursor: pointer;
}

@media screen and (max-width: 768px) {
  .immersive-translate-toast {
    top: 0;
    padding: 12px 0px 0 10px;
  }
  .immersive-translate-toast-content {
    flex-direction: column;
    text-align: center;
  }
  .immersive-translate-toast-hidden {
    margin: 10px auto;
  }
}

.immersive-translate-modal {
  display: none;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 50% auto !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #007bff;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}
</style></head><body class="bg-white leading-normal antialiased dark:bg-slate-950"><input type="hidden" id="hn-user"><style id="__jsx-668768712">@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Book-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Book-WebXL.woff")format("woff");font-weight:450;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Medium-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Medium-WebXL.woff")format("woff");font-weight:500;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-SemiBold-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-SemiBold-WebXL.woff")format("woff");font-weight:600;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Bold-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Bold-WebXL.woff")format("woff");font-weight:700;font-style:normal;font-display:block}html{--font-inter:__Inter_a184c8;--font-suisse-intl:'Suisse Intl';--font-mermaid:var(--font-inter)}</style><div id="__next"><div class="bg-white dark:bg-slate-950" data-theme="light"><script type="application/ld+json">{"@context":"https://schema.org","@type":"NewsArticle","url":"https://blog.surkar.in/ai-agents-under-the-hood","mainEntityOfPage":"https://blog.surkar.in/ai-agents-under-the-hood","headline":"AI Agents Under The Hood","description":"Motivation: Why You Should Care\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like patra.app. While building those and reading through a lot of resources, I learned how AI agents actually wor...","datePublished":"2025-06-22T10:36:29.574Z","dateModified":"2025-06-23T06:56:54.444Z","isAccessibleForFree":true,"author":{"@type":"Person","name":"Manthan Surkar","url":"https://hashnode.com/@surkar"},"publisher":{"@type":"Organization","name":"Manthan Surkar","url":"https://blog.surkar.in","logo":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1559814205701%2Fek9fO-yT0.jpeg%3Fw%3D800%26bm%3Dnormal%26balph%3D100%26txt64%3DTWFudGhhbiBTdXJrYXI%26txtsize%3D42%26txtfit%3Dmax%26txtalign%3Dmiddle%2Ccenter%26txtfont%3DHelvetica%20Neue%2CBold%26txtclr%3D000000%26blend%3Dffffff"}}</script><header class="blog-header z-50 w-full border-b relative transform-none md:sticky md:top-0 md:left-0 md:backdrop-blur-lg border-black/10 bg-white bg-opacity-70 dark:border-white/10 dark:bg-slate-900 dark:bg-opacity-70" style="transform: translateY(0px);"><div class="container mx-auto px-2 md:px-4 md:py-1 2xl:px-10"><div class="relative z-40 flex flex-row items-center justify-between pb-2 pt-8 md:py-4"><div class="mb-2 flex flex-row items-center md:mb-0 dark:text-white"><a aria-label="Back to blog home" class="blog-back-to-home-button focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20 mr-2 p-3" data-state="closed" href="/"><svg class="h-4 w-4 fill-current pr-1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 17"><path d="M7.75135 16.7197L0.885098 9.55347C0.683348 9.31347 0.600098 9.08847 0.600098 8.89722C0.600098 8.70597 0.68331 8.44834 0.850898 8.27509L7.71715 1.10884C8.06035 0.749066 8.6299 0.737366 8.9884 1.08189C9.34933 1.42408 9.36107 1.99576 9.01535 2.35351L2.7466 8.89722L9.0466 15.4747C9.39231 15.831 9.38057 16.404 9.01965 16.7463C8.6626 17.091 8.0926 17.0797 7.75135 16.7197Z"></path></svg></a><div class="mr-2"><button type="button" aria-label="Open blog links" class="blog-bars-button focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20 mr-2 p-2" data-state="closed"><svg class="h-6 w-6 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M20.9889 11.9969H11.9945H3M20.9889 17.8745H3M21 6.12451H3" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div><div class="hidden md:block"><div class="blog-title text-lg md:text-xl text-left break-words font-heading font-semibold leading-snug md:font-bold dark:text-white"><a href="/?source=top_nav_blog_home" class="focus-ring-base flex flex-row items-center focus-ring-colors-base" aria-label="Manthan Surkar home page">Manthan Surkar</a></div></div></div><div class="flex flex-row items-center dark:text-white"><button type="button" aria-label="Open blog search" class="blog-search-button focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20 mr-2 p-2" data-state="closed"><svg class="h-6 w-6 stroke-current" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"><path d="M21 21L15.8091 15.8091M18 10.5C18 14.6421 14.6421 18 10.5 18C6.35786 18 3 14.6421 3 10.5C3 6.35786 6.35786 3 10.5 3C14.6421 3 18 6.35786 18 10.5Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><button type="button" aria-label="Toggle blog theme" class="blog-theme-switcher focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20 mr-2 p-2" data-state="closed"><svg class="h-6 w-6 stroke-current" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"><path d="M3 11.4489C3 16.7238 7.16904 21 12.3118 21C16.2709 21 19.6529 18.4657 21 14.8925C19.9331 15.4065 18.7418 15.6938 17.485 15.6938C12.9137 15.6938 9.20787 11.8928 9.20787 7.20396C9.20787 5.24299 9.85605 3.4373 10.9446 2C6.45002 2.6783 3 6.65034 3 11.4489Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><div class="hidden md:mr-2 md:block"><button type="button" class="blog-follow-button focus-ring-base flex flex-row items-center rounded-full border-1-1/2 px-4 py-2 text-center text-sm font-medium transition-colors duration-150 hover:bg-opacity-90 disabled:cursor-not-allowed disabled:opacity-50 bg-blue-600 text-white border-blue-600 dark:bg-white dark:border-white dark:text-blue-600 dark:hover:bg-blue-50 focus-ring-colors-base" aria-label="Follow blog" data-state="closed"><svg class="mr-2 h-5 w-5 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2.5 19.25C2.5 15.5221 5.52208 12.5 9.25 12.5V12.5C12.9779 12.5 16 15.5221 16 19.25V19.5C16 20.6046 15.1046 21.5 14 21.5H4.5C3.39543 21.5 2.5 20.6046 2.5 19.5V19.25Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12.75 6C12.75 7.933 11.183 9.5 9.25 9.5C7.317 9.5 5.75 7.933 5.75 6C5.75 4.067 7.317 2.5 9.25 2.5C11.183 2.5 12.75 4.067 12.75 6Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M19 7.5V10.5M19 10.5V13.5M19 10.5H16M19 10.5H22" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><span>Follow</span></button></div><div class="hidden md:mr-2 md:block"><button class="blog-newsletter-button rounded-full border-1-1/2 bg-transparent p-2 transition-colors duration-150 focus-ring-base border-blue-600 text-blue-600 hover:bg-blue-50 dark:border-white dark:text-white hover:dark:bg-slate-800 focus-ring-colors-base" type="button" aria-label="Open subscribe to newsletter" data-state="closed"><svg class="h-5 w-5 fill-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.1367 7.50493C13.551 7.50493 13.8867 7.16914 13.8867 6.75493C13.8867 6.34071 13.551 6.00493 13.1367 6.00493V7.50493ZM19.9024 13.0846C19.9024 12.6704 19.5666 12.3346 19.1524 12.3346C18.7382 12.3346 18.4024 12.6704 18.4024 13.0846H19.9024ZM2.5013 9.95291C2.1333 9.76278 1.68084 9.90697 1.49071 10.275C1.30058 10.643 1.44477 11.0954 1.81277 11.2855L2.5013 9.95291ZM16.5938 12.1078C16.9382 11.8778 17.031 11.412 16.8009 11.0676C16.5709 10.7231 16.1051 10.6304 15.7607 10.8604L16.5938 12.1078ZM16.2825 6.01303C15.8683 6.01303 15.5325 6.34882 15.5325 6.76303C15.5325 7.17725 15.8683 7.51303 16.2825 7.51303V6.01303ZM22 7.51303C22.4142 7.51303 22.75 7.17725 22.75 6.76303C22.75 6.34882 22.4142 6.01303 22 6.01303V7.51303ZM18.3913 9.62177C18.3913 10.036 18.727 10.3718 19.1413 10.3718C19.5555 10.3718 19.8913 10.036 19.8913 9.62177H18.3913ZM19.8913 3.9043C19.8913 3.49008 19.5555 3.1543 19.1413 3.1543C18.727 3.1543 18.3913 3.49008 18.3913 3.9043H19.8913ZM8.27708 13.7812L7.93282 14.4475L8.27708 13.7812ZM10.1277 14.5662L10.0103 15.307L10.1277 14.5662ZM11.3949 14.4952L11.1955 13.7722L11.3949 14.4952ZM18.4024 18.1899C18.4024 18.8282 17.8849 19.3457 17.2466 19.3457V20.8457C18.7134 20.8457 19.9024 19.6566 19.9024 18.1899H18.4024ZM17.2466 19.3457H3.90583V20.8457H17.2466V19.3457ZM3.90583 19.3457C3.26748 19.3457 2.75 18.8282 2.75 18.1899H1.25C1.25 19.6566 2.43905 20.8457 3.90583 20.8457V19.3457ZM2.75 18.1899V8.66075H1.25V18.1899H2.75ZM2.75 8.66075C2.75 8.02241 3.26748 7.50493 3.90583 7.50493V6.00493C2.43905 6.00493 1.25 7.19398 1.25 8.66075H2.75ZM3.90583 7.50493H13.1367V6.00493H3.90583V7.50493ZM19.9024 18.1899V13.0846H18.4024V18.1899H19.9024ZM1.81277 11.2855L7.93282 14.4475L8.62134 13.1149L2.5013 9.95291L1.81277 11.2855ZM13.5627 14.1321L16.5938 12.1078L15.7607 10.8604L12.7297 12.8847L13.5627 14.1321ZM16.2825 7.51303H19.1413V6.01303H16.2825V7.51303ZM19.1413 7.51303H22V6.01303H19.1413V7.51303ZM19.8913 9.62177V6.76303H18.3913V9.62177H19.8913ZM19.8913 6.76303V3.9043H18.3913V6.76303H19.8913ZM7.93282 14.4475C8.80209 14.8966 9.38471 15.2078 10.0103 15.307L10.2451 13.8255C9.91517 13.7732 9.58255 13.6115 8.62134 13.1149L7.93282 14.4475ZM12.7297 12.8847C11.8299 13.4856 11.5175 13.6834 11.1955 13.7722L11.5943 15.2182C12.2049 15.0498 12.7491 14.6755 13.5627 14.1321L12.7297 12.8847ZM10.0103 15.307C10.5386 15.3907 11.0786 15.3604 11.5943 15.2182L11.1955 13.7722C10.8861 13.8575 10.562 13.8757 10.2451 13.8255L10.0103 15.307Z"></path></svg></button></div><div class="h-10 w-10 rounded-full"><button type="button" aria-label="Toggle sign-up options" class="focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20 blog-more-icon p-2" id="radix-:rc:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg class="h-6 w-6 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6 9L12 15L18 9" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div></div></div><div class="mx-auto my-5 flex w-2/3 flex-row items-center justify-center md:hidden"><div class="blog-title text-2xl text-center break-words font-heading font-semibold leading-snug md:font-bold dark:text-white"><a href="/?source=top_nav_blog_home" class="focus-ring-base flex flex-row items-center focus-ring-colors-base" aria-label="Manthan Surkar home page">Manthan Surkar</a></div></div><div class="blog-sub-header mb-4 md:hidden" data-testid="blog-sub-header"><div class="md:(mb-0 ml-auto) flex flex-row items-center justify-center gap-x-3"><button type="button" class="blog-follow-button focus-ring-base flex flex-row items-center rounded-full border-1-1/2 px-4 py-2 text-center text-sm font-medium transition-colors duration-150 hover:bg-opacity-90 disabled:cursor-not-allowed disabled:opacity-50 bg-blue-600 text-white border-blue-600 dark:bg-white dark:border-white dark:text-blue-600 dark:hover:bg-blue-50 focus-ring-colors-base" aria-label="Follow blog" data-state="closed"><svg class="mr-2 h-5 w-5 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2.5 19.25C2.5 15.5221 5.52208 12.5 9.25 12.5V12.5C12.9779 12.5 16 15.5221 16 19.25V19.5C16 20.6046 15.1046 21.5 14 21.5H4.5C3.39543 21.5 2.5 20.6046 2.5 19.5V19.25Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12.75 6C12.75 7.933 11.183 9.5 9.25 9.5C7.317 9.5 5.75 7.933 5.75 6C5.75 4.067 7.317 2.5 9.25 2.5C11.183 2.5 12.75 4.067 12.75 6Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M19 7.5V10.5M19 10.5V13.5M19 10.5H16M19 10.5H22" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><span>Follow</span></button><button class="blog-newsletter-button rounded-full border-1-1/2 bg-transparent p-2 transition-colors duration-150 focus-ring-base border-blue-600 text-blue-600 hover:bg-blue-50 dark:border-white dark:text-white hover:dark:bg-slate-800 focus-ring-colors-base" type="button" aria-label="Open subscribe to newsletter" data-state="closed"><svg class="h-5 w-5 fill-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M13.1367 7.50493C13.551 7.50493 13.8867 7.16914 13.8867 6.75493C13.8867 6.34071 13.551 6.00493 13.1367 6.00493V7.50493ZM19.9024 13.0846C19.9024 12.6704 19.5666 12.3346 19.1524 12.3346C18.7382 12.3346 18.4024 12.6704 18.4024 13.0846H19.9024ZM2.5013 9.95291C2.1333 9.76278 1.68084 9.90697 1.49071 10.275C1.30058 10.643 1.44477 11.0954 1.81277 11.2855L2.5013 9.95291ZM16.5938 12.1078C16.9382 11.8778 17.031 11.412 16.8009 11.0676C16.5709 10.7231 16.1051 10.6304 15.7607 10.8604L16.5938 12.1078ZM16.2825 6.01303C15.8683 6.01303 15.5325 6.34882 15.5325 6.76303C15.5325 7.17725 15.8683 7.51303 16.2825 7.51303V6.01303ZM22 7.51303C22.4142 7.51303 22.75 7.17725 22.75 6.76303C22.75 6.34882 22.4142 6.01303 22 6.01303V7.51303ZM18.3913 9.62177C18.3913 10.036 18.727 10.3718 19.1413 10.3718C19.5555 10.3718 19.8913 10.036 19.8913 9.62177H18.3913ZM19.8913 3.9043C19.8913 3.49008 19.5555 3.1543 19.1413 3.1543C18.727 3.1543 18.3913 3.49008 18.3913 3.9043H19.8913ZM8.27708 13.7812L7.93282 14.4475L8.27708 13.7812ZM10.1277 14.5662L10.0103 15.307L10.1277 14.5662ZM11.3949 14.4952L11.1955 13.7722L11.3949 14.4952ZM18.4024 18.1899C18.4024 18.8282 17.8849 19.3457 17.2466 19.3457V20.8457C18.7134 20.8457 19.9024 19.6566 19.9024 18.1899H18.4024ZM17.2466 19.3457H3.90583V20.8457H17.2466V19.3457ZM3.90583 19.3457C3.26748 19.3457 2.75 18.8282 2.75 18.1899H1.25C1.25 19.6566 2.43905 20.8457 3.90583 20.8457V19.3457ZM2.75 18.1899V8.66075H1.25V18.1899H2.75ZM2.75 8.66075C2.75 8.02241 3.26748 7.50493 3.90583 7.50493V6.00493C2.43905 6.00493 1.25 7.19398 1.25 8.66075H2.75ZM3.90583 7.50493H13.1367V6.00493H3.90583V7.50493ZM19.9024 18.1899V13.0846H18.4024V18.1899H19.9024ZM1.81277 11.2855L7.93282 14.4475L8.62134 13.1149L2.5013 9.95291L1.81277 11.2855ZM13.5627 14.1321L16.5938 12.1078L15.7607 10.8604L12.7297 12.8847L13.5627 14.1321ZM16.2825 7.51303H19.1413V6.01303H16.2825V7.51303ZM19.1413 7.51303H22V6.01303H19.1413V7.51303ZM19.8913 9.62177V6.76303H18.3913V9.62177H19.8913ZM19.8913 6.76303V3.9043H18.3913V6.76303H19.8913ZM7.93282 14.4475C8.80209 14.8966 9.38471 15.2078 10.0103 15.307L10.2451 13.8255C9.91517 13.7732 9.58255 13.6115 8.62134 13.1149L7.93282 14.4475ZM12.7297 12.8847C11.8299 13.4856 11.5175 13.6834 11.1955 13.7722L11.5943 15.2182C12.2049 15.0498 12.7491 14.6755 13.5627 14.1321L12.7297 12.8847ZM10.0103 15.307C10.5386 15.3907 11.0786 15.3604 11.5943 15.2182L11.1955 13.7722C10.8861 13.8575 10.562 13.8757 10.2451 13.8255L10.0103 15.307Z"></path></svg></button></div><div class="mt-6"><div class="blog-social-media-section flex flex-row flex-wrap gap-y-2 justify-center gap-x-1.5 text-slate-700 dark:text-slate-300"><a href="https://twitter.com/manthan_surkar" aria-label="Find me on Twitter, external website, opens in new tab" target="_blank" rel="me noopener" class="focus-ring-base flex flex-row items-center justify-center rounded-full p-2 transition-colors duration-150 focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20"><svg class="h-5 w-5 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.643 13.346L4.26862 4.86856C3.85863 4.32329 4.2478 3.54408 4.93001 3.54431L7.2184 3.54508C7.47633 3.54517 7.71945 3.66557 7.87585 3.87066L12.9065 10.4675M10.643 13.346L5.19311 20.5093M10.643 13.346L15.8028 20.077C15.9588 20.2805 16.2003 20.4001 16.4567 20.4009L18.7925 20.4082C19.4778 20.4104 19.8683 19.6261 19.4536 19.0805L12.9065 10.4675M12.9065 10.4675L18.2181 3.50928" stroke-width="1.5" stroke-linecap="round"></path></svg></a><a href="https://github.com/thesmallstar" aria-label="Find me on Github, opens in new tab" target="_blank" rel="me noopener" class="focus-ring-base flex flex-row items-center justify-center rounded-full p-2 transition-colors duration-150 focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20"><svg class="h-5 w-5 fill-current" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://hashnode.com/@surkar" aria-label="Find me on Hashnode, external website, opens in new tab" target="_blank" rel="me noopener" class="focus-ring-base flex flex-row items-center justify-center rounded-full p-2 transition-colors duration-150 focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20"><svg class="h-5 w-5 fill-current" viewBox="0 0 200 200" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.742 66.824c-18.323 18.323-18.323 48.029 0 66.352l53.082 53.082c18.323 18.323 48.029 18.323 66.352 0l53.082-53.082c18.323-18.323 18.323-48.03 0-66.352l-53.082-53.082c-18.323-18.323-48.03-18.323-66.352 0L13.742 66.824zm109.481 56.399c12.826-12.826 12.826-33.62 0-46.446s-33.62-12.826-46.446 0-12.826 33.62 0 46.446 33.62 12.826 46.446 0z"></path></svg></a><a href="/rss.xml" aria-label="Open blog XML Feed, opens in new tab" target="_blank" rel="me noopener" class="focus-ring-base flex flex-row items-center justify-center rounded-full p-2 transition-colors duration-150 focus-ring-colors-base hover:bg-black/10 dark:hover:bg-white/20"><svg class="h-5 w-5 fill-current" viewBox="0 0 448 512"><path d="M80 368c17.645 0 32 14.355 32 32s-14.355 32-32 32-32-14.355-32-32 14.355-32 32-32m0-48c-44.183 0-80 35.817-80 80s35.817 80 80 80 80-35.817 80-80-35.817-80-80-80zm367.996 147.615c-6.449-237.834-198.057-429.163-435.61-435.61C5.609 31.821 0 37.229 0 44.007v24.02c0 6.482 5.147 11.808 11.626 11.992 211.976 6.04 382.316 176.735 388.354 388.354.185 6.479 5.51 11.626 11.992 11.626h24.02c6.78.001 12.187-5.608 12.004-12.384zm-136.239-.05C305.401 305.01 174.966 174.599 12.435 168.243 5.643 167.977 0 173.444 0 180.242v24.024c0 6.431 5.072 11.705 11.497 11.98 136.768 5.847 246.411 115.511 252.258 252.258.275 6.425 5.549 11.497 11.98 11.497h24.024c6.797-.001 12.264-5.644 11.998-12.436z"></path></svg></a></div></div></div></div></header><div class="blog-post-area relative z-40"><main class="blog-post-detail-card pb-24"><article><style>
    [data-rmiz-ghost] {
      position: absolute;
      pointer-events: none;
    }
    [data-rmiz-btn-zoom],
    [data-rmiz-btn-unzoom] {
      background-color: rgba(0, 0, 0, 0.7);
      border-radius: 50%;
      border: none;
      box-shadow: 0 0 1px rgba(255, 255, 255, 0.5);
      color: #fff;
      height: 40px;
      margin: 0;
      outline-offset: 2px;
      padding: 9px;
      touch-action: manipulation;
      width: 40px;
      -webkit-appearance: none;
      -moz-appearance: none;
      appearance: none;
    }
    [data-rmiz-btn-zoom]:not(:focus):not(:active) {
      position: absolute;
      clip: rect(0 0 0 0);
      clip-path: inset(50%);
      height: 1px;
      overflow: hidden;
      pointer-events: none;
      white-space: nowrap;
      width: 1px;
    }
    [data-rmiz-btn-zoom] {
      position: absolute;
      inset: 10px 10px auto auto;
      cursor: zoom-in;
    }
    [data-rmiz-btn-unzoom] {
      position: absolute;
      inset: 20px 20px auto auto;
      cursor: zoom-out;
      z-index: 1;
      display: none;
    }
    [data-rmiz-content="found"] img,
    [data-rmiz-content="found"] svg,
    [data-rmiz-content="found"] [role="img"],
    [data-rmiz-content="found"] [data-zoom] {
      cursor: zoom-in;
    }
    [data-rmiz-modal]::backdrop {
      display: none;
    }
    [data-rmiz-modal][open] {
      position: fixed;
      width: 100vw;
      width: 100dvw;
      height: 100vh;
      height: 100dvh;
      max-width: none;
      max-height: none;
      margin: 0;
      padding: 0;
      border: 0;
      background: transparent;
      overflow: hidden;
    }
    [data-rmiz-modal-overlay] {
      position: absolute;
      inset: 0;
      transition: background-color 0.3s;
    }
    [data-rmiz-modal-overlay="hidden"] {
      background-color: rgba(255, 255, 255, 0);
    }
    [data-rmiz-modal-overlay="visible"] {
      /* This bg color is different from default */
      background-color: rgba(0, 0, 0, 0.5);
    }
    [data-rmiz-modal-content] {
      position: relative;
      width: 100%;
      height: 100%;
    }
    [data-rmiz-modal-img] {
      position: absolute;
      cursor: zoom-out;
      image-rendering: high-quality;
      transform-origin: top left;
      transition: transform 0.3s;
      /* This is added additionally to override prose styles of image*/
      margin: 0 !important;
    }
    @media (prefers-reduced-motion: reduce) {
      [data-rmiz-modal-overlay],
      [data-rmiz-modal-img] {
        transition-duration: 0.01ms !important;
      }
    }
</style><div class="blog-article-page container relative mx-auto grid grid-cols-8"><div class="col-span-full lg:col-span-6 lg:col-start-2"><div class="mt-6 break-words px-4 text-center font-heading text-3xl font-bold text-slate-900 dark:text-white md:mt-10 md:px-5 md:text-4xl lg:px-8 xl:px-20 xl:text-5xl mb-5"><h1 class="leading-tight" data-query="post-title">AI Agents Under The Hood</h1></div><div class="mb-8 px-4 text-center font-heading md:mb-14 md:px-5 lg:px-8 xl:px-20"><h2 class="text-2xl leading-snug text-slate-700 dark:text-slate-400 md:text-3xl xl:text-3xl">Simplifying AI Agents - What They Are and How They Work</h2></div><div class="relative z-20 mb-8 flex flex-row flex-wrap items-center justify-center px-4 md:-mt-7 md:mb-14 md:text-lg last:md:mb-10"><div class="mb-5 flex w-full flex-row items-center justify-center md:mb-0 md:w-auto md:justify-start"><div style="z-index:1" class="overflow-hidden rounded-full  bg-slate-200  dark:bg-white/20 md:mr-3 h-10 w-10 md:h-12 md:w-12"><a href="https://hashnode.com/@surkar" class="relative block h-full w-full"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27200%27%20height=%27200%27/%3e"></span><img alt="Manthan Surkar's photo" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" decoding="async" data-nimg="intrinsic" class="relative z-20 block w-full rounded-full" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"></span></a></div><a href="https://hashnode.com/@surkar" class="ml-2 font-semibold text-slate-600 dark:text-white md:ml-0"><span>Manthan Surkar</span></a></div><div class="mb-5 flex w-full flex-row items-center justify-center md:mb-0 md:w-auto md:justify-start"><span class="mx-3 hidden font-bold text-slate-500 md:block">·</span><a href="https://blog.surkar.in/ai-agents-under-the-hood" class="tooltip-handle text-slate-600 dark:text-slate-400" data-title="Jun 22, 2025 10:36"><time datetime="2025-06-22T10:36:29.574Z">Jun 22, 2025</time></a><span class="mx-3 block font-bold text-slate-500">·</span><p class="flex flex-row items-center text-slate-600 dark:text-slate-400"><svg class="mr-2 h-5 w-5 fill-current opacity-75" viewBox="0 0 576 512"><path d="M540.9 56.77c-45.95-16.66-90.23-24.09-129.1-24.75-60.7.94-102.7 17.45-123.8 27.72-21.1-10.27-64.1-26.8-123.2-27.74-40-.05-84.4 8.35-129.7 24.77C14.18 64.33 0 84.41 0 106.7v302.9c0 14.66 6.875 28.06 18.89 36.8 11.81 8.531 26.64 10.98 40.73 6.781 118.9-36.34 209.3 19.05 214.3 22.19C277.8 477.6 281.2 480 287.1 480c6.52 0 10.12-2.373 14.07-4.578 10.78-6.688 98.3-57.66 214.3-22.27 14.11 4.25 28.86 1.75 40.75-6.812C569.1 437.6 576 424.2 576 409.6V106.7c0-22.28-14.2-42.35-35.1-49.93zM272 438.1c-24.95-12.03-71.01-29.37-130.5-29.37-27.83 0-58.5 3.812-91.19 13.77-4.406 1.344-9 .594-12.69-2.047C34.02 417.8 32 413.1 32 409.6V106.7c0-8.859 5.562-16.83 13.86-19.83C87.66 71.7 127.9 63.95 164.5 64c51.8.81 89.7 15.26 107.5 23.66V438.1zm272-28.5c0 4.375-2.016 8.234-5.594 10.84-3.766 2.703-8.297 3.422-12.69 2.125C424.1 391.6 341.3 420.4 304 438.3V87.66c17.8-8.4 55.7-22.85 107.4-23.66 35.31-.063 76.34 7.484 118.8 22.88 8.2 3 13.8 10.96 13.8 19.82v302.9z"></path></svg><span>23<!-- --> min read</span></p></div></div><div class="-mt-7 mb-8 flex flex-col items-center md:mb-14 md:flex-row md:justify-center"><button type="button" class="group mb-2 ml-0 mt-4 flex flex-row items-center overflow-hidden rounded-full bg-slate-100 pl-2 pr-1 text-sm font-semibold leading-snug text-slate-600 hover:bg-slate-200 dark:bg-slate-800 dark:text-slate-200 hover:dark:bg-slate-700 md:mb-0 md:ml-4 md:mt-0" data-state="closed"><div class="mr-3 p-2"><svg class="h-6 w-6 stroke-current" fill="none" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M14.3083 8.97852C14.9383 7.44645 15.2408 5.7389 14.7557 4.08374C14.0577 1.70199 11.5262 0.6286 9.47593 1.19739C8.45082 1.48178 7.53408 2.13598 7.15271 3.35617C6.17303 2.53487 5.03486 2.49894 4.03173 2.79293C1.99015 3.39126 0.447158 5.69084 1.14518 8.07259C1.89721 10.6386 4.31075 12.2888 6.48391 13.2341M14.3083 8.97852C14.0084 8.57633 13.6208 8.25477 13.2004 8.00413C11.373 6.91481 8.63784 7.34826 7.367 9.48015C6.67907 10.6342 6.44594 11.9384 6.48391 13.2341M14.3083 8.97852C14.6489 9.43523 14.8764 9.99591 14.9107 10.6748C16.0645 10.1243 17.1676 10.3511 18.0735 10.909C19.8851 12.0248 20.8205 14.6105 19.5497 16.7423C17.008 21.0062 9.71032 20.7837 9.10119 20.4206C8.65692 20.1558 6.5862 16.7257 6.48391 13.2341" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div><div class="relative h-8 w-8 rounded-full border-1-1/2 border-slate-100 bg-white group-hover:border-slate-200 dark:border-slate-800 dark:bg-slate-600 group-hover:dark:border-slate-700 [&amp;:not(:first-of-type)]:-ml-3" style="z-index: 1;"><img data-sizes="auto" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1638302401608/dnmaFlTCZ.png?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1638302401608/dnmaFlTCZ.png?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" width="200" height="200" alt="raj gupta's photo" class="lazyload block mr-3 h-full w-full rounded-full"></div><div class="relative h-8 w-8 rounded-full border-1-1/2 border-slate-100 bg-white group-hover:border-slate-200 dark:border-slate-800 dark:bg-slate-600 group-hover:dark:border-slate-700 [&amp;:not(:first-of-type)]:-ml-3" style="z-index: 2;"><img data-sizes="auto" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750727323921/8f39bb96-4bac-4987-9dd6-4357d50c743a.jpeg?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750727323921/8f39bb96-4bac-4987-9dd6-4357d50c743a.jpeg?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" width="200" height="200" alt="Harsh Khandelwal's photo" class="lazyload block mr-3 h-full w-full rounded-full"></div><div class="relative h-8 w-8 rounded-full border-1-1/2 border-slate-100 bg-white group-hover:border-slate-200 dark:border-slate-800 dark:bg-slate-600 group-hover:dark:border-slate-700 [&amp;:not(:first-of-type)]:-ml-3" style="z-index: 3;"><img data-sizes="auto" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1730207466180/eaef67f9-2062-4284-be67-67853462ee5b.jpeg?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1730207466180/eaef67f9-2062-4284-be67-67853462ee5b.jpeg?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" width="200" height="200" alt="Riya Jawandhiya's photo" class="lazyload block mr-3 h-full w-full rounded-full"></div></button></div></div></div><div class="blog-content-wrapper article-main-wrapper container relative z-30 mx-auto grid grid-flow-row grid-cols-8 xl:gap-6 2xl:grid-cols-10"><section class="blog-content-main z-20 col-span-8 mb-10 px-4 md:z-10 lg:col-span-6 lg:col-start-2 lg:px-0 xl:col-span-6 xl:col-start-2 2xl:col-span-6 2xl:col-start-3"><div class="relative"><div id="post-content-parent" class="relative mb-10 pb-14"><div id="post-content-wrapper" class="prose prose-base mx-auto mb-10 min-h-30 break-words dark:prose-dark lg:prose-lg"><h2 id="heading-motivation-why-you-should-care" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-motivation-why-you-should-care" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-motivation-why-you-should-care" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Motivation: Why You Should Care</h2>
<p>Not a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like <a target="_blank" href="https://patra.app">patra.app</a>. While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...</p>
<p>During one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”</p>
<p>They gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.</p>
<p>Well, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.</p>
<p>I promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:</p>
<ol>
<li><p>What an AI agent is</p>
</li>
<li><p>How an AI agent works</p>
</li>
<li><p>What the heck tools are</p>
</li>
<li><p>What an orchestration framework is</p>
</li>
<li><p>What memory is</p>
</li>
<li><p>What the types of AI agents are</p>
</li>
<li><p>The mental model for building an AI agent</p>
</li>
<li><p>What a multi-agent framework is</p>
</li>
</ol>
<p>Before we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.</p>
<h2 id="heading-the-problem" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-the-problem" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-the-problem" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>The Problem</h2>
<p>Ok, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:</p>
<p><span aria-owns="rmiz-modal-28f87d084ec5" data-rmiz=""><span data-rmiz-content="found" style="visibility: visible;"><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png?auto=compress,format&amp;format=webp" loading="lazy" class="image--center mx-auto"></span><span data-rmiz-ghost="" style="height: 304px; left: 87px; width: 738px; top: 1548px;"><button aria-label="Expand image" data-rmiz-btn-zoom="" type="button"><svg aria-hidden="true" data-rmiz-btn-zoom-icon="true" fill="currentColor" focusable="false" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M 9 1 L 9 2 L 12.292969 2 L 2 12.292969 L 2 9 L 1 9 L 1 14 L 6 14 L 6 13 L 2.707031 13 L 13 2.707031 L 13 6 L 14 6 L 14 1 Z"></path></svg></button></span></span></p>
<blockquote>
<p>An AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention</p>
</blockquote>
<p>You see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.</p>
<p>If I ask, "What is an LLM?" we get a much more acceptable answer:</p>
<blockquote>
<p>A Large Language Model (LLM) is <strong>a type of AI model, specifically a deep learning model, trained on massive amounts of text data.</strong></p>
</blockquote>
<p><img loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png?auto=compress,format&amp;format=webp" alt="" class="image--center mx-auto"></p>
<p>Notice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.</p>
<h1 id="heading-defining-ai-agent" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-defining-ai-agent" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-defining-ai-agent" style="height: 38.88px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Defining AI Agent</h1>
<p>Let’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:</p>
<p>Agents are <strong>software systems</strong> where <strong>LLMs</strong> use reasoning to control the flow of execution, <strong>dynamically</strong> choosing which <strong>tools</strong> to use and determining each step required to reach a <strong>goal</strong>.</p>
<p>That’s a mouthful. Let’s break down each part so we can actually understand it.</p>
<h2 id="heading-agents-are-software-systems" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-agents-are-software-systems" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-agents-are-software-systems" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a><strong>Agents are Software Systems</strong></h2>
<p>This is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:</p>
<ol>
<li><p>LLMs</p>
</li>
<li><p>Working Memory or state</p>
</li>
<li><p>Prompts</p>
</li>
<li><p>Tools</p>
</li>
<li><p>Orchestration Layer</p>
</li>
</ol>
<p>You already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.</p>
<p>In our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.</p>
<h2 id="heading-dynamic-flow-of-execution" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-dynamic-flow-of-execution" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-dynamic-flow-of-execution" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a><strong>Dynamic</strong> Flow of Execution</h2>
<p>To execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.</p>
<p>Let’s look at an example.</p>
<p>Suppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.</p>
<p>Notice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.</p>
<p>We won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:</p>
<p><img loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png?auto=compress,format&amp;format=webp" alt="" class="image--center mx-auto"></p>
<div data-node-type="callout">
<div data-node-type="callout-emoji">💡</div>
<div data-node-type="callout-text">You may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading</div>
</div>

<p>Notice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-comment"># Build workflow</span>
workflow = StateGraph(SupportTicketState)

<span class="hljs-comment"># Add nodes</span>
workflow.add_node(<span class="hljs-string">"classify_ticket"</span>, classify_ticket)
workflow.add_node(<span class="hljs-string">"generate_initial_response"</span>, generate_initial_response)
workflow.add_node(<span class="hljs-string">"check_escalation"</span>, check_escalation_needed)
workflow.add_node(<span class="hljs-string">"escalate_ticket"</span>, escalate_ticket)
workflow.add_node(<span class="hljs-string">"resolve_ticket"</span>, resolve_ticket)

<span class="hljs-comment"># Add edges</span>
workflow.add_edge(START, <span class="hljs-string">"classify_ticket"</span>)
workflow.add_edge(<span class="hljs-string">"classify_ticket"</span>, <span class="hljs-string">"generate_initial_response"</span>)
workflow.add_edge(<span class="hljs-string">"generate_initial_response"</span>, <span class="hljs-string">"check_escalation"</span>)

<span class="hljs-comment"># Conditional edges for escalation</span>
workflow.add_conditional_edges(
    <span class="hljs-string">"check_escalation"</span>,
    should_escalate,
    {
        <span class="hljs-string">"escalate"</span>: <span class="hljs-string">"escalate_ticket"</span>,
        <span class="hljs-string">"resolve"</span>: <span class="hljs-string">"resolve_ticket"</span>
    }
)

workflow.add_edge(<span class="hljs-string">"escalate_ticket"</span>, END)
workflow.add_edge(<span class="hljs-string">"resolve_ticket"</span>, END)
</code></pre></div></div>
<p>Entire code for this is available here: <a target="_blank" href="https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py">https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py</a></p>
<p>This is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.</p>
<p>In the example above, the value of should_escalate, which comes from the check_escalation node, is used to determine which part of the graph or “workflow” we go to next.</p>
<p>A node like "resolve ticket" will look something like this:</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">resolve_ticket</span>(<span class="hljs-params">state: SupportTicketState</span>):</span>
    <span class="hljs-string">"""Resolve the ticket and generate a final customer-facing response."""</span>
    call_resolution_api(state[<span class="hljs-string">'ticket_id'</span>])
    prompt = <span class="hljs-string">f"""
    Generate a customer-facing response to inform them their ticket is resolved.

    Ticket ID: <span class="hljs-subst">{state[<span class="hljs-string">'ticket_id'</span>]}</span>
    Customer: <span class="hljs-subst">{state[<span class="hljs-string">'customer_name'</span>]}</span>
    Issue: <span class="hljs-subst">{state[<span class="hljs-string">'issue_description'</span>]}</span>

    The response should:
    1. State clearly that the issue has been resolved.
    2. Briefly explain the solution.
    3. Thank the customer for their patience.
    4. Ask if they need any further assistance.
    """</span>
    response = llm.invoke(prompt)
    <span class="hljs-keyword">return</span> {
        <span class="hljs-string">"final_response"</span>: response.content,
        <span class="hljs-string">"status"</span>: <span class="hljs-string">"Resolved"</span>
    }
</code></pre></div></div>
<p>Notice how we first call the resolution API and then run the prompt to generate a response for the ticket.</p>
<p>You might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.</p>
<p>Let’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.</p>
<p><strong>By the way, ReAct stands for "Reasoning and Acting."</strong><br>It is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.</p>
<p><img loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png?auto=compress,format&amp;format=webp" alt="" class="image--center mx-auto"></p>
<p>In our example:</p>
<p>The <strong>task</strong> is to either resolve or escalate the ticket and give back a response.</p>
<p>In the <strong>Act</strong> stage, the agent can use a tool to classify, escalate, or resolve the ticket.</p>
<p>In the <strong>Observe</strong> stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.</p>
<p>In the <strong>Reasoning</strong> stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.</p>
<p>Notice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.</p>
<p>To understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.</p>
<p><strong>Now getting to the code:</strong></p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-comment"># --- Agent Definition ---</span>
support_agent = Agent(
    role=<span class="hljs-string">"Senior Customer Support Specialist"</span>,
    goal=<span class="hljs-string">"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses."</span>,
    backstory=(
        <span class="hljs-string">"You are a seasoned support specialist with a knack for understanding customer needs. "</span>
        <span class="hljs-string">"You excel at identifying the root cause of issues, communicating clearly, and "</span>
        <span class="hljs-string">"knowing precisely when a problem needs to be escalated to a senior team member. "</span>
        <span class="hljs-string">"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality."</span>
    ),
    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],
    llm=llm,
    verbose=<span class="hljs-literal">True</span>,
    allow_delegation=<span class="hljs-literal">False</span>
)

<span class="hljs-comment"># --- Task Definition ---</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_ticket_processing_task</span>(<span class="hljs-params">agent, ticket_id, customer_name, issue_description</span>):</span>
    <span class="hljs-keyword">return</span> Task(
        description=<span class="hljs-string">f"""
        Process customer support ticket with the following details:
        - Ticket ID: <span class="hljs-subst">{ticket_id}</span>
        - Customer Name: <span class="hljs-subst">{customer_name}</span>
        - Issue Description: <span class="hljs-subst">{issue_description}</span>

        Follow this exact workflow:
        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).
        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.
        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.
        4.  **Use a Tool**:
            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.
            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.
        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.

        Your final output must be a comprehensive report in markdown format that includes:
        - The classified priority and category.
        - The initial response.
        - The action taken with the corresponding tool.
        - The final customer-facing response.
        """</span>,
        agent=agent,
        expected_output=<span class="hljs-string">"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response."</span>
    )
</code></pre></div></div>
<p>Entire code for this available here: <a target="_blank" href="https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py">https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py</a></p>
<p>Ok, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.</p>
<p><strong>The Little Trick We Play</strong></p>
<p>But here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?</p>
<p><strong>Isn’t That Just a Static Workflow?</strong></p>
<p>Well, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.</p>
<p>For example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.</p>
<p><strong>Real World Example</strong></p>
<p>When I was creating <a target="_blank" href="http://patra.app">patra.app</a><a target="_blank" href="https://patra.app">,</a> which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.</p>
<p>Example:<br>Create me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.</p>
<p>Imagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.</p>
<p>Now imagine an action like:<br>Check my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.</p>
<p>These are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.</p>
<p><strong>Don’t Overcomplicate Simple Things</strong></p>
<p>WOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...</p>
<p>Stop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?</p>
<p>Agents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.</p>
<p>In a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.</p>
<p><img loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png?auto=compress,format&amp;format=webp" alt="" class="image--center mx-auto"></p>
<p><strong>What’s Next?</strong></p>
<p>So far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.</p>
<h2 id="heading-tools-amp-orchestration-framework" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-tools-amp-orchestration-framework" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-tools-amp-orchestration-framework" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a><strong>Tools &amp;</strong> orchestration <strong>Framework</strong></h2>
<p>LLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”</p>
<p><strong>A Simple Example</strong></p>
<p>Let’s break this down with a simple program.</p>
<p>Suppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.</p>
<p><strong>Why Use Tools?</strong></p>
<p>Tools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.</p>
<p><strong>Defining a Tool</strong></p>
<p>Let’s define how our tool will look:</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">add</span>(<span class="hljs-params">a: int, b: int</span>) -&gt; int:</span>
    <span class="hljs-string">"""Adds two integers together."""</span>
    <span class="hljs-keyword">return</span> a + b

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">subtract</span>(<span class="hljs-params">a: int, b: int</span>) -&gt; int:</span>
    <span class="hljs-string">"""Subtracts the second integer from the first."""</span>
    <span class="hljs-keyword">return</span> a - b

SYSTEM_PROMPT = <span class="hljs-string">"""You are a helpful assistant with access to the following functions:

1. `add(a: int, b: int)`: Adds two integers together.
2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.

When a user asks a question that can be answered by one of these functions, 
you MUST respond ONLY with a JSON object in the following format:
{
  "function_name": "name_of_the_function",
  "arguments": {"arg_name": "value", ...}
}

Do not include any other text, explanations, or markdown formatting. 
Your entire response must be only the JSON object.

If you can answer the question without a function, 
just provide the answer directly in plain text."""</span>
</code></pre></div></div>
<p>Notice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can "parse" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.</p>
<p><strong>What does "continuing the conversation" mean?</strong><br>It’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.</p>
<p><strong>That’s basically it.</strong><br>This is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_and_execute</span>(<span class="hljs-params">response_content: str</span>) -&gt; (str, str):</span>
    <span class="hljs-string">"""
    Tries to parse the LLM's text response as a JSON function call.
    If successful, it executes the function and returns the result and function name.
    Otherwise, it returns (None, None).
    """</span>
    <span class="hljs-keyword">try</span>:
        call_data = json.loads(response_content)
        function_name = call_data.get(<span class="hljs-string">"function_name"</span>)
        function_args = call_data.get(<span class="hljs-string">"arguments"</span>)

        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> all([function_name, isinstance(function_args, dict)]):
            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span> <span class="hljs-comment"># Not a valid function call structure</span>

        print(<span class="hljs-string">f"Parser is executing function: '<span class="hljs-subst">{function_name}</span>' with args: <span class="hljs-subst">{function_args}</span>"</span>)

        available_functions = {<span class="hljs-string">"add"</span>: add, <span class="hljs-string">"subtract"</span>: subtract}
        function_to_call = available_functions.get(function_name)

        <span class="hljs-keyword">if</span> function_to_call:
            result = function_to_call(**function_args)
            <span class="hljs-keyword">return</span> str(result), function_name
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">return</span> <span class="hljs-string">f"Error: Unknown function '<span class="hljs-subst">{function_name}</span>'."</span>, function_name

    <span class="hljs-keyword">except</span> (json.JSONDecodeError, TypeError):
        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span> <span class="hljs-comment"># Not JSON or not a dictionary</span>
</code></pre></div></div>
<p>The entire code for this is available here: <a target="_blank" href="https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py">https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py</a></p>
<p>And then there’s the <strong>invoke</strong> method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-comment"># --- 5. The Main Invocation Logic ---</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">invoke</span>(<span class="hljs-params">user_prompt: str</span>):</span>
    <span class="hljs-string">"""
    Invokes the LLM, manually handling the function-calling loop.
    """</span>
    print(<span class="hljs-string">f"\n<span class="hljs-subst">{<span class="hljs-string">'='</span>*<span class="hljs-number">20</span>}</span> Invoking for prompt: '<span class="hljs-subst">{user_prompt}</span>' <span class="hljs-subst">{<span class="hljs-string">'='</span>*<span class="hljs-number">20</span>}</span>"</span>)

    messages = [
        {<span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <span class="hljs-string">"content"</span>: SYSTEM_PROMPT},
        {<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: user_prompt}
    ]

    <span class="hljs-comment"># === Step 1: First LLM Call (without the `tools` parameter) ===</span>
    print(<span class="hljs-string">"\n--- 1. Sending prompt to LLM to generate function call JSON... ---"</span>)
    response = client.chat.completions.create(
        model=<span class="hljs-string">"gpt-4o"</span>,
        messages=messages
    )

    response_message = response.choices[<span class="hljs-number">0</span>].message
    messages.append({<span class="hljs-string">"role"</span>: <span class="hljs-string">"assistant"</span>, <span class="hljs-string">"content"</span>: response_message.content})

    <span class="hljs-comment"># === Step 2: Manually parse the response for a function call ===</span>
    print(<span class="hljs-string">"\n--- 2. Manually parsing response for a function call... ---"</span>)
    function_output, function_name = parse_and_execute(response_message.content)

    <span class="hljs-keyword">if</span> function_output:
        <span class="hljs-comment"># We got a result from our function, so we continue the conversation</span>
        messages.append({
            <span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-comment"># We provide the function result back as the user</span>
            <span class="hljs-string">"content"</span>: <span class="hljs-string">f"I have called the function '<span class="hljs-subst">{function_name}</span>'. The result is: <span class="hljs-subst">{function_output}</span>"</span>
        })

        <span class="hljs-comment"># === Step 3: Second LLM Call with function results ===</span>
        print(<span class="hljs-string">"\n--- 3. Sending function output back to LLM... ---"</span>)

        second_response = client.chat.completions.create(
            model=<span class="hljs-string">"gpt-4o"</span>,
            messages=messages
        )
        final_response = second_response.choices[<span class="hljs-number">0</span>].message.content
    <span class="hljs-keyword">else</span>:
        <span class="hljs-comment"># If parsing failed, the LLM's first response is the final answer</span>
        final_response = response_message.content

    print(<span class="hljs-string">f"\n--- Final Answer ---"</span>)
    print(final_response)
    <span class="hljs-keyword">return</span> final_response
</code></pre></div></div>
<p>You know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.</p>
<p>Today, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: <a target="_blank" href="https://platform.openai.com/docs/quickstart?api-mode=responses">https://platform.openai.com/docs/quickstart?api-mode=responses</a></p>
<p><strong>Exploring Popular Agent Frameworks</strong></p>
<p>Some of the popular Agent frameworks includes -</p>
<ul>
<li><p><strong>CrewAI</strong> – A Python framework for coordinating multiple agents as a team.<br>  Read more: <a target="_blank" href="https://github.com/crewAIInc/crewAI">CrewAI on Github</a></p>
</li>
<li><p><strong>OpenAI Agents SDK</strong> – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.<br>  Read more: <a target="_blank" href="https://openai.github.io/openai-agents-python/">OpenAI Agents SDK (Python)</a></p>
</li>
<li><p><strong>MetaGPT</strong> – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.<br>  Read more: <a target="_blank" href="https://github.com/FoundationAgents/MetaGPT">MetaGPT on GitHub</a></p>
</li>
</ul>
<p>Now that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.</p>
<p><strong>Wait, Persona?</strong></p>
<p>That’s new. Why does an agent need a persona? What is a persona, anyway?</p>
<p>If you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.</p>
<p><strong>Up Next: Multi-Agent Systems</strong></p>
<p>In the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.</p>
<h1 id="heading-multi-agent-system" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-multi-agent-system" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-multi-agent-system" style="height: 38.88px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Multi Agent System</h1>
<p>Now that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.</p>
<p><strong>Remember, agents are just:</strong></p>
<ul>
<li><p>An LLM with access to tools</p>
</li>
<li><p>A set of prompts (like persona, goal, etc.)</p>
</li>
<li><p>Memory (which we’ll talk about later)</p>
</li>
<li><p>All built using an orchestration framework so everything works together</p>
</li>
</ul>
<p>But what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.</p>
<p><img loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png?auto=compress,format&amp;format=webp" alt="" class="image--center mx-auto"></p>
<p>Source: <a target="_blank" href="https://docs.crewai.com/concepts/collaboration">CrewAI Collaboration Concepts</a></p>
<p>All the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.</p>
<p><strong>Why Use Multi-Agent Systems?</strong></p>
<p>Multi-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their <a target="_blank" href="https://www.anthropic.com/engineering/built-multi-agent-research-system">blog post</a> on multi-agent systems, is that you can use more tokens (so the system can "think more") when tackling a complex problem.</p>
<p>In the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.</p>
<p>You can read about different types of multi agent systems later <a target="_blank" href="https://langchain-ai.github.io/langgraph/concepts/multi_agent/">here</a>.</p>
<p><strong>Warning:</strong> As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.</p>
<h1 id="heading-memory" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-memory" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-memory" style="height: 38.88px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Memory</h1>
<p>We have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.</p>
<p>In many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.</p>
<p>There are two forms of memory that an AI agent can potentially have, much like humans do:</p>
<h3 id="heading-short-term-memory" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-short-term-memory" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-short-term-memory" style="height: 36px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a><strong>Short Term Memory</strong></h3>
<p>Short term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.</p>
<p>Here’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:</p>
<p>M1: User: perform 10 + 20 + 30 + 40 + 50<br>M2: LLM: <em>Tool call, 10 + 20</em><br>M3: User: Output 30<br>M4: LLM: <em>Current answer is 30, let’s proceed. Tool call 30 + 30</em><br>M5: User: Output 60<br>M6: LLM: <em>Current answer is 60, let’s proceed. Tool call 60 + 40</em></p>
<p>At this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:</p>
<p>M1: User: perform 10 + 20 + 30 + 40 + 50<br>M2’: User: Output of 10 + 20 + 30 is 60, proceed further.<br>M6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40</p>
<p>Notice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.</p>
<p>Sometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.</p>
<p>We also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.<br><strong>RAISE stands for Reasoning and Acting through Scratchpad and Examples.</strong> The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.</p>
<p>Read the paper that introduced RAISE framework here: <a target="_blank" href="https://arxiv.org/pdf/2401.02777">https://arxiv.org/pdf/2401.02777</a></p>
<h3 id="heading-long-term-memory" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-long-term-memory" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-long-term-memory" style="height: 36px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a><strong>Long Term Memory</strong></h3>
<p>Long-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.</p>
<p>In our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.</p>
<p>Notice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.</p>
<h1 id="heading-mental-model-to-work-with-agents" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-mental-model-to-work-with-agents" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-mental-model-to-work-with-agents" style="height: 38.88px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Mental Model to work with agents</h1>
<p>That’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made <a target="_blank" href="http://patra.app">patra.app</a> work reliably, and also how I’ve shipped multiple other production systems.</p>
<p><strong>The golden model:</strong><br>Keep yourself in the place of the agent. Imagine you are that agent.</p>
<p>It might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.</p>
<p>Put yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?</p>
<p>Now, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.</p>
<h2 id="heading-conclusion" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="#heading-conclusion" data-clipboard-text="https://blog.surkar.in/ai-agents-under-the-hood#heading-conclusion" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Conclusion</h2>
<p>Hopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.</p>
<p>If you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.</p>
<p>There is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions "AI agent" in conversation, you will know not only what it is but also how it thinks and works.</p>
<p>If you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens.</p>
</div><style>.post-floating-bar {
              bottom: -60px;
            }
            .post-floating-bar.animation {
              -webkit-transition: .2s all;
              -o-transition: .2s all;
              transition: .2s all;
              transition-timing-function: ease-in;
            }
            .post-floating-bar.active {
              bottom: 40px
            }
            .post-floating-bar.freeze {
              bottom: 0!important;
              position: absolute!important;
              transition: none!important;
            }
            .post-floating-bar.freeze > div {
              box-shadow: none!important;
            }
            </style><div class="post-floating-bar fixed left-0 right-0 z-50 flex h-12 w-full flex-wrap justify-center 2xl:h-14"><div class="relative mx-auto flex h-12 shrink flex-wrap items-center justify-center rounded-full border-1/2 border-slate-200 bg-white px-5 py-1 text-sm text-slate-800 shadow-xl dark:border-slate-700 dark:bg-slate-900 dark:text-slate-50 2xl:h-14"><div class="relative"><style>
          @keyframes slideUpAndFade {
            from {
              opacity: 0;
              transform: translateY(2px);
            }
            to {
              opacity: 1;
              transform: translateY(0);
            }
          }

          .reaction-count-tooltip-content {
            box-shadow: hsl(206 22% 7% / 35%) 0px 10px 38px -10px, hsl(206 22% 7% / 20%) 0px 10px 20px -15px;
            user-select: none;
            transition: .2s all;
            animation-duration: 400ms;
            animation-timing-function: cubic-bezier(0.16, 1, 0.3, 1);
            will-change: transform, opacity;
          }
          .reaction-count-tooltip-content[data-state='instant-open'][data-side='top'] {
            animation-name: slideUpAndFade;
          }

          @keyframes shake {
            0% { transform: translateX(0) }
            25% { transform: translateX(1px) }
            50% { transform: translateX(-1px) }
            75% { transform: translateX(1px) }
            100% { transform: translateX(0) }
          }
          .shake {
            animation-name: shake;
            animation-iteration-count: 2;
            animation-duration: 400ms;
            animation-timing-function: cubic-bezier(0.16, 1, 0.3, 1);
            will-change: transform, opacity;
          }
          </style><div class="outline-none! relative flex cursor-pointer items-center"><div class="outline-none! relative flex w-8 cursor-pointer items-center sm:w-10"><button type="button" aria-label="Like this article" class="outline-none absolute z-50 rounded-full p-2 hover:bg-slate-100 focus:outline-none dark:hover:bg-slate-800" data-state="closed"><svg viewBox="0 0 22 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6 stroke-current text-slate-800 dark:text-slate-50"><path d="M11 19C12 19 21 14.0002 21 7.00043C21 3.50057 18 1.04405 15 1.00065C13.5 0.978943 12 1.50065 11 3.00059C10 1.50065 8.47405 1.00065 7 1.00065C4 1.00065 1 3.50057 1 7.00043C1 14.0002 10 19 11 19Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div><div><button type="button" class="outline-none outline-none! text-sm text-slate-800 hover:underline dark:text-slate-200" data-state="closed">4</button></div></div></div><div data-orientation="vertical" aria-orientation="vertical" role="separator" class="my-auto w-px bg-slate-200 dark:bg-slate-700 mx-2 h-5"></div><div data-state="closed" class="outline-none"><button type="button" aria-label="1 comment, open the comments" class="outline-none! flex cursor-pointer items-center rounded-full hover:bg-slate-100 dark:hover:bg-slate-800"><span class="rounded-full p-2"><svg class="h-4 w-4 stroke-current text-slate-800 dark:text-slate-50 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.5 10.6667H9.83333M6.5 7.75H12.3333M9 16.5C13.1421 16.5 16.5 13.1421 16.5 9C16.5 4.85786 13.1421 1.5 9 1.5C4.85786 1.5 1.5 4.85786 1.5 9C1.5 9.99762 1.69478 10.9497 2.04839 11.8204C2.11606 11.9871 2.1499 12.0704 2.165 12.1377C2.17976 12.2036 2.18516 12.2524 2.18517 12.3199C2.18518 12.3889 2.17265 12.4641 2.14759 12.6145L1.65344 15.5794C1.60169 15.8898 1.57582 16.0451 1.62397 16.1573C1.66611 16.2556 1.7444 16.3339 1.84265 16.376C1.95491 16.4242 2.11015 16.3983 2.42063 16.3466L5.38554 15.8524C5.53591 15.8273 5.61109 15.8148 5.68011 15.8148C5.74763 15.8148 5.79638 15.8202 5.86227 15.835C5.92962 15.8501 6.01294 15.8839 6.17958 15.9516C7.05025 16.3052 8.00238 16.5 9 16.5Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span><span class="ml-0.5 pr-2">1</span></button></div><div data-orientation="vertical" aria-orientation="vertical" role="separator" class="my-auto w-px bg-slate-200 dark:bg-slate-700 mx-2 h-5"></div><button type="button" title="Add Bookmark" aria-label="Add Bookmark" class="outline-none outline-none! flex cursor-pointer items-center" data-state="closed"><span class="rounded-full p-2 hover:bg-slate-100 dark:hover:bg-slate-800"><svg viewBox="0 0 16 20" class="h-4 w-4 scale-[0.97] stroke-current text-slate-800 dark:text-slate-50 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M15.2 19V5.8C15.2 4.11984 15.2 3.27976 14.8731 2.63803C14.5854 2.07354 14.1265 1.6146 13.562 1.32698C12.9203 1 12.0802 1 10.4 1H5.60005C3.91989 1 3.07981 1 2.43808 1.32698C1.87359 1.6146 1.41465 2.07354 1.12703 2.63803C0.800049 3.27976 0.800049 4.11984 0.800049 5.8V19L5.85342 16.4733C6.64052 16.0798 7.03406 15.883 7.44686 15.8055C7.81246 15.737 8.18764 15.737 8.55324 15.8055C8.96603 15.883 9.35959 16.0798 10.1467 16.4733L15.2 19Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></button><div id="portal-content"></div><div data-orientation="vertical" aria-orientation="vertical" role="separator" class="my-auto w-px bg-slate-200 dark:bg-slate-700 mx-2 h-5"></div><button type="button" id="radix-:r4:" aria-haspopup="menu" aria-expanded="false" data-state="closed" aria-label="Share this article" class="outline-none outline-none! cursor-pointer rounded-full p-2 hover:bg-slate-100 dark:hover:bg-slate-800"><svg viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 stroke-current text-slate-800 dark:text-slate-50 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6"><path d="M6.25 7.91667L11.75 5.08333M6.25 10.0833L11.75 12.9167M6.5 9C6.5 10.3807 5.38071 11.5 4 11.5C2.61929 11.5 1.5 10.3807 1.5 9C1.5 7.61929 2.61929 6.5 4 6.5C5.38071 6.5 6.5 7.61929 6.5 9ZM16.5 4C16.5 5.38071 15.3807 6.5 14 6.5C12.6193 6.5 11.5 5.38071 11.5 4C11.5 2.61929 12.6193 1.5 14 1.5C15.3807 1.5 16.5 2.61929 16.5 4ZM16.5 14C16.5 15.3807 15.3807 16.5 14 16.5C12.6193 16.5 11.5 15.3807 11.5 14C11.5 12.6193 12.6193 11.5 14 11.5C15.3807 11.5 16.5 12.6193 16.5 14Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div></div></div><div class="my-10 mt-20 flex w-full flex-col items-center pb-10 md:px-5"><h2 class="mb-5 text-center font-heading text-2xl font-bold text-slate-900 dark:text-slate-50 md:text-3xl">Subscribe to our newsletter</h2><p class="mb-5 text-center text-lg text-slate-700 dark:text-slate-300 md:w-2/3 md:text-xl">Read articles from <strong>Manthan Surkar</strong> directly inside your inbox. Subscribe to the newsletter, and don't miss out.</p><div class="flex flex-row overflow-hidden rounded-lg border border-slate-800 dark:border-slate-200 md:w-2/3"><input aria-label="Enter your email address" type="email" placeholder="Enter your email address" class="w-full bg-transparent p-3 text-black outline-none dark:text-white md:p-5 md:text-lg" value=""><button class="border border-transparent py-1 text-base leading-relaxed disabled:opacity-50 flex flex-row items-center focus:outline-none shrink-0 rounded-none bg-slate-800 px-3 font-bold uppercase tracking-wide text-white hover:bg-slate-700 dark:bg-slate-200 dark:text-black dark:hover:bg-slate-300 md:px-5" type="button" variant="transparent">Subscribe</button></div></div><div class="mb-5 flex w-full flex-row flex-wrap justify-center md:mb-0"><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="/tag/ai?source=tags_bottom_blogs"><span>AI</span></a><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="/tag/ai-agent?source=tags_bottom_blogs"><span>ai-agent</span></a><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="/tag/software-development?source=tags_bottom_blogs"><span>software development</span></a></div></div></section></div><div class="absolute h-px w-px overflow-hidden" id="refNode1" style="top:100px;left:100px">&nbsp;</div><div class="absolute left-0 top-0 h-px w-px overflow-hidden" id="refNode2"></div><div class="absolute z-50 mt-4 hidden"><div class="flex flex-row items-center rounded-lg border border-slate-300 bg-white p-4 text-slate-800 shadow-lg dark:border-white dark:bg-slate-800 dark:text-slate-300"><span class="mr-3 block">Share this</span><a href="https://twitter.com/share?url=https%3A%2F%2Fblog.surkar.in%2Fai-agents-under-the-hood&amp;text=%20%40surkar" class="rounded-full border border-transparent py-1 font-medium text-slate-700 dark:text-slate-200 hover:bg-slate-200 disabled:opacity-50 hover:dark:bg-slate-700 flex flex-row items-center focus:outline-none px-2 text-sm" variant="transparent" target="_blank" rel="noopener"><svg class="h-6 w-6 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.643 13.346L4.26862 4.86856C3.85863 4.32329 4.2478 3.54408 4.93001 3.54431L7.2184 3.54508C7.47633 3.54517 7.71945 3.66557 7.87585 3.87066L12.9065 10.4675M10.643 13.346L5.19311 20.5093M10.643 13.346L15.8028 20.077C15.9588 20.2805 16.2003 20.4001 16.4567 20.4009L18.7925 20.4082C19.4778 20.4104 19.8683 19.6261 19.4536 19.0805L12.9065 10.4675M12.9065 10.4675L18.2181 3.50928" stroke-width="1.5" stroke-linecap="round"></path></svg></a><a href="http://www.reddit.com/submit?title=AI%20Agents%20Under%20The%20Hood&amp;selftext=true&amp;text=%20https%3A%2F%2Fblog.surkar.in%2Fai-agents-under-the-hood" class="rounded-full border border-transparent py-1 font-medium hover:bg-slate-200 disabled:opacity-50 hover:dark:bg-slate-700 flex flex-row items-center focus:outline-none px-2 text-sm text-red-600 dark:text-red-600" variant="transparent" target="_blank" rel="noopener"><svg class="h-6 w-6 fill-current" viewBox="0 0 512 512"><path d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"></path></svg></a><button class="rounded-full border border-transparent py-1 font-medium text-slate-700 dark:text-slate-200 hover:bg-slate-200 disabled:opacity-50 hover:dark:bg-slate-700 flex flex-row items-center focus:outline-none px-2 text-sm" type="button" variant="transparent" data-clipboard-text=" https://blog.surkar.in/ai-agents-under-the-hood" id="text-sharer"><svg class="h-6 w-6 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></button></div></div><div class="blog-more-articles mb-20 mt-10"><h3 class="blog-more-articles-title mb-5 text-center font-semibold uppercase tracking-wider text-slate-500 dark:text-slate-400">More articles</h3><div class="blog-more-articles-wrapper container mx-auto grid grid-flow-row grid-cols-6 px-4 xl:grid-cols-9 xl:gap-6 2xl:px-0"><div class="mb-5 px-2 dark:border-slate-800 lg:mb-0 col-span-full md:col-span-3 lg:col-span-2 xl:col-span-3"><div class="blog-similar-article-wrapper h-full rounded-lg border p-4 dark:border-slate-800"><div class="blog-similar-author-wrapper mb-3 flex flex-row items-center"><div class="flex flex-row items-center"><div class="mr-2 h-6 w-6 overflow-hidden rounded-full"><a href="https://hashnode.com/@surkar" class="relative block h-full w-full"><span style="box-sizing: border-box; display: inline-block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative; max-width: 100%;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; max-width: 100%;"><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2770%27%20height=%2770%27/%3e" style="display: block; max-width: 100%; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px;"></span><img alt="Manthan Surkar's photo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="blog-similar-author-photo author-photo relative z-20 block w-full rounded-full" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a></div><a href="https://hashnode.com/@surkar" class="blog-similar-author-name font-bold text-black dark:text-white">Manthan Surkar</a></div></div><div class="blog-post-details break-words"><h1 class="mb-2 font-heading text-2xl font-bold leading-tight tracking-tight text-slate-900 dark:text-white"><a href="https://blog.surkar.in/prompt-smells-just-like-code?source=more_articles_bottom_blogs">Prompt Smells, Just Like Code</a></h1><p class="text-base md:text-lg text-slate-700 dark:text-slate-400"><a href="https://blog.surkar.in/prompt-smells-just-like-code?source=more_articles_bottom_blogs">Prompt Smells
The term "code smell" was introduced by Kent Beck in the late 1990s. It was meant to c…</a></p></div></div></div><div class="mb-5 px-2 dark:border-slate-800 lg:mb-0 col-span-full md:col-span-3 lg:col-span-2 xl:col-span-3"><div class="blog-similar-article-wrapper h-full rounded-lg border p-4 dark:border-slate-800"><div class="blog-similar-author-wrapper mb-3 flex flex-row items-center"><div class="flex flex-row items-center"><div class="mr-2 h-6 w-6 overflow-hidden rounded-full"><a href="https://hashnode.com/@surkar" class="relative block h-full w-full"><span style="box-sizing: border-box; display: inline-block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative; max-width: 100%;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; max-width: 100%;"><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2770%27%20height=%2770%27/%3e" style="display: block; max-width: 100%; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px;"></span><img alt="Manthan Surkar's photo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="blog-similar-author-photo author-photo relative z-20 block w-full rounded-full" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a></div><a href="https://hashnode.com/@surkar" class="blog-similar-author-name font-bold text-black dark:text-white">Manthan Surkar</a></div></div><div class="blog-post-details break-words"><h1 class="mb-2 font-heading text-2xl font-bold leading-tight tracking-tight text-slate-900 dark:text-white"><a href="https://blog.surkar.in/words-dont-compile?source=more_articles_bottom_blogs">Words Don’t Compile</a></h1><p class="text-base md:text-lg text-slate-700 dark:text-slate-400"><a href="https://blog.surkar.in/words-dont-compile?source=more_articles_bottom_blogs">I wrote my first line of code at ten. It was either a small tweak to a WordPress plugin or a little …</a></p></div></div></div><div class="mb-5 px-2 dark:border-slate-800 lg:mb-0 col-span-full md:col-span-3 lg:col-span-2 xl:col-span-3"><div class="blog-similar-article-wrapper h-full rounded-lg border p-4 dark:border-slate-800"><div class="blog-similar-author-wrapper mb-3 flex flex-row items-center"><div class="flex flex-row items-center"><div class="mr-2 h-6 w-6 overflow-hidden rounded-full"><a href="https://hashnode.com/@surkar" class="relative block h-full w-full"><span style="box-sizing: border-box; display: inline-block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative; max-width: 100%;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; max-width: 100%;"><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2770%27%20height=%2770%27/%3e" style="display: block; max-width: 100%; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px;"></span><img alt="Manthan Surkar's photo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="blog-similar-author-photo author-photo relative z-20 block w-full rounded-full" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a></div><a href="https://hashnode.com/@surkar" class="blog-similar-author-name font-bold text-black dark:text-white">Manthan Surkar</a></div></div><a href="https://blog.surkar.in/o1-models-vs-simple-chain-of-thought-whats-the-difference?source=more_articles_bottom_blogs" class="blog-similar-article-cover post-cover mb-3 block rounded border bg-cover bg-center dark:border-slate-800"><span style="box-sizing: border-box; display: block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 52.4% 0px 0px;"></span><img alt="O1 Models vs. Simple Chain of Thought: What’s the Difference?" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a><div class="blog-post-details break-words"><h1 class="mb-2 font-heading text-2xl font-bold leading-tight tracking-tight text-slate-900 dark:text-white"><a href="https://blog.surkar.in/o1-models-vs-simple-chain-of-thought-whats-the-difference?source=more_articles_bottom_blogs">O1 Models vs. Simple Chain of Thought: What’s the Difference?</a></h1><p class="text-base text-slate-700 dark:text-slate-400"><a href="https://blog.surkar.in/o1-models-vs-simple-chain-of-thought-whats-the-difference?source=more_articles_bottom_blogs">OpenAI recently released the O1 model series, which has outperformed on multiple benchmarks (more on…</a></p></div></div></div></div></div><div class="container relative z-20 mx-auto grid grid-flow-row grid-cols-8 xl:gap-6 2xl:grid-cols-10"><div class="blog-comments-section-wrapper col-span-8 px-4 lg:col-span-6 lg:col-start-2 lg:px-0 xl:col-span-6 xl:col-start-2 2xl:col-span-6 2xl:col-start-3"></div></div></article></main></div><div class="blog-footer border-t bg-slate-100 dark:border-slate-800 dark:bg-slate-950"><footer class="container mx-auto grid grid-cols-2 items-center gap-12 px-4 pb-20 pt-10 xl:px-10 2xl:px-24"><div class="col-span-full flex flex-col items-center gap-3 md:col-span-1 md:items-start md:gap-5"><p class="text-sm font-medium text-slate-600 dark:text-slate-400">©2025 Manthan Surkar</p></div><div class="col-span-full md:col-span-1"><div class="flex flex-row flex-wrap justify-center gap-2 text-sm text-slate-800 dark:text-slate-200 md:flex-nowrap md:justify-end"><a class="hover:text-blue-600 dark:hover:text-blue-500" rel="noopener" href="/archive">Archive</a><span class="font-extrabold text-slate-500 dark:text-slate-400">·</span><a href="https://hashnode.com/privacy?source=blog-footer" class="hover:text-blue-600 dark:hover:text-blue-500">Privacy policy</a><span class="font-extrabold text-slate-500 dark:text-slate-400">·</span><a class="hover:text-blue-600 dark:hover:text-blue-500" href="https://hashnode.com/terms?source=blog-footer">Terms</a></div></div><div class="col-span-full flex flex-row items-center justify-center gap-1 text-slate-600 dark:text-slate-500"><svg fill="none" class="h-3 w-3 stroke-current" viewBox="0 0 24 24"><path stroke="currentColor" stroke-width="1.5" d="M11.2 5.06s.3-1.295.8-1.295.8 1.295.8 1.295c1.34 4.47 1.67 4.8 6.14 6.14 0 0 1.295.3 1.295.8s-1.295.8-1.295.8c-4.47 1.34-4.8 1.67-6.14 6.14 0 0-.3 1.295-.8 1.295s-.8-1.295-.8-1.295c-1.34-4.47-1.67-4.8-6.14-6.14 0 0-1.295-.3-1.295-.8s1.295-.8 1.295-.8c4.47-1.34 4.8-1.67 6.14-6.14Z"></path></svg><svg fill="none" class="h-3 w-3 stroke-current" viewBox="0 0 24 24"><path stroke="currentColor" stroke-width="1.5" d="M11.2 5.06s.3-1.295.8-1.295.8 1.295.8 1.295c1.34 4.47 1.67 4.8 6.14 6.14 0 0 1.295.3 1.295.8s-1.295.8-1.295.8c-4.47 1.34-4.8 1.67-6.14 6.14 0 0-.3 1.295-.8 1.295s-.8-1.295-.8-1.295c-1.34-4.47-1.67-4.8-6.14-6.14 0 0-1.295-.3-1.295-.8s1.295-.8 1.295-.8c4.47-1.34 4.8-1.67 6.14-6.14Z"></path></svg><svg fill="none" class="h-3 w-3 stroke-current" viewBox="0 0 24 24"><path stroke="currentColor" stroke-width="1.5" d="M11.2 5.06s.3-1.295.8-1.295.8 1.295.8 1.295c1.34 4.47 1.67 4.8 6.14 6.14 0 0 1.295.3 1.295.8s-1.295.8-1.295.8c-4.47 1.34-4.8 1.67-6.14 6.14 0 0-.3 1.295-.8 1.295s-.8-1.295-.8-1.295c-1.34-4.47-1.67-4.8-6.14-6.14 0 0-1.295-.3-1.295-.8s1.295-.8 1.295-.8c4.47-1.34 4.8-1.67 6.14-6.14Z"></path></svg><svg fill="none" class="h-3 w-3 stroke-current" viewBox="0 0 24 24"><path stroke="currentColor" stroke-width="1.5" d="M11.2 5.06s.3-1.295.8-1.295.8 1.295.8 1.295c1.34 4.47 1.67 4.8 6.14 6.14 0 0 1.295.3 1.295.8s-1.295.8-1.295.8c-4.47 1.34-4.8 1.67-6.14 6.14 0 0-.3 1.295-.8 1.295s-.8-1.295-.8-1.295c-1.34-4.47-1.67-4.8-6.14-6.14 0 0-1.295-.3-1.295-.8s1.295-.8 1.295-.8c4.47-1.34 4.8-1.67 6.14-6.14Z"></path></svg></div><div class="col-span-full flex flex-col items-center justify-center gap-5 text-slate-600 dark:text-slate-400"><a href="https://hashnode.com?source=blog-footer" target="_Blank" rel="noopener" class="hover:text-slate-800 dark:hover:text-slate-50"><svg class="h-8 w-8 fill-current" viewBox="0 0 200 200" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.742 66.824c-18.323 18.323-18.323 48.029 0 66.352l53.082 53.082c18.323 18.323 48.029 18.323 66.352 0l53.082-53.082c18.323-18.323 18.323-48.03 0-66.352l-53.082-53.082c-18.323-18.323-48.03-18.323-66.352 0L13.742 66.824zm109.481 56.399c12.826-12.826 12.826-33.62 0-46.446s-33.62-12.826-46.446 0-12.826 33.62 0 46.446 33.62 12.826 46.446 0z"></path></svg></a><p class="text-center text-sm">Powered by Hashnode - Build your developer hub.</p><div class="flex flex-row gap-2"><a href="https://hashnode.com/products/blogs?source=blog-footer" class="block rounded-lg border bg-white px-4 py-2 text-sm hover:bg-slate-50 dark:border-slate-700 dark:bg-slate-900 dark:hover:bg-slate-800">Start your blog</a><a href="https://hashnode.com/products/docs?source=blog-footer" class="block rounded-lg border bg-white px-4 py-2 text-sm hover:bg-slate-50 dark:border-slate-700 dark:bg-slate-900 dark:hover:bg-slate-800">Create docs</a></div></div></footer></div></div></div><script type="text/javascript">
              var SUPPORTS_PASSIVE = false;
              try {
                var opts = Object.defineProperty({}, 'passive', {
                  get: function() {
                    SUPPORTS_PASSIVE = true;
                  }
                });
                window.addEventListener("testPassive", null, opts);
                window.removeEventListener("testPassive", null, opts);
              } catch (e) {}
            </script><script type="text/javascript">
              // Array.prototype.flat polyfill
              if (!Array.prototype.flat) {
                // eslint-disable-next-line no-extend-native
                Object.defineProperty(Array.prototype, 'flat', {
                  configurable: true,
                  writable: true,
                  value() {
                    // eslint-disable-next-line prefer-rest-params
                    const depth = typeof arguments[0] === 'undefined' ? 1 : Number(arguments[0]) || 0;
                    const result = [];
                    const { forEach } = result;

                    // eslint-disable-next-line no-var
                    var flatDeep = function (arr, depth) {
                      forEach.call(arr, (val) => {
                        if (depth > 0 && Array.isArray(val)) {
                          flatDeep(val, depth - 1);
                        } else {
                          result.push(val);
                        }
                      });
                    };

                    flatDeep(this, depth);
                    return result;
                  },
                });
              }
            </script><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":"{\"_id\":\"6857dcad0f01cc2215fffd04\",\"partOfPublication\":true,\"author\":{\"_id\":\"669e9506d4920b5b5b00bcef\",\"name\":\"Manthan Surkar\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg\",\"username\":\"surkar\",\"bio\":\"\",\"socialMedia\":{\"website\":\"https://surkar.in\",\"github\":\"https://github.com/thesmallstar\",\"twitter\":\"\",\"facebook\":\"\",\"stackoverflow\":\"\",\"linkedin\":\"https://www.linkedin.com/in/manthansurkar/\"},\"isDeactivated\":false},\"bookmarkedIn\":[],\"publication\":{\"_id\":\"669e957c19b8bd50367fe79c\",\"author\":{\"_id\":\"669e9506d4920b5b5b00bcef\",\"name\":\"Manthan Surkar\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg\",\"username\":\"surkar\"},\"badgePageEnabled\":true,\"description\":\"\",\"domain\":\"blog.surkar.in\",\"domainStatus\":{\"ready\":true,\"certIssued\":true},\"wwwPrefixedDomainStatus\":{},\"customCSSEnabled\":false,\"customCSSPublished\":{\"homeMin\":\"\",\"postMin\":\"\",\"staticMin\":\"\"},\"customRules\":[],\"darkModeEnabled\":false,\"darkModeLogo\":\"\",\"disableFooterBranding\":false,\"isSubscriptionModalDisabled\":false,\"publicMembersCount\":1,\"displayTitle\":\"\",\"favicon\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1751198022133/1c8c4430-333f-4491-9e43-465d6dcb65c0.png\",\"gaTrackingID\":\"\",\"gTagManagerID\":\"\",\"hasBadges\":true,\"headerColor\":\"\",\"hideMembersPage\":false,\"isTeam\":true,\"layout\":\"stacked\",\"membersPageEnabled\":true,\"menu\":[],\"metaHTML\":\"\",\"metaHTMLSanitized\":\"\",\"newsletterEnabled\":true,\"proTeamEnabled\":false,\"newsletterPageEnabled\":false,\"ogImage\":\"\",\"logo\":\"\",\"textSelectionSharerEnabled\":true,\"title\":\"Manthan Surkar\",\"urlPattern\":\"simple\",\"username\":\"surkar\",\"viewCountVisible\":true,\"readTimeHidden\":false,\"links\":{\"twitter\":\"https://twitter.com/manthan_surkar\",\"instagram\":\"\",\"github\":\"https://github.com/thesmallstar\",\"website\":\"\",\"hashnode\":\"https://hashnode.com/@surkar\",\"youtube\":\"\",\"dailydev\":\"\",\"linkedin\":\"\",\"mastodon\":\"\",\"facebook\":\"\"},\"numPosts\":4,\"sponsorship\":{\"content\":\"\",\"contentMarkdown\":\"\"},\"allowContributorEdits\":true,\"allowCrawlingByGPT\":false},\"tags\":[{\"_id\":\"56744721958ef13879b9488e\",\"slug\":\"ai\",\"name\":\"AI\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"65f70fe712e12dacdb744b16\",\"slug\":\"ai-agent\",\"name\":\"ai-agent\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"56744721958ef13879b94ad1\",\"slug\":\"software-development\",\"name\":\"software development\",\"isActive\":true,\"isApproved\":true}],\"coAuthors\":[],\"responseCount\":1,\"replyCount\":0,\"contentMarkdown\":\"## Motivation: Why You Should Care\\n\\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like [patra.app](https://patra.app). While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...\\n\\nDuring one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”\\n\\nThey gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.\\n\\nWell, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.\\n\\nI promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:\\n\\n1. What an AI agent is\\n    \\n2. How an AI agent works\\n    \\n3. What the heck tools are\\n    \\n4. What an orchestration framework is\\n    \\n5. What memory is\\n    \\n6. What the types of AI agents are\\n    \\n7. The mental model for building an AI agent\\n    \\n8. What a multi-agent framework is\\n    \\n\\nBefore we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.\\n\\n## The Problem\\n\\nOk, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png align=\\\"center\\\")\\n\\n\u003e An AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention\\n\\nYou see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.\\n\\nIf I ask, \\\"What is an LLM?\\\" we get a much more acceptable answer:\\n\\n\u003e A Large Language Model (LLM) is **a type of AI model, specifically a deep learning model, trained on massive amounts of text data.**\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png align=\\\"center\\\")\\n\\nNotice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.\\n\\n# Defining AI Agent\\n\\nLet’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:\\n\\nAgents are **software systems** where **LLMs** use reasoning to control the flow of execution, **dynamically** choosing which **tools** to use and determining each step required to reach a **goal**.\\n\\nThat’s a mouthful. Let’s break down each part so we can actually understand it.\\n\\n## **Agents are Software Systems**\\n\\nThis is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:\\n\\n1. LLMs\\n    \\n2. Working Memory or state\\n    \\n3. Prompts\\n    \\n4. Tools\\n    \\n5. Orchestration Layer\\n    \\n\\nYou already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.\\n\\nIn our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.\\n\\n## **Dynamic** Flow of Execution\\n\\nTo execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.\\n\\nLet’s look at an example.\\n\\nSuppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.\\n\\nNotice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.\\n\\nWe won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png align=\\\"center\\\")\\n\\n\u003cdiv data-node-type=\\\"callout\\\"\u003e\\n\u003cdiv data-node-type=\\\"callout-emoji\\\"\u003e💡\u003c/div\u003e\\n\u003cdiv data-node-type=\\\"callout-text\\\"\u003eYou may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading\u003c/div\u003e\\n\u003c/div\u003e\\n\\nNotice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.\\n\\n```python\\n# Build workflow\\nworkflow = StateGraph(SupportTicketState)\\n\\n# Add nodes\\nworkflow.add_node(\\\"classify_ticket\\\", classify_ticket)\\nworkflow.add_node(\\\"generate_initial_response\\\", generate_initial_response)\\nworkflow.add_node(\\\"check_escalation\\\", check_escalation_needed)\\nworkflow.add_node(\\\"escalate_ticket\\\", escalate_ticket)\\nworkflow.add_node(\\\"resolve_ticket\\\", resolve_ticket)\\n\\n# Add edges\\nworkflow.add_edge(START, \\\"classify_ticket\\\")\\nworkflow.add_edge(\\\"classify_ticket\\\", \\\"generate_initial_response\\\")\\nworkflow.add_edge(\\\"generate_initial_response\\\", \\\"check_escalation\\\")\\n\\n# Conditional edges for escalation\\nworkflow.add_conditional_edges(\\n    \\\"check_escalation\\\",\\n    should_escalate,\\n    {\\n        \\\"escalate\\\": \\\"escalate_ticket\\\",\\n        \\\"resolve\\\": \\\"resolve_ticket\\\"\\n    }\\n)\\n\\nworkflow.add_edge(\\\"escalate_ticket\\\", END)\\nworkflow.add_edge(\\\"resolve_ticket\\\", END)\\n```\\n\\nEntire code for this is available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py)\\n\\nThis is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.\\n\\nIn the example above, the value of should\\\\_escalate, which comes from the check\\\\_escalation node, is used to determine which part of the graph or “workflow” we go to next.\\n\\nA node like \\\"resolve ticket\\\" will look something like this:\\n\\n```python\\ndef resolve_ticket(state: SupportTicketState):\\n    \\\"\\\"\\\"Resolve the ticket and generate a final customer-facing response.\\\"\\\"\\\"\\n    call_resolution_api(state['ticket_id'])\\n    prompt = f\\\"\\\"\\\"\\n    Generate a customer-facing response to inform them their ticket is resolved.\\n    \\n    Ticket ID: {state['ticket_id']}\\n    Customer: {state['customer_name']}\\n    Issue: {state['issue_description']}\\n    \\n    The response should:\\n    1. State clearly that the issue has been resolved.\\n    2. Briefly explain the solution.\\n    3. Thank the customer for their patience.\\n    4. Ask if they need any further assistance.\\n    \\\"\\\"\\\"\\n    response = llm.invoke(prompt)\\n    return {\\n        \\\"final_response\\\": response.content,\\n        \\\"status\\\": \\\"Resolved\\\"\\n    }\\n```\\n\\nNotice how we first call the resolution API and then run the prompt to generate a response for the ticket.\\n\\nYou might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.\\n\\nLet’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.\\n\\n**By the way, ReAct stands for \\\"Reasoning and Acting.\\\"**  \\nIt is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png align=\\\"center\\\")\\n\\nIn our example:\\n\\nThe **task** is to either resolve or escalate the ticket and give back a response.\\n\\nIn the **Act** stage, the agent can use a tool to classify, escalate, or resolve the ticket.\\n\\nIn the **Observe** stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.\\n\\nIn the **Reasoning** stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.\\n\\nNotice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.\\n\\nTo understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.\\n\\n**Now getting to the code:**\\n\\n```python\\n# --- Agent Definition ---\\nsupport_agent = Agent(\\n    role=\\\"Senior Customer Support Specialist\\\",\\n    goal=\\\"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses.\\\",\\n    backstory=(\\n        \\\"You are a seasoned support specialist with a knack for understanding customer needs. \\\"\\n        \\\"You excel at identifying the root cause of issues, communicating clearly, and \\\"\\n        \\\"knowing precisely when a problem needs to be escalated to a senior team member. \\\"\\n        \\\"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality.\\\"\\n    ),\\n    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],\\n    llm=llm,\\n    verbose=True,\\n    allow_delegation=False\\n)\\n\\n# --- Task Definition ---\\ndef create_ticket_processing_task(agent, ticket_id, customer_name, issue_description):\\n    return Task(\\n        description=f\\\"\\\"\\\"\\n        Process customer support ticket with the following details:\\n        - Ticket ID: {ticket_id}\\n        - Customer Name: {customer_name}\\n        - Issue Description: {issue_description}\\n\\n        Follow this exact workflow:\\n        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).\\n        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.\\n        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.\\n        4.  **Use a Tool**:\\n            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.\\n            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.\\n        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.\\n\\n        Your final output must be a comprehensive report in markdown format that includes:\\n        - The classified priority and category.\\n        - The initial response.\\n        - The action taken with the corresponding tool.\\n        - The final customer-facing response.\\n        \\\"\\\"\\\",\\n        agent=agent,\\n        expected_output=\\\"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response.\\\"\\n    )\\n```\\n\\nEntire code for this available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py)\\n\\nOk, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.\\n\\n**The Little Trick We Play**\\n\\nBut here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?\\n\\n**Isn’t That Just a Static Workflow?**\\n\\nWell, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.\\n\\nFor example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.\\n\\n**Real World Example**\\n\\nWhen I was creating [patra.app](http://patra.app)[,](https://patra.app) which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.\\n\\nExample:  \\nCreate me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.\\n\\nImagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.\\n\\nNow imagine an action like:  \\nCheck my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.\\n\\nThese are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.\\n\\n**Don’t Overcomplicate Simple Things**\\n\\nWOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...\\n\\nStop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?\\n\\nAgents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.\\n\\nIn a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png align=\\\"center\\\")\\n\\n**What’s Next?**\\n\\nSo far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.\\n\\n## **Tools \u0026** orchestration **Framework**\\n\\nLLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”\\n\\n**A Simple Example**\\n\\nLet’s break this down with a simple program.\\n\\nSuppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.\\n\\n**Why Use Tools?**\\n\\nTools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.\\n\\n**Defining a Tool**\\n\\nLet’s define how our tool will look:\\n\\n```python\\ndef add(a: int, b: int) -\u003e int:\\n    \\\"\\\"\\\"Adds two integers together.\\\"\\\"\\\"\\n    return a + b\\n\\ndef subtract(a: int, b: int) -\u003e int:\\n    \\\"\\\"\\\"Subtracts the second integer from the first.\\\"\\\"\\\"\\n    return a - b\\n\\nSYSTEM_PROMPT = \\\"\\\"\\\"You are a helpful assistant with access to the following functions:\\n\\n1. `add(a: int, b: int)`: Adds two integers together.\\n2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.\\n\\nWhen a user asks a question that can be answered by one of these functions, \\nyou MUST respond ONLY with a JSON object in the following format:\\n{\\n  \\\"function_name\\\": \\\"name_of_the_function\\\",\\n  \\\"arguments\\\": {\\\"arg_name\\\": \\\"value\\\", ...}\\n}\\n\\nDo not include any other text, explanations, or markdown formatting. \\nYour entire response must be only the JSON object.\\n\\nIf you can answer the question without a function, \\njust provide the answer directly in plain text.\\\"\\\"\\\"\\n```\\n\\nNotice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can \\\"parse\\\" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.\\n\\n**What does \\\"continuing the conversation\\\" mean?**  \\nIt’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.\\n\\n**That’s basically it.**  \\nThis is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:\\n\\n```python\\ndef parse_and_execute(response_content: str) -\u003e (str, str):\\n    \\\"\\\"\\\"\\n    Tries to parse the LLM's text response as a JSON function call.\\n    If successful, it executes the function and returns the result and function name.\\n    Otherwise, it returns (None, None).\\n    \\\"\\\"\\\"\\n    try:\\n        call_data = json.loads(response_content)\\n        function_name = call_data.get(\\\"function_name\\\")\\n        function_args = call_data.get(\\\"arguments\\\")\\n\\n        if not all([function_name, isinstance(function_args, dict)]):\\n            return None, None # Not a valid function call structure\\n\\n        print(f\\\"Parser is executing function: '{function_name}' with args: {function_args}\\\")\\n\\n        available_functions = {\\\"add\\\": add, \\\"subtract\\\": subtract}\\n        function_to_call = available_functions.get(function_name)\\n\\n        if function_to_call:\\n            result = function_to_call(**function_args)\\n            return str(result), function_name\\n        else:\\n            return f\\\"Error: Unknown function '{function_name}'.\\\", function_name\\n\\n    except (json.JSONDecodeError, TypeError):\\n        return None, None # Not JSON or not a dictionary\\n```\\n\\nThe entire code for this is available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py)\\n\\nAnd then there’s the **invoke** method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.\\n\\n```python\\n# --- 5. The Main Invocation Logic ---\\ndef invoke(user_prompt: str):\\n    \\\"\\\"\\\"\\n    Invokes the LLM, manually handling the function-calling loop.\\n    \\\"\\\"\\\"\\n    print(f\\\"\\\\n{'='*20} Invoking for prompt: '{user_prompt}' {'='*20}\\\")\\n    \\n    messages = [\\n        {\\\"role\\\": \\\"system\\\", \\\"content\\\": SYSTEM_PROMPT},\\n        {\\\"role\\\": \\\"user\\\", \\\"content\\\": user_prompt}\\n    ]\\n\\n    # === Step 1: First LLM Call (without the `tools` parameter) ===\\n    print(\\\"\\\\n--- 1. Sending prompt to LLM to generate function call JSON... ---\\\")\\n    response = client.chat.completions.create(\\n        model=\\\"gpt-4o\\\",\\n        messages=messages\\n    )\\n    \\n    response_message = response.choices[0].message\\n    messages.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": response_message.content})\\n\\n    # === Step 2: Manually parse the response for a function call ===\\n    print(\\\"\\\\n--- 2. Manually parsing response for a function call... ---\\\")\\n    function_output, function_name = parse_and_execute(response_message.content)\\n\\n    if function_output:\\n        # We got a result from our function, so we continue the conversation\\n        messages.append({\\n            \\\"role\\\": \\\"user\\\", # We provide the function result back as the user\\n            \\\"content\\\": f\\\"I have called the function '{function_name}'. The result is: {function_output}\\\"\\n        })\\n\\n        # === Step 3: Second LLM Call with function results ===\\n        print(\\\"\\\\n--- 3. Sending function output back to LLM... ---\\\")\\n        \\n        second_response = client.chat.completions.create(\\n            model=\\\"gpt-4o\\\",\\n            messages=messages\\n        )\\n        final_response = second_response.choices[0].message.content\\n    else:\\n        # If parsing failed, the LLM's first response is the final answer\\n        final_response = response_message.content\\n\\n    print(f\\\"\\\\n--- Final Answer ---\\\")\\n    print(final_response)\\n    return final_response\\n```\\n\\nYou know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.\\n\\nToday, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: [https://platform.openai.com/docs/quickstart?api-mode=responses](https://platform.openai.com/docs/quickstart?api-mode=responses)\\n\\n**Exploring Popular Agent Frameworks**\\n\\nSome of the popular Agent frameworks includes -\\n\\n* **CrewAI** – A Python framework for coordinating multiple agents as a team.  \\n    Read more: [CrewAI on Github](https://github.com/crewAIInc/crewAI)\\n    \\n* **OpenAI Agents SDK** – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.  \\n    Read more: [OpenAI Agents SDK (Python)](https://openai.github.io/openai-agents-python/)\\n    \\n* **MetaGPT** – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.  \\n    Read more: [MetaGPT on GitHub](https://github.com/FoundationAgents/MetaGPT)\\n    \\n\\nNow that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.\\n\\n**Wait, Persona?**\\n\\nThat’s new. Why does an agent need a persona? What is a persona, anyway?\\n\\nIf you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.\\n\\n**Up Next: Multi-Agent Systems**\\n\\nIn the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.\\n\\n# Multi Agent System\\n\\nNow that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.\\n\\n**Remember, agents are just:**\\n\\n* An LLM with access to tools\\n    \\n* A set of prompts (like persona, goal, etc.)\\n    \\n* Memory (which we’ll talk about later)\\n    \\n* All built using an orchestration framework so everything works together\\n    \\n\\nBut what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png align=\\\"center\\\")\\n\\nSource: [CrewAI Collaboration Concepts](https://docs.crewai.com/concepts/collaboration)\\n\\nAll the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.\\n\\n**Why Use Multi-Agent Systems?**\\n\\nMulti-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their [blog post](https://www.anthropic.com/engineering/built-multi-agent-research-system) on multi-agent systems, is that you can use more tokens (so the system can \\\"think more\\\") when tackling a complex problem.\\n\\nIn the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.\\n\\nYou can read about different types of multi agent systems later [here](https://langchain-ai.github.io/langgraph/concepts/multi_agent/).\\n\\n**Warning:** As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.\\n\\n# Memory\\n\\nWe have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.\\n\\nIn many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.\\n\\nThere are two forms of memory that an AI agent can potentially have, much like humans do:\\n\\n### **Short Term Memory**\\n\\nShort term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.\\n\\nHere’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:\\n\\nM1: User: perform 10 + 20 + 30 + 40 + 50  \\nM2: LLM: *Tool call, 10 + 20*  \\nM3: User: Output 30  \\nM4: LLM: *Current answer is 30, let’s proceed. Tool call 30 + 30*  \\nM5: User: Output 60  \\nM6: LLM: *Current answer is 60, let’s proceed. Tool call 60 + 40*\\n\\nAt this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:\\n\\nM1: User: perform 10 + 20 + 30 + 40 + 50  \\nM2’: User: Output of 10 + 20 + 30 is 60, proceed further.  \\nM6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40\\n\\nNotice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.\\n\\nSometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.\\n\\nWe also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.  \\n**RAISE stands for Reasoning and Acting through Scratchpad and Examples.** The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.\\n\\nRead the paper that introduced RAISE framework here: [https://arxiv.org/pdf/2401.02777](https://arxiv.org/pdf/2401.02777)\\n\\n### **Long Term Memory**\\n\\nLong-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.\\n\\nIn our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.\\n\\nNotice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.\\n\\n# Mental Model to work with agents\\n\\nThat’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made [patra.app](http://patra.app) work reliably, and also how I’ve shipped multiple other production systems.\\n\\n**The golden model:**  \\nKeep yourself in the place of the agent. Imagine you are that agent.\\n\\nIt might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.\\n\\nPut yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?\\n\\nNow, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.\\n\\n## Conclusion\\n\\nHopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.\\n\\nIf you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.\\n\\nThere is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions \\\"AI agent\\\" in conversation, you will know not only what it is but also how it thinks and works.\\n\\nIf you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens.\",\"content\":\"\u003ch2 id=\\\"heading-motivation-why-you-should-care\\\"\u003eMotivation: Why You Should Care\u003c/h2\u003e\\n\u003cp\u003eNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like \u003ca target=\\\"_blank\\\" href=\\\"https://patra.app\\\"\u003epatra.app\u003c/a\u003e. While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...\u003c/p\u003e\\n\u003cp\u003eDuring one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”\u003c/p\u003e\\n\u003cp\u003eThey gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.\u003c/p\u003e\\n\u003cp\u003eWell, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.\u003c/p\u003e\\n\u003cp\u003eI promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003eWhat an AI agent is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eHow an AI agent works\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat the heck tools are\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat an orchestration framework is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat memory is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat the types of AI agents are\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eThe mental model for building an AI agent\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat a multi-agent framework is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eBefore we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-the-problem\\\"\u003eThe Problem\u003c/h2\u003e\\n\u003cp\u003eOk, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cblockquote\u003e\\n\u003cp\u003eAn AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention\u003c/p\u003e\\n\u003c/blockquote\u003e\\n\u003cp\u003eYou see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.\u003c/p\u003e\\n\u003cp\u003eIf I ask, \\\"What is an LLM?\\\" we get a much more acceptable answer:\u003c/p\u003e\\n\u003cblockquote\u003e\\n\u003cp\u003eA Large Language Model (LLM) is \u003cstrong\u003ea type of AI model, specifically a deep learning model, trained on massive amounts of text data.\u003c/strong\u003e\u003c/p\u003e\\n\u003c/blockquote\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eNotice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-defining-ai-agent\\\"\u003eDefining AI Agent\u003c/h1\u003e\\n\u003cp\u003eLet’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:\u003c/p\u003e\\n\u003cp\u003eAgents are \u003cstrong\u003esoftware systems\u003c/strong\u003e where \u003cstrong\u003eLLMs\u003c/strong\u003e use reasoning to control the flow of execution, \u003cstrong\u003edynamically\u003c/strong\u003e choosing which \u003cstrong\u003etools\u003c/strong\u003e to use and determining each step required to reach a \u003cstrong\u003egoal\u003c/strong\u003e.\u003c/p\u003e\\n\u003cp\u003eThat’s a mouthful. Let’s break down each part so we can actually understand it.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-agents-are-software-systems\\\"\u003e\u003cstrong\u003eAgents are Software Systems\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eThis is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003eLLMs\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWorking Memory or state\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003ePrompts\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eTools\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eOrchestration Layer\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eYou already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.\u003c/p\u003e\\n\u003cp\u003eIn our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-flow-of-execution\\\"\u003e\u003cstrong\u003eDynamic\u003c/strong\u003e Flow of Execution\u003c/h2\u003e\\n\u003cp\u003eTo execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.\u003c/p\u003e\\n\u003cp\u003eLet’s look at an example.\u003c/p\u003e\\n\u003cp\u003eSuppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.\u003c/p\u003e\\n\u003cp\u003eNotice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.\u003c/p\u003e\\n\u003cp\u003eWe won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cdiv data-node-type=\\\"callout\\\"\u003e\\n\u003cdiv data-node-type=\\\"callout-emoji\\\"\u003e💡\u003c/div\u003e\\n\u003cdiv data-node-type=\\\"callout-text\\\"\u003eYou may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading\u003c/div\u003e\\n\u003c/div\u003e\\n\\n\u003cp\u003eNotice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# Build workflow\u003c/span\u003e\\nworkflow = StateGraph(SupportTicketState)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Add nodes\u003c/span\u003e\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e, classify_ticket)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e, generate_initial_response)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e, check_escalation_needed)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e, escalate_ticket)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e, resolve_ticket)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Add edges\u003c/span\u003e\\nworkflow.add_edge(START, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Conditional edges for escalation\u003c/span\u003e\\nworkflow.add_conditional_edges(\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e,\\n    should_escalate,\\n    {\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e,\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e\\n    }\\n)\\n\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e, END)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e, END)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eEntire code for this is available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eThis is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.\u003c/p\u003e\\n\u003cp\u003eIn the example above, the value of should_escalate, which comes from the check_escalation node, is used to determine which part of the graph or “workflow” we go to next.\u003c/p\u003e\\n\u003cp\u003eA node like \\\"resolve ticket\\\" will look something like this:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eresolve_ticket\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003estate: SupportTicketState\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Resolve the ticket and generate a final customer-facing response.\\\"\\\"\\\"\u003c/span\u003e\\n    call_resolution_api(state[\u003cspan class=\\\"hljs-string\\\"\u003e'ticket_id'\u003c/span\u003e])\\n    prompt = \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"\\n    Generate a customer-facing response to inform them their ticket is resolved.\\n\\n    Ticket ID: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'ticket_id'\u003c/span\u003e]}\u003c/span\u003e\\n    Customer: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'customer_name'\u003c/span\u003e]}\u003c/span\u003e\\n    Issue: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'issue_description'\u003c/span\u003e]}\u003c/span\u003e\\n\\n    The response should:\\n    1. State clearly that the issue has been resolved.\\n    2. Briefly explain the solution.\\n    3. Thank the customer for their patience.\\n    4. Ask if they need any further assistance.\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    response = llm.invoke(prompt)\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e {\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"final_response\\\"\u003c/span\u003e: response.content,\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"status\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Resolved\\\"\u003c/span\u003e\\n    }\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eNotice how we first call the resolution API and then run the prompt to generate a response for the ticket.\u003c/p\u003e\\n\u003cp\u003eYou might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.\u003c/p\u003e\\n\u003cp\u003eLet’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eBy the way, ReAct stands for \\\"Reasoning and Acting.\\\"\u003c/strong\u003e\u003cbr /\u003eIt is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eIn our example:\u003c/p\u003e\\n\u003cp\u003eThe \u003cstrong\u003etask\u003c/strong\u003e is to either resolve or escalate the ticket and give back a response.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eAct\u003c/strong\u003e stage, the agent can use a tool to classify, escalate, or resolve the ticket.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eObserve\u003c/strong\u003e stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eReasoning\u003c/strong\u003e stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.\u003c/p\u003e\\n\u003cp\u003eNotice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.\u003c/p\u003e\\n\u003cp\u003eTo understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eNow getting to the code:\u003c/strong\u003e\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# --- Agent Definition ---\u003c/span\u003e\\nsupport_agent = Agent(\\n    role=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Senior Customer Support Specialist\\\"\u003c/span\u003e,\\n    goal=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses.\\\"\u003c/span\u003e,\\n    backstory=(\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a seasoned support specialist with a knack for understanding customer needs. \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You excel at identifying the root cause of issues, communicating clearly, and \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"knowing precisely when a problem needs to be escalated to a senior team member. \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality.\\\"\u003c/span\u003e\\n    ),\\n    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],\\n    llm=llm,\\n    verbose=\u003cspan class=\\\"hljs-literal\\\"\u003eTrue\u003c/span\u003e,\\n    allow_delegation=\u003cspan class=\\\"hljs-literal\\\"\u003eFalse\u003c/span\u003e\\n)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# --- Task Definition ---\u003c/span\u003e\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003ecreate_ticket_processing_task\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eagent, ticket_id, customer_name, issue_description\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e Task(\\n        description=\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"\\n        Process customer support ticket with the following details:\\n        - Ticket ID: \u003cspan class=\\\"hljs-subst\\\"\u003e{ticket_id}\u003c/span\u003e\\n        - Customer Name: \u003cspan class=\\\"hljs-subst\\\"\u003e{customer_name}\u003c/span\u003e\\n        - Issue Description: \u003cspan class=\\\"hljs-subst\\\"\u003e{issue_description}\u003c/span\u003e\\n\\n        Follow this exact workflow:\\n        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).\\n        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.\\n        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.\\n        4.  **Use a Tool**:\\n            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.\\n            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.\\n        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.\\n\\n        Your final output must be a comprehensive report in markdown format that includes:\\n        - The classified priority and category.\\n        - The initial response.\\n        - The action taken with the corresponding tool.\\n        - The final customer-facing response.\\n        \\\"\\\"\\\"\u003c/span\u003e,\\n        agent=agent,\\n        expected_output=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response.\\\"\u003c/span\u003e\\n    )\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eEntire code for this available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eOk, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThe Little Trick We Play\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eBut here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eIsn’t That Just a Static Workflow?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWell, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.\u003c/p\u003e\\n\u003cp\u003eFor example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eReal World Example\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWhen I was creating \u003ca target=\\\"_blank\\\" href=\\\"http://patra.app\\\"\u003epatra.app\u003c/a\u003e\u003ca target=\\\"_blank\\\" href=\\\"https://patra.app\\\"\u003e,\u003c/a\u003e which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.\u003c/p\u003e\\n\u003cp\u003eExample:\u003cbr /\u003eCreate me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.\u003c/p\u003e\\n\u003cp\u003eImagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.\u003c/p\u003e\\n\u003cp\u003eNow imagine an action like:\u003cbr /\u003eCheck my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.\u003c/p\u003e\\n\u003cp\u003eThese are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eDon’t Overcomplicate Simple Things\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...\u003c/p\u003e\\n\u003cp\u003eStop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?\u003c/p\u003e\\n\u003cp\u003eAgents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.\u003c/p\u003e\\n\u003cp\u003eIn a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhat’s Next?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eSo far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-tools-amp-orchestration-framework\\\"\u003e\u003cstrong\u003eTools \u0026amp;\u003c/strong\u003e orchestration \u003cstrong\u003eFramework\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eLLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eA Simple Example\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eLet’s break this down with a simple program.\u003c/p\u003e\\n\u003cp\u003eSuppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhy Use Tools?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eTools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eDefining a Tool\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eLet’s define how our tool will look:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eadd\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003ea: int, b: int\u003c/span\u003e) -\u0026gt; int:\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Adds two integers together.\\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e a + b\\n\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003esubtract\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003ea: int, b: int\u003c/span\u003e) -\u0026gt; int:\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Subtracts the second integer from the first.\\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e a - b\\n\\nSYSTEM_PROMPT = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"You are a helpful assistant with access to the following functions:\\n\\n1. `add(a: int, b: int)`: Adds two integers together.\\n2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.\\n\\nWhen a user asks a question that can be answered by one of these functions, \\nyou MUST respond ONLY with a JSON object in the following format:\\n{\\n  \\\"function_name\\\": \\\"name_of_the_function\\\",\\n  \\\"arguments\\\": {\\\"arg_name\\\": \\\"value\\\", ...}\\n}\\n\\nDo not include any other text, explanations, or markdown formatting. \\nYour entire response must be only the JSON object.\\n\\nIf you can answer the question without a function, \\njust provide the answer directly in plain text.\\\"\\\"\\\"\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eNotice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can \\\"parse\\\" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhat does \\\"continuing the conversation\\\" mean?\u003c/strong\u003e\u003cbr /\u003eIt’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThat’s basically it.\u003c/strong\u003e\u003cbr /\u003eThis is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eparse_and_execute\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eresponse_content: str\u003c/span\u003e) -\u0026gt; (str, str):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"\\n    Tries to parse the LLM's text response as a JSON function call.\\n    If successful, it executes the function and returns the result and function name.\\n    Otherwise, it returns (None, None).\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003etry\u003c/span\u003e:\\n        call_data = json.loads(response_content)\\n        function_name = call_data.get(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"function_name\\\"\u003c/span\u003e)\\n        function_args = call_data.get(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"arguments\\\"\u003c/span\u003e)\\n\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003enot\u003c/span\u003e all([function_name, isinstance(function_args, dict)]):\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e, \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e \u003cspan class=\\\"hljs-comment\\\"\u003e# Not a valid function call structure\u003c/span\u003e\\n\\n        print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"Parser is executing function: '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e' with args: \u003cspan class=\\\"hljs-subst\\\"\u003e{function_args}\u003c/span\u003e\\\"\u003c/span\u003e)\\n\\n        available_functions = {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"add\\\"\u003c/span\u003e: add, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"subtract\\\"\u003c/span\u003e: subtract}\\n        function_to_call = available_functions.get(function_name)\\n\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e function_to_call:\\n            result = function_to_call(**function_args)\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e str(result), function_name\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eelse\u003c/span\u003e:\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"Error: Unknown function '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e'.\\\"\u003c/span\u003e, function_name\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eexcept\u003c/span\u003e (json.JSONDecodeError, TypeError):\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e, \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e \u003cspan class=\\\"hljs-comment\\\"\u003e# Not JSON or not a dictionary\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe entire code for this is available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eAnd then there’s the \u003cstrong\u003einvoke\u003c/strong\u003e method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# --- 5. The Main Invocation Logic ---\u003c/span\u003e\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003einvoke\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003euser_prompt: str\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"\\n    Invokes the LLM, manually handling the function-calling loop.\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\\n\u003cspan class=\\\"hljs-subst\\\"\u003e{\u003cspan class=\\\"hljs-string\\\"\u003e'='\u003c/span\u003e*\u003cspan class=\\\"hljs-number\\\"\u003e20\u003c/span\u003e}\u003c/span\u003e Invoking for prompt: '\u003cspan class=\\\"hljs-subst\\\"\u003e{user_prompt}\u003c/span\u003e' \u003cspan class=\\\"hljs-subst\\\"\u003e{\u003cspan class=\\\"hljs-string\\\"\u003e'='\u003c/span\u003e*\u003cspan class=\\\"hljs-number\\\"\u003e20\u003c/span\u003e}\u003c/span\u003e\\\"\u003c/span\u003e)\\n\\n    messages = [\\n        {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: SYSTEM_PROMPT},\\n        {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"user\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: user_prompt}\\n    ]\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 1: First LLM Call (without the `tools` parameter) ===\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 1. Sending prompt to LLM to generate function call JSON... ---\\\"\u003c/span\u003e)\\n    response = client.chat.completions.create(\\n        model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-4o\\\"\u003c/span\u003e,\\n        messages=messages\\n    )\\n\\n    response_message = response.choices[\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e].message\\n    messages.append({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"assistant\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: response_message.content})\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 2: Manually parse the response for a function call ===\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 2. Manually parsing response for a function call... ---\\\"\u003c/span\u003e)\\n    function_output, function_name = parse_and_execute(response_message.content)\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e function_output:\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# We got a result from our function, so we continue the conversation\u003c/span\u003e\\n        messages.append({\\n            \u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"user\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-comment\\\"\u003e# We provide the function result back as the user\u003c/span\u003e\\n            \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"I have called the function '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e'. The result is: \u003cspan class=\\\"hljs-subst\\\"\u003e{function_output}\u003c/span\u003e\\\"\u003c/span\u003e\\n        })\\n\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 3: Second LLM Call with function results ===\u003c/span\u003e\\n        print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 3. Sending function output back to LLM... ---\\\"\u003c/span\u003e)\\n\\n        second_response = client.chat.completions.create(\\n            model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-4o\\\"\u003c/span\u003e,\\n            messages=messages\\n        )\\n        final_response = second_response.choices[\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e].message.content\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eelse\u003c/span\u003e:\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# If parsing failed, the LLM's first response is the final answer\u003c/span\u003e\\n        final_response = response_message.content\\n\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\\n--- Final Answer ---\\\"\u003c/span\u003e)\\n    print(final_response)\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e final_response\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eYou know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.\u003c/p\u003e\\n\u003cp\u003eToday, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: \u003ca target=\\\"_blank\\\" href=\\\"https://platform.openai.com/docs/quickstart?api-mode=responses\\\"\u003ehttps://platform.openai.com/docs/quickstart?api-mode=responses\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eExploring Popular Agent Frameworks\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eSome of the popular Agent frameworks includes -\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCrewAI\u003c/strong\u003e – A Python framework for coordinating multiple agents as a team.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/crewAIInc/crewAI\\\"\u003eCrewAI on Github\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eOpenAI Agents SDK\u003c/strong\u003e – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://openai.github.io/openai-agents-python/\\\"\u003eOpenAI Agents SDK (Python)\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eMetaGPT\u003c/strong\u003e – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/FoundationAgents/MetaGPT\\\"\u003eMetaGPT on GitHub\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eNow that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWait, Persona?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eThat’s new. Why does an agent need a persona? What is a persona, anyway?\u003c/p\u003e\\n\u003cp\u003eIf you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eUp Next: Multi-Agent Systems\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eIn the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-multi-agent-system\\\"\u003eMulti Agent System\u003c/h1\u003e\\n\u003cp\u003eNow that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eRemember, agents are just:\u003c/strong\u003e\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cp\u003eAn LLM with access to tools\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eA set of prompts (like persona, goal, etc.)\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eMemory (which we’ll talk about later)\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eAll built using an orchestration framework so everything works together\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eBut what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eSource: \u003ca target=\\\"_blank\\\" href=\\\"https://docs.crewai.com/concepts/collaboration\\\"\u003eCrewAI Collaboration Concepts\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eAll the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhy Use Multi-Agent Systems?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eMulti-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their \u003ca target=\\\"_blank\\\" href=\\\"https://www.anthropic.com/engineering/built-multi-agent-research-system\\\"\u003eblog post\u003c/a\u003e on multi-agent systems, is that you can use more tokens (so the system can \\\"think more\\\") when tackling a complex problem.\u003c/p\u003e\\n\u003cp\u003eIn the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.\u003c/p\u003e\\n\u003cp\u003eYou can read about different types of multi agent systems later \u003ca target=\\\"_blank\\\" href=\\\"https://langchain-ai.github.io/langgraph/concepts/multi_agent/\\\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWarning:\u003c/strong\u003e As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-memory\\\"\u003eMemory\u003c/h1\u003e\\n\u003cp\u003eWe have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.\u003c/p\u003e\\n\u003cp\u003eIn many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.\u003c/p\u003e\\n\u003cp\u003eThere are two forms of memory that an AI agent can potentially have, much like humans do:\u003c/p\u003e\\n\u003ch3 id=\\\"heading-short-term-memory\\\"\u003e\u003cstrong\u003eShort Term Memory\u003c/strong\u003e\u003c/h3\u003e\\n\u003cp\u003eShort term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.\u003c/p\u003e\\n\u003cp\u003eHere’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:\u003c/p\u003e\\n\u003cp\u003eM1: User: perform 10 + 20 + 30 + 40 + 50\u003cbr /\u003eM2: LLM: \u003cem\u003eTool call, 10 + 20\u003c/em\u003e\u003cbr /\u003eM3: User: Output 30\u003cbr /\u003eM4: LLM: \u003cem\u003eCurrent answer is 30, let’s proceed. Tool call 30 + 30\u003c/em\u003e\u003cbr /\u003eM5: User: Output 60\u003cbr /\u003eM6: LLM: \u003cem\u003eCurrent answer is 60, let’s proceed. Tool call 60 + 40\u003c/em\u003e\u003c/p\u003e\\n\u003cp\u003eAt this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:\u003c/p\u003e\\n\u003cp\u003eM1: User: perform 10 + 20 + 30 + 40 + 50\u003cbr /\u003eM2’: User: Output of 10 + 20 + 30 is 60, proceed further.\u003cbr /\u003eM6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40\u003c/p\u003e\\n\u003cp\u003eNotice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.\u003c/p\u003e\\n\u003cp\u003eSometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.\u003c/p\u003e\\n\u003cp\u003eWe also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.\u003cbr /\u003e\u003cstrong\u003eRAISE stands for Reasoning and Acting through Scratchpad and Examples.\u003c/strong\u003e The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.\u003c/p\u003e\\n\u003cp\u003eRead the paper that introduced RAISE framework here: \u003ca target=\\\"_blank\\\" href=\\\"https://arxiv.org/pdf/2401.02777\\\"\u003ehttps://arxiv.org/pdf/2401.02777\u003c/a\u003e\u003c/p\u003e\\n\u003ch3 id=\\\"heading-long-term-memory\\\"\u003e\u003cstrong\u003eLong Term Memory\u003c/strong\u003e\u003c/h3\u003e\\n\u003cp\u003eLong-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.\u003c/p\u003e\\n\u003cp\u003eIn our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.\u003c/p\u003e\\n\u003cp\u003eNotice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-mental-model-to-work-with-agents\\\"\u003eMental Model to work with agents\u003c/h1\u003e\\n\u003cp\u003eThat’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made \u003ca target=\\\"_blank\\\" href=\\\"http://patra.app\\\"\u003epatra.app\u003c/a\u003e work reliably, and also how I’ve shipped multiple other production systems.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThe golden model:\u003c/strong\u003e\u003cbr /\u003eKeep yourself in the place of the agent. Imagine you are that agent.\u003c/p\u003e\\n\u003cp\u003eIt might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.\u003c/p\u003e\\n\u003cp\u003ePut yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?\u003c/p\u003e\\n\u003cp\u003eNow, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-conclusion\\\"\u003eConclusion\u003c/h2\u003e\\n\u003cp\u003eHopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.\u003c/p\u003e\\n\u003cp\u003eIf you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.\u003c/p\u003e\\n\u003cp\u003eThere is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions \\\"AI agent\\\" in conversation, you will know not only what it is but also how it thinks and works.\u003c/p\u003e\\n\u003cp\u003eIf you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens.\u003c/p\u003e\\n\",\"cuid\":\"cmc7j8wli000102l4hfte2pxh\",\"views\":611,\"title\":\"AI Agents Under The Hood\",\"slug\":\"ai-agents-under-the-hood\",\"dateAdded\":\"2025-06-22T10:36:29.574Z\",\"dateUpdated\":\"2025-06-23T06:56:54.444Z\",\"type\":\"story\",\"isCoverImagePortrait\":false,\"brief\":\"Motivation: Why You Should Care\\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like patra.app. While building those and reading through a lot of resources, I learned how AI agents actually wor...\",\"isFollowing\":false,\"totalReactions\":4,\"totalReactionsByCurrentUser\":0,\"series\":null,\"isPinnedToBlog\":false,\"readTime\":23,\"sB\":false,\"isAMA\":false,\"subtitle\":\"Simplifying AI Agents - What They Are and How They Work\",\"isPartOfSeries\":false,\"hasTags\":true,\"ogImage\":\"\",\"metaTitle\":\"\",\"metaDescription\":\"\",\"isRepublished\":false,\"autoPublishedFromRSS\":false,\"responses\":[],\"isFeatured\":false,\"hasLatex\":false,\"stickCoverToBottom\":true,\"hideBadges\":false,\"badges\":[],\"isDelisted\":false,\"audioUrls\":{},\"disableComments\":false,\"enableToc\":false,\"toc\":[],\"noIndex\":false}","publication":"{\"__typename\":\"Publication\",\"id\":\"669e957c19b8bd50367fe79c\",\"url\":\"https://blog.surkar.in\",\"canonicalURL\":\"https://blog.surkar.in\",\"urlPattern\":\"SIMPLE\",\"title\":\"Manthan Surkar\",\"displayTitle\":null,\"hasBadges\":true,\"descriptionSEO\":null,\"publicMembers\":{\"totalDocuments\":1},\"about\":null,\"features\":{\"proTeam\":{\"isEnabled\":false},\"newsletter\":{\"isEnabled\":true},\"viewCount\":{\"isEnabled\":true},\"readTime\":{\"isEnabled\":true},\"textSelectionSharer\":{\"isEnabled\":true},\"customCSS\":{\"isEnabled\":false,\"published\":null,\"draft\":null},\"gptBotCrawling\":{\"__typename\":\"GPTBotCrawlingFeature\",\"isEnabled\":false}},\"metaTags\":null,\"ogMetaData\":{\"image\":null},\"author\":{\"__typename\":\"User\",\"id\":\"669e9506d4920b5b5b00bcef\",\"name\":\"Manthan Surkar\",\"username\":\"surkar\",\"profilePicture\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg\"},\"preferences\":{\"__typename\":\"Preferences\",\"logo\":null,\"darkMode\":{\"__typename\":\"DarkModePreferences\",\"logo\":null,\"enabled\":false},\"navbarItems\":[],\"enabledPages\":{\"__typename\":\"PagesPreferences\",\"badges\":false,\"newsletter\":true,\"members\":true},\"layout\":\"stacked\",\"disableFooterBranding\":false,\"isSubscriptionModalDisabled\":false},\"favicon\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1751198022133/1c8c4430-333f-4491-9e43-465d6dcb65c0.png\",\"headerColor\":null,\"integrations\":{\"fbPixelID\":null,\"fathomSiteID\":null,\"fathomCustomDomainEnabled\":null,\"fathomCustomDomain\":null,\"hotjarSiteID\":null,\"matomoSiteID\":null,\"matomoURL\":null,\"gaTrackingID\":null,\"gTagManagerID\":null,\"plausibleAnalyticsEnabled\":null,\"wmPaymentPointer\":null,\"koalaPublicKey\":null,\"msClarityID\":null},\"imprintV2\":null,\"postsCount\":{\"totalDocuments\":4},\"isTeam\":true,\"links\":{\"twitter\":\"https://twitter.com/manthan_surkar\",\"instagram\":null,\"github\":\"https://github.com/thesmallstar\",\"website\":null,\"hashnode\":\"https://hashnode.com/@surkar\",\"youtube\":null,\"dailydev\":null,\"linkedin\":null,\"mastodon\":null,\"facebook\":null,\"bluesky\":null},\"domainInfo\":{\"__typename\":\"DomainInfo\",\"hashnodeSubdomain\":\"surkar\",\"domain\":{\"__typename\":\"DomainStatus\",\"host\":\"blog.surkar.in\",\"ready\":true},\"wwwPrefixedDomain\":null},\"redirectionRules\":[],\"totalRecommendedPublications\":0,\"sponsorship\":{\"content\":null,\"stripe\":null},\"allowContributorEdits\":true,\"rssImport\":null,\"post\":{\"id\":\"6857dcad0f01cc2215fffd04\",\"cuid\":\"cmc7j8wli000102l4hfte2pxh\",\"title\":\"AI Agents Under The Hood\",\"subtitle\":\"Simplifying AI Agents - What They Are and How They Work\",\"slug\":\"ai-agents-under-the-hood\",\"brief\":\"Motivation: Why You Should Care\\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like patra.app. While building those and reading through a lot of resources, I learned how AI agents actually wor...\",\"featured\":false,\"publishedAt\":\"2025-06-22T10:36:29.574Z\",\"updatedAt\":\"2025-06-23T06:56:54.444Z\",\"author\":{\"__typename\":\"User\",\"id\":\"669e9506d4920b5b5b00bcef\",\"name\":\"Manthan Surkar\",\"username\":\"surkar\",\"deactivated\":false,\"profilePicture\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg\",\"bio\":{\"html\":\"\"},\"socialMediaLinks\":{\"website\":\"https://surkar.in\",\"github\":\"https://github.com/thesmallstar\",\"twitter\":\"\",\"facebook\":\"\",\"stackoverflow\":\"\",\"linkedin\":\"https://www.linkedin.com/in/manthansurkar/\"}},\"coAuthors\":[],\"seo\":{\"title\":null,\"description\":null,\"shouldNotIndex\":false},\"coverImage\":null,\"responseCount\":1,\"reactionCount\":4,\"replyCount\":0,\"content\":{\"html\":\"\u003ch2 id=\\\"heading-motivation-why-you-should-care\\\"\u003eMotivation: Why You Should Care\u003c/h2\u003e\\n\u003cp\u003eNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like \u003ca target=\\\"_blank\\\" href=\\\"https://patra.app\\\"\u003epatra.app\u003c/a\u003e. While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...\u003c/p\u003e\\n\u003cp\u003eDuring one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”\u003c/p\u003e\\n\u003cp\u003eThey gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.\u003c/p\u003e\\n\u003cp\u003eWell, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.\u003c/p\u003e\\n\u003cp\u003eI promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003eWhat an AI agent is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eHow an AI agent works\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat the heck tools are\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat an orchestration framework is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat memory is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat the types of AI agents are\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eThe mental model for building an AI agent\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat a multi-agent framework is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eBefore we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-the-problem\\\"\u003eThe Problem\u003c/h2\u003e\\n\u003cp\u003eOk, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cblockquote\u003e\\n\u003cp\u003eAn AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention\u003c/p\u003e\\n\u003c/blockquote\u003e\\n\u003cp\u003eYou see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.\u003c/p\u003e\\n\u003cp\u003eIf I ask, \\\"What is an LLM?\\\" we get a much more acceptable answer:\u003c/p\u003e\\n\u003cblockquote\u003e\\n\u003cp\u003eA Large Language Model (LLM) is \u003cstrong\u003ea type of AI model, specifically a deep learning model, trained on massive amounts of text data.\u003c/strong\u003e\u003c/p\u003e\\n\u003c/blockquote\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eNotice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-defining-ai-agent\\\"\u003eDefining AI Agent\u003c/h1\u003e\\n\u003cp\u003eLet’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:\u003c/p\u003e\\n\u003cp\u003eAgents are \u003cstrong\u003esoftware systems\u003c/strong\u003e where \u003cstrong\u003eLLMs\u003c/strong\u003e use reasoning to control the flow of execution, \u003cstrong\u003edynamically\u003c/strong\u003e choosing which \u003cstrong\u003etools\u003c/strong\u003e to use and determining each step required to reach a \u003cstrong\u003egoal\u003c/strong\u003e.\u003c/p\u003e\\n\u003cp\u003eThat’s a mouthful. Let’s break down each part so we can actually understand it.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-agents-are-software-systems\\\"\u003e\u003cstrong\u003eAgents are Software Systems\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eThis is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003eLLMs\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWorking Memory or state\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003ePrompts\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eTools\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eOrchestration Layer\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eYou already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.\u003c/p\u003e\\n\u003cp\u003eIn our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-flow-of-execution\\\"\u003e\u003cstrong\u003eDynamic\u003c/strong\u003e Flow of Execution\u003c/h2\u003e\\n\u003cp\u003eTo execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.\u003c/p\u003e\\n\u003cp\u003eLet’s look at an example.\u003c/p\u003e\\n\u003cp\u003eSuppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.\u003c/p\u003e\\n\u003cp\u003eNotice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.\u003c/p\u003e\\n\u003cp\u003eWe won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cdiv data-node-type=\\\"callout\\\"\u003e\\n\u003cdiv data-node-type=\\\"callout-emoji\\\"\u003e💡\u003c/div\u003e\\n\u003cdiv data-node-type=\\\"callout-text\\\"\u003eYou may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading\u003c/div\u003e\\n\u003c/div\u003e\\n\\n\u003cp\u003eNotice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# Build workflow\u003c/span\u003e\\nworkflow = StateGraph(SupportTicketState)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Add nodes\u003c/span\u003e\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e, classify_ticket)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e, generate_initial_response)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e, check_escalation_needed)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e, escalate_ticket)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e, resolve_ticket)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Add edges\u003c/span\u003e\\nworkflow.add_edge(START, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Conditional edges for escalation\u003c/span\u003e\\nworkflow.add_conditional_edges(\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e,\\n    should_escalate,\\n    {\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e,\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e\\n    }\\n)\\n\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e, END)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e, END)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eEntire code for this is available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eThis is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.\u003c/p\u003e\\n\u003cp\u003eIn the example above, the value of should_escalate, which comes from the check_escalation node, is used to determine which part of the graph or “workflow” we go to next.\u003c/p\u003e\\n\u003cp\u003eA node like \\\"resolve ticket\\\" will look something like this:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eresolve_ticket\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003estate: SupportTicketState\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Resolve the ticket and generate a final customer-facing response.\\\"\\\"\\\"\u003c/span\u003e\\n    call_resolution_api(state[\u003cspan class=\\\"hljs-string\\\"\u003e'ticket_id'\u003c/span\u003e])\\n    prompt = \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"\\n    Generate a customer-facing response to inform them their ticket is resolved.\\n\\n    Ticket ID: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'ticket_id'\u003c/span\u003e]}\u003c/span\u003e\\n    Customer: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'customer_name'\u003c/span\u003e]}\u003c/span\u003e\\n    Issue: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'issue_description'\u003c/span\u003e]}\u003c/span\u003e\\n\\n    The response should:\\n    1. State clearly that the issue has been resolved.\\n    2. Briefly explain the solution.\\n    3. Thank the customer for their patience.\\n    4. Ask if they need any further assistance.\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    response = llm.invoke(prompt)\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e {\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"final_response\\\"\u003c/span\u003e: response.content,\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"status\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Resolved\\\"\u003c/span\u003e\\n    }\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eNotice how we first call the resolution API and then run the prompt to generate a response for the ticket.\u003c/p\u003e\\n\u003cp\u003eYou might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.\u003c/p\u003e\\n\u003cp\u003eLet’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eBy the way, ReAct stands for \\\"Reasoning and Acting.\\\"\u003c/strong\u003e\u003cbr /\u003eIt is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eIn our example:\u003c/p\u003e\\n\u003cp\u003eThe \u003cstrong\u003etask\u003c/strong\u003e is to either resolve or escalate the ticket and give back a response.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eAct\u003c/strong\u003e stage, the agent can use a tool to classify, escalate, or resolve the ticket.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eObserve\u003c/strong\u003e stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eReasoning\u003c/strong\u003e stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.\u003c/p\u003e\\n\u003cp\u003eNotice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.\u003c/p\u003e\\n\u003cp\u003eTo understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eNow getting to the code:\u003c/strong\u003e\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# --- Agent Definition ---\u003c/span\u003e\\nsupport_agent = Agent(\\n    role=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Senior Customer Support Specialist\\\"\u003c/span\u003e,\\n    goal=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses.\\\"\u003c/span\u003e,\\n    backstory=(\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a seasoned support specialist with a knack for understanding customer needs. \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You excel at identifying the root cause of issues, communicating clearly, and \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"knowing precisely when a problem needs to be escalated to a senior team member. \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality.\\\"\u003c/span\u003e\\n    ),\\n    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],\\n    llm=llm,\\n    verbose=\u003cspan class=\\\"hljs-literal\\\"\u003eTrue\u003c/span\u003e,\\n    allow_delegation=\u003cspan class=\\\"hljs-literal\\\"\u003eFalse\u003c/span\u003e\\n)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# --- Task Definition ---\u003c/span\u003e\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003ecreate_ticket_processing_task\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eagent, ticket_id, customer_name, issue_description\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e Task(\\n        description=\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"\\n        Process customer support ticket with the following details:\\n        - Ticket ID: \u003cspan class=\\\"hljs-subst\\\"\u003e{ticket_id}\u003c/span\u003e\\n        - Customer Name: \u003cspan class=\\\"hljs-subst\\\"\u003e{customer_name}\u003c/span\u003e\\n        - Issue Description: \u003cspan class=\\\"hljs-subst\\\"\u003e{issue_description}\u003c/span\u003e\\n\\n        Follow this exact workflow:\\n        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).\\n        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.\\n        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.\\n        4.  **Use a Tool**:\\n            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.\\n            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.\\n        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.\\n\\n        Your final output must be a comprehensive report in markdown format that includes:\\n        - The classified priority and category.\\n        - The initial response.\\n        - The action taken with the corresponding tool.\\n        - The final customer-facing response.\\n        \\\"\\\"\\\"\u003c/span\u003e,\\n        agent=agent,\\n        expected_output=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response.\\\"\u003c/span\u003e\\n    )\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eEntire code for this available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eOk, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThe Little Trick We Play\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eBut here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eIsn’t That Just a Static Workflow?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWell, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.\u003c/p\u003e\\n\u003cp\u003eFor example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eReal World Example\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWhen I was creating \u003ca target=\\\"_blank\\\" href=\\\"http://patra.app\\\"\u003epatra.app\u003c/a\u003e\u003ca target=\\\"_blank\\\" href=\\\"https://patra.app\\\"\u003e,\u003c/a\u003e which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.\u003c/p\u003e\\n\u003cp\u003eExample:\u003cbr /\u003eCreate me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.\u003c/p\u003e\\n\u003cp\u003eImagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.\u003c/p\u003e\\n\u003cp\u003eNow imagine an action like:\u003cbr /\u003eCheck my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.\u003c/p\u003e\\n\u003cp\u003eThese are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eDon’t Overcomplicate Simple Things\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...\u003c/p\u003e\\n\u003cp\u003eStop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?\u003c/p\u003e\\n\u003cp\u003eAgents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.\u003c/p\u003e\\n\u003cp\u003eIn a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhat’s Next?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eSo far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-tools-amp-orchestration-framework\\\"\u003e\u003cstrong\u003eTools \u0026amp;\u003c/strong\u003e orchestration \u003cstrong\u003eFramework\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eLLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eA Simple Example\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eLet’s break this down with a simple program.\u003c/p\u003e\\n\u003cp\u003eSuppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhy Use Tools?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eTools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eDefining a Tool\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eLet’s define how our tool will look:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eadd\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003ea: int, b: int\u003c/span\u003e) -\u0026gt; int:\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Adds two integers together.\\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e a + b\\n\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003esubtract\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003ea: int, b: int\u003c/span\u003e) -\u0026gt; int:\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Subtracts the second integer from the first.\\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e a - b\\n\\nSYSTEM_PROMPT = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"You are a helpful assistant with access to the following functions:\\n\\n1. `add(a: int, b: int)`: Adds two integers together.\\n2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.\\n\\nWhen a user asks a question that can be answered by one of these functions, \\nyou MUST respond ONLY with a JSON object in the following format:\\n{\\n  \\\"function_name\\\": \\\"name_of_the_function\\\",\\n  \\\"arguments\\\": {\\\"arg_name\\\": \\\"value\\\", ...}\\n}\\n\\nDo not include any other text, explanations, or markdown formatting. \\nYour entire response must be only the JSON object.\\n\\nIf you can answer the question without a function, \\njust provide the answer directly in plain text.\\\"\\\"\\\"\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eNotice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can \\\"parse\\\" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhat does \\\"continuing the conversation\\\" mean?\u003c/strong\u003e\u003cbr /\u003eIt’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThat’s basically it.\u003c/strong\u003e\u003cbr /\u003eThis is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eparse_and_execute\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eresponse_content: str\u003c/span\u003e) -\u0026gt; (str, str):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"\\n    Tries to parse the LLM's text response as a JSON function call.\\n    If successful, it executes the function and returns the result and function name.\\n    Otherwise, it returns (None, None).\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003etry\u003c/span\u003e:\\n        call_data = json.loads(response_content)\\n        function_name = call_data.get(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"function_name\\\"\u003c/span\u003e)\\n        function_args = call_data.get(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"arguments\\\"\u003c/span\u003e)\\n\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003enot\u003c/span\u003e all([function_name, isinstance(function_args, dict)]):\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e, \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e \u003cspan class=\\\"hljs-comment\\\"\u003e# Not a valid function call structure\u003c/span\u003e\\n\\n        print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"Parser is executing function: '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e' with args: \u003cspan class=\\\"hljs-subst\\\"\u003e{function_args}\u003c/span\u003e\\\"\u003c/span\u003e)\\n\\n        available_functions = {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"add\\\"\u003c/span\u003e: add, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"subtract\\\"\u003c/span\u003e: subtract}\\n        function_to_call = available_functions.get(function_name)\\n\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e function_to_call:\\n            result = function_to_call(**function_args)\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e str(result), function_name\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eelse\u003c/span\u003e:\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"Error: Unknown function '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e'.\\\"\u003c/span\u003e, function_name\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eexcept\u003c/span\u003e (json.JSONDecodeError, TypeError):\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e, \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e \u003cspan class=\\\"hljs-comment\\\"\u003e# Not JSON or not a dictionary\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe entire code for this is available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eAnd then there’s the \u003cstrong\u003einvoke\u003c/strong\u003e method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# --- 5. The Main Invocation Logic ---\u003c/span\u003e\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003einvoke\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003euser_prompt: str\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"\\n    Invokes the LLM, manually handling the function-calling loop.\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\\n\u003cspan class=\\\"hljs-subst\\\"\u003e{\u003cspan class=\\\"hljs-string\\\"\u003e'='\u003c/span\u003e*\u003cspan class=\\\"hljs-number\\\"\u003e20\u003c/span\u003e}\u003c/span\u003e Invoking for prompt: '\u003cspan class=\\\"hljs-subst\\\"\u003e{user_prompt}\u003c/span\u003e' \u003cspan class=\\\"hljs-subst\\\"\u003e{\u003cspan class=\\\"hljs-string\\\"\u003e'='\u003c/span\u003e*\u003cspan class=\\\"hljs-number\\\"\u003e20\u003c/span\u003e}\u003c/span\u003e\\\"\u003c/span\u003e)\\n\\n    messages = [\\n        {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: SYSTEM_PROMPT},\\n        {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"user\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: user_prompt}\\n    ]\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 1: First LLM Call (without the `tools` parameter) ===\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 1. Sending prompt to LLM to generate function call JSON... ---\\\"\u003c/span\u003e)\\n    response = client.chat.completions.create(\\n        model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-4o\\\"\u003c/span\u003e,\\n        messages=messages\\n    )\\n\\n    response_message = response.choices[\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e].message\\n    messages.append({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"assistant\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: response_message.content})\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 2: Manually parse the response for a function call ===\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 2. Manually parsing response for a function call... ---\\\"\u003c/span\u003e)\\n    function_output, function_name = parse_and_execute(response_message.content)\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e function_output:\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# We got a result from our function, so we continue the conversation\u003c/span\u003e\\n        messages.append({\\n            \u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"user\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-comment\\\"\u003e# We provide the function result back as the user\u003c/span\u003e\\n            \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"I have called the function '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e'. The result is: \u003cspan class=\\\"hljs-subst\\\"\u003e{function_output}\u003c/span\u003e\\\"\u003c/span\u003e\\n        })\\n\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 3: Second LLM Call with function results ===\u003c/span\u003e\\n        print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 3. Sending function output back to LLM... ---\\\"\u003c/span\u003e)\\n\\n        second_response = client.chat.completions.create(\\n            model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-4o\\\"\u003c/span\u003e,\\n            messages=messages\\n        )\\n        final_response = second_response.choices[\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e].message.content\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eelse\u003c/span\u003e:\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# If parsing failed, the LLM's first response is the final answer\u003c/span\u003e\\n        final_response = response_message.content\\n\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\\n--- Final Answer ---\\\"\u003c/span\u003e)\\n    print(final_response)\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e final_response\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eYou know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.\u003c/p\u003e\\n\u003cp\u003eToday, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: \u003ca target=\\\"_blank\\\" href=\\\"https://platform.openai.com/docs/quickstart?api-mode=responses\\\"\u003ehttps://platform.openai.com/docs/quickstart?api-mode=responses\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eExploring Popular Agent Frameworks\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eSome of the popular Agent frameworks includes -\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCrewAI\u003c/strong\u003e – A Python framework for coordinating multiple agents as a team.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/crewAIInc/crewAI\\\"\u003eCrewAI on Github\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eOpenAI Agents SDK\u003c/strong\u003e – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://openai.github.io/openai-agents-python/\\\"\u003eOpenAI Agents SDK (Python)\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eMetaGPT\u003c/strong\u003e – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/FoundationAgents/MetaGPT\\\"\u003eMetaGPT on GitHub\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eNow that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWait, Persona?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eThat’s new. Why does an agent need a persona? What is a persona, anyway?\u003c/p\u003e\\n\u003cp\u003eIf you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eUp Next: Multi-Agent Systems\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eIn the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-multi-agent-system\\\"\u003eMulti Agent System\u003c/h1\u003e\\n\u003cp\u003eNow that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eRemember, agents are just:\u003c/strong\u003e\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cp\u003eAn LLM with access to tools\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eA set of prompts (like persona, goal, etc.)\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eMemory (which we’ll talk about later)\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eAll built using an orchestration framework so everything works together\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eBut what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eSource: \u003ca target=\\\"_blank\\\" href=\\\"https://docs.crewai.com/concepts/collaboration\\\"\u003eCrewAI Collaboration Concepts\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eAll the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhy Use Multi-Agent Systems?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eMulti-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their \u003ca target=\\\"_blank\\\" href=\\\"https://www.anthropic.com/engineering/built-multi-agent-research-system\\\"\u003eblog post\u003c/a\u003e on multi-agent systems, is that you can use more tokens (so the system can \\\"think more\\\") when tackling a complex problem.\u003c/p\u003e\\n\u003cp\u003eIn the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.\u003c/p\u003e\\n\u003cp\u003eYou can read about different types of multi agent systems later \u003ca target=\\\"_blank\\\" href=\\\"https://langchain-ai.github.io/langgraph/concepts/multi_agent/\\\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWarning:\u003c/strong\u003e As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-memory\\\"\u003eMemory\u003c/h1\u003e\\n\u003cp\u003eWe have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.\u003c/p\u003e\\n\u003cp\u003eIn many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.\u003c/p\u003e\\n\u003cp\u003eThere are two forms of memory that an AI agent can potentially have, much like humans do:\u003c/p\u003e\\n\u003ch3 id=\\\"heading-short-term-memory\\\"\u003e\u003cstrong\u003eShort Term Memory\u003c/strong\u003e\u003c/h3\u003e\\n\u003cp\u003eShort term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.\u003c/p\u003e\\n\u003cp\u003eHere’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:\u003c/p\u003e\\n\u003cp\u003eM1: User: perform 10 + 20 + 30 + 40 + 50\u003cbr /\u003eM2: LLM: \u003cem\u003eTool call, 10 + 20\u003c/em\u003e\u003cbr /\u003eM3: User: Output 30\u003cbr /\u003eM4: LLM: \u003cem\u003eCurrent answer is 30, let’s proceed. Tool call 30 + 30\u003c/em\u003e\u003cbr /\u003eM5: User: Output 60\u003cbr /\u003eM6: LLM: \u003cem\u003eCurrent answer is 60, let’s proceed. Tool call 60 + 40\u003c/em\u003e\u003c/p\u003e\\n\u003cp\u003eAt this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:\u003c/p\u003e\\n\u003cp\u003eM1: User: perform 10 + 20 + 30 + 40 + 50\u003cbr /\u003eM2’: User: Output of 10 + 20 + 30 is 60, proceed further.\u003cbr /\u003eM6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40\u003c/p\u003e\\n\u003cp\u003eNotice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.\u003c/p\u003e\\n\u003cp\u003eSometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.\u003c/p\u003e\\n\u003cp\u003eWe also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.\u003cbr /\u003e\u003cstrong\u003eRAISE stands for Reasoning and Acting through Scratchpad and Examples.\u003c/strong\u003e The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.\u003c/p\u003e\\n\u003cp\u003eRead the paper that introduced RAISE framework here: \u003ca target=\\\"_blank\\\" href=\\\"https://arxiv.org/pdf/2401.02777\\\"\u003ehttps://arxiv.org/pdf/2401.02777\u003c/a\u003e\u003c/p\u003e\\n\u003ch3 id=\\\"heading-long-term-memory\\\"\u003e\u003cstrong\u003eLong Term Memory\u003c/strong\u003e\u003c/h3\u003e\\n\u003cp\u003eLong-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.\u003c/p\u003e\\n\u003cp\u003eIn our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.\u003c/p\u003e\\n\u003cp\u003eNotice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-mental-model-to-work-with-agents\\\"\u003eMental Model to work with agents\u003c/h1\u003e\\n\u003cp\u003eThat’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made \u003ca target=\\\"_blank\\\" href=\\\"http://patra.app\\\"\u003epatra.app\u003c/a\u003e work reliably, and also how I’ve shipped multiple other production systems.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThe golden model:\u003c/strong\u003e\u003cbr /\u003eKeep yourself in the place of the agent. Imagine you are that agent.\u003c/p\u003e\\n\u003cp\u003eIt might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.\u003c/p\u003e\\n\u003cp\u003ePut yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?\u003c/p\u003e\\n\u003cp\u003eNow, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-conclusion\\\"\u003eConclusion\u003c/h2\u003e\\n\u003cp\u003eHopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.\u003c/p\u003e\\n\u003cp\u003eIf you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.\u003c/p\u003e\\n\u003cp\u003eThere is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions \\\"AI agent\\\" in conversation, you will know not only what it is but also how it thinks and works.\u003c/p\u003e\\n\u003cp\u003eIf you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens.\u003c/p\u003e\\n\",\"markdown\":\"## Motivation: Why You Should Care\\n\\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like [patra.app](https://patra.app). While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...\\n\\nDuring one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”\\n\\nThey gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.\\n\\nWell, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.\\n\\nI promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:\\n\\n1. What an AI agent is\\n    \\n2. How an AI agent works\\n    \\n3. What the heck tools are\\n    \\n4. What an orchestration framework is\\n    \\n5. What memory is\\n    \\n6. What the types of AI agents are\\n    \\n7. The mental model for building an AI agent\\n    \\n8. What a multi-agent framework is\\n    \\n\\nBefore we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.\\n\\n## The Problem\\n\\nOk, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png align=\\\"center\\\")\\n\\n\u003e An AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention\\n\\nYou see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.\\n\\nIf I ask, \\\"What is an LLM?\\\" we get a much more acceptable answer:\\n\\n\u003e A Large Language Model (LLM) is **a type of AI model, specifically a deep learning model, trained on massive amounts of text data.**\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png align=\\\"center\\\")\\n\\nNotice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.\\n\\n# Defining AI Agent\\n\\nLet’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:\\n\\nAgents are **software systems** where **LLMs** use reasoning to control the flow of execution, **dynamically** choosing which **tools** to use and determining each step required to reach a **goal**.\\n\\nThat’s a mouthful. Let’s break down each part so we can actually understand it.\\n\\n## **Agents are Software Systems**\\n\\nThis is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:\\n\\n1. LLMs\\n    \\n2. Working Memory or state\\n    \\n3. Prompts\\n    \\n4. Tools\\n    \\n5. Orchestration Layer\\n    \\n\\nYou already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.\\n\\nIn our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.\\n\\n## **Dynamic** Flow of Execution\\n\\nTo execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.\\n\\nLet’s look at an example.\\n\\nSuppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.\\n\\nNotice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.\\n\\nWe won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png align=\\\"center\\\")\\n\\n\u003cdiv data-node-type=\\\"callout\\\"\u003e\\n\u003cdiv data-node-type=\\\"callout-emoji\\\"\u003e💡\u003c/div\u003e\\n\u003cdiv data-node-type=\\\"callout-text\\\"\u003eYou may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading\u003c/div\u003e\\n\u003c/div\u003e\\n\\nNotice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.\\n\\n```python\\n# Build workflow\\nworkflow = StateGraph(SupportTicketState)\\n\\n# Add nodes\\nworkflow.add_node(\\\"classify_ticket\\\", classify_ticket)\\nworkflow.add_node(\\\"generate_initial_response\\\", generate_initial_response)\\nworkflow.add_node(\\\"check_escalation\\\", check_escalation_needed)\\nworkflow.add_node(\\\"escalate_ticket\\\", escalate_ticket)\\nworkflow.add_node(\\\"resolve_ticket\\\", resolve_ticket)\\n\\n# Add edges\\nworkflow.add_edge(START, \\\"classify_ticket\\\")\\nworkflow.add_edge(\\\"classify_ticket\\\", \\\"generate_initial_response\\\")\\nworkflow.add_edge(\\\"generate_initial_response\\\", \\\"check_escalation\\\")\\n\\n# Conditional edges for escalation\\nworkflow.add_conditional_edges(\\n    \\\"check_escalation\\\",\\n    should_escalate,\\n    {\\n        \\\"escalate\\\": \\\"escalate_ticket\\\",\\n        \\\"resolve\\\": \\\"resolve_ticket\\\"\\n    }\\n)\\n\\nworkflow.add_edge(\\\"escalate_ticket\\\", END)\\nworkflow.add_edge(\\\"resolve_ticket\\\", END)\\n```\\n\\nEntire code for this is available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py)\\n\\nThis is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.\\n\\nIn the example above, the value of should\\\\_escalate, which comes from the check\\\\_escalation node, is used to determine which part of the graph or “workflow” we go to next.\\n\\nA node like \\\"resolve ticket\\\" will look something like this:\\n\\n```python\\ndef resolve_ticket(state: SupportTicketState):\\n    \\\"\\\"\\\"Resolve the ticket and generate a final customer-facing response.\\\"\\\"\\\"\\n    call_resolution_api(state['ticket_id'])\\n    prompt = f\\\"\\\"\\\"\\n    Generate a customer-facing response to inform them their ticket is resolved.\\n    \\n    Ticket ID: {state['ticket_id']}\\n    Customer: {state['customer_name']}\\n    Issue: {state['issue_description']}\\n    \\n    The response should:\\n    1. State clearly that the issue has been resolved.\\n    2. Briefly explain the solution.\\n    3. Thank the customer for their patience.\\n    4. Ask if they need any further assistance.\\n    \\\"\\\"\\\"\\n    response = llm.invoke(prompt)\\n    return {\\n        \\\"final_response\\\": response.content,\\n        \\\"status\\\": \\\"Resolved\\\"\\n    }\\n```\\n\\nNotice how we first call the resolution API and then run the prompt to generate a response for the ticket.\\n\\nYou might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.\\n\\nLet’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.\\n\\n**By the way, ReAct stands for \\\"Reasoning and Acting.\\\"**  \\nIt is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png align=\\\"center\\\")\\n\\nIn our example:\\n\\nThe **task** is to either resolve or escalate the ticket and give back a response.\\n\\nIn the **Act** stage, the agent can use a tool to classify, escalate, or resolve the ticket.\\n\\nIn the **Observe** stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.\\n\\nIn the **Reasoning** stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.\\n\\nNotice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.\\n\\nTo understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.\\n\\n**Now getting to the code:**\\n\\n```python\\n# --- Agent Definition ---\\nsupport_agent = Agent(\\n    role=\\\"Senior Customer Support Specialist\\\",\\n    goal=\\\"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses.\\\",\\n    backstory=(\\n        \\\"You are a seasoned support specialist with a knack for understanding customer needs. \\\"\\n        \\\"You excel at identifying the root cause of issues, communicating clearly, and \\\"\\n        \\\"knowing precisely when a problem needs to be escalated to a senior team member. \\\"\\n        \\\"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality.\\\"\\n    ),\\n    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],\\n    llm=llm,\\n    verbose=True,\\n    allow_delegation=False\\n)\\n\\n# --- Task Definition ---\\ndef create_ticket_processing_task(agent, ticket_id, customer_name, issue_description):\\n    return Task(\\n        description=f\\\"\\\"\\\"\\n        Process customer support ticket with the following details:\\n        - Ticket ID: {ticket_id}\\n        - Customer Name: {customer_name}\\n        - Issue Description: {issue_description}\\n\\n        Follow this exact workflow:\\n        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).\\n        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.\\n        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.\\n        4.  **Use a Tool**:\\n            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.\\n            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.\\n        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.\\n\\n        Your final output must be a comprehensive report in markdown format that includes:\\n        - The classified priority and category.\\n        - The initial response.\\n        - The action taken with the corresponding tool.\\n        - The final customer-facing response.\\n        \\\"\\\"\\\",\\n        agent=agent,\\n        expected_output=\\\"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response.\\\"\\n    )\\n```\\n\\nEntire code for this available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py)\\n\\nOk, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.\\n\\n**The Little Trick We Play**\\n\\nBut here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?\\n\\n**Isn’t That Just a Static Workflow?**\\n\\nWell, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.\\n\\nFor example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.\\n\\n**Real World Example**\\n\\nWhen I was creating [patra.app](http://patra.app)[,](https://patra.app) which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.\\n\\nExample:  \\nCreate me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.\\n\\nImagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.\\n\\nNow imagine an action like:  \\nCheck my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.\\n\\nThese are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.\\n\\n**Don’t Overcomplicate Simple Things**\\n\\nWOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...\\n\\nStop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?\\n\\nAgents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.\\n\\nIn a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png align=\\\"center\\\")\\n\\n**What’s Next?**\\n\\nSo far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.\\n\\n## **Tools \u0026** orchestration **Framework**\\n\\nLLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”\\n\\n**A Simple Example**\\n\\nLet’s break this down with a simple program.\\n\\nSuppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.\\n\\n**Why Use Tools?**\\n\\nTools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.\\n\\n**Defining a Tool**\\n\\nLet’s define how our tool will look:\\n\\n```python\\ndef add(a: int, b: int) -\u003e int:\\n    \\\"\\\"\\\"Adds two integers together.\\\"\\\"\\\"\\n    return a + b\\n\\ndef subtract(a: int, b: int) -\u003e int:\\n    \\\"\\\"\\\"Subtracts the second integer from the first.\\\"\\\"\\\"\\n    return a - b\\n\\nSYSTEM_PROMPT = \\\"\\\"\\\"You are a helpful assistant with access to the following functions:\\n\\n1. `add(a: int, b: int)`: Adds two integers together.\\n2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.\\n\\nWhen a user asks a question that can be answered by one of these functions, \\nyou MUST respond ONLY with a JSON object in the following format:\\n{\\n  \\\"function_name\\\": \\\"name_of_the_function\\\",\\n  \\\"arguments\\\": {\\\"arg_name\\\": \\\"value\\\", ...}\\n}\\n\\nDo not include any other text, explanations, or markdown formatting. \\nYour entire response must be only the JSON object.\\n\\nIf you can answer the question without a function, \\njust provide the answer directly in plain text.\\\"\\\"\\\"\\n```\\n\\nNotice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can \\\"parse\\\" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.\\n\\n**What does \\\"continuing the conversation\\\" mean?**  \\nIt’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.\\n\\n**That’s basically it.**  \\nThis is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:\\n\\n```python\\ndef parse_and_execute(response_content: str) -\u003e (str, str):\\n    \\\"\\\"\\\"\\n    Tries to parse the LLM's text response as a JSON function call.\\n    If successful, it executes the function and returns the result and function name.\\n    Otherwise, it returns (None, None).\\n    \\\"\\\"\\\"\\n    try:\\n        call_data = json.loads(response_content)\\n        function_name = call_data.get(\\\"function_name\\\")\\n        function_args = call_data.get(\\\"arguments\\\")\\n\\n        if not all([function_name, isinstance(function_args, dict)]):\\n            return None, None # Not a valid function call structure\\n\\n        print(f\\\"Parser is executing function: '{function_name}' with args: {function_args}\\\")\\n\\n        available_functions = {\\\"add\\\": add, \\\"subtract\\\": subtract}\\n        function_to_call = available_functions.get(function_name)\\n\\n        if function_to_call:\\n            result = function_to_call(**function_args)\\n            return str(result), function_name\\n        else:\\n            return f\\\"Error: Unknown function '{function_name}'.\\\", function_name\\n\\n    except (json.JSONDecodeError, TypeError):\\n        return None, None # Not JSON or not a dictionary\\n```\\n\\nThe entire code for this is available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py)\\n\\nAnd then there’s the **invoke** method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.\\n\\n```python\\n# --- 5. The Main Invocation Logic ---\\ndef invoke(user_prompt: str):\\n    \\\"\\\"\\\"\\n    Invokes the LLM, manually handling the function-calling loop.\\n    \\\"\\\"\\\"\\n    print(f\\\"\\\\n{'='*20} Invoking for prompt: '{user_prompt}' {'='*20}\\\")\\n    \\n    messages = [\\n        {\\\"role\\\": \\\"system\\\", \\\"content\\\": SYSTEM_PROMPT},\\n        {\\\"role\\\": \\\"user\\\", \\\"content\\\": user_prompt}\\n    ]\\n\\n    # === Step 1: First LLM Call (without the `tools` parameter) ===\\n    print(\\\"\\\\n--- 1. Sending prompt to LLM to generate function call JSON... ---\\\")\\n    response = client.chat.completions.create(\\n        model=\\\"gpt-4o\\\",\\n        messages=messages\\n    )\\n    \\n    response_message = response.choices[0].message\\n    messages.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": response_message.content})\\n\\n    # === Step 2: Manually parse the response for a function call ===\\n    print(\\\"\\\\n--- 2. Manually parsing response for a function call... ---\\\")\\n    function_output, function_name = parse_and_execute(response_message.content)\\n\\n    if function_output:\\n        # We got a result from our function, so we continue the conversation\\n        messages.append({\\n            \\\"role\\\": \\\"user\\\", # We provide the function result back as the user\\n            \\\"content\\\": f\\\"I have called the function '{function_name}'. The result is: {function_output}\\\"\\n        })\\n\\n        # === Step 3: Second LLM Call with function results ===\\n        print(\\\"\\\\n--- 3. Sending function output back to LLM... ---\\\")\\n        \\n        second_response = client.chat.completions.create(\\n            model=\\\"gpt-4o\\\",\\n            messages=messages\\n        )\\n        final_response = second_response.choices[0].message.content\\n    else:\\n        # If parsing failed, the LLM's first response is the final answer\\n        final_response = response_message.content\\n\\n    print(f\\\"\\\\n--- Final Answer ---\\\")\\n    print(final_response)\\n    return final_response\\n```\\n\\nYou know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.\\n\\nToday, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: [https://platform.openai.com/docs/quickstart?api-mode=responses](https://platform.openai.com/docs/quickstart?api-mode=responses)\\n\\n**Exploring Popular Agent Frameworks**\\n\\nSome of the popular Agent frameworks includes -\\n\\n* **CrewAI** – A Python framework for coordinating multiple agents as a team.  \\n    Read more: [CrewAI on Github](https://github.com/crewAIInc/crewAI)\\n    \\n* **OpenAI Agents SDK** – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.  \\n    Read more: [OpenAI Agents SDK (Python)](https://openai.github.io/openai-agents-python/)\\n    \\n* **MetaGPT** – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.  \\n    Read more: [MetaGPT on GitHub](https://github.com/FoundationAgents/MetaGPT)\\n    \\n\\nNow that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.\\n\\n**Wait, Persona?**\\n\\nThat’s new. Why does an agent need a persona? What is a persona, anyway?\\n\\nIf you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.\\n\\n**Up Next: Multi-Agent Systems**\\n\\nIn the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.\\n\\n# Multi Agent System\\n\\nNow that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.\\n\\n**Remember, agents are just:**\\n\\n* An LLM with access to tools\\n    \\n* A set of prompts (like persona, goal, etc.)\\n    \\n* Memory (which we’ll talk about later)\\n    \\n* All built using an orchestration framework so everything works together\\n    \\n\\nBut what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png align=\\\"center\\\")\\n\\nSource: [CrewAI Collaboration Concepts](https://docs.crewai.com/concepts/collaboration)\\n\\nAll the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.\\n\\n**Why Use Multi-Agent Systems?**\\n\\nMulti-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their [blog post](https://www.anthropic.com/engineering/built-multi-agent-research-system) on multi-agent systems, is that you can use more tokens (so the system can \\\"think more\\\") when tackling a complex problem.\\n\\nIn the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.\\n\\nYou can read about different types of multi agent systems later [here](https://langchain-ai.github.io/langgraph/concepts/multi_agent/).\\n\\n**Warning:** As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.\\n\\n# Memory\\n\\nWe have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.\\n\\nIn many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.\\n\\nThere are two forms of memory that an AI agent can potentially have, much like humans do:\\n\\n### **Short Term Memory**\\n\\nShort term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.\\n\\nHere’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:\\n\\nM1: User: perform 10 + 20 + 30 + 40 + 50  \\nM2: LLM: *Tool call, 10 + 20*  \\nM3: User: Output 30  \\nM4: LLM: *Current answer is 30, let’s proceed. Tool call 30 + 30*  \\nM5: User: Output 60  \\nM6: LLM: *Current answer is 60, let’s proceed. Tool call 60 + 40*\\n\\nAt this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:\\n\\nM1: User: perform 10 + 20 + 30 + 40 + 50  \\nM2’: User: Output of 10 + 20 + 30 is 60, proceed further.  \\nM6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40\\n\\nNotice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.\\n\\nSometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.\\n\\nWe also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.  \\n**RAISE stands for Reasoning and Acting through Scratchpad and Examples.** The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.\\n\\nRead the paper that introduced RAISE framework here: [https://arxiv.org/pdf/2401.02777](https://arxiv.org/pdf/2401.02777)\\n\\n### **Long Term Memory**\\n\\nLong-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.\\n\\nIn our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.\\n\\nNotice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.\\n\\n# Mental Model to work with agents\\n\\nThat’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made [patra.app](http://patra.app) work reliably, and also how I’ve shipped multiple other production systems.\\n\\n**The golden model:**  \\nKeep yourself in the place of the agent. Imagine you are that agent.\\n\\nIt might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.\\n\\nPut yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?\\n\\nNow, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.\\n\\n## Conclusion\\n\\nHopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.\\n\\nIf you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.\\n\\nThere is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions \\\"AI agent\\\" in conversation, you will know not only what it is but also how it thinks and works.\\n\\nIf you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens.\"},\"views\":611,\"preferences\":{\"pinnedToBlog\":false,\"disableComments\":false,\"stickCoverToBottom\":true,\"isDelisted\":false},\"readTimeInMinutes\":23,\"series\":null,\"tags\":[{\"id\":\"56744721958ef13879b9488e\",\"slug\":\"ai\",\"name\":\"AI\"},{\"id\":\"65f70fe712e12dacdb744b16\",\"slug\":\"ai-agent\",\"name\":\"ai-agent\"},{\"id\":\"56744721958ef13879b94ad1\",\"slug\":\"software-development\",\"name\":\"software development\"}],\"ogMetaData\":{\"image\":null},\"canonicalUrl\":null,\"hasLatexInPost\":false,\"audioUrls\":null,\"isFollowed\":null,\"bookmarked\":false,\"features\":{\"tableOfContents\":{\"isEnabled\":false,\"items\":[]},\"badges\":{\"isEnabled\":true,\"items\":[]}},\"isAutoPublishedFromRSS\":false,\"authenticatedUserLikes\":{\"edges\":[]},\"totalUserLikes\":{\"totalDocuments\":3},\"isShadowBanned\":false,\"isAskMeAnything\":false},\"redirectedPost\":null,\"staticPage\":null}","totalUsersWhoLikedArticle":3,"integrations":{"fbPixelID":null,"fathomSiteID":null,"fathomCustomDomainEnabled":null,"fathomCustomDomain":null,"hotjarSiteID":null,"matomoSiteID":null,"matomoURL":null,"gaTrackingID":null,"gTagManagerID":null,"plausibleAnalyticsEnabled":null,"koalaPublicKey":null,"msClarityID":null,"domainURL":"blog.surkar.in"},"rootLayout":{"legacyPublicationJSON":"{\"_id\":\"669e957c19b8bd50367fe79c\",\"author\":{\"_id\":\"669e9506d4920b5b5b00bcef\",\"name\":\"Manthan Surkar\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg\",\"username\":\"surkar\"},\"badgePageEnabled\":true,\"description\":\"\",\"domain\":\"blog.surkar.in\",\"domainStatus\":{\"ready\":true,\"certIssued\":true},\"wwwPrefixedDomainStatus\":{},\"customCSSEnabled\":false,\"customCSSPublished\":{\"homeMin\":\"\",\"postMin\":\"\",\"staticMin\":\"\"},\"customRules\":[],\"darkModeEnabled\":false,\"darkModeLogo\":\"\",\"disableFooterBranding\":false,\"isSubscriptionModalDisabled\":false,\"publicMembersCount\":1,\"displayTitle\":\"\",\"favicon\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1751198022133/1c8c4430-333f-4491-9e43-465d6dcb65c0.png\",\"gaTrackingID\":\"\",\"gTagManagerID\":\"\",\"hasBadges\":true,\"headerColor\":\"\",\"hideMembersPage\":false,\"isTeam\":true,\"layout\":\"stacked\",\"membersPageEnabled\":true,\"menu\":[],\"metaHTML\":\"\",\"metaHTMLSanitized\":\"\",\"newsletterEnabled\":true,\"proTeamEnabled\":false,\"newsletterPageEnabled\":false,\"ogImage\":\"\",\"logo\":\"\",\"textSelectionSharerEnabled\":true,\"title\":\"Manthan Surkar\",\"urlPattern\":\"simple\",\"username\":\"surkar\",\"viewCountVisible\":true,\"readTimeHidden\":false,\"links\":{\"twitter\":\"https://twitter.com/manthan_surkar\",\"instagram\":\"\",\"github\":\"https://github.com/thesmallstar\",\"website\":\"\",\"hashnode\":\"https://hashnode.com/@surkar\",\"youtube\":\"\",\"dailydev\":\"\",\"linkedin\":\"\",\"mastodon\":\"\",\"facebook\":\"\"},\"numPosts\":4,\"sponsorship\":{\"content\":\"\",\"contentMarkdown\":\"\"},\"allowContributorEdits\":true,\"allowCrawlingByGPT\":false}","legacyPostJSON":"{\"_id\":\"6857dcad0f01cc2215fffd04\",\"partOfPublication\":true,\"author\":{\"_id\":\"669e9506d4920b5b5b00bcef\",\"name\":\"Manthan Surkar\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg\",\"username\":\"surkar\",\"bio\":\"\",\"socialMedia\":{\"website\":\"https://surkar.in\",\"github\":\"https://github.com/thesmallstar\",\"twitter\":\"\",\"facebook\":\"\",\"stackoverflow\":\"\",\"linkedin\":\"https://www.linkedin.com/in/manthansurkar/\"},\"isDeactivated\":false},\"bookmarkedIn\":[],\"publication\":{\"_id\":\"669e957c19b8bd50367fe79c\",\"author\":{\"_id\":\"669e9506d4920b5b5b00bcef\",\"name\":\"Manthan Surkar\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg\",\"username\":\"surkar\"},\"badgePageEnabled\":true,\"description\":\"\",\"domain\":\"blog.surkar.in\",\"domainStatus\":{\"ready\":true,\"certIssued\":true},\"wwwPrefixedDomainStatus\":{},\"customCSSEnabled\":false,\"customCSSPublished\":{\"homeMin\":\"\",\"postMin\":\"\",\"staticMin\":\"\"},\"customRules\":[],\"darkModeEnabled\":false,\"darkModeLogo\":\"\",\"disableFooterBranding\":false,\"isSubscriptionModalDisabled\":false,\"publicMembersCount\":1,\"displayTitle\":\"\",\"favicon\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1751198022133/1c8c4430-333f-4491-9e43-465d6dcb65c0.png\",\"gaTrackingID\":\"\",\"gTagManagerID\":\"\",\"hasBadges\":true,\"headerColor\":\"\",\"hideMembersPage\":false,\"isTeam\":true,\"layout\":\"stacked\",\"membersPageEnabled\":true,\"menu\":[],\"metaHTML\":\"\",\"metaHTMLSanitized\":\"\",\"newsletterEnabled\":true,\"proTeamEnabled\":false,\"newsletterPageEnabled\":false,\"ogImage\":\"\",\"logo\":\"\",\"textSelectionSharerEnabled\":true,\"title\":\"Manthan Surkar\",\"urlPattern\":\"simple\",\"username\":\"surkar\",\"viewCountVisible\":true,\"readTimeHidden\":false,\"links\":{\"twitter\":\"https://twitter.com/manthan_surkar\",\"instagram\":\"\",\"github\":\"https://github.com/thesmallstar\",\"website\":\"\",\"hashnode\":\"https://hashnode.com/@surkar\",\"youtube\":\"\",\"dailydev\":\"\",\"linkedin\":\"\",\"mastodon\":\"\",\"facebook\":\"\"},\"numPosts\":4,\"sponsorship\":{\"content\":\"\",\"contentMarkdown\":\"\"},\"allowContributorEdits\":true,\"allowCrawlingByGPT\":false},\"tags\":[{\"_id\":\"56744721958ef13879b9488e\",\"slug\":\"ai\",\"name\":\"AI\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"65f70fe712e12dacdb744b16\",\"slug\":\"ai-agent\",\"name\":\"ai-agent\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"56744721958ef13879b94ad1\",\"slug\":\"software-development\",\"name\":\"software development\",\"isActive\":true,\"isApproved\":true}],\"coAuthors\":[],\"responseCount\":1,\"replyCount\":0,\"contentMarkdown\":\"## Motivation: Why You Should Care\\n\\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like [patra.app](https://patra.app). While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...\\n\\nDuring one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”\\n\\nThey gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.\\n\\nWell, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.\\n\\nI promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:\\n\\n1. What an AI agent is\\n    \\n2. How an AI agent works\\n    \\n3. What the heck tools are\\n    \\n4. What an orchestration framework is\\n    \\n5. What memory is\\n    \\n6. What the types of AI agents are\\n    \\n7. The mental model for building an AI agent\\n    \\n8. What a multi-agent framework is\\n    \\n\\nBefore we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.\\n\\n## The Problem\\n\\nOk, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png align=\\\"center\\\")\\n\\n\u003e An AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention\\n\\nYou see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.\\n\\nIf I ask, \\\"What is an LLM?\\\" we get a much more acceptable answer:\\n\\n\u003e A Large Language Model (LLM) is **a type of AI model, specifically a deep learning model, trained on massive amounts of text data.**\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png align=\\\"center\\\")\\n\\nNotice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.\\n\\n# Defining AI Agent\\n\\nLet’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:\\n\\nAgents are **software systems** where **LLMs** use reasoning to control the flow of execution, **dynamically** choosing which **tools** to use and determining each step required to reach a **goal**.\\n\\nThat’s a mouthful. Let’s break down each part so we can actually understand it.\\n\\n## **Agents are Software Systems**\\n\\nThis is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:\\n\\n1. LLMs\\n    \\n2. Working Memory or state\\n    \\n3. Prompts\\n    \\n4. Tools\\n    \\n5. Orchestration Layer\\n    \\n\\nYou already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.\\n\\nIn our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.\\n\\n## **Dynamic** Flow of Execution\\n\\nTo execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.\\n\\nLet’s look at an example.\\n\\nSuppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.\\n\\nNotice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.\\n\\nWe won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png align=\\\"center\\\")\\n\\n\u003cdiv data-node-type=\\\"callout\\\"\u003e\\n\u003cdiv data-node-type=\\\"callout-emoji\\\"\u003e💡\u003c/div\u003e\\n\u003cdiv data-node-type=\\\"callout-text\\\"\u003eYou may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading\u003c/div\u003e\\n\u003c/div\u003e\\n\\nNotice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.\\n\\n```python\\n# Build workflow\\nworkflow = StateGraph(SupportTicketState)\\n\\n# Add nodes\\nworkflow.add_node(\\\"classify_ticket\\\", classify_ticket)\\nworkflow.add_node(\\\"generate_initial_response\\\", generate_initial_response)\\nworkflow.add_node(\\\"check_escalation\\\", check_escalation_needed)\\nworkflow.add_node(\\\"escalate_ticket\\\", escalate_ticket)\\nworkflow.add_node(\\\"resolve_ticket\\\", resolve_ticket)\\n\\n# Add edges\\nworkflow.add_edge(START, \\\"classify_ticket\\\")\\nworkflow.add_edge(\\\"classify_ticket\\\", \\\"generate_initial_response\\\")\\nworkflow.add_edge(\\\"generate_initial_response\\\", \\\"check_escalation\\\")\\n\\n# Conditional edges for escalation\\nworkflow.add_conditional_edges(\\n    \\\"check_escalation\\\",\\n    should_escalate,\\n    {\\n        \\\"escalate\\\": \\\"escalate_ticket\\\",\\n        \\\"resolve\\\": \\\"resolve_ticket\\\"\\n    }\\n)\\n\\nworkflow.add_edge(\\\"escalate_ticket\\\", END)\\nworkflow.add_edge(\\\"resolve_ticket\\\", END)\\n```\\n\\nEntire code for this is available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py)\\n\\nThis is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.\\n\\nIn the example above, the value of should\\\\_escalate, which comes from the check\\\\_escalation node, is used to determine which part of the graph or “workflow” we go to next.\\n\\nA node like \\\"resolve ticket\\\" will look something like this:\\n\\n```python\\ndef resolve_ticket(state: SupportTicketState):\\n    \\\"\\\"\\\"Resolve the ticket and generate a final customer-facing response.\\\"\\\"\\\"\\n    call_resolution_api(state['ticket_id'])\\n    prompt = f\\\"\\\"\\\"\\n    Generate a customer-facing response to inform them their ticket is resolved.\\n    \\n    Ticket ID: {state['ticket_id']}\\n    Customer: {state['customer_name']}\\n    Issue: {state['issue_description']}\\n    \\n    The response should:\\n    1. State clearly that the issue has been resolved.\\n    2. Briefly explain the solution.\\n    3. Thank the customer for their patience.\\n    4. Ask if they need any further assistance.\\n    \\\"\\\"\\\"\\n    response = llm.invoke(prompt)\\n    return {\\n        \\\"final_response\\\": response.content,\\n        \\\"status\\\": \\\"Resolved\\\"\\n    }\\n```\\n\\nNotice how we first call the resolution API and then run the prompt to generate a response for the ticket.\\n\\nYou might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.\\n\\nLet’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.\\n\\n**By the way, ReAct stands for \\\"Reasoning and Acting.\\\"**  \\nIt is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png align=\\\"center\\\")\\n\\nIn our example:\\n\\nThe **task** is to either resolve or escalate the ticket and give back a response.\\n\\nIn the **Act** stage, the agent can use a tool to classify, escalate, or resolve the ticket.\\n\\nIn the **Observe** stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.\\n\\nIn the **Reasoning** stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.\\n\\nNotice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.\\n\\nTo understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.\\n\\n**Now getting to the code:**\\n\\n```python\\n# --- Agent Definition ---\\nsupport_agent = Agent(\\n    role=\\\"Senior Customer Support Specialist\\\",\\n    goal=\\\"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses.\\\",\\n    backstory=(\\n        \\\"You are a seasoned support specialist with a knack for understanding customer needs. \\\"\\n        \\\"You excel at identifying the root cause of issues, communicating clearly, and \\\"\\n        \\\"knowing precisely when a problem needs to be escalated to a senior team member. \\\"\\n        \\\"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality.\\\"\\n    ),\\n    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],\\n    llm=llm,\\n    verbose=True,\\n    allow_delegation=False\\n)\\n\\n# --- Task Definition ---\\ndef create_ticket_processing_task(agent, ticket_id, customer_name, issue_description):\\n    return Task(\\n        description=f\\\"\\\"\\\"\\n        Process customer support ticket with the following details:\\n        - Ticket ID: {ticket_id}\\n        - Customer Name: {customer_name}\\n        - Issue Description: {issue_description}\\n\\n        Follow this exact workflow:\\n        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).\\n        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.\\n        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.\\n        4.  **Use a Tool**:\\n            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.\\n            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.\\n        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.\\n\\n        Your final output must be a comprehensive report in markdown format that includes:\\n        - The classified priority and category.\\n        - The initial response.\\n        - The action taken with the corresponding tool.\\n        - The final customer-facing response.\\n        \\\"\\\"\\\",\\n        agent=agent,\\n        expected_output=\\\"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response.\\\"\\n    )\\n```\\n\\nEntire code for this available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py)\\n\\nOk, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.\\n\\n**The Little Trick We Play**\\n\\nBut here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?\\n\\n**Isn’t That Just a Static Workflow?**\\n\\nWell, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.\\n\\nFor example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.\\n\\n**Real World Example**\\n\\nWhen I was creating [patra.app](http://patra.app)[,](https://patra.app) which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.\\n\\nExample:  \\nCreate me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.\\n\\nImagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.\\n\\nNow imagine an action like:  \\nCheck my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.\\n\\nThese are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.\\n\\n**Don’t Overcomplicate Simple Things**\\n\\nWOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...\\n\\nStop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?\\n\\nAgents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.\\n\\nIn a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png align=\\\"center\\\")\\n\\n**What’s Next?**\\n\\nSo far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.\\n\\n## **Tools \u0026** orchestration **Framework**\\n\\nLLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”\\n\\n**A Simple Example**\\n\\nLet’s break this down with a simple program.\\n\\nSuppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.\\n\\n**Why Use Tools?**\\n\\nTools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.\\n\\n**Defining a Tool**\\n\\nLet’s define how our tool will look:\\n\\n```python\\ndef add(a: int, b: int) -\u003e int:\\n    \\\"\\\"\\\"Adds two integers together.\\\"\\\"\\\"\\n    return a + b\\n\\ndef subtract(a: int, b: int) -\u003e int:\\n    \\\"\\\"\\\"Subtracts the second integer from the first.\\\"\\\"\\\"\\n    return a - b\\n\\nSYSTEM_PROMPT = \\\"\\\"\\\"You are a helpful assistant with access to the following functions:\\n\\n1. `add(a: int, b: int)`: Adds two integers together.\\n2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.\\n\\nWhen a user asks a question that can be answered by one of these functions, \\nyou MUST respond ONLY with a JSON object in the following format:\\n{\\n  \\\"function_name\\\": \\\"name_of_the_function\\\",\\n  \\\"arguments\\\": {\\\"arg_name\\\": \\\"value\\\", ...}\\n}\\n\\nDo not include any other text, explanations, or markdown formatting. \\nYour entire response must be only the JSON object.\\n\\nIf you can answer the question without a function, \\njust provide the answer directly in plain text.\\\"\\\"\\\"\\n```\\n\\nNotice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can \\\"parse\\\" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.\\n\\n**What does \\\"continuing the conversation\\\" mean?**  \\nIt’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.\\n\\n**That’s basically it.**  \\nThis is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:\\n\\n```python\\ndef parse_and_execute(response_content: str) -\u003e (str, str):\\n    \\\"\\\"\\\"\\n    Tries to parse the LLM's text response as a JSON function call.\\n    If successful, it executes the function and returns the result and function name.\\n    Otherwise, it returns (None, None).\\n    \\\"\\\"\\\"\\n    try:\\n        call_data = json.loads(response_content)\\n        function_name = call_data.get(\\\"function_name\\\")\\n        function_args = call_data.get(\\\"arguments\\\")\\n\\n        if not all([function_name, isinstance(function_args, dict)]):\\n            return None, None # Not a valid function call structure\\n\\n        print(f\\\"Parser is executing function: '{function_name}' with args: {function_args}\\\")\\n\\n        available_functions = {\\\"add\\\": add, \\\"subtract\\\": subtract}\\n        function_to_call = available_functions.get(function_name)\\n\\n        if function_to_call:\\n            result = function_to_call(**function_args)\\n            return str(result), function_name\\n        else:\\n            return f\\\"Error: Unknown function '{function_name}'.\\\", function_name\\n\\n    except (json.JSONDecodeError, TypeError):\\n        return None, None # Not JSON or not a dictionary\\n```\\n\\nThe entire code for this is available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py)\\n\\nAnd then there’s the **invoke** method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.\\n\\n```python\\n# --- 5. The Main Invocation Logic ---\\ndef invoke(user_prompt: str):\\n    \\\"\\\"\\\"\\n    Invokes the LLM, manually handling the function-calling loop.\\n    \\\"\\\"\\\"\\n    print(f\\\"\\\\n{'='*20} Invoking for prompt: '{user_prompt}' {'='*20}\\\")\\n    \\n    messages = [\\n        {\\\"role\\\": \\\"system\\\", \\\"content\\\": SYSTEM_PROMPT},\\n        {\\\"role\\\": \\\"user\\\", \\\"content\\\": user_prompt}\\n    ]\\n\\n    # === Step 1: First LLM Call (without the `tools` parameter) ===\\n    print(\\\"\\\\n--- 1. Sending prompt to LLM to generate function call JSON... ---\\\")\\n    response = client.chat.completions.create(\\n        model=\\\"gpt-4o\\\",\\n        messages=messages\\n    )\\n    \\n    response_message = response.choices[0].message\\n    messages.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": response_message.content})\\n\\n    # === Step 2: Manually parse the response for a function call ===\\n    print(\\\"\\\\n--- 2. Manually parsing response for a function call... ---\\\")\\n    function_output, function_name = parse_and_execute(response_message.content)\\n\\n    if function_output:\\n        # We got a result from our function, so we continue the conversation\\n        messages.append({\\n            \\\"role\\\": \\\"user\\\", # We provide the function result back as the user\\n            \\\"content\\\": f\\\"I have called the function '{function_name}'. The result is: {function_output}\\\"\\n        })\\n\\n        # === Step 3: Second LLM Call with function results ===\\n        print(\\\"\\\\n--- 3. Sending function output back to LLM... ---\\\")\\n        \\n        second_response = client.chat.completions.create(\\n            model=\\\"gpt-4o\\\",\\n            messages=messages\\n        )\\n        final_response = second_response.choices[0].message.content\\n    else:\\n        # If parsing failed, the LLM's first response is the final answer\\n        final_response = response_message.content\\n\\n    print(f\\\"\\\\n--- Final Answer ---\\\")\\n    print(final_response)\\n    return final_response\\n```\\n\\nYou know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.\\n\\nToday, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: [https://platform.openai.com/docs/quickstart?api-mode=responses](https://platform.openai.com/docs/quickstart?api-mode=responses)\\n\\n**Exploring Popular Agent Frameworks**\\n\\nSome of the popular Agent frameworks includes -\\n\\n* **CrewAI** – A Python framework for coordinating multiple agents as a team.  \\n    Read more: [CrewAI on Github](https://github.com/crewAIInc/crewAI)\\n    \\n* **OpenAI Agents SDK** – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.  \\n    Read more: [OpenAI Agents SDK (Python)](https://openai.github.io/openai-agents-python/)\\n    \\n* **MetaGPT** – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.  \\n    Read more: [MetaGPT on GitHub](https://github.com/FoundationAgents/MetaGPT)\\n    \\n\\nNow that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.\\n\\n**Wait, Persona?**\\n\\nThat’s new. Why does an agent need a persona? What is a persona, anyway?\\n\\nIf you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.\\n\\n**Up Next: Multi-Agent Systems**\\n\\nIn the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.\\n\\n# Multi Agent System\\n\\nNow that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.\\n\\n**Remember, agents are just:**\\n\\n* An LLM with access to tools\\n    \\n* A set of prompts (like persona, goal, etc.)\\n    \\n* Memory (which we’ll talk about later)\\n    \\n* All built using an orchestration framework so everything works together\\n    \\n\\nBut what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.\\n\\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png align=\\\"center\\\")\\n\\nSource: [CrewAI Collaboration Concepts](https://docs.crewai.com/concepts/collaboration)\\n\\nAll the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.\\n\\n**Why Use Multi-Agent Systems?**\\n\\nMulti-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their [blog post](https://www.anthropic.com/engineering/built-multi-agent-research-system) on multi-agent systems, is that you can use more tokens (so the system can \\\"think more\\\") when tackling a complex problem.\\n\\nIn the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.\\n\\nYou can read about different types of multi agent systems later [here](https://langchain-ai.github.io/langgraph/concepts/multi_agent/).\\n\\n**Warning:** As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.\\n\\n# Memory\\n\\nWe have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.\\n\\nIn many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.\\n\\nThere are two forms of memory that an AI agent can potentially have, much like humans do:\\n\\n### **Short Term Memory**\\n\\nShort term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.\\n\\nHere’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:\\n\\nM1: User: perform 10 + 20 + 30 + 40 + 50  \\nM2: LLM: *Tool call, 10 + 20*  \\nM3: User: Output 30  \\nM4: LLM: *Current answer is 30, let’s proceed. Tool call 30 + 30*  \\nM5: User: Output 60  \\nM6: LLM: *Current answer is 60, let’s proceed. Tool call 60 + 40*\\n\\nAt this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:\\n\\nM1: User: perform 10 + 20 + 30 + 40 + 50  \\nM2’: User: Output of 10 + 20 + 30 is 60, proceed further.  \\nM6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40\\n\\nNotice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.\\n\\nSometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.\\n\\nWe also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.  \\n**RAISE stands for Reasoning and Acting through Scratchpad and Examples.** The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.\\n\\nRead the paper that introduced RAISE framework here: [https://arxiv.org/pdf/2401.02777](https://arxiv.org/pdf/2401.02777)\\n\\n### **Long Term Memory**\\n\\nLong-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.\\n\\nIn our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.\\n\\nNotice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.\\n\\n# Mental Model to work with agents\\n\\nThat’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made [patra.app](http://patra.app) work reliably, and also how I’ve shipped multiple other production systems.\\n\\n**The golden model:**  \\nKeep yourself in the place of the agent. Imagine you are that agent.\\n\\nIt might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.\\n\\nPut yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?\\n\\nNow, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.\\n\\n## Conclusion\\n\\nHopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.\\n\\nIf you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.\\n\\nThere is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions \\\"AI agent\\\" in conversation, you will know not only what it is but also how it thinks and works.\\n\\nIf you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens.\",\"content\":\"\u003ch2 id=\\\"heading-motivation-why-you-should-care\\\"\u003eMotivation: Why You Should Care\u003c/h2\u003e\\n\u003cp\u003eNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like \u003ca target=\\\"_blank\\\" href=\\\"https://patra.app\\\"\u003epatra.app\u003c/a\u003e. While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...\u003c/p\u003e\\n\u003cp\u003eDuring one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”\u003c/p\u003e\\n\u003cp\u003eThey gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.\u003c/p\u003e\\n\u003cp\u003eWell, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.\u003c/p\u003e\\n\u003cp\u003eI promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003eWhat an AI agent is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eHow an AI agent works\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat the heck tools are\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat an orchestration framework is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat memory is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat the types of AI agents are\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eThe mental model for building an AI agent\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWhat a multi-agent framework is\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eBefore we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-the-problem\\\"\u003eThe Problem\u003c/h2\u003e\\n\u003cp\u003eOk, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cblockquote\u003e\\n\u003cp\u003eAn AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention\u003c/p\u003e\\n\u003c/blockquote\u003e\\n\u003cp\u003eYou see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.\u003c/p\u003e\\n\u003cp\u003eIf I ask, \\\"What is an LLM?\\\" we get a much more acceptable answer:\u003c/p\u003e\\n\u003cblockquote\u003e\\n\u003cp\u003eA Large Language Model (LLM) is \u003cstrong\u003ea type of AI model, specifically a deep learning model, trained on massive amounts of text data.\u003c/strong\u003e\u003c/p\u003e\\n\u003c/blockquote\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eNotice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-defining-ai-agent\\\"\u003eDefining AI Agent\u003c/h1\u003e\\n\u003cp\u003eLet’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:\u003c/p\u003e\\n\u003cp\u003eAgents are \u003cstrong\u003esoftware systems\u003c/strong\u003e where \u003cstrong\u003eLLMs\u003c/strong\u003e use reasoning to control the flow of execution, \u003cstrong\u003edynamically\u003c/strong\u003e choosing which \u003cstrong\u003etools\u003c/strong\u003e to use and determining each step required to reach a \u003cstrong\u003egoal\u003c/strong\u003e.\u003c/p\u003e\\n\u003cp\u003eThat’s a mouthful. Let’s break down each part so we can actually understand it.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-agents-are-software-systems\\\"\u003e\u003cstrong\u003eAgents are Software Systems\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eThis is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003eLLMs\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eWorking Memory or state\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003ePrompts\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eTools\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eOrchestration Layer\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eYou already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.\u003c/p\u003e\\n\u003cp\u003eIn our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-flow-of-execution\\\"\u003e\u003cstrong\u003eDynamic\u003c/strong\u003e Flow of Execution\u003c/h2\u003e\\n\u003cp\u003eTo execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.\u003c/p\u003e\\n\u003cp\u003eLet’s look at an example.\u003c/p\u003e\\n\u003cp\u003eSuppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.\u003c/p\u003e\\n\u003cp\u003eNotice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.\u003c/p\u003e\\n\u003cp\u003eWe won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cdiv data-node-type=\\\"callout\\\"\u003e\\n\u003cdiv data-node-type=\\\"callout-emoji\\\"\u003e💡\u003c/div\u003e\\n\u003cdiv data-node-type=\\\"callout-text\\\"\u003eYou may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading\u003c/div\u003e\\n\u003c/div\u003e\\n\\n\u003cp\u003eNotice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# Build workflow\u003c/span\u003e\\nworkflow = StateGraph(SupportTicketState)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Add nodes\u003c/span\u003e\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e, classify_ticket)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e, generate_initial_response)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e, check_escalation_needed)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e, escalate_ticket)\\nworkflow.add_node(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e, resolve_ticket)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Add edges\u003c/span\u003e\\nworkflow.add_edge(START, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"classify_ticket\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"generate_initial_response\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# Conditional edges for escalation\u003c/span\u003e\\nworkflow.add_conditional_edges(\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"check_escalation\\\"\u003c/span\u003e,\\n    should_escalate,\\n    {\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e,\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e\\n    }\\n)\\n\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"escalate_ticket\\\"\u003c/span\u003e, END)\\nworkflow.add_edge(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"resolve_ticket\\\"\u003c/span\u003e, END)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eEntire code for this is available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eThis is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.\u003c/p\u003e\\n\u003cp\u003eIn the example above, the value of should_escalate, which comes from the check_escalation node, is used to determine which part of the graph or “workflow” we go to next.\u003c/p\u003e\\n\u003cp\u003eA node like \\\"resolve ticket\\\" will look something like this:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eresolve_ticket\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003estate: SupportTicketState\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Resolve the ticket and generate a final customer-facing response.\\\"\\\"\\\"\u003c/span\u003e\\n    call_resolution_api(state[\u003cspan class=\\\"hljs-string\\\"\u003e'ticket_id'\u003c/span\u003e])\\n    prompt = \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"\\n    Generate a customer-facing response to inform them their ticket is resolved.\\n\\n    Ticket ID: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'ticket_id'\u003c/span\u003e]}\u003c/span\u003e\\n    Customer: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'customer_name'\u003c/span\u003e]}\u003c/span\u003e\\n    Issue: \u003cspan class=\\\"hljs-subst\\\"\u003e{state[\u003cspan class=\\\"hljs-string\\\"\u003e'issue_description'\u003c/span\u003e]}\u003c/span\u003e\\n\\n    The response should:\\n    1. State clearly that the issue has been resolved.\\n    2. Briefly explain the solution.\\n    3. Thank the customer for their patience.\\n    4. Ask if they need any further assistance.\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    response = llm.invoke(prompt)\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e {\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"final_response\\\"\u003c/span\u003e: response.content,\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"status\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Resolved\\\"\u003c/span\u003e\\n    }\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eNotice how we first call the resolution API and then run the prompt to generate a response for the ticket.\u003c/p\u003e\\n\u003cp\u003eYou might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.\u003c/p\u003e\\n\u003cp\u003eLet’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eBy the way, ReAct stands for \\\"Reasoning and Acting.\\\"\u003c/strong\u003e\u003cbr /\u003eIt is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eIn our example:\u003c/p\u003e\\n\u003cp\u003eThe \u003cstrong\u003etask\u003c/strong\u003e is to either resolve or escalate the ticket and give back a response.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eAct\u003c/strong\u003e stage, the agent can use a tool to classify, escalate, or resolve the ticket.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eObserve\u003c/strong\u003e stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.\u003c/p\u003e\\n\u003cp\u003eIn the \u003cstrong\u003eReasoning\u003c/strong\u003e stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.\u003c/p\u003e\\n\u003cp\u003eNotice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.\u003c/p\u003e\\n\u003cp\u003eTo understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eNow getting to the code:\u003c/strong\u003e\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# --- Agent Definition ---\u003c/span\u003e\\nsupport_agent = Agent(\\n    role=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Senior Customer Support Specialist\\\"\u003c/span\u003e,\\n    goal=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses.\\\"\u003c/span\u003e,\\n    backstory=(\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a seasoned support specialist with a knack for understanding customer needs. \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You excel at identifying the root cause of issues, communicating clearly, and \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"knowing precisely when a problem needs to be escalated to a senior team member. \\\"\u003c/span\u003e\\n        \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality.\\\"\u003c/span\u003e\\n    ),\\n    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],\\n    llm=llm,\\n    verbose=\u003cspan class=\\\"hljs-literal\\\"\u003eTrue\u003c/span\u003e,\\n    allow_delegation=\u003cspan class=\\\"hljs-literal\\\"\u003eFalse\u003c/span\u003e\\n)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# --- Task Definition ---\u003c/span\u003e\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003ecreate_ticket_processing_task\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eagent, ticket_id, customer_name, issue_description\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e Task(\\n        description=\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"\\n        Process customer support ticket with the following details:\\n        - Ticket ID: \u003cspan class=\\\"hljs-subst\\\"\u003e{ticket_id}\u003c/span\u003e\\n        - Customer Name: \u003cspan class=\\\"hljs-subst\\\"\u003e{customer_name}\u003c/span\u003e\\n        - Issue Description: \u003cspan class=\\\"hljs-subst\\\"\u003e{issue_description}\u003c/span\u003e\\n\\n        Follow this exact workflow:\\n        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).\\n        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.\\n        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.\\n        4.  **Use a Tool**:\\n            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.\\n            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.\\n        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.\\n\\n        Your final output must be a comprehensive report in markdown format that includes:\\n        - The classified priority and category.\\n        - The initial response.\\n        - The action taken with the corresponding tool.\\n        - The final customer-facing response.\\n        \\\"\\\"\\\"\u003c/span\u003e,\\n        agent=agent,\\n        expected_output=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response.\\\"\u003c/span\u003e\\n    )\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eEntire code for this available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eOk, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThe Little Trick We Play\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eBut here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eIsn’t That Just a Static Workflow?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWell, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.\u003c/p\u003e\\n\u003cp\u003eFor example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eReal World Example\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWhen I was creating \u003ca target=\\\"_blank\\\" href=\\\"http://patra.app\\\"\u003epatra.app\u003c/a\u003e\u003ca target=\\\"_blank\\\" href=\\\"https://patra.app\\\"\u003e,\u003c/a\u003e which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.\u003c/p\u003e\\n\u003cp\u003eExample:\u003cbr /\u003eCreate me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.\u003c/p\u003e\\n\u003cp\u003eImagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.\u003c/p\u003e\\n\u003cp\u003eNow imagine an action like:\u003cbr /\u003eCheck my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.\u003c/p\u003e\\n\u003cp\u003eThese are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eDon’t Overcomplicate Simple Things\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eWOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...\u003c/p\u003e\\n\u003cp\u003eStop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?\u003c/p\u003e\\n\u003cp\u003eAgents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.\u003c/p\u003e\\n\u003cp\u003eIn a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhat’s Next?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eSo far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-tools-amp-orchestration-framework\\\"\u003e\u003cstrong\u003eTools \u0026amp;\u003c/strong\u003e orchestration \u003cstrong\u003eFramework\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eLLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eA Simple Example\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eLet’s break this down with a simple program.\u003c/p\u003e\\n\u003cp\u003eSuppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhy Use Tools?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eTools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eDefining a Tool\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eLet’s define how our tool will look:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eadd\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003ea: int, b: int\u003c/span\u003e) -\u0026gt; int:\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Adds two integers together.\\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e a + b\\n\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003esubtract\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003ea: int, b: int\u003c/span\u003e) -\u0026gt; int:\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Subtracts the second integer from the first.\\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e a - b\\n\\nSYSTEM_PROMPT = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"You are a helpful assistant with access to the following functions:\\n\\n1. `add(a: int, b: int)`: Adds two integers together.\\n2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.\\n\\nWhen a user asks a question that can be answered by one of these functions, \\nyou MUST respond ONLY with a JSON object in the following format:\\n{\\n  \\\"function_name\\\": \\\"name_of_the_function\\\",\\n  \\\"arguments\\\": {\\\"arg_name\\\": \\\"value\\\", ...}\\n}\\n\\nDo not include any other text, explanations, or markdown formatting. \\nYour entire response must be only the JSON object.\\n\\nIf you can answer the question without a function, \\njust provide the answer directly in plain text.\\\"\\\"\\\"\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eNotice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can \\\"parse\\\" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhat does \\\"continuing the conversation\\\" mean?\u003c/strong\u003e\u003cbr /\u003eIt’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThat’s basically it.\u003c/strong\u003e\u003cbr /\u003eThis is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eparse_and_execute\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eresponse_content: str\u003c/span\u003e) -\u0026gt; (str, str):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"\\n    Tries to parse the LLM's text response as a JSON function call.\\n    If successful, it executes the function and returns the result and function name.\\n    Otherwise, it returns (None, None).\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003etry\u003c/span\u003e:\\n        call_data = json.loads(response_content)\\n        function_name = call_data.get(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"function_name\\\"\u003c/span\u003e)\\n        function_args = call_data.get(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"arguments\\\"\u003c/span\u003e)\\n\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003enot\u003c/span\u003e all([function_name, isinstance(function_args, dict)]):\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e, \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e \u003cspan class=\\\"hljs-comment\\\"\u003e# Not a valid function call structure\u003c/span\u003e\\n\\n        print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"Parser is executing function: '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e' with args: \u003cspan class=\\\"hljs-subst\\\"\u003e{function_args}\u003c/span\u003e\\\"\u003c/span\u003e)\\n\\n        available_functions = {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"add\\\"\u003c/span\u003e: add, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"subtract\\\"\u003c/span\u003e: subtract}\\n        function_to_call = available_functions.get(function_name)\\n\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e function_to_call:\\n            result = function_to_call(**function_args)\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e str(result), function_name\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003eelse\u003c/span\u003e:\\n            \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"Error: Unknown function '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e'.\\\"\u003c/span\u003e, function_name\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eexcept\u003c/span\u003e (json.JSONDecodeError, TypeError):\\n        \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e, \u003cspan class=\\\"hljs-literal\\\"\u003eNone\u003c/span\u003e \u003cspan class=\\\"hljs-comment\\\"\u003e# Not JSON or not a dictionary\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe entire code for this is available here: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py\\\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eAnd then there’s the \u003cstrong\u003einvoke\u003c/strong\u003e method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-comment\\\"\u003e# --- 5. The Main Invocation Logic ---\u003c/span\u003e\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003einvoke\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003euser_prompt: str\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"\\n    Invokes the LLM, manually handling the function-calling loop.\\n    \\\"\\\"\\\"\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\\n\u003cspan class=\\\"hljs-subst\\\"\u003e{\u003cspan class=\\\"hljs-string\\\"\u003e'='\u003c/span\u003e*\u003cspan class=\\\"hljs-number\\\"\u003e20\u003c/span\u003e}\u003c/span\u003e Invoking for prompt: '\u003cspan class=\\\"hljs-subst\\\"\u003e{user_prompt}\u003c/span\u003e' \u003cspan class=\\\"hljs-subst\\\"\u003e{\u003cspan class=\\\"hljs-string\\\"\u003e'='\u003c/span\u003e*\u003cspan class=\\\"hljs-number\\\"\u003e20\u003c/span\u003e}\u003c/span\u003e\\\"\u003c/span\u003e)\\n\\n    messages = [\\n        {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: SYSTEM_PROMPT},\\n        {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"user\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: user_prompt}\\n    ]\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 1: First LLM Call (without the `tools` parameter) ===\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 1. Sending prompt to LLM to generate function call JSON... ---\\\"\u003c/span\u003e)\\n    response = client.chat.completions.create(\\n        model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-4o\\\"\u003c/span\u003e,\\n        messages=messages\\n    )\\n\\n    response_message = response.choices[\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e].message\\n    messages.append({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"assistant\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: response_message.content})\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 2: Manually parse the response for a function call ===\u003c/span\u003e\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 2. Manually parsing response for a function call... ---\\\"\u003c/span\u003e)\\n    function_output, function_name = parse_and_execute(response_message.content)\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eif\u003c/span\u003e function_output:\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# We got a result from our function, so we continue the conversation\u003c/span\u003e\\n        messages.append({\\n            \u003cspan class=\\\"hljs-string\\\"\u003e\\\"role\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"user\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-comment\\\"\u003e# We provide the function result back as the user\u003c/span\u003e\\n            \u003cspan class=\\\"hljs-string\\\"\u003e\\\"content\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"I have called the function '\u003cspan class=\\\"hljs-subst\\\"\u003e{function_name}\u003c/span\u003e'. The result is: \u003cspan class=\\\"hljs-subst\\\"\u003e{function_output}\u003c/span\u003e\\\"\u003c/span\u003e\\n        })\\n\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# === Step 3: Second LLM Call with function results ===\u003c/span\u003e\\n        print(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n--- 3. Sending function output back to LLM... ---\\\"\u003c/span\u003e)\\n\\n        second_response = client.chat.completions.create(\\n            model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-4o\\\"\u003c/span\u003e,\\n            messages=messages\\n        )\\n        final_response = second_response.choices[\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e].message.content\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003eelse\u003c/span\u003e:\\n        \u003cspan class=\\\"hljs-comment\\\"\u003e# If parsing failed, the LLM's first response is the final answer\u003c/span\u003e\\n        final_response = response_message.content\\n\\n    print(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\\n--- Final Answer ---\\\"\u003c/span\u003e)\\n    print(final_response)\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e final_response\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eYou know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.\u003c/p\u003e\\n\u003cp\u003eToday, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: \u003ca target=\\\"_blank\\\" href=\\\"https://platform.openai.com/docs/quickstart?api-mode=responses\\\"\u003ehttps://platform.openai.com/docs/quickstart?api-mode=responses\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eExploring Popular Agent Frameworks\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eSome of the popular Agent frameworks includes -\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCrewAI\u003c/strong\u003e – A Python framework for coordinating multiple agents as a team.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/crewAIInc/crewAI\\\"\u003eCrewAI on Github\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eOpenAI Agents SDK\u003c/strong\u003e – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://openai.github.io/openai-agents-python/\\\"\u003eOpenAI Agents SDK (Python)\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eMetaGPT\u003c/strong\u003e – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.\u003cbr /\u003e  Read more: \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/FoundationAgents/MetaGPT\\\"\u003eMetaGPT on GitHub\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eNow that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWait, Persona?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eThat’s new. Why does an agent need a persona? What is a persona, anyway?\u003c/p\u003e\\n\u003cp\u003eIf you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eUp Next: Multi-Agent Systems\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eIn the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-multi-agent-system\\\"\u003eMulti Agent System\u003c/h1\u003e\\n\u003cp\u003eNow that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eRemember, agents are just:\u003c/strong\u003e\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cp\u003eAn LLM with access to tools\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eA set of prompts (like persona, goal, etc.)\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eMemory (which we’ll talk about later)\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003eAll built using an orchestration framework so everything works together\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eBut what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png\\\" alt class=\\\"image--center mx-auto\\\" /\u003e\u003c/p\u003e\\n\u003cp\u003eSource: \u003ca target=\\\"_blank\\\" href=\\\"https://docs.crewai.com/concepts/collaboration\\\"\u003eCrewAI Collaboration Concepts\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eAll the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWhy Use Multi-Agent Systems?\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eMulti-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their \u003ca target=\\\"_blank\\\" href=\\\"https://www.anthropic.com/engineering/built-multi-agent-research-system\\\"\u003eblog post\u003c/a\u003e on multi-agent systems, is that you can use more tokens (so the system can \\\"think more\\\") when tackling a complex problem.\u003c/p\u003e\\n\u003cp\u003eIn the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.\u003c/p\u003e\\n\u003cp\u003eYou can read about different types of multi agent systems later \u003ca target=\\\"_blank\\\" href=\\\"https://langchain-ai.github.io/langgraph/concepts/multi_agent/\\\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eWarning:\u003c/strong\u003e As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-memory\\\"\u003eMemory\u003c/h1\u003e\\n\u003cp\u003eWe have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.\u003c/p\u003e\\n\u003cp\u003eIn many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.\u003c/p\u003e\\n\u003cp\u003eThere are two forms of memory that an AI agent can potentially have, much like humans do:\u003c/p\u003e\\n\u003ch3 id=\\\"heading-short-term-memory\\\"\u003e\u003cstrong\u003eShort Term Memory\u003c/strong\u003e\u003c/h3\u003e\\n\u003cp\u003eShort term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.\u003c/p\u003e\\n\u003cp\u003eHere’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:\u003c/p\u003e\\n\u003cp\u003eM1: User: perform 10 + 20 + 30 + 40 + 50\u003cbr /\u003eM2: LLM: \u003cem\u003eTool call, 10 + 20\u003c/em\u003e\u003cbr /\u003eM3: User: Output 30\u003cbr /\u003eM4: LLM: \u003cem\u003eCurrent answer is 30, let’s proceed. Tool call 30 + 30\u003c/em\u003e\u003cbr /\u003eM5: User: Output 60\u003cbr /\u003eM6: LLM: \u003cem\u003eCurrent answer is 60, let’s proceed. Tool call 60 + 40\u003c/em\u003e\u003c/p\u003e\\n\u003cp\u003eAt this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:\u003c/p\u003e\\n\u003cp\u003eM1: User: perform 10 + 20 + 30 + 40 + 50\u003cbr /\u003eM2’: User: Output of 10 + 20 + 30 is 60, proceed further.\u003cbr /\u003eM6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40\u003c/p\u003e\\n\u003cp\u003eNotice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.\u003c/p\u003e\\n\u003cp\u003eSometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.\u003c/p\u003e\\n\u003cp\u003eWe also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.\u003cbr /\u003e\u003cstrong\u003eRAISE stands for Reasoning and Acting through Scratchpad and Examples.\u003c/strong\u003e The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.\u003c/p\u003e\\n\u003cp\u003eRead the paper that introduced RAISE framework here: \u003ca target=\\\"_blank\\\" href=\\\"https://arxiv.org/pdf/2401.02777\\\"\u003ehttps://arxiv.org/pdf/2401.02777\u003c/a\u003e\u003c/p\u003e\\n\u003ch3 id=\\\"heading-long-term-memory\\\"\u003e\u003cstrong\u003eLong Term Memory\u003c/strong\u003e\u003c/h3\u003e\\n\u003cp\u003eLong-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.\u003c/p\u003e\\n\u003cp\u003eIn our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.\u003c/p\u003e\\n\u003cp\u003eNotice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.\u003c/p\u003e\\n\u003ch1 id=\\\"heading-mental-model-to-work-with-agents\\\"\u003eMental Model to work with agents\u003c/h1\u003e\\n\u003cp\u003eThat’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made \u003ca target=\\\"_blank\\\" href=\\\"http://patra.app\\\"\u003epatra.app\u003c/a\u003e work reliably, and also how I’ve shipped multiple other production systems.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eThe golden model:\u003c/strong\u003e\u003cbr /\u003eKeep yourself in the place of the agent. Imagine you are that agent.\u003c/p\u003e\\n\u003cp\u003eIt might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.\u003c/p\u003e\\n\u003cp\u003ePut yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?\u003c/p\u003e\\n\u003cp\u003eNow, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-conclusion\\\"\u003eConclusion\u003c/h2\u003e\\n\u003cp\u003eHopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.\u003c/p\u003e\\n\u003cp\u003eIf you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.\u003c/p\u003e\\n\u003cp\u003eThere is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions \\\"AI agent\\\" in conversation, you will know not only what it is but also how it thinks and works.\u003c/p\u003e\\n\u003cp\u003eIf you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens.\u003c/p\u003e\\n\",\"cuid\":\"cmc7j8wli000102l4hfte2pxh\",\"views\":611,\"title\":\"AI Agents Under The Hood\",\"slug\":\"ai-agents-under-the-hood\",\"dateAdded\":\"2025-06-22T10:36:29.574Z\",\"dateUpdated\":\"2025-06-23T06:56:54.444Z\",\"type\":\"story\",\"isCoverImagePortrait\":false,\"brief\":\"Motivation: Why You Should Care\\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like patra.app. While building those and reading through a lot of resources, I learned how AI agents actually wor...\",\"isFollowing\":false,\"totalReactions\":4,\"totalReactionsByCurrentUser\":0,\"series\":null,\"isPinnedToBlog\":false,\"readTime\":23,\"sB\":false,\"isAMA\":false,\"subtitle\":\"Simplifying AI Agents - What They Are and How They Work\",\"isPartOfSeries\":false,\"hasTags\":true,\"ogImage\":\"\",\"metaTitle\":\"\",\"metaDescription\":\"\",\"isRepublished\":false,\"autoPublishedFromRSS\":false,\"responses\":[],\"isFeatured\":false,\"hasLatex\":false,\"stickCoverToBottom\":true,\"hideBadges\":false,\"badges\":[],\"isDelisted\":false,\"audioUrls\":{},\"disableComments\":false,\"enableToc\":false,\"toc\":[],\"noIndex\":false}","legacySeriesJSON":null,"headProps":{"title":"AI Agents Under The Hood","description":"Simplifying AI Agents - What They Are and How They Work","author":{"name":"Manthan Surkar","username":"surkar"},"links":[{"rel":"canonical","href":"https://blog.surkar.in/ai-agents-under-the-hood"}],"pageType":"article","bannerType":"large","ogSiteName":"Manthan Surkar","url":"https://blog.surkar.in/ai-agents-under-the-hood","ogImage":"https://blog.surkar.in/api/og/post?og=eyJ0aXRsZSI6IkFJJTIwQWdlbnRzJTIwVW5kZXIlMjBUaGUlMjBIb29kIiwiYXV0aG9yIjoiTWFudGhhbiUyMFN1cmthciIsImRvbWFpbiI6ImJsb2cuc3Vya2FyLmluIiwicGhvdG8iOiJodHRwczovL2Nkbi5oYXNobm9kZS5jb20vcmVzL2hhc2hub2RlL2ltYWdlL3VwbG9hZC92MTcyMTY2ODg3MTYwNi9lNDIzMWYwNC0yYjkxLTQ0ZDYtYmJiNy1hMzQzNGZkMTQ4MTkuanBlZyIsInJlYWRUaW1lIjoyMywicmVhY3Rpb25zIjo0LCJjb21tZW50cyI6MX0=","twitterImage":"https://blog.surkar.in/api/og/post?og=eyJ0aXRsZSI6IkFJJTIwQWdlbnRzJTIwVW5kZXIlMjBUaGUlMjBIb29kIiwiYXV0aG9yIjoiTWFudGhhbiUyMFN1cmthciIsImRvbWFpbiI6ImJsb2cuc3Vya2FyLmluIiwicGhvdG8iOiJodHRwczovL2Nkbi5oYXNobm9kZS5jb20vcmVzL2hhc2hub2RlL2ltYWdlL3VwbG9hZC92MTcyMTY2ODg3MTYwNi9lNDIzMWYwNC0yYjkxLTQ0ZDYtYmJiNy1hMzQzNGZkMTQ4MTkuanBlZyIsInJlYWRUaW1lIjoyMywicmVhY3Rpb25zIjo0LCJjb21tZW50cyI6MX0=","twitterHandle":"","monetization":null,"style":{},"customHeadItems":{"customFavicon":"https://cdn.hashnode.com/res/hashnode/image/upload/v1751198022133/1c8c4430-333f-4491-9e43-465d6dcb65c0.png?auto=compress,format\u0026format=webp\u0026fm=png","customTheme":null,"customMeta":null},"hljs":true},"isDarkTheme":false,"headerColor":null,"isBadge":null,"isRecommendations":null,"isHome":null,"currentMenuId":null,"hnmcMode":false,"postCUID":"cmc7j8wli000102l4hfte2pxh","seoSchema":{"@context":"https://schema.org","@type":"NewsArticle","url":"https://blog.surkar.in/ai-agents-under-the-hood","mainEntityOfPage":"https://blog.surkar.in/ai-agents-under-the-hood","headline":"AI Agents Under The Hood","description":"Motivation: Why You Should Care\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like patra.app. While building those and reading through a lot of resources, I learned how AI agents actually wor...","datePublished":"2025-06-22T10:36:29.574Z","dateModified":"2025-06-23T06:56:54.444Z","isAccessibleForFree":true,"author":{"@type":"Person","name":"Manthan Surkar","url":"https://hashnode.com/@surkar"},"publisher":{"@type":"Organization","name":"Manthan Surkar","url":"https://blog.surkar.in","logo":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1559814205701%2Fek9fO-yT0.jpeg%3Fw%3D800%26bm%3Dnormal%26balph%3D100%26txt64%3DTWFudGhhbiBTdXJrYXI%26txtsize%3D42%26txtfit%3Dmax%26txtalign%3Dmiddle%2Ccenter%26txtfont%3DHelvetica%20Neue%2CBold%26txtclr%3D000000%26blend%3Dffffff"}},"publication":{"__typename":"Publication","id":"669e957c19b8bd50367fe79c","url":"https://blog.surkar.in","canonicalURL":"https://blog.surkar.in","urlPattern":"SIMPLE","title":"Manthan Surkar","displayTitle":null,"hasBadges":true,"descriptionSEO":null,"publicMembers":{"totalDocuments":1},"about":null,"features":{"proTeam":{"isEnabled":false},"newsletter":{"isEnabled":true},"viewCount":{"isEnabled":true},"readTime":{"isEnabled":true},"textSelectionSharer":{"isEnabled":true},"customCSS":{"isEnabled":false,"published":null,"draft":null},"gptBotCrawling":{"__typename":"GPTBotCrawlingFeature","isEnabled":false}},"metaTags":null,"ogMetaData":{"image":null},"author":{"__typename":"User","id":"669e9506d4920b5b5b00bcef","name":"Manthan Surkar","username":"surkar","profilePicture":"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg"},"preferences":{"__typename":"Preferences","logo":null,"darkMode":{"__typename":"DarkModePreferences","logo":null,"enabled":false},"navbarItems":[],"enabledPages":{"__typename":"PagesPreferences","badges":false,"newsletter":true,"members":true},"layout":"stacked","disableFooterBranding":false,"isSubscriptionModalDisabled":false},"favicon":"https://cdn.hashnode.com/res/hashnode/image/upload/v1751198022133/1c8c4430-333f-4491-9e43-465d6dcb65c0.png","headerColor":null,"integrations":{"fbPixelID":null,"fathomSiteID":null,"fathomCustomDomainEnabled":null,"fathomCustomDomain":null,"hotjarSiteID":null,"matomoSiteID":null,"matomoURL":null,"gaTrackingID":null,"gTagManagerID":null,"plausibleAnalyticsEnabled":null,"koalaPublicKey":null,"msClarityID":null},"imprintV2":null,"postsCount":{"totalDocuments":4},"isTeam":true,"links":{"twitter":"https://twitter.com/manthan_surkar","instagram":null,"github":"https://github.com/thesmallstar","website":null,"hashnode":"https://hashnode.com/@surkar","youtube":null,"dailydev":null,"linkedin":null,"mastodon":null,"facebook":null,"bluesky":null},"domainInfo":{"__typename":"DomainInfo","hashnodeSubdomain":"surkar","domain":{"__typename":"DomainStatus","host":"blog.surkar.in","ready":true},"wwwPrefixedDomain":null},"redirectionRules":[],"totalRecommendedPublications":0,"sponsorship":{"content":null,"stripe":null},"allowContributorEdits":true,"rssImport":null,"post":{"id":"6857dcad0f01cc2215fffd04","cuid":"cmc7j8wli000102l4hfte2pxh","title":"AI Agents Under The Hood","subtitle":"Simplifying AI Agents - What They Are and How They Work","slug":"ai-agents-under-the-hood","brief":"Motivation: Why You Should Care\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like patra.app. While building those and reading through a lot of resources, I learned how AI agents actually wor...","featured":false,"publishedAt":"2025-06-22T10:36:29.574Z","updatedAt":"2025-06-23T06:56:54.444Z","author":{"__typename":"User","id":"669e9506d4920b5b5b00bcef","name":"Manthan Surkar","username":"surkar","deactivated":false,"profilePicture":"https://cdn.hashnode.com/res/hashnode/image/upload/v1721668871606/e4231f04-2b91-44d6-bbb7-a3434fd14819.jpeg","bio":{"html":""},"socialMediaLinks":{"website":"https://surkar.in","github":"https://github.com/thesmallstar","twitter":"","facebook":"","stackoverflow":"","linkedin":"https://www.linkedin.com/in/manthansurkar/"}},"coAuthors":[],"seo":{"title":null,"description":null,"shouldNotIndex":false},"coverImage":null,"responseCount":1,"reactionCount":4,"replyCount":0,"content":{"html":"\u003ch2 id=\"heading-motivation-why-you-should-care\"\u003eMotivation: Why You Should Care\u003c/h2\u003e\n\u003cp\u003eNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like \u003ca target=\"_blank\" href=\"https://patra.app\"\u003epatra.app\u003c/a\u003e. While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...\u003c/p\u003e\n\u003cp\u003eDuring one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”\u003c/p\u003e\n\u003cp\u003eThey gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.\u003c/p\u003e\n\u003cp\u003eWell, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.\u003c/p\u003e\n\u003cp\u003eI promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003eWhat an AI agent is\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eHow an AI agent works\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eWhat the heck tools are\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eWhat an orchestration framework is\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eWhat memory is\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eWhat the types of AI agents are\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eThe mental model for building an AI agent\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eWhat a multi-agent framework is\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBefore we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.\u003c/p\u003e\n\u003ch2 id=\"heading-the-problem\"\u003eThe Problem\u003c/h2\u003e\n\u003cp\u003eOk, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png\" alt class=\"image--center mx-auto\" /\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAn AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eYou see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.\u003c/p\u003e\n\u003cp\u003eIf I ask, \"What is an LLM?\" we get a much more acceptable answer:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA Large Language Model (LLM) is \u003cstrong\u003ea type of AI model, specifically a deep learning model, trained on massive amounts of text data.\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png\" alt class=\"image--center mx-auto\" /\u003e\u003c/p\u003e\n\u003cp\u003eNotice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.\u003c/p\u003e\n\u003ch1 id=\"heading-defining-ai-agent\"\u003eDefining AI Agent\u003c/h1\u003e\n\u003cp\u003eLet’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:\u003c/p\u003e\n\u003cp\u003eAgents are \u003cstrong\u003esoftware systems\u003c/strong\u003e where \u003cstrong\u003eLLMs\u003c/strong\u003e use reasoning to control the flow of execution, \u003cstrong\u003edynamically\u003c/strong\u003e choosing which \u003cstrong\u003etools\u003c/strong\u003e to use and determining each step required to reach a \u003cstrong\u003egoal\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eThat’s a mouthful. Let’s break down each part so we can actually understand it.\u003c/p\u003e\n\u003ch2 id=\"heading-agents-are-software-systems\"\u003e\u003cstrong\u003eAgents are Software Systems\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eThis is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003eLLMs\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eWorking Memory or state\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003ePrompts\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eTools\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eOrchestration Layer\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eYou already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.\u003c/p\u003e\n\u003cp\u003eIn our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.\u003c/p\u003e\n\u003ch2 id=\"heading-dynamic-flow-of-execution\"\u003e\u003cstrong\u003eDynamic\u003c/strong\u003e Flow of Execution\u003c/h2\u003e\n\u003cp\u003eTo execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.\u003c/p\u003e\n\u003cp\u003eLet’s look at an example.\u003c/p\u003e\n\u003cp\u003eSuppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.\u003c/p\u003e\n\u003cp\u003eNotice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.\u003c/p\u003e\n\u003cp\u003eWe won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png\" alt class=\"image--center mx-auto\" /\u003e\u003c/p\u003e\n\u003cdiv data-node-type=\"callout\"\u003e\n\u003cdiv data-node-type=\"callout-emoji\"\u003e💡\u003c/div\u003e\n\u003cdiv data-node-type=\"callout-text\"\u003eYou may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003eNotice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# Build workflow\u003c/span\u003e\nworkflow = StateGraph(SupportTicketState)\n\n\u003cspan class=\"hljs-comment\"\u003e# Add nodes\u003c/span\u003e\nworkflow.add_node(\u003cspan class=\"hljs-string\"\u003e\"classify_ticket\"\u003c/span\u003e, classify_ticket)\nworkflow.add_node(\u003cspan class=\"hljs-string\"\u003e\"generate_initial_response\"\u003c/span\u003e, generate_initial_response)\nworkflow.add_node(\u003cspan class=\"hljs-string\"\u003e\"check_escalation\"\u003c/span\u003e, check_escalation_needed)\nworkflow.add_node(\u003cspan class=\"hljs-string\"\u003e\"escalate_ticket\"\u003c/span\u003e, escalate_ticket)\nworkflow.add_node(\u003cspan class=\"hljs-string\"\u003e\"resolve_ticket\"\u003c/span\u003e, resolve_ticket)\n\n\u003cspan class=\"hljs-comment\"\u003e# Add edges\u003c/span\u003e\nworkflow.add_edge(START, \u003cspan class=\"hljs-string\"\u003e\"classify_ticket\"\u003c/span\u003e)\nworkflow.add_edge(\u003cspan class=\"hljs-string\"\u003e\"classify_ticket\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"generate_initial_response\"\u003c/span\u003e)\nworkflow.add_edge(\u003cspan class=\"hljs-string\"\u003e\"generate_initial_response\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"check_escalation\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# Conditional edges for escalation\u003c/span\u003e\nworkflow.add_conditional_edges(\n    \u003cspan class=\"hljs-string\"\u003e\"check_escalation\"\u003c/span\u003e,\n    should_escalate,\n    {\n        \u003cspan class=\"hljs-string\"\u003e\"escalate\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"escalate_ticket\"\u003c/span\u003e,\n        \u003cspan class=\"hljs-string\"\u003e\"resolve\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"resolve_ticket\"\u003c/span\u003e\n    }\n)\n\nworkflow.add_edge(\u003cspan class=\"hljs-string\"\u003e\"escalate_ticket\"\u003c/span\u003e, END)\nworkflow.add_edge(\u003cspan class=\"hljs-string\"\u003e\"resolve_ticket\"\u003c/span\u003e, END)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEntire code for this is available here: \u003ca target=\"_blank\" href=\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.\u003c/p\u003e\n\u003cp\u003eIn the example above, the value of should_escalate, which comes from the check_escalation node, is used to determine which part of the graph or “workflow” we go to next.\u003c/p\u003e\n\u003cp\u003eA node like \"resolve ticket\" will look something like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003eresolve_ticket\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003estate: SupportTicketState\u003c/span\u003e):\u003c/span\u003e\n    \u003cspan class=\"hljs-string\"\u003e\"\"\"Resolve the ticket and generate a final customer-facing response.\"\"\"\u003c/span\u003e\n    call_resolution_api(state[\u003cspan class=\"hljs-string\"\u003e'ticket_id'\u003c/span\u003e])\n    prompt = \u003cspan class=\"hljs-string\"\u003ef\"\"\"\n    Generate a customer-facing response to inform them their ticket is resolved.\n\n    Ticket ID: \u003cspan class=\"hljs-subst\"\u003e{state[\u003cspan class=\"hljs-string\"\u003e'ticket_id'\u003c/span\u003e]}\u003c/span\u003e\n    Customer: \u003cspan class=\"hljs-subst\"\u003e{state[\u003cspan class=\"hljs-string\"\u003e'customer_name'\u003c/span\u003e]}\u003c/span\u003e\n    Issue: \u003cspan class=\"hljs-subst\"\u003e{state[\u003cspan class=\"hljs-string\"\u003e'issue_description'\u003c/span\u003e]}\u003c/span\u003e\n\n    The response should:\n    1. State clearly that the issue has been resolved.\n    2. Briefly explain the solution.\n    3. Thank the customer for their patience.\n    4. Ask if they need any further assistance.\n    \"\"\"\u003c/span\u003e\n    response = llm.invoke(prompt)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e {\n        \u003cspan class=\"hljs-string\"\u003e\"final_response\"\u003c/span\u003e: response.content,\n        \u003cspan class=\"hljs-string\"\u003e\"status\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Resolved\"\u003c/span\u003e\n    }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNotice how we first call the resolution API and then run the prompt to generate a response for the ticket.\u003c/p\u003e\n\u003cp\u003eYou might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.\u003c/p\u003e\n\u003cp\u003eLet’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBy the way, ReAct stands for \"Reasoning and Acting.\"\u003c/strong\u003e\u003cbr /\u003eIt is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png\" alt class=\"image--center mx-auto\" /\u003e\u003c/p\u003e\n\u003cp\u003eIn our example:\u003c/p\u003e\n\u003cp\u003eThe \u003cstrong\u003etask\u003c/strong\u003e is to either resolve or escalate the ticket and give back a response.\u003c/p\u003e\n\u003cp\u003eIn the \u003cstrong\u003eAct\u003c/strong\u003e stage, the agent can use a tool to classify, escalate, or resolve the ticket.\u003c/p\u003e\n\u003cp\u003eIn the \u003cstrong\u003eObserve\u003c/strong\u003e stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.\u003c/p\u003e\n\u003cp\u003eIn the \u003cstrong\u003eReasoning\u003c/strong\u003e stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.\u003c/p\u003e\n\u003cp\u003eNotice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.\u003c/p\u003e\n\u003cp\u003eTo understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNow getting to the code:\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# --- Agent Definition ---\u003c/span\u003e\nsupport_agent = Agent(\n    role=\u003cspan class=\"hljs-string\"\u003e\"Senior Customer Support Specialist\"\u003c/span\u003e,\n    goal=\u003cspan class=\"hljs-string\"\u003e\"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses.\"\u003c/span\u003e,\n    backstory=(\n        \u003cspan class=\"hljs-string\"\u003e\"You are a seasoned support specialist with a knack for understanding customer needs. \"\u003c/span\u003e\n        \u003cspan class=\"hljs-string\"\u003e\"You excel at identifying the root cause of issues, communicating clearly, and \"\u003c/span\u003e\n        \u003cspan class=\"hljs-string\"\u003e\"knowing precisely when a problem needs to be escalated to a senior team member. \"\u003c/span\u003e\n        \u003cspan class=\"hljs-string\"\u003e\"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality.\"\u003c/span\u003e\n    ),\n    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],\n    llm=llm,\n    verbose=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n    allow_delegation=\u003cspan class=\"hljs-literal\"\u003eFalse\u003c/span\u003e\n)\n\n\u003cspan class=\"hljs-comment\"\u003e# --- Task Definition ---\u003c/span\u003e\n\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003ecreate_ticket_processing_task\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eagent, ticket_id, customer_name, issue_description\u003c/span\u003e):\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e Task(\n        description=\u003cspan class=\"hljs-string\"\u003ef\"\"\"\n        Process customer support ticket with the following details:\n        - Ticket ID: \u003cspan class=\"hljs-subst\"\u003e{ticket_id}\u003c/span\u003e\n        - Customer Name: \u003cspan class=\"hljs-subst\"\u003e{customer_name}\u003c/span\u003e\n        - Issue Description: \u003cspan class=\"hljs-subst\"\u003e{issue_description}\u003c/span\u003e\n\n        Follow this exact workflow:\n        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).\n        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.\n        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.\n        4.  **Use a Tool**:\n            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.\n            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.\n        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.\n\n        Your final output must be a comprehensive report in markdown format that includes:\n        - The classified priority and category.\n        - The initial response.\n        - The action taken with the corresponding tool.\n        - The final customer-facing response.\n        \"\"\"\u003c/span\u003e,\n        agent=agent,\n        expected_output=\u003cspan class=\"hljs-string\"\u003e\"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response.\"\u003c/span\u003e\n    )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEntire code for this available here: \u003ca target=\"_blank\" href=\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOk, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThe Little Trick We Play\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eBut here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIsn’t That Just a Static Workflow?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWell, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.\u003c/p\u003e\n\u003cp\u003eFor example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReal World Example\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWhen I was creating \u003ca target=\"_blank\" href=\"http://patra.app\"\u003epatra.app\u003c/a\u003e\u003ca target=\"_blank\" href=\"https://patra.app\"\u003e,\u003c/a\u003e which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.\u003c/p\u003e\n\u003cp\u003eExample:\u003cbr /\u003eCreate me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.\u003c/p\u003e\n\u003cp\u003eImagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.\u003c/p\u003e\n\u003cp\u003eNow imagine an action like:\u003cbr /\u003eCheck my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.\u003c/p\u003e\n\u003cp\u003eThese are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDon’t Overcomplicate Simple Things\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...\u003c/p\u003e\n\u003cp\u003eStop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?\u003c/p\u003e\n\u003cp\u003eAgents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.\u003c/p\u003e\n\u003cp\u003eIn a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png\" alt class=\"image--center mx-auto\" /\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWhat’s Next?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eSo far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.\u003c/p\u003e\n\u003ch2 id=\"heading-tools-amp-orchestration-framework\"\u003e\u003cstrong\u003eTools \u0026amp;\u003c/strong\u003e orchestration \u003cstrong\u003eFramework\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eLLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eA Simple Example\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLet’s break this down with a simple program.\u003c/p\u003e\n\u003cp\u003eSuppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWhy Use Tools?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eTools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDefining a Tool\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLet’s define how our tool will look:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003eadd\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003ea: int, b: int\u003c/span\u003e) -\u0026gt; int:\u003c/span\u003e\n    \u003cspan class=\"hljs-string\"\u003e\"\"\"Adds two integers together.\"\"\"\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e a + b\n\n\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003esubtract\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003ea: int, b: int\u003c/span\u003e) -\u0026gt; int:\u003c/span\u003e\n    \u003cspan class=\"hljs-string\"\u003e\"\"\"Subtracts the second integer from the first.\"\"\"\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e a - b\n\nSYSTEM_PROMPT = \u003cspan class=\"hljs-string\"\u003e\"\"\"You are a helpful assistant with access to the following functions:\n\n1. `add(a: int, b: int)`: Adds two integers together.\n2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.\n\nWhen a user asks a question that can be answered by one of these functions, \nyou MUST respond ONLY with a JSON object in the following format:\n{\n  \"function_name\": \"name_of_the_function\",\n  \"arguments\": {\"arg_name\": \"value\", ...}\n}\n\nDo not include any other text, explanations, or markdown formatting. \nYour entire response must be only the JSON object.\n\nIf you can answer the question without a function, \njust provide the answer directly in plain text.\"\"\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNotice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can \"parse\" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWhat does \"continuing the conversation\" mean?\u003c/strong\u003e\u003cbr /\u003eIt’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThat’s basically it.\u003c/strong\u003e\u003cbr /\u003eThis is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003eparse_and_execute\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eresponse_content: str\u003c/span\u003e) -\u0026gt; (str, str):\u003c/span\u003e\n    \u003cspan class=\"hljs-string\"\u003e\"\"\"\n    Tries to parse the LLM's text response as a JSON function call.\n    If successful, it executes the function and returns the result and function name.\n    Otherwise, it returns (None, None).\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003etry\u003c/span\u003e:\n        call_data = json.loads(response_content)\n        function_name = call_data.get(\u003cspan class=\"hljs-string\"\u003e\"function_name\"\u003c/span\u003e)\n        function_args = call_data.get(\u003cspan class=\"hljs-string\"\u003e\"arguments\"\u003c/span\u003e)\n\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003enot\u003c/span\u003e all([function_name, isinstance(function_args, dict)]):\n            \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e, \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e \u003cspan class=\"hljs-comment\"\u003e# Not a valid function call structure\u003c/span\u003e\n\n        print(\u003cspan class=\"hljs-string\"\u003ef\"Parser is executing function: '\u003cspan class=\"hljs-subst\"\u003e{function_name}\u003c/span\u003e' with args: \u003cspan class=\"hljs-subst\"\u003e{function_args}\u003c/span\u003e\"\u003c/span\u003e)\n\n        available_functions = {\u003cspan class=\"hljs-string\"\u003e\"add\"\u003c/span\u003e: add, \u003cspan class=\"hljs-string\"\u003e\"subtract\"\u003c/span\u003e: subtract}\n        function_to_call = available_functions.get(function_name)\n\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e function_to_call:\n            result = function_to_call(**function_args)\n            \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e str(result), function_name\n        \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e:\n            \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003ef\"Error: Unknown function '\u003cspan class=\"hljs-subst\"\u003e{function_name}\u003c/span\u003e'.\"\u003c/span\u003e, function_name\n\n    \u003cspan class=\"hljs-keyword\"\u003eexcept\u003c/span\u003e (json.JSONDecodeError, TypeError):\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e, \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e \u003cspan class=\"hljs-comment\"\u003e# Not JSON or not a dictionary\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe entire code for this is available here: \u003ca target=\"_blank\" href=\"https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py\"\u003ehttps://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAnd then there’s the \u003cstrong\u003einvoke\u003c/strong\u003e method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# --- 5. The Main Invocation Logic ---\u003c/span\u003e\n\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003einvoke\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003euser_prompt: str\u003c/span\u003e):\u003c/span\u003e\n    \u003cspan class=\"hljs-string\"\u003e\"\"\"\n    Invokes the LLM, manually handling the function-calling loop.\n    \"\"\"\u003c/span\u003e\n    print(\u003cspan class=\"hljs-string\"\u003ef\"\\n\u003cspan class=\"hljs-subst\"\u003e{\u003cspan class=\"hljs-string\"\u003e'='\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e}\u003c/span\u003e Invoking for prompt: '\u003cspan class=\"hljs-subst\"\u003e{user_prompt}\u003c/span\u003e' \u003cspan class=\"hljs-subst\"\u003e{\u003cspan class=\"hljs-string\"\u003e'='\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e}\u003c/span\u003e\"\u003c/span\u003e)\n\n    messages = [\n        {\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"system\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e: SYSTEM_PROMPT},\n        {\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e: user_prompt}\n    ]\n\n    \u003cspan class=\"hljs-comment\"\u003e# === Step 1: First LLM Call (without the `tools` parameter) ===\u003c/span\u003e\n    print(\u003cspan class=\"hljs-string\"\u003e\"\\n--- 1. Sending prompt to LLM to generate function call JSON... ---\"\u003c/span\u003e)\n    response = client.chat.completions.create(\n        model=\u003cspan class=\"hljs-string\"\u003e\"gpt-4o\"\u003c/span\u003e,\n        messages=messages\n    )\n\n    response_message = response.choices[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].message\n    messages.append({\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"assistant\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e: response_message.content})\n\n    \u003cspan class=\"hljs-comment\"\u003e# === Step 2: Manually parse the response for a function call ===\u003c/span\u003e\n    print(\u003cspan class=\"hljs-string\"\u003e\"\\n--- 2. Manually parsing response for a function call... ---\"\u003c/span\u003e)\n    function_output, function_name = parse_and_execute(response_message.content)\n\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e function_output:\n        \u003cspan class=\"hljs-comment\"\u003e# We got a result from our function, so we continue the conversation\u003c/span\u003e\n        messages.append({\n            \u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e, \u003cspan class=\"hljs-comment\"\u003e# We provide the function result back as the user\u003c/span\u003e\n            \u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003ef\"I have called the function '\u003cspan class=\"hljs-subst\"\u003e{function_name}\u003c/span\u003e'. The result is: \u003cspan class=\"hljs-subst\"\u003e{function_output}\u003c/span\u003e\"\u003c/span\u003e\n        })\n\n        \u003cspan class=\"hljs-comment\"\u003e# === Step 3: Second LLM Call with function results ===\u003c/span\u003e\n        print(\u003cspan class=\"hljs-string\"\u003e\"\\n--- 3. Sending function output back to LLM... ---\"\u003c/span\u003e)\n\n        second_response = client.chat.completions.create(\n            model=\u003cspan class=\"hljs-string\"\u003e\"gpt-4o\"\u003c/span\u003e,\n            messages=messages\n        )\n        final_response = second_response.choices[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].message.content\n    \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e:\n        \u003cspan class=\"hljs-comment\"\u003e# If parsing failed, the LLM's first response is the final answer\u003c/span\u003e\n        final_response = response_message.content\n\n    print(\u003cspan class=\"hljs-string\"\u003ef\"\\n--- Final Answer ---\"\u003c/span\u003e)\n    print(final_response)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e final_response\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.\u003c/p\u003e\n\u003cp\u003eToday, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: \u003ca target=\"_blank\" href=\"https://platform.openai.com/docs/quickstart?api-mode=responses\"\u003ehttps://platform.openai.com/docs/quickstart?api-mode=responses\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eExploring Popular Agent Frameworks\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eSome of the popular Agent frameworks includes -\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCrewAI\u003c/strong\u003e – A Python framework for coordinating multiple agents as a team.\u003cbr /\u003e  Read more: \u003ca target=\"_blank\" href=\"https://github.com/crewAIInc/crewAI\"\u003eCrewAI on Github\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eOpenAI Agents SDK\u003c/strong\u003e – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.\u003cbr /\u003e  Read more: \u003ca target=\"_blank\" href=\"https://openai.github.io/openai-agents-python/\"\u003eOpenAI Agents SDK (Python)\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eMetaGPT\u003c/strong\u003e – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.\u003cbr /\u003e  Read more: \u003ca target=\"_blank\" href=\"https://github.com/FoundationAgents/MetaGPT\"\u003eMetaGPT on GitHub\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWait, Persona?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThat’s new. Why does an agent need a persona? What is a persona, anyway?\u003c/p\u003e\n\u003cp\u003eIf you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eUp Next: Multi-Agent Systems\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIn the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.\u003c/p\u003e\n\u003ch1 id=\"heading-multi-agent-system\"\u003eMulti Agent System\u003c/h1\u003e\n\u003cp\u003eNow that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRemember, agents are just:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eAn LLM with access to tools\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eA set of prompts (like persona, goal, etc.)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eMemory (which we’ll talk about later)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eAll built using an orchestration framework so everything works together\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBut what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png\" alt class=\"image--center mx-auto\" /\u003e\u003c/p\u003e\n\u003cp\u003eSource: \u003ca target=\"_blank\" href=\"https://docs.crewai.com/concepts/collaboration\"\u003eCrewAI Collaboration Concepts\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAll the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWhy Use Multi-Agent Systems?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eMulti-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their \u003ca target=\"_blank\" href=\"https://www.anthropic.com/engineering/built-multi-agent-research-system\"\u003eblog post\u003c/a\u003e on multi-agent systems, is that you can use more tokens (so the system can \"think more\") when tackling a complex problem.\u003c/p\u003e\n\u003cp\u003eIn the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.\u003c/p\u003e\n\u003cp\u003eYou can read about different types of multi agent systems later \u003ca target=\"_blank\" href=\"https://langchain-ai.github.io/langgraph/concepts/multi_agent/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWarning:\u003c/strong\u003e As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.\u003c/p\u003e\n\u003ch1 id=\"heading-memory\"\u003eMemory\u003c/h1\u003e\n\u003cp\u003eWe have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.\u003c/p\u003e\n\u003cp\u003eIn many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.\u003c/p\u003e\n\u003cp\u003eThere are two forms of memory that an AI agent can potentially have, much like humans do:\u003c/p\u003e\n\u003ch3 id=\"heading-short-term-memory\"\u003e\u003cstrong\u003eShort Term Memory\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eShort term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.\u003c/p\u003e\n\u003cp\u003eHere’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:\u003c/p\u003e\n\u003cp\u003eM1: User: perform 10 + 20 + 30 + 40 + 50\u003cbr /\u003eM2: LLM: \u003cem\u003eTool call, 10 + 20\u003c/em\u003e\u003cbr /\u003eM3: User: Output 30\u003cbr /\u003eM4: LLM: \u003cem\u003eCurrent answer is 30, let’s proceed. Tool call 30 + 30\u003c/em\u003e\u003cbr /\u003eM5: User: Output 60\u003cbr /\u003eM6: LLM: \u003cem\u003eCurrent answer is 60, let’s proceed. Tool call 60 + 40\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAt this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:\u003c/p\u003e\n\u003cp\u003eM1: User: perform 10 + 20 + 30 + 40 + 50\u003cbr /\u003eM2’: User: Output of 10 + 20 + 30 is 60, proceed further.\u003cbr /\u003eM6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40\u003c/p\u003e\n\u003cp\u003eNotice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.\u003c/p\u003e\n\u003cp\u003eSometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.\u003c/p\u003e\n\u003cp\u003eWe also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.\u003cbr /\u003e\u003cstrong\u003eRAISE stands for Reasoning and Acting through Scratchpad and Examples.\u003c/strong\u003e The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.\u003c/p\u003e\n\u003cp\u003eRead the paper that introduced RAISE framework here: \u003ca target=\"_blank\" href=\"https://arxiv.org/pdf/2401.02777\"\u003ehttps://arxiv.org/pdf/2401.02777\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"heading-long-term-memory\"\u003e\u003cstrong\u003eLong Term Memory\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eLong-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.\u003c/p\u003e\n\u003cp\u003eIn our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.\u003c/p\u003e\n\u003cp\u003eNotice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.\u003c/p\u003e\n\u003ch1 id=\"heading-mental-model-to-work-with-agents\"\u003eMental Model to work with agents\u003c/h1\u003e\n\u003cp\u003eThat’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made \u003ca target=\"_blank\" href=\"http://patra.app\"\u003epatra.app\u003c/a\u003e work reliably, and also how I’ve shipped multiple other production systems.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThe golden model:\u003c/strong\u003e\u003cbr /\u003eKeep yourself in the place of the agent. Imagine you are that agent.\u003c/p\u003e\n\u003cp\u003eIt might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.\u003c/p\u003e\n\u003cp\u003ePut yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?\u003c/p\u003e\n\u003cp\u003eNow, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.\u003c/p\u003e\n\u003ch2 id=\"heading-conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eHopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.\u003c/p\u003e\n\u003cp\u003eIf you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.\u003c/p\u003e\n\u003cp\u003eThere is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions \"AI agent\" in conversation, you will know not only what it is but also how it thinks and works.\u003c/p\u003e\n\u003cp\u003eIf you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens.\u003c/p\u003e\n","markdown":"## Motivation: Why You Should Care\n\nNot a day goes by without hearing the term “AI agent.” I have built multiple systems that use AI agents, like [patra.app](https://patra.app). While building those and reading through a lot of resources, I learned how AI agents actually work and what they really are under the hood. I used to think everyone understood what they are. You hear about them every day right, right? But then...\n\nDuring one of our late night walks, I asked my friend, “What do you think an AI agent is, anyway?”\n\nThey gave a surprising answer that somehow included fine-tuning, chatbot, and even “MCP” 🤯. I tried asking a few more people and realized that anyone who hasn’t actually built an agent or has only seen the abstractions thinks it’s all just magic. I want to reveal that magic in this article. I don’t want you to see AI agents as something mysterious anymore. Instead, I want you to gain both an understanding and a mental model to work with them.\n\nWell, I don’t blame them or you. There are just too many definitions for what an AI agent does, rather than what it actually is.\n\nI promise that by the end of this, you will not only understand what an AI agent is, but also how it works, how to think about them, and why they do what they do under the hood. If you stick with this, you’ll be able to explain to your friends:\n\n1. What an AI agent is\n    \n2. How an AI agent works\n    \n3. What the heck tools are\n    \n4. What an orchestration framework is\n    \n5. What memory is\n    \n6. What the types of AI agents are\n    \n7. The mental model for building an AI agent\n    \n8. What a multi-agent framework is\n    \n\nBefore we begin, understand that an AI agent isn’t just any chatbot. A chatbot might simply reply with information using an LLM, or it might actually have an agent behind it that can do real tasks for you, like booking flights or checking prices using tools and APIs. Not every chatbot is an agent, but every agent can appear just like a regular chatbot on the surface. Now, let’s look at the problem with how the internet explains AI agents.\n\n## The Problem\n\nOk, first things first, let’s understand the definition of what an AI agent is, straight from our good old friend Google search, who recently gave birth to this Search Labs thing:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png align=\"center\")\n\n\u003e An AI agent is a software program that utilizes artificial intelligence to perform tasks and achieve goals autonomously, often with minimal human intervention\n\nYou see the problem? Most definitions of what an AI agent is are based on what to expect as output or how it behaves, instead of focusing on what it actually is.\n\nIf I ask, \"What is an LLM?\" we get a much more acceptable answer:\n\n\u003e A Large Language Model (LLM) is **a type of AI model, specifically a deep learning model, trained on massive amounts of text data.**\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750505830733/b209c299-31cf-4b19-b28e-fc47f9f227a5.png align=\"center\")\n\nNotice how this answer is not about LLMs generating the next most likely token, but more about what they are fundamentally. For AI agents, we are going to fix this problem in this article. Enough promises. Let’s get to the point.\n\n# Defining AI Agent\n\nLet’s first write an acceptable definition of an AI agent. All we have to do in this article is break that definition down into smaller pieces and understand each part of it:\n\nAgents are **software systems** where **LLMs** use reasoning to control the flow of execution, **dynamically** choosing which **tools** to use and determining each step required to reach a **goal**.\n\nThat’s a mouthful. Let’s break down each part so we can actually understand it.\n\n## **Agents are Software Systems**\n\nThis is the first clarification, and it’s the easiest. When someone says “AI agent,” it should pop up in your head that it’s just software. For a simple agent, it might just be a few files of code, nothing more. The reason we also call it a system is because it contains different pieces or modules, such as:\n\n1. LLMs\n    \n2. Working Memory or state\n    \n3. Prompts\n    \n4. Tools\n    \n5. Orchestration Layer\n    \n\nYou already know what LLMs are. When we dive deeper into the other parts of our definition, the other modules of an AI agent will reveal themselves. Don’t worry if you can’t remember these yet. They will come up again.\n\nIn our definition, we mention a flow of execution that is dynamic. Let’s see what that means next.\n\n## **Dynamic** Flow of Execution\n\nTo execute any task, we usually need to take one or more steps or actions. These decisions can be thought of as a workflow, or a set of rules that determine how we complete a task.\n\nLet’s look at an example.\n\nSuppose you want to create a customer success bot that takes a ticket as input, then responds to the creator, and either resolves the ticket or escalates it if needed.\n\nNotice that resolving or escalating the ticket is basically an operation that needs to be performed on some external CRM software. Our LLM program should be able to handle this.\n\nWe won’t get into the details of what the code would look like right now. I’ve created a sample you can check out if you’re interested. You can use a library like “langgraph” to achieve this, and the graph or flow of execution looks something like this:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750523331009/2478546b-8dd2-47d0-81fd-9b37556dafe9.png align=\"center\")\n\n\u003cdiv data-node-type=\"callout\"\u003e\n\u003cdiv data-node-type=\"callout-emoji\"\u003e💡\u003c/div\u003e\n\u003cdiv data-node-type=\"callout-text\"\u003eYou may notice a few code examples below. If they’re not relevant to you, feel free to skip them and continue reading\u003c/div\u003e\n\u003c/div\u003e\n\nNotice how we first start by classifying a ticket, which would be handled by an LLM prompt. Next, we generate the initial response, which is another LLM prompt. Then, we check if escalation is needed. This can either be done through an API call or by using a static piece of code to decide if we should escalate. Finally, depending on what’s needed, we can escalate the ticket and generate a final response to let the customer know what happened.\n\n```python\n# Build workflow\nworkflow = StateGraph(SupportTicketState)\n\n# Add nodes\nworkflow.add_node(\"classify_ticket\", classify_ticket)\nworkflow.add_node(\"generate_initial_response\", generate_initial_response)\nworkflow.add_node(\"check_escalation\", check_escalation_needed)\nworkflow.add_node(\"escalate_ticket\", escalate_ticket)\nworkflow.add_node(\"resolve_ticket\", resolve_ticket)\n\n# Add edges\nworkflow.add_edge(START, \"classify_ticket\")\nworkflow.add_edge(\"classify_ticket\", \"generate_initial_response\")\nworkflow.add_edge(\"generate_initial_response\", \"check_escalation\")\n\n# Conditional edges for escalation\nworkflow.add_conditional_edges(\n    \"check_escalation\",\n    should_escalate,\n    {\n        \"escalate\": \"escalate_ticket\",\n        \"resolve\": \"resolve_ticket\"\n    }\n)\n\nworkflow.add_edge(\"escalate_ticket\", END)\nworkflow.add_edge(\"resolve_ticket\", END)\n```\n\nEntire code for this is available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/workflow.py)\n\nThis is how we can create the entire flow in langgraph. We start with a StateGraph(see the first line of the example above) and set an initial state. Then, we add multiple nodes or logical blocks. If needed, we can include a conditional block that makes decisions based on the output of the previous node.\n\nIn the example above, the value of should\\_escalate, which comes from the check\\_escalation node, is used to determine which part of the graph or “workflow” we go to next.\n\nA node like \"resolve ticket\" will look something like this:\n\n```python\ndef resolve_ticket(state: SupportTicketState):\n    \"\"\"Resolve the ticket and generate a final customer-facing response.\"\"\"\n    call_resolution_api(state['ticket_id'])\n    prompt = f\"\"\"\n    Generate a customer-facing response to inform them their ticket is resolved.\n    \n    Ticket ID: {state['ticket_id']}\n    Customer: {state['customer_name']}\n    Issue: {state['issue_description']}\n    \n    The response should:\n    1. State clearly that the issue has been resolved.\n    2. Briefly explain the solution.\n    3. Thank the customer for their patience.\n    4. Ask if they need any further assistance.\n    \"\"\"\n    response = llm.invoke(prompt)\n    return {\n        \"final_response\": response.content,\n        \"status\": \"Resolved\"\n    }\n```\n\nNotice how we first call the resolution API and then run the prompt to generate a response for the ticket.\n\nYou might have guessed by now that we have complete control over the flow of the program. We can specify exactly what we want and when we want it. For example, the first step will always be to classify a ticket, then generate the initial response, and then follow a fixed set of steps or a workflow. This is a workflow system and not an agent. We are missing the dynamic flow of execution here, because we have already decided what happens at each step.\n\nLet’s try to make an agentic flow 🫣 for this. We will be using the ReAct agent flow. Don’t worry if this sounds new, we will cover it in detail soon. We will uncover it layer by layer, but first, let’s look at this along with the abstractions that exist.\n\n**By the way, ReAct stands for \"Reasoning and Acting.\"**  \nIt is a popular agent flow that lets the model reason step by step and choose when and how to act (for example, by calling tools) as part of the process.\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750524956830/946ad5ed-a30f-4883-9530-73be62fd190f.png align=\"center\")\n\nIn our example:\n\nThe **task** is to either resolve or escalate the ticket and give back a response.\n\nIn the **Act** stage, the agent can use a tool to classify, escalate, or resolve the ticket.\n\nIn the **Observe** stage, the agent gets new observations, which are outputs from tool calls, like what the classification of the ticket is or whether the escalation was successful.\n\nIn the **Reasoning** stage, which is basically the LLM “thinking” about what it should do next, the agent might have to decide whether to call a tool, generate a response, or check the output from the Observe stage. As you might expect, the Reasoning stage is where this loop starts.\n\nNotice something here? We never talked about a workflow. We never decided, in the form of code or a static flow, when the LLM should use a tool, classify a ticket, or resolve a ticket.\n\nTo understand this further, let’s check out the code that can be used to do the same. Note that we are using the CrewAI library to achieve this. Remember when we defined what an agent is: Tools, LLM, Prompts, Memory, and an Orchestration Layer. CrewAI is the Orchestration Layer here. It abstracts away a lot of the details about how the agent makes a tool call, how the response gets back to the agent, and adds a lot of syntactic sugar to make creating an agent simpler. This is where all the magic of how the agent works under the hood happens. We will look at the responsibility of this Orchestration Layer in detail later, and also see what popular options exist and what features they offer.\n\n**Now getting to the code:**\n\n```python\n# --- Agent Definition ---\nsupport_agent = Agent(\n    role=\"Senior Customer Support Specialist\",\n    goal=\"Efficiently and accurately process customer support tickets, ensuring high customer satisfaction by providing timely and helpful responses.\",\n    backstory=(\n        \"You are a seasoned support specialist with a knack for understanding customer needs. \"\n        \"You excel at identifying the root cause of issues, communicating clearly, and \"\n        \"knowing precisely when a problem needs to be escalated to a senior team member. \"\n        \"Your goal is to resolve issues on the first touch whenever possible, but never at the expense of quality.\"\n    ),\n    tools=[ClassifyTicketTool(), EscalateTicketTool(), ResolveTicketTool()],\n    llm=llm,\n    verbose=True,\n    allow_delegation=False\n)\n\n# --- Task Definition ---\ndef create_ticket_processing_task(agent, ticket_id, customer_name, issue_description):\n    return Task(\n        description=f\"\"\"\n        Process customer support ticket with the following details:\n        - Ticket ID: {ticket_id}\n        - Customer Name: {customer_name}\n        - Issue Description: {issue_description}\n\n        Follow this exact workflow:\n        1.  **Analyze and Classify**: Carefully read the issue description to understand the problem. Classify its 'Priority' (Low, Medium, High, Critical) and 'Category' (e.g., Technical, Billing, Feature Request).\n        2.  **Draft Initial Response**: Write a professional and empathetic initial response to the customer acknowledging their issue.\n        3.  **Decide to Escalate or Resolve**: Review the ticket content and its priority. You MUST decide if escalation is necessary. Escalate for 'High' or 'Critical' priority, or if the customer uses keywords like 'urgent', 'angry', 'third time', 'unacceptable', etc.\n        4.  **Use a Tool**:\n            - If you decide to escalate, you MUST use the 'Escalate Ticket' tool. Provide a clear reason for the escalation.\n            - If you decide to resolve, you MUST use the 'Resolve Ticket' tool.\n        5.  **Draft Final Response**: Based on the action you took (escalation or resolution), write a final, clear, customer-facing response. If escalated, inform them it's with a specialist. If resolved, confirm the solution and close the loop.\n\n        Your final output must be a comprehensive report in markdown format that includes:\n        - The classified priority and category.\n        - The initial response.\n        - The action taken with the corresponding tool.\n        - The final customer-facing response.\n        \"\"\",\n        agent=agent,\n        expected_output=\"A detailed markdown report with the classified ticket details, initial response, action taken, and final customer-facing response.\"\n    )\n```\n\nEntire code for this available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/agent.py)\n\nOk, the initial observations are clear. There’s no static workflow but only a dynamic one. Instead of the software dictating each step, the LLM decides what to do at every step.\n\n**The Little Trick We Play**\n\nBut here’s a fun little trick we play: we say, “Follow this exact workflow” in the Task’s description (which is syntactic sugar in CrewAI). Wait, so what’s the point of it being an agent? Didn’t we just instruct the exact workflow, but this time in plain English?\n\n**Isn’t That Just a Static Workflow?**\n\nWell, yes, you did. But the point is, you can’t always do this. Not all problems are simple enough to be a five-step process where you can predict exactly what those steps will be and in what order.\n\nFor example, if you’ve used Cursor’s agent mode, can you say the agent will always do X first and then Y? No. It depends on your request. In a complex problem, it’s hard (if not impossible) to write a fixed workflow.\n\n**Real World Example**\n\nWhen I was creating [patra.app](http://patra.app)[,](https://patra.app) which is basically a Jira agent on Slack, there were endless possibilities for the kinds of queries users could ask.\n\nExample:  \nCreate me a Jira ticket for this thread, assign it to ManthanSurkar, add a label Y, and set the priority to Z.\n\nImagine trying to do this in a static workflow. There would be multiple steps involved. First, check if a user is tagged in the Slack message. If they are, find their email, and so on. Let’s not get into the weeds.\n\nNow imagine an action like:  \nCheck my Google Calendar and create a Jira ticket for the action items from the event that happened yesterday evening.\n\nThese are complex, real-world scenarios. Writing a specific workflow for each is hard. That’s why AI agents have a dynamic flow of execution.\n\n**Don’t Overcomplicate Simple Things**\n\nWOW, THAT’S GREAT! HOW ABOUT WE ALWAYS HAVE A DYNAMIC FLOW OF...\n\nStop. No. Don’t make that mistake. When you can be deterministic, why would you want to add a layer of non-determinism to your software application? Is the job not hard enough already that you want to bring in an AI model that is non-deterministic?\n\nAgents are meant for complex problems, not the ones where you already know the solution and can jot it down as a workflow. Don’t complicate your life. Unless you just want to overengineer stuff. That’s fun, I’ll admit.\n\nIn a real-world scenario, a mix of both approaches is often used. For example, imagine you have three support agents, each dedicated to a different product. Depending on which product a ticket is linked to, you can select the appropriate agent and route the request to that agent.\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750586210175/09c85433-260c-4dbf-bc87-b2ff4b356c2f.png align=\"center\")\n\n**What’s Next?**\n\nSo far, we’ve kept tools and the orchestration framework as a black box. What the heck are those? How does an LLM call a tool? What is a tool, anyway? Let’s cover the “under the hood” of all these terms in the next section.\n\n## **Tools \u0026** orchestration **Framework**\n\nLLMs predict the next token. You’ve heard this a million times by now. If that’s the case, how does it call a tool just by predicting tokens? Well, actually, it doesn’t. The LLM just indicates that it wants to use a tool, then waits for the orchestration framework to figure out what tool it should call, actually perform the call, and then let the LLM know, “Hey, the tool was called and here is the output.”\n\n**A Simple Example**\n\nLet’s break this down with a simple program.\n\nSuppose we want to add or subtract two numbers based on a natural language message from a user. Since we’re dealing with natural language, we can use an LLM. But adding two numbers is a solved problem, and we should be able to do it deterministically, right? This is exactly where tools come in.\n\n**Why Use Tools?**\n\nTools let the LLM communicate with other systems through APIs. They can also allow the LLM to talk to other agents (drum roll for multi-agent systems) or perform deterministic tasks, like adding two numbers.\n\n**Defining a Tool**\n\nLet’s define how our tool will look:\n\n```python\ndef add(a: int, b: int) -\u003e int:\n    \"\"\"Adds two integers together.\"\"\"\n    return a + b\n\ndef subtract(a: int, b: int) -\u003e int:\n    \"\"\"Subtracts the second integer from the first.\"\"\"\n    return a - b\n\nSYSTEM_PROMPT = \"\"\"You are a helpful assistant with access to the following functions:\n\n1. `add(a: int, b: int)`: Adds two integers together.\n2. `subtract(a: int, b: int)`: Subtracts the second integer from the first.\n\nWhen a user asks a question that can be answered by one of these functions, \nyou MUST respond ONLY with a JSON object in the following format:\n{\n  \"function_name\": \"name_of_the_function\",\n  \"arguments\": {\"arg_name\": \"value\", ...}\n}\n\nDo not include any other text, explanations, or markdown formatting. \nYour entire response must be only the JSON object.\n\nIf you can answer the question without a function, \njust provide the answer directly in plain text.\"\"\"\n```\n\nNotice that we define two Python functions. They can perform the deterministic task of calculating. The prompt lets the LLM know that it can call the above functions. If the LLM wants to use any of these tools, it gives us the output in a specific format, and we can \"parse\" and identify which function needs to be called. Once the call is completed, we let the LLM know the answer and allow it to continue execution.\n\n**What does \"continuing the conversation\" mean?**  \nIt’s simply adding a new message, saying that the tool call was successful and the output is X, or letting the LLM know the tool call has failed. What happens next? We let the LLM do its job of generating the next token, but now with the output of the tool call added in.\n\n**That’s basically it.**  \nThis is how tool calls work under the hood. There is a parser and in our example, here’s what a parse function would look like:\n\n```python\ndef parse_and_execute(response_content: str) -\u003e (str, str):\n    \"\"\"\n    Tries to parse the LLM's text response as a JSON function call.\n    If successful, it executes the function and returns the result and function name.\n    Otherwise, it returns (None, None).\n    \"\"\"\n    try:\n        call_data = json.loads(response_content)\n        function_name = call_data.get(\"function_name\")\n        function_args = call_data.get(\"arguments\")\n\n        if not all([function_name, isinstance(function_args, dict)]):\n            return None, None # Not a valid function call structure\n\n        print(f\"Parser is executing function: '{function_name}' with args: {function_args}\")\n\n        available_functions = {\"add\": add, \"subtract\": subtract}\n        function_to_call = available_functions.get(function_name)\n\n        if function_to_call:\n            result = function_to_call(**function_args)\n            return str(result), function_name\n        else:\n            return f\"Error: Unknown function '{function_name}'.\", function_name\n\n    except (json.JSONDecodeError, TypeError):\n        return None, None # Not JSON or not a dictionary\n```\n\nThe entire code for this is available here: [https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py](https://github.com/thesmallstar/AI-Agents-Under-the-hood-blog/blob/main/tool.py)\n\nAnd then there’s the **invoke** method. This allows you to merge the response from the tool call back into the original set of messages, so the LLM can generate the next token with this extra piece of information included.\n\n```python\n# --- 5. The Main Invocation Logic ---\ndef invoke(user_prompt: str):\n    \"\"\"\n    Invokes the LLM, manually handling the function-calling loop.\n    \"\"\"\n    print(f\"\\n{'='*20} Invoking for prompt: '{user_prompt}' {'='*20}\")\n    \n    messages = [\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": user_prompt}\n    ]\n\n    # === Step 1: First LLM Call (without the `tools` parameter) ===\n    print(\"\\n--- 1. Sending prompt to LLM to generate function call JSON... ---\")\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=messages\n    )\n    \n    response_message = response.choices[0].message\n    messages.append({\"role\": \"assistant\", \"content\": response_message.content})\n\n    # === Step 2: Manually parse the response for a function call ===\n    print(\"\\n--- 2. Manually parsing response for a function call... ---\")\n    function_output, function_name = parse_and_execute(response_message.content)\n\n    if function_output:\n        # We got a result from our function, so we continue the conversation\n        messages.append({\n            \"role\": \"user\", # We provide the function result back as the user\n            \"content\": f\"I have called the function '{function_name}'. The result is: {function_output}\"\n        })\n\n        # === Step 3: Second LLM Call with function results ===\n        print(\"\\n--- 3. Sending function output back to LLM... ---\")\n        \n        second_response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages\n        )\n        final_response = second_response.choices[0].message.content\n    else:\n        # If parsing failed, the LLM's first response is the final answer\n        final_response = response_message.content\n\n    print(f\"\\n--- Final Answer ---\")\n    print(final_response)\n    return final_response\n```\n\nYou know what we just did? We built a mini agent framework. This framework is an oversimplified version of how things work under the hood in more complex systems. They all have parsing layers to figure out what the next action should be. Is it a tool call? Should another agent continue the execution? And so on.\n\nToday, OpenAI and Anthropic both support tool calling out of the box in their SDKs. You can learn more about OpenAI’s new Responses API and its support for function calls here: [https://platform.openai.com/docs/quickstart?api-mode=responses](https://platform.openai.com/docs/quickstart?api-mode=responses)\n\n**Exploring Popular Agent Frameworks**\n\nSome of the popular Agent frameworks includes -\n\n* **CrewAI** – A Python framework for coordinating multiple agents as a team.  \n    Read more: [CrewAI on Github](https://github.com/crewAIInc/crewAI)\n    \n* **OpenAI Agents SDK** – A lightweight toolkit for building and connecting agents, with built-in tracing and guardrails.  \n    Read more: [OpenAI Agents SDK (Python)](https://openai.github.io/openai-agents-python/)\n    \n* **MetaGPT** – A multi-agent system that simulates a software team by assigning roles like product manager and developer to different agents.  \n    Read more: [MetaGPT on GitHub](https://github.com/FoundationAgents/MetaGPT)\n    \n\nNow that you know what tools and frameworks are, it makes sense to explore the popular options. Keep in mind, each one will have its own syntactic sugar for defining a tool, setting up different aspects of an agent, or describing its goal and persona.\n\n**Wait, Persona?**\n\nThat’s new. Why does an agent need a persona? What is a persona, anyway?\n\nIf you think about it, having a specific persona helps the agent stay focused on its goal and make better decisions about what tools to use. This becomes especially important in a multi-agent system where different agents interact with one another. A complex problem can be solved by a multi-agent system where each agent has a different persona.\n\n**Up Next: Multi-Agent Systems**\n\nIn the next section, let’s talk more about multi-agent frameworks and why we might need multiple agents working together to get the job done.\n\n# Multi Agent System\n\nNow that we understand what an agent is, a multi-agent system is, as you might expect, simply multiple agents working together.\n\n**Remember, agents are just:**\n\n* An LLM with access to tools\n    \n* A set of prompts (like persona, goal, etc.)\n    \n* Memory (which we’ll talk about later)\n    \n* All built using an orchestration framework so everything works together\n    \n\nBut what does it actually mean to have multiple agents in a system? How do they communicate? Well, that’s up to the orchestration framework. For example, CrewAI allows two main operations in a multi-agent system.\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750530783347/e075dac0-4879-4b27-9505-2d6446ff99ed.png align=\"center\")\n\nSource: [CrewAI Collaboration Concepts](https://docs.crewai.com/concepts/collaboration)\n\nAll the other agents are added as tools. The current agent can either ask a question to an expert agent or delegate the task to that agent, assuming it can take over that responsibility.\n\n**Why Use Multi-Agent Systems?**\n\nMulti-agent systems help organize tasks and break them into smaller problems. Each problem can be solved by an individual expert agent with access to specific tools and a particular persona, much like a team working on a project. Another advantage, as noted by Anthropic in their [blog post](https://www.anthropic.com/engineering/built-multi-agent-research-system) on multi-agent systems, is that you can use more tokens (so the system can \"think more\") when tackling a complex problem.\n\nIn the example above, asking a question means starting with fresh working memory (chat history), which can extend to tens of thousands of tokens and answer a specific query before the main agent continues its work.\n\nYou can read about different types of multi agent systems later [here](https://langchain-ai.github.io/langgraph/concepts/multi_agent/).\n\n**Warning:** As you might expect, multi-agent systems are complex, hard to debug, and difficult to evaluate. I think it’s a good idea to start with a workflow. If the flow of execution becomes complex, then try building an agent. If it’s still complicated and you’re running into issues like context window limits, then consider using a multi-agent framework. Don’t use more complexity or power than you actually need.\n\n# Memory\n\nWe have touched on all the aspects of what an AI agent is, except memory. Let’s dive into this now.\n\nIn many cases, you don’t need to care much about the memory aspect of the agent until your system gets complex enough, or unless you are using an agent framework that relies on some form of memory.\n\nThere are two forms of memory that an AI agent can potentially have, much like humans do:\n\n### **Short Term Memory**\n\nShort term memory lets the LLM keep track of the recent or active conversation that is happening. For example, when an agent decides to make a tool call, it doesn’t forget anything that has happened before the tool was triggered. The conversation doesn’t start over; it continues right where it left off. Simply put, whatever is in the context window of the LLM is its short term memory. Sometimes, if the context window isn’t long enough to hold everything, we can summarize the older messages and keep the most recent ones as they are.\n\nHere’s an example. Let’s say you are doing a complex mathematical operation using an AI agent, but you only have a small context window:\n\nM1: User: perform 10 + 20 + 30 + 40 + 50  \nM2: LLM: *Tool call, 10 + 20*  \nM3: User: Output 30  \nM4: LLM: *Current answer is 30, let’s proceed. Tool call 30 + 30*  \nM5: User: Output 60  \nM6: LLM: *Current answer is 60, let’s proceed. Tool call 60 + 40*\n\nAt this point, we can summarize or even eliminate M2 to M4 into one line, like M2’:\n\nM1: User: perform 10 + 20 + 30 + 40 + 50  \nM2’: User: Output of 10 + 20 + 30 is 60, proceed further.  \nM6: LLM: Current answer is 60, let’s proceed. Tool call 60 + 40\n\nNotice how we compressed this information without losing anything important. This is a very simplified example, but in more complex situations, things can get tricky. Making sure that the right things stay in the agent’s short term memory can be a real challenge.\n\nSometimes, you may not even summarize, but just ignore older messages. The implementation and use of short term memory for an agent can vary, depending on the problem you are trying to solve.\n\nWe also mentioned that an agentic framework might depend on short term memory. An example is the RAISE framework, which is an extension of the ReAct framework we saw earlier.  \n**RAISE stands for Reasoning and Acting through Scratchpad and Examples.** The scratchpad lives in the agent’s short term memory and is used during execution. Examples, on the other hand, are long term memory.\n\nRead the paper that introduced RAISE framework here: [https://arxiv.org/pdf/2401.02777](https://arxiv.org/pdf/2401.02777)\n\n### **Long Term Memory**\n\nLong-term memory is what agents remember across multiple conversations. If you have used ChatGPT and tried out the memory feature, that’s like long-term memory for the system. When you have a conversation, the system stores relevant information that it can retrieve later to give you a better answer. That’s long-term memory in action.\n\nIn our previous example of a customer success bot, you could store previously answered tickets, whether answered by a human or by the agent, and then retrieve relevant examples to help answer the current ticket better. This is long-term memory being used, which is often accessed through a tool call. The tool call can be a simple database query or a RAG system that helps retrieve memory stored in persistent storage.\n\nNotice that for long-term memory to actually be useful, it needs to appear in working memory or short-term memory, where it will be used and considered when generating the next token.\n\n# Mental Model to work with agents\n\nThat’s a lot of theory and under-the-hood information. I want you to leave with a practical mental model I use while developing agents, or really any LLM application. This is how I have made [patra.app](http://patra.app) work reliably, and also how I’ve shipped multiple other production systems.\n\n**The golden model:**  \nKeep yourself in the place of the agent. Imagine you are that agent.\n\nIt might sound cliché. But what does “be that agent” really mean? LLMs are not magic. If a human cannot figure out how to proceed in a particular situation, most likely an agent will not be able to either. Let’s say you are building a coding agent and you give it a task to fix a bug.\n\nPut yourself in the shoes of the agent. Imagine facing a codebase with 1000 files. How is it supposed to know where to begin? It has no business context, and no code context. As you develop this empathy for agents, you stop believing they are some kind of magic wand. You’ll write better goals, provide more context, and add more tools. Do exactly what you or a human would do in the same situation. Does the agent have everything a human would need?\n\nNow, don’t take this literally and overcomplicate everything. The point is to develop empathy for agents. When you do, your agent design will always improve.\n\n## Conclusion\n\nHopefully, you now see that AI agents are not magic. They are just smart systems with the right setup: LLMs, memory, tools, some orchestration, and a good mental model for solving real problems. The hype is justified, but the reality is both simpler and more practical than most people realize.\n\nIf you take away just one thing, let it be this: building effective AI agents is about clarity, empathy, and structure. Treat your agent like a new teammate. Give it context, clear goals, and the right tools. Do not expect it to read your mind.\n\nThere is still a lot evolving in this space. New frameworks are coming up, new approaches to memory are being tested, and multi-agent collaboration is getting more creative. But if you understand the basics, you are already ahead of most. So the next time someone mentions \"AI agent\" in conversation, you will know not only what it is but also how it thinks and works.\n\nIf you ever get stuck, just ask yourself: if I was the agent, what would I need to succeed? That is where the real magic happens."},"views":611,"preferences":{"pinnedToBlog":false,"disableComments":false,"stickCoverToBottom":true,"isDelisted":false},"readTimeInMinutes":23,"series":null,"tags":[{"id":"56744721958ef13879b9488e","slug":"ai","name":"AI"},{"id":"65f70fe712e12dacdb744b16","slug":"ai-agent","name":"ai-agent"},{"id":"56744721958ef13879b94ad1","slug":"software-development","name":"software development"}],"ogMetaData":{"image":null},"canonicalUrl":null,"hasLatexInPost":false,"audioUrls":null,"isFollowed":null,"bookmarked":false,"features":{"tableOfContents":{"isEnabled":false,"items":[]},"badges":{"isEnabled":true,"items":[]}},"isAutoPublishedFromRSS":false,"authenticatedUserLikes":{"edges":[]},"totalUserLikes":{"totalDocuments":3},"isShadowBanned":false,"isAskMeAnything":false},"redirectedPost":null,"staticPage":null},"series":null}},"__N_SSP":true},"page":"/[...slug]","query":{"x-host":"blog.surkar.in","slug":["ai-agents-under-the-hood"]},"buildId":"NQCZqh8ei5oJzgkpVggZD","isFallback":false,"dynamicIds":[87179],"gssp":true,"scriptLoader":[]}</script><div id="hn-modal"></div><div id="hn-toast"></div><next-route-announcer><p aria-live="assertive" id="__next-route-announcer__" role="alert" style="border: 0px; clip: rect(0px, 0px, 0px, 0px); height: 1px; margin: -1px; overflow: hidden; padding: 0px; position: absolute; top: 0px; width: 1px; white-space: nowrap; overflow-wrap: normal;"></p></next-route-announcer><div id="fluent-read-floating-ball-container" data-v-app=""><div data-v-dbf64f24="" class="floating-ball" data-position="right" style="top: 50%;"><div data-v-dbf64f24="" class="floating-ball-icon"><div data-v-dbf64f24="" class="icon-container"><!--v-if--><!--v-if--><svg data-v-dbf64f24="" class="imt-fb-logo-img-big-bg translation-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path data-v-dbf64f24="" fill="none" d="M0 0h24v24H0z"></path><path data-v-dbf64f24="" d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><!--v-if--><!-- 添加快捷键提示 --><!--v-if--><!-- 波纹效果容器 --><div data-v-dbf64f24="" class="ripple-container"></div></div></div></div></div><div id="fluent-read-selection-translator-container" data-v-app=""></div><!-- 小红点指示器 --><div data-v-22baf78a="" class="selection-indicator" style="left: 1069.8px; top: 346px; transform: translate(3px, -50%);"></div><!-- 翻译结果弹窗 --><!--v-if--><!-- 复制成功提示 --><!--v-if--><div id="fluent-read-translation-status-container" data-v-app=""><!--v-if--></div><iframe allow="join-ad-interest-group" data-tagging-id="AW-344963816" data-load-time="1751601126745" height="0" width="0" src="https://td.doubleclick.net/td/rul/344963816?random=1751601126737&amp;cv=11&amp;fst=1751601126737&amp;fmt=3&amp;bg=ffffff&amp;guid=ON&amp;async=1&amp;gtm=45he5710v893467680za204&amp;gcd=13l3l3l3l1l1&amp;dma=0&amp;tag_exp=101509157~103116026~103200004~103233427~103351869~103351871~104684208~104684211~104718208~104839054~104839056~104885889~104885891~104908321~104908323&amp;u_w=1920&amp;u_h=1080&amp;url=https%3A%2F%2Fblog.surkar.in%2Fai-agents-under-the-hood&amp;ref=https%3A%2F%2Fwww.inoreader.com%2F&amp;hn=www.googleadservices.com&amp;frm=0&amp;tiba=AI%20Agents%20Under%20The%20Hood&amp;npa=0&amp;auid=2001752842.1751601025&amp;uaa=x86&amp;uab=64&amp;uafvl=Not.A%252FBrand%3B99.0.0.0%7CChromium%3B136.0.7103.94&amp;uamb=0&amp;uam=&amp;uap=Windows&amp;uapv=19.0.0&amp;uaw=0&amp;fledge=1&amp;_tu=BA&amp;data=event%3Dgtag.config" style="display: none; visibility: hidden;"></iframe><iframe height="0" width="0" style="display: none; visibility: hidden;"></iframe><div data-rmiz-portal=""><dialog aria-labelledby="rmiz-modal-img-28f87d084ec5" aria-modal="true" class="prose outline-none" data-rmiz-modal="" id="rmiz-modal-28f87d084ec5" role="dialog"><div data-rmiz-modal-overlay="hidden"></div><div data-rmiz-modal-content=""><img alt="" sizes="" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1750505693141/99eb7803-dd5c-4c52-8d81-ed99522678ee.png?auto=compress,format&amp;format=webp" srcset="" data-rmiz-modal-img="" height="583.9898386891908" id="rmiz-modal-img-28f87d084ec5" width="1416" style="top: 1984.97px; left: 583.453px; width: 1416px; height: 583.99px; transform: translate(0px, 0px) scale(0.521253);"><button aria-label="Minimize image" data-rmiz-btn-unzoom="" type="button"><svg aria-hidden="true" data-rmiz-btn-unzoom-icon="true" fill="currentColor" focusable="false" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M 14.144531 1.148438 L 9 6.292969 L 9 3 L 8 3 L 8 8 L 13 8 L 13 7 L 9.707031 7 L 14.855469 1.851563 Z M 8 8 L 3 8 L 3 9 L 6.292969 9 L 1.148438 14.144531 L 1.851563 14.855469 L 7 9.707031 L 7 13 L 8 13 Z"></path></svg></button></div></dialog></div><script src="/_next/static/chunks/5772-330b7829e95060dd.js"></script><script src="/_next/static/chunks/4960-b70b6f04f379686e.js"></script><script src="/_next/static/chunks/pages/index-77bcfcca4712573b.js"></script></body><div id="immersive-translate-browser-popup" style="all: initial"></div><div id="__yetone-openai-translator" style="z-index: 2147483647;"></div></html>