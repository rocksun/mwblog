<!doctype html><html lang="en"><head><title data-rh="true">Finding the Best Open-Source Embedding Model for RAG | by Team Timescale | Timescale | Dec, 2024 | Medium</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2024-12-23T02:30:40.693Z"/><meta data-rh="true" name="title" content="Finding the Best Open-Source Embedding Model for RAG | by Team Timescale | Timescale | Dec, 2024 | Medium"/><meta data-rh="true" property="og:title" content="Finding the Best Open-Source Embedding Model for RAG"/><meta data-rh="true" property="al:android:url" content="medium://p/929d1656d331"/><meta data-rh="true" property="al:ios:url" content="medium://p/929d1656d331"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="Looking for the best open-source embedding model for your RAG application? We share a simple comparison workflow so you can stop paying the OpenAI tax."/><meta data-rh="true" property="og:description" content="Looking for the best open-source embedding model for your RAG app? We share a comparison workflow so you can stop paying the OpenAI tax."/><meta data-rh="true" property="og:url" content="https://medium.com/timescale/finding-the-best-open-source-embedding-model-for-rag-929d1656d331"/><meta data-rh="true" property="al:web:url" content="https://medium.com/timescale/finding-the-best-open-source-embedding-model-for-rag-929d1656d331"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*bhXrFWJTiZEY_4UO"/><meta data-rh="true" property="og:image:alt" content="Finding the Best Open-Source Embedding Model for RAG"/><meta data-rh="true" property="article:author" content="https://medium.com/@team-timescale"/><meta data-rh="true" name="author" content="Team Timescale"/><meta data-rh="true" name="robots" content="index,noarchive,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="Finding the Best Open-Source Embedding Model for RAG"/><meta data-rh="true" name="twitter:site" content="@timescaledb"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/929d1656d331"/><meta data-rh="true" property="twitter:description" content="Looking for the best open-source embedding model for your RAG app? We share a comparison workflow so you can stop paying the OpenAI tax."/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*bhXrFWJTiZEY_4UO"/><meta data-rh="true" name="twitter:image:alt" content="Finding the Best Open-Source Embedding Model for RAG"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="12 min read"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:304:304/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:240:240/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:152:152/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:120:120/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="mask-icon" href="https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@team-timescale"/><link data-rh="true" rel="canonical" href="https://www.timescale.com/blog/finding-the-best-open-source-embedding-model-for-rag"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/929d1656d331"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fda:true\u002Fresize:fit:1200\u002F0*bhXrFWJTiZEY_4UO"],"url":"https:\u002F\u002Fmedium.com\u002Ftimescale\u002Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331","dateCreated":"2024-12-23T02:30:40.693Z","datePublished":"2024-12-23T02:30:40.693Z","dateModified":"2024-12-23T02:30:40.842Z","headline":"Finding the Best Open-Source Embedding Model for RAG","name":"Finding the Best Open-Source Embedding Model for RAG","description":"Looking for the best open-source embedding model for your RAG application? We share a simple comparison workflow so you can stop paying the OpenAI tax.","identifier":"929d1656d331","author":{"@type":"Person","name":"Team Timescale","url":"https:\u002F\u002Fmedium.com\u002F@team-timescale"},"creator":["Team Timescale"],"publisher":{"@type":"Organization","name":"Timescale","url":"https:\u002F\u002Fmedium.com\u002Ftimescale","logo":{"@type":"ImageObject","width":163,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:326\u002F1*gOEnwizcgWX1HSdbJslc9A.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002Ftimescale\u002Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331"}</script><style type="text/css" data-fela-rehydration="576" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="576" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{width:auto}.av path{fill:#242424}.aw{height:25px}.ax{margin-left:16px}.ay{border:none}.az{border-radius:20px}.ba{width:240px}.bb{background:#F9F9F9}.bc path{fill:#6B6B6B}.be{outline:none}.bf{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bg{font-size:14px}.bh{width:100%}.bi{padding:10px 20px 10px 0}.bj{background-color:transparent}.bk{color:#242424}.bl::placeholder{color:#6B6B6B}.bm{display:inline-block}.bn{margin-left:12px}.bo{margin-right:12px}.bp{border-radius:4px}.bq{margin-left:24px}.br{height:24px}.bx{background-color:#F9F9F9}.by{border-radius:50%}.bz{height:32px}.ca{width:32px}.cb{justify-content:center}.ch{max-width:680px}.ci{min-width:0}.cj{animation:k1 1.2s ease-in-out infinite}.ck{height:100vh}.cl{margin-bottom:16px}.cm{margin-top:48px}.cn{align-items:flex-start}.co{flex-direction:column}.cp{justify-content:space-between}.cq{margin-bottom:24px}.cw{width:80%}.cx{background-color:#F2F2F2}.dd{height:44px}.de{width:44px}.df{margin:auto 0}.dg{margin-bottom:4px}.dh{height:16px}.di{width:120px}.dj{width:80px}.dp{margin-bottom:8px}.dq{width:96%}.dr{width:98%}.ds{width:81%}.dt{margin-left:8px}.du{color:#6B6B6B}.dv{font-size:13px}.dw{height:100%}.ep{color:#FFFFFF}.eq{fill:#FFFFFF}.er{background:rgba(134, 132, 132, 1)}.es{border-color:rgba(134, 132, 132, 1)}.ew:disabled{cursor:inherit !important}.ex:disabled{opacity:0.3}.ey:disabled:hover{background:rgba(134, 132, 132, 1)}.ez:disabled:hover{border-color:rgba(134, 132, 132, 1)}.fa{border-radius:99em}.fb{border-width:1px}.fc{border-style:solid}.fd{box-sizing:border-box}.fe{text-decoration:none}.ff{text-align:center}.fi{margin-right:32px}.fj{position:relative}.fk{fill:#6B6B6B}.fn{background:transparent}.fo svg{margin-left:4px}.fp svg{fill:#6B6B6B}.fr{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fs{position:absolute}.fz{margin:0 24px}.gd{background:rgba(255, 255, 255, 1)}.ge{border:1px solid #F2F2F2}.gf{box-shadow:0 1px 4px #F2F2F2}.gg{max-height:100vh}.gh{overflow-y:auto}.gi{left:0}.gj{top:calc(100vh + 100px)}.gk{bottom:calc(100vh + 100px)}.gl{width:10px}.gm{pointer-events:none}.gn{word-break:break-word}.go{word-wrap:break-word}.gp:after{display:block}.gq:after{content:""}.gr:after{clear:both}.gs{line-height:1.23}.gt{letter-spacing:0}.gu{font-style:normal}.gv{font-weight:700}.ia{align-items:baseline}.ib{width:48px}.ic{height:48px}.id{border:2px solid rgba(255, 255, 255, 1)}.ie{z-index:0}.if{box-shadow:none}.ig{border:1px solid rgba(0, 0, 0, 0.05)}.ih{margin-left:-12px}.ii{width:28px}.ij{height:28px}.ik{z-index:1}.il{width:24px}.im{margin-bottom:2px}.in{flex-wrap:nowrap}.io{font-size:16px}.ip{line-height:24px}.ir{margin:0 8px}.is{display:inline}.it{color:rgba(134, 132, 132, 1)}.iu{fill:rgba(134, 132, 132, 1)}.ix{flex:0 0 auto}.ja{flex-wrap:wrap}.jd{white-space:pre-wrap}.je{margin-right:4px}.jf{overflow:hidden}.jg{max-height:20px}.jh{text-overflow:ellipsis}.ji{display:-webkit-box}.jj{-webkit-line-clamp:1}.jk{-webkit-box-orient:vertical}.jl{word-break:break-all}.jn{padding-left:8px}.jo{padding-right:8px}.kp> *{flex-shrink:0}.kq{overflow-x:scroll}.kr::-webkit-scrollbar{display:none}.ks{scrollbar-width:none}.kt{-ms-overflow-style:none}.ku{width:74px}.kv{flex-direction:row}.kw{z-index:2}.kz{-webkit-user-select:none}.la{border:0}.lb{fill:rgba(117, 117, 117, 1)}.le{outline:0}.lf{user-select:none}.lg> svg{pointer-events:none}.lp{cursor:progress}.lq{opacity:1}.lr{padding:4px 0}.lu{margin-top:0px}.lv{width:16px}.lx{display:inline-flex}.md{max-width:100%}.me{padding:8px 2px}.mf svg{color:#6B6B6B}.mw{margin-left:auto}.mx{margin-right:auto}.my{max-width:1920px}.ne{clear:both}.ng{cursor:zoom-in}.nh{z-index:auto}.nj{height:auto}.nk{line-height:1.58}.nl{letter-spacing:-0.004em}.nm{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.oh{margin-bottom:-0.46em}.oi{text-decoration:underline}.oj{line-height:1.12}.ok{letter-spacing:-0.022em}.ol{font-weight:600}.pg{margin-bottom:-0.28em}.pm{list-style-type:disc}.pn{margin-left:30px}.po{padding-left:0px}.pu{line-height:1.18}.qi{margin-bottom:-0.31em}.qj{max-width:746px}.qp{padding:2px 4px}.qq{font-size:75%}.qr> strong{font-family:inherit}.qs{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.qt{overflow-x:auto}.qu{padding:32px}.qv{border:1px solid #E5E5E5}.qw{line-height:1.4}.qx{margin-top:-0.2em}.qy{margin-bottom:-0.2em}.qz{white-space:pre}.ra{min-width:fit-content}.rb{list-style-type:decimal}.rc{max-width:831px}.rd{font-style:italic}.re{max-width:1099px}.rf{max-width:914px}.rg{margin-top:32px}.rh{margin-bottom:14px}.ri{padding-top:24px}.rj{padding-bottom:10px}.rk{background-color:#000000}.rl{height:3px}.rm{width:3px}.rn{margin-right:20px}.ro{margin-bottom:26px}.rp{margin-top:6px}.rq{margin-top:8px}.rr{margin-right:8px}.rs{padding:8px 16px}.rt{border-radius:100px}.ru{transition:background 300ms ease}.rw{white-space:nowrap}.rx{border-top:none}.ry{height:52px}.rz{max-height:52px}.sa{box-sizing:content-box}.sb{position:static}.sd{max-width:155px}.so{height:0px}.sp{margin-bottom:40px}.sq{margin-bottom:48px}.te{border-radius:2px}.tg{height:64px}.th{width:64px}.ti{align-self:flex-end}.tj{flex:1 1 auto}.tp{padding-right:4px}.tq{font-weight:500}.tx{margin-top:16px}.ty{color:rgba(255, 255, 255, 1)}.tz{fill:rgba(255, 255, 255, 1)}.ua{background:rgba(25, 25, 25, 1)}.ub{border-color:rgba(25, 25, 25, 1)}.ue:disabled{opacity:0.1}.uf:disabled:hover{background:rgba(25, 25, 25, 1)}.ug:disabled:hover{border-color:rgba(25, 25, 25, 1)}.uh{margin-bottom:54px}.un{gap:18px}.uo{fill:rgba(61, 61, 61, 1)}.va{border-bottom:solid 1px #E5E5E5}.vb{margin-top:72px}.vc{padding:24px 0}.vd{margin-bottom:0px}.ve{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.et:hover{background:rgba(115, 113, 113, 1)}.eu:hover{border-color:rgba(115, 113, 113, 1)}.ev:hover{cursor:pointer}.fl:hover{color:#242424}.fm:hover{fill:#242424}.fq:hover svg{fill:#242424}.ft:hover{background-color:rgba(0, 0, 0, 0.1)}.iq:hover{text-decoration:underline}.iv:hover:not(:disabled){color:rgba(115, 113, 113, 1)}.iw:hover:not(:disabled){fill:rgba(115, 113, 113, 1)}.ld:hover{fill:rgba(8, 8, 8, 1)}.ls:hover{fill:#000000}.lt:hover p{color:#000000}.lw:hover{color:#000000}.mg:hover svg{color:#000000}.rv:hover{background-color:#F2F2F2}.tf:hover{background-color:none}.uc:hover{background:#000000}.ud:hover{border-color:#242424}.up:hover{fill:rgba(25, 25, 25, 1)}.bd:focus-within path{fill:#242424}.lc:focus{fill:rgba(8, 8, 8, 1)}.mh:focus svg{color:#000000}.ni:focus{transform:scale(1.01)}.lh:active{border-style:none}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bw{width:64px}.cg{margin:0 64px}.cv{height:48px}.dc{margin-bottom:52px}.do{margin-bottom:48px}.ef{font-size:14px}.eg{line-height:20px}.em{font-size:13px}.eo{padding:5px 12px}.fh{display:flex}.fy{margin-bottom:68px}.gc{max-width:680px}.hq{font-size:42px}.hr{margin-top:1.19em}.hs{margin-bottom:32px}.ht{line-height:52px}.hu{letter-spacing:-0.011em}.hz{align-items:center}.kb{border-top:solid 1px #F2F2F2}.kc{border-bottom:solid 1px #F2F2F2}.kd{margin:32px 0 0}.ke{padding:3px 8px}.kn> *{margin-right:24px}.ko> :last-child{margin-right:0}.lo{margin-top:0px}.mc{margin:0}.nd{margin-top:40px}.od{font-size:20px}.oe{margin-top:2.14em}.of{line-height:32px}.og{letter-spacing:-0.003em}.pc{font-size:24px}.pd{margin-top:1.95em}.pe{line-height:30px}.pf{letter-spacing:-0.016em}.pl{margin-top:0.94em}.pt{margin-top:1.14em}.qf{margin-top:1.72em}.qg{line-height:24px}.qh{letter-spacing:0}.qo{margin-top:56px}.si{display:inline-block}.sn{margin-bottom:104px}.sr{flex-direction:row}.su{margin-bottom:0}.sv{margin-right:20px}.tk{max-width:500px}.um{margin-bottom:72px}.uu{margin:40px 0 0}.uz{padding-top:72px}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ln{margin-top:0px}.sh{display:inline-block}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.lm{margin-top:0px}.sg{display:inline-block}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.lk{margin-top:0px}.ll{margin-right:0px}.sf{display:inline-block}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dx{font-size:13px}.dy{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:4px}.gw{font-size:32px}.gx{margin-top:1.01em}.gy{margin-bottom:24px}.gz{line-height:38px}.ha{letter-spacing:-0.014em}.hv{align-items:flex-start}.iy{flex-direction:column}.jb{margin-bottom:2px}.jp{margin:24px -24px 0}.jq{padding:0}.kf> *{margin-right:8px}.kg> :last-child{margin-right:24px}.kx{margin-left:0px}.li{margin-top:0px}.lj{margin-right:0px}.ly{margin:0}.mi{border:1px solid #F2F2F2}.mj{border-radius:99em}.mk{padding:0px 16px 0px 12px}.ml{height:38px}.mm{align-items:center}.mo svg{margin-right:8px}.mz{margin-top:32px}.nn{font-size:18px}.no{margin-top:1.56em}.np{line-height:28px}.nq{letter-spacing:-0.003em}.om{font-size:20px}.on{margin-top:1.2em}.oo{line-height:24px}.op{letter-spacing:0}.ph{margin-top:0.67em}.pp{margin-top:1.34em}.pv{font-size:16px}.pw{margin-top:1.23em}.qk{margin-top:40px}.se{display:inline-block}.sj{margin-bottom:96px}.tc{margin-bottom:20px}.td{margin-right:0}.to{max-width:100%}.tr{font-size:24px}.ts{line-height:30px}.tt{letter-spacing:-0.016em}.ui{margin-bottom:64px}.uq{margin:32px 0 0}.uv{padding-top:48px}.mn:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ed{font-size:14px}.ee{line-height:20px}.ek{font-size:13px}.el{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:68px}.gb{max-width:680px}.hl{font-size:42px}.hm{margin-top:1.19em}.hn{margin-bottom:32px}.ho{line-height:52px}.hp{letter-spacing:-0.011em}.hy{align-items:center}.jx{border-top:solid 1px #F2F2F2}.jy{border-bottom:solid 1px #F2F2F2}.jz{margin:32px 0 0}.ka{padding:3px 8px}.kl> *{margin-right:24px}.km> :last-child{margin-right:0}.mb{margin:0}.nc{margin-top:40px}.nz{font-size:20px}.oa{margin-top:2.14em}.ob{line-height:32px}.oc{letter-spacing:-0.003em}.oy{font-size:24px}.oz{margin-top:1.95em}.pa{line-height:30px}.pb{letter-spacing:-0.016em}.pk{margin-top:0.94em}.ps{margin-top:1.14em}.qc{margin-top:1.72em}.qd{line-height:24px}.qe{letter-spacing:0}.qn{margin-top:56px}.sm{margin-bottom:104px}.ss{flex-direction:row}.sw{margin-bottom:0}.sx{margin-right:20px}.tl{max-width:500px}.ul{margin-bottom:72px}.ut{margin:40px 0 0}.uy{padding-top:72px}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bu{width:64px}.ce{margin:0 48px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.eb{font-size:13px}.ec{line-height:20px}.ej{padding:0px 8px 1px}.fw{margin-bottom:68px}.ga{max-width:680px}.hg{font-size:42px}.hh{margin-top:1.19em}.hi{margin-bottom:32px}.hj{line-height:52px}.hk{letter-spacing:-0.011em}.hx{align-items:center}.jt{border-top:solid 1px #F2F2F2}.ju{border-bottom:solid 1px #F2F2F2}.jv{margin:32px 0 0}.jw{padding:3px 8px}.kj> *{margin-right:24px}.kk> :last-child{margin-right:0}.ma{margin:0}.nb{margin-top:40px}.nv{font-size:20px}.nw{margin-top:2.14em}.nx{line-height:32px}.ny{letter-spacing:-0.003em}.ou{font-size:24px}.ov{margin-top:1.95em}.ow{line-height:30px}.ox{letter-spacing:-0.016em}.pj{margin-top:0.94em}.pr{margin-top:1.14em}.pz{margin-top:1.72em}.qa{line-height:24px}.qb{letter-spacing:0}.qm{margin-top:56px}.sl{margin-bottom:104px}.st{flex-direction:row}.sy{margin-bottom:0}.sz{margin-right:20px}.tm{max-width:500px}.uk{margin-bottom:72px}.us{margin:40px 0 0}.ux{padding-top:72px}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bt{width:24px}.cd{margin:0 24px}.cs{height:40px}.cz{margin-bottom:44px}.dl{margin-bottom:32px}.dz{font-size:13px}.ea{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:4px}.hb{font-size:32px}.hc{margin-top:1.01em}.hd{margin-bottom:24px}.he{line-height:38px}.hf{letter-spacing:-0.014em}.hw{align-items:flex-start}.iz{flex-direction:column}.jc{margin-bottom:2px}.jr{margin:24px 0 0}.js{padding:0}.kh> *{margin-right:8px}.ki> :last-child{margin-right:8px}.ky{margin-left:0px}.lz{margin:0}.mp{border:1px solid #F2F2F2}.mq{border-radius:99em}.mr{padding:0px 16px 0px 12px}.ms{height:38px}.mt{align-items:center}.mv svg{margin-right:8px}.na{margin-top:32px}.nr{font-size:18px}.ns{margin-top:1.56em}.nt{line-height:28px}.nu{letter-spacing:-0.003em}.oq{font-size:20px}.or{margin-top:1.2em}.os{line-height:24px}.ot{letter-spacing:0}.pi{margin-top:0.67em}.pq{margin-top:1.34em}.px{font-size:16px}.py{margin-top:1.23em}.ql{margin-top:40px}.sk{margin-bottom:96px}.ta{margin-bottom:20px}.tb{margin-right:0}.tn{max-width:100%}.tu{font-size:24px}.tv{line-height:30px}.tw{letter-spacing:-0.016em}.uj{margin-bottom:64px}.ur{margin:32px 0 0}.uw{padding-top:48px}.mu:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="print">.sc{display:none}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.jm{max-height:none}</style><style type="text/css" data-fela-rehydration="576" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.nf{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="du ag dv bf ak b am an ao ap aq ar as at s u w i d q dw z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F929d1656d331&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---top_nav_layout_nav----------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="dt"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ab q"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><button class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" data-testid="headerSignUpButton">Sign up</button></span></p><div class="ax l"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" rel="noopener follow" href="/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2Ftimescale%2Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331&amp;source=post_page---top_nav_layout_nav-----------------------global_nav-----------">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" rel="noopener follow" href="/?source=---top_nav_layout_nav----------------------------------"><svg xmlns="http://www.w3.org/2000/svg" width="719" height="160" fill="none" viewBox="0 0 719 160" class="au av aw"><path fill="#242424" d="m174.104 9.734.215-.047V8.02H130.39L89.6 103.89 48.81 8.021H1.472v1.666l.212.047c8.018 1.81 12.09 4.509 12.09 14.242V137.93c0 9.734-4.087 12.433-12.106 14.243l-.212.047v1.671h32.118v-1.665l-.213-.048c-8.018-1.809-12.089-4.509-12.089-14.242V30.586l52.399 123.305h2.972l53.925-126.743V140.75c-.687 7.688-4.721 10.062-11.982 11.701l-.215.05v1.652h55.948v-1.652l-.215-.05c-7.269-1.639-11.4-4.013-12.087-11.701l-.037-116.774h.037c0-9.733 4.071-12.432 12.087-14.242m25.555 75.488c.915-20.474 8.268-35.252 20.606-35.507 3.806.063 6.998 1.312 9.479 3.714 5.272 5.118 7.751 15.812 7.368 31.793zm-.553 5.77h65.573v-.275c-.186-15.656-4.721-27.834-13.466-36.196-7.559-7.227-18.751-11.203-30.507-11.203h-.263c-6.101 0-13.584 1.48-18.909 4.16-6.061 2.807-11.407 7.003-15.855 12.511-7.161 8.874-11.499 20.866-12.554 34.343q-.05.606-.092 1.212a50 50 0 0 0-.065 1.151 85.807 85.807 0 0 0-.094 5.689c.71 30.524 17.198 54.917 46.483 54.917 25.705 0 40.675-18.791 44.407-44.013l-1.886-.664c-6.557 13.556-18.334 21.771-31.738 20.769-18.297-1.369-32.314-19.922-31.042-42.395m139.722 41.359c-2.151 5.101-6.639 7.908-12.653 7.908s-11.513-4.129-15.418-11.63c-4.197-8.053-6.405-19.436-6.405-32.92 0-28.067 8.729-46.22 22.24-46.22 5.657 0 10.111 2.807 12.236 7.704zm43.499 20.008c-8.019-1.897-12.089-4.722-12.089-14.951V1.309l-48.716 14.353v1.757l.299-.024c6.72-.543 11.278.386 13.925 2.83 2.072 1.915 3.082 4.853 3.082 8.987v18.66c-4.803-3.067-10.516-4.56-17.448-4.56-14.059 0-26.909 5.92-36.176 16.672-9.66 11.205-14.767 26.518-14.767 44.278-.003 31.72 15.612 53.039 38.851 53.039 13.595 0 24.533-7.449 29.54-20.013v16.865h43.711v-1.746zM424.1 19.819c0-9.904-7.468-17.374-17.375-17.374-9.859 0-17.573 7.632-17.573 17.374s7.721 17.374 17.573 17.374c9.907 0 17.375-7.47 17.375-17.374m11.499 132.546c-8.019-1.897-12.089-4.722-12.089-14.951h-.035V43.635l-43.714 12.551v1.705l.263.024c9.458.842 12.047 4.1 12.047 15.152v81.086h43.751v-1.746zm112.013 0c-8.018-1.897-12.089-4.722-12.089-14.951V43.635l-41.621 12.137v1.71l.246.026c7.733.813 9.967 4.257 9.967 15.36v59.279c-2.578 5.102-7.415 8.131-13.274 8.336-9.503 0-14.736-6.419-14.736-18.073V43.638l-43.714 12.55v1.703l.262.024c9.459.84 12.05 4.097 12.05 15.152v50.17a56.3 56.3 0 0 0 .91 10.444l.787 3.423c3.701 13.262 13.398 20.197 28.59 20.197 12.868 0 24.147-7.966 29.115-20.43v17.311h43.714v-1.747zm169.818 1.788v-1.749l-.213-.05c-8.7-2.006-12.089-5.789-12.089-13.49v-63.79c0-19.89-11.171-31.761-29.883-31.761-13.64 0-25.141 7.882-29.569 20.16-3.517-13.01-13.639-20.16-28.606-20.16-13.146 0-23.449 6.938-27.869 18.657V43.643L545.487 55.68v1.715l.263.024c9.345.829 12.047 4.181 12.047 14.95v81.784h40.787v-1.746l-.215-.053c-6.941-1.631-9.181-4.606-9.181-12.239V66.998c1.836-4.289 5.537-9.37 12.853-9.37 9.086 0 13.692 6.296 13.692 18.697v77.828h40.797v-1.746l-.215-.053c-6.94-1.631-9.18-4.606-9.18-12.239V75.066a42 42 0 0 0-.578-7.26c1.947-4.661 5.86-10.177 13.475-10.177 9.214 0 13.691 6.114 13.691 18.696v77.828z"></path></svg></a><div class="ax h"><div class="ab ay az ba bb q bc bd"><div class="bm" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bn bo ab"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ay be bf bg z bh bi bj bk bl" placeholder="Search" value=""/></div></div></div><div class="h k w fg fh"><div class="fi ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" rel="noopener follow" href="/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav-----------"><div class="bf b bg z du fj fk ab q fl fm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Write"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg><div class="dt l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fi ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" rel="noopener follow" href="/search?source=---top_nav_layout_nav----------------------------------"><div class="bf b bg z du fj fk ab q fl fm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Search"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div></a></div></div><div class="fi h k j"><div class="ab q"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><button class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" data-testid="headerSignUpButton">Sign up</button></span></p><div class="ax l"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" rel="noopener follow" href="/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2Ftimescale%2Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331&amp;source=post_page---top_nav_layout_nav-----------------------global_nav-----------">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ay fn am ab q ao fo fp fq" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fj"><img alt="" class="l fd by bz ca cx" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fr by l bz ca fs n ay ft"></div></div></button></div></div></div><div class="l"><div class="fu fv fw fx fy l"><div class="ab cb"><div class="ci bh fz ga gb gc"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fs gi gj gk gl gm"></div><div class="gn go gp gq gr"><div class="ab cb"><div class="ci bh fz ga gb gc"><div><h1 id="e5ab" class="pw-post-title gs gt gu bf gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr hs ht hu bk" data-testid="storyTitle">Finding the Best Open-Source Embedding Model for RAG</h1><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hv hw hx hy hz ab"><div><div class="ab ia"><div><div class="bm" aria-hidden="false"><a rel="noopener follow" href="/@team-timescale?source=post_page---byline--929d1656d331--------------------------------"><div class="l ib ic by id ie"><div class="l fj"><img alt="Team Timescale" class="l fd by dd de cx" src="https://miro.medium.com/v2/resize:fill:88:88/1*1hiEAsTlce_ICvVpGm2Cgg.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"/><div class="if by l dd de fs n ig ft"></div></div></div></a></div></div><div class="ih ab fj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/timescale?source=post_page---byline--929d1656d331--------------------------------" rel="noopener follow"><div class="l ii ij by id ik"><div class="l fj"><img alt="Timescale" class="l fd by br il cx" src="https://miro.medium.com/v2/resize:fill:48:48/1*1hiEAsTlce_ICvVpGm2Cgg.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto"/><div class="if by l br il fs n ig ft"></div></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="im ab q"><div class="ab q in"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b io ip bk"><a class="af ag ah ai aj ak al am an ao ap aq ar iq" data-testid="authorName" rel="noopener follow" href="/@team-timescale?source=post_page---byline--929d1656d331--------------------------------">Team Timescale</a></p></div></div></div><span class="ir is" aria-hidden="true"><span class="bf b bg z du">·</span></span><p class="bf b io ip du"><span><a class="it iu ah ai aj ak al am an ao ap aq ar ex iv iw" rel="noopener follow" href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc84b80175451&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Ftimescale%2Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331&amp;user=Team+Timescale&amp;userId=c84b80175451&amp;source=post_page-c84b80175451--byline--929d1656d331---------------------post_header-----------">Follow</a></span></p></div></div></span></div></div><div class="l ix"><span class="bf b bg z du"><div class="ab cn iy iz ja"><div class="jb jc ab"><div class="bf b bg z du ab jd"><span class="je l ix">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar iq ab q" data-testid="publicationName" href="https://medium.com/timescale?source=post_page---byline--929d1656d331--------------------------------" rel="noopener follow"><p class="bf b bg z jf jg jh ji jj jk jl jm bk">Timescale</p></a></div></div></div><div class="h k"><span class="ir is" aria-hidden="true"><span class="bf b bg z du">·</span></span></div></div><span class="bf b bg z du"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="jn jo l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z du">·</span></span></div>Just now</div></span></div></span></div></div></div><div class="ab cp jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke"><div class="h k w fg fh q"><div class="ku l"><div class="ab q kv kw"><div class="pw-multi-vote-icon fj je kx ky kz"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" rel="noopener follow" href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftimescale%2F929d1656d331&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Ftimescale%2Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331&amp;user=Team+Timescale&amp;userId=c84b80175451&amp;source=---header_actions--929d1656d331---------------------clap_footer-----------"><div><div class="bm" aria-hidden="false"><div class="la ao lb lc ld le am lf lg lh kz"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l li lj lk ll lm ln lo"><p class="bf b dv z du"><span class="lp">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao la lq lr ab q fk ls lt" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="lu"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div><div class="ab q kf kg kh ki kj kk kl km kn ko kp kq kr ks kt"><div class="lv k j i d"></div><div class="h k"><div><div class="bm" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" rel="noopener follow" href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F929d1656d331&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Ftimescale%2Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331&amp;source=---header_actions--929d1656d331---------------------bookmark_footer-----------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du lw" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="fd lx cn"><div class="l ae"><div class="ab cb"><div class="ly lz ma mb mc md ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af fk ah ai aj ak al me an ao ap ex mf mg lt mh mi mj mk ml s mm mn mo mp mq mr ms u mt mu mv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z du">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fk ah ai aj ak al me an ao ap ex mf mg lt mh mi mj mk ml s mm mn mo mp mq mr ms u mt mu mv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z du">Share</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mz na nb nc nd ne mw mx paragraph-image"><div role="button" tabindex="0" class="nf ng fj nh bh ni"><div class="mw mx my"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*bhXrFWJTiZEY_4UO 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*bhXrFWJTiZEY_4UO 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*bhXrFWJTiZEY_4UO 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*bhXrFWJTiZEY_4UO 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*bhXrFWJTiZEY_4UO 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*bhXrFWJTiZEY_4UO 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bhXrFWJTiZEY_4UO 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*bhXrFWJTiZEY_4UO 640w, https://miro.medium.com/v2/resize:fit:720/0*bhXrFWJTiZEY_4UO 720w, https://miro.medium.com/v2/resize:fit:750/0*bhXrFWJTiZEY_4UO 750w, https://miro.medium.com/v2/resize:fit:786/0*bhXrFWJTiZEY_4UO 786w, https://miro.medium.com/v2/resize:fit:828/0*bhXrFWJTiZEY_4UO 828w, https://miro.medium.com/v2/resize:fit:1100/0*bhXrFWJTiZEY_4UO 1100w, https://miro.medium.com/v2/resize:fit:1400/0*bhXrFWJTiZEY_4UO 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="Finding the Best Open-Source Embedding Model for RAG" class="bh md nj c" width="700" height="310" loading="eager"/></picture></div></div></figure><p id="062a" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Proprietary embedding models like <a class="af oi" href="https://platform.openai.com/docs/models?ref=timescale.ghost.io#embeddings" rel="noopener ugc nofollow" target="_blank">OpenAI</a>’s text-embedding-large-3 and text-embedding-small are popular for retrieval-augmented augmentation (RAG) applications, but they come with added costs, third-party API dependencies, and potential <strong class="nm gv">data privacy</strong> concerns.</p><p id="098a" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">On the other hand, open-source embedding models provide a cost-effective and customizable alternative. By running these models locally, you can <a class="af oi" href="https://www.timescale.com/blog/the-emerging-open-source-ai-stack?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">stop paying the OpenAI tax</a> and regain complete control over the embedding creation process, enhance data privacy, and tailor the models to your needs.</p><p id="dfff" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">However, evaluating open-source embedding models can be complex, time-consuming, and resource-intensive, causing many engineers to default to proprietary solutions.</p><p id="9e47" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">This blog post will walk you through an <strong class="nm gv">easy-to-replicate workflow for comparing open-source embedding models</strong> using <a class="af oi" href="https://ollama.com/?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Ollama</a>, an open-source platform for running large language models (LLMs) locally, and <a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/vectorizer.md?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">pgai Vectorizer</a>, a PostgreSQL-based tool for automating embedding generation and management with a single SQL command. <a class="af oi" href="https://paulgraham.com/articles.html?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Paul Graham’s essays</a> will be our evaluation dataset to demonstrate this workflow.</p><h1 id="a218" class="oj ok gu bf ol om on oo op oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Picking the Best Open-Source Embedding Model: Evaluation Workflow</h1><p id="3d2c" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">An evaluation workflow for comparing open-source embedding models typically includes the following steps:</p><ul class=""><li id="e083" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk">Preparing the evaluation dataset for embedding generation</li><li id="6806" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Downloading and setting up the embedding models on your local machine</li><li id="4012" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Setting up a vector database to store the embeddings</li><li id="857c" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Generating and storing embeddings for each model</li><li id="38db" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Designing the evaluation pipeline to assess the models</li><li id="94ee" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Running the embedding through the evaluation pipeline</li><li id="608d" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Comparing the results to identify the best model</li></ul><p id="874a" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">While this workflow may sound straightforward, implementing it can quickly become complex and resource-intensive due to several challenges:</p><ul class=""><li id="f308" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><strong class="nm gv">Access and management of open-source models</strong>: Installing dependencies and ensuring system compatibility for each embedding model can be tedious. Storage management is another concern, as large models can consume significant space on your local machine.</li><li id="2f0a" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><strong class="nm gv">Automating embedding generation</strong>: Building a reliable workflow to generate and ingest embeddings across multiple models is complex. You’ll need to handle resource limitations, monitor errors, and ensure efficiency, which can require significant effort.</li><li id="e9d4" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><strong class="nm gv">Creating a fair and robust evaluation pipeline</strong>: Selecting the proper evaluation dataset and defining clear and relevant criteria — like retrieval quality or search accuracy — are essential to ensuring consistent, unbiased, and meaningful evaluations across all models.</li></ul><p id="ce19" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Fear not — we can make this easier!</p><p id="e4e4" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">While the specifics of a robust evaluation pipeline may vary depending on your RAG application, you can significantly reduce the complexity with just two tools: <strong class="nm gv">Ollama</strong> for accessing and managing the embedding models and <strong class="nm gv">pgai Vectorizer</strong> for automating embedding generation and management across multiple models (we shared how to <a class="af oi" href="https://www.timescale.com/blog/how-to-automatically-create-update-embeddings-in-postgresql?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">automate embedding generation</a> in a previous article).</p><p id="499e" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk"><strong class="nm gv">Want to follow along?</strong> Check out this <a class="af oi" href="https://github.com/timescale/pgai/tree/main/examples/finding_best_open_source_embedding_model?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">GitHub repository</a> for all the code used in this post.</p><h1 id="3a5e" class="oj ok gu bf ol om on oo op oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Ollama: Simplified Access to Open-Source Embedding Models</h1><p id="b224" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">Ollama makes running open-source models effortless by eliminating dependency and compatibility headaches. Simply download and run the model — no complex setup required. It works seamlessly across macOS, Linux, Windows, and Docker environments. In this evaluation, we are running Ollama within a Docker container.</p><p id="c0f8" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Ollama simplifies model management by bundling a model’s configuration, data, and weights. This bundle makes cleanup and experimentation straightforward while ensuring full data ownership — you retain complete control over how your data is handled and where it flows.</p><h2 id="001a" class="pu ok gu bf ol pv pw dy op px py ea ot nv pz qa qb nz qc qd qe od qf qg qh qi bk">Open-source embedding models compared</h2><p id="1790" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">Ollama provides access to state-of-the-art large language models. In this evaluation, we compared three of the most popular embedding models available on <a class="af oi" href="https://ollama.com/search?c=embedding&amp;ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Ollama</a>:</p><figure class="qk ql qm qn qo ne mw mx paragraph-image"><div role="button" tabindex="0" class="nf ng fj nh bh ni"><div class="mw mx qj"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*paXYY4s_s_SvRReXVG7dLQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*paXYY4s_s_SvRReXVG7dLQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*paXYY4s_s_SvRReXVG7dLQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*paXYY4s_s_SvRReXVG7dLQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*paXYY4s_s_SvRReXVG7dLQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*paXYY4s_s_SvRReXVG7dLQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*paXYY4s_s_SvRReXVG7dLQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*paXYY4s_s_SvRReXVG7dLQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*paXYY4s_s_SvRReXVG7dLQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*paXYY4s_s_SvRReXVG7dLQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*paXYY4s_s_SvRReXVG7dLQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*paXYY4s_s_SvRReXVG7dLQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*paXYY4s_s_SvRReXVG7dLQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*paXYY4s_s_SvRReXVG7dLQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="Open-source embedding models compared" class="bh md nj c" width="700" height="136" loading="lazy"/></picture></div></div></figure><p id="d2e3" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">These open-source embedding models rival industry-standard proprietary embedding models like OpenAI’s:</p><ul class=""><li id="0204" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><a class="af oi" href="https://www.nomic.ai/blog/posts/nomic-embed-text-v1?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">nomic-embed-text</a>: outperforms <strong class="nm gv">text-embedding-ada-002</strong> and <strong class="nm gv">text-embedding-3-small</strong> on both short and long-context text embedding tasks</li><li id="003f" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><a class="af oi" href="https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">mxbai-embed-large</a>: outperforms <strong class="nm gv">text-embedding-3-large</strong> while being significantly smaller than the latter.</li></ul><h1 id="f117" class="oj ok gu bf ol om on oo op oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Pgai Vectorizer: Automatic Embedding Management in PostgreSQL</h1><p id="3ba3" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk"><a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/vectorizer.md?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Pgai Vectorizer</a> eliminates the need to build complex automation infrastructure to generate and manage embeddings across multiple models. It is an open-source, powerful tool designed to automate embedding creation and management directly in PostgreSQL, a widely adopted and robust database with vector capabilities via extensions like <a class="af oi" href="https://github.com/pgvector/pgvector?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">pgvector</a> and <a class="af oi" href="https://github.com/timescale/pgai?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">pgai</a>.</p><p id="f7bb" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">In this evaluation, we use PostgreSQL as our database to store the evaluation dataset and its corresponding embeddings.</p><p id="27fb" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">What sets pgai Vectorizer apart for this use case is its <strong class="nm gv">integration with Ollama</strong>, allowing you to generate embeddings using any open-source model supported by Ollama.</p><p id="1f86" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">To configure a vectorizer for each embedding model, just use one SQL command with all the configurations needed for your embeddings, as demonstrated below in the <code class="cx qp qq qr qs b">create_vectorizer</code> function. You can find more about these configurations in <a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/vectorizer-api-reference.md?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">pgai Vectorizer’s API reference</a>.</p><pre class="qk ql qm qn qo qt qs qu bp qv bb bk"><span id="e722" class="qw ok gu qs b bg qx qy l qz ra">def create_vectorizer(embedding_model, embeddings_dimensions):<br/>    embeddings_view_name = f&quot;{&#x27;essays&#x27;}{&#x27;_&#x27;}{embedding_model.replace(&#x27;-&#x27;,&#x27;_&#x27;)}{&#x27;_&#x27;}{&#x27;embeddings&#x27;}&quot;<br/><br/>    with connect_db() as conn:<br/>        with conn.cursor() as cur:<br/>            cur.execute(&quot;&quot;&quot;<br/>                SELECT ai.create_vectorizer(<br/>                &#x27;essays&#x27;::regclass,<br/>                destination =&gt; %s,<br/>                embedding =&gt; ai.embedding_ollama(%s, %s),<br/>                chunking =&gt; ai.chunking_recursive_character_text_splitter(&#x27;text&#x27;, 512, 50),<br/>                formatting =&gt; ai.formatting_python_template(&#x27;title: $title $chunk&#x27;)<br/>            );<br/>            &quot;&quot;&quot;, (embeddings_view_name, embedding_model, embeddings_dimensions, )<br/>            )</span></pre><p id="aa8a" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">From there, pgai Vectorizer handles all the heavy lifting:</p><ul class=""><li id="5c5a" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk">Automatically generating and updating embeddings as your dataset changes</li><li id="22fb" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Splitting the data into chunks and formatting them</li><li id="58f3" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Creating a table to store the embeddings with the specified name</li><li id="c843" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Generating a view that combines your data with its embeddings for easy access and querying</li><li id="c62a" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">Manages the embedding generation queue</li></ul><p id="91bf" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Using this <a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md?ref=timescale.ghost.io#setup-a-local-development-environment" rel="noopener ugc nofollow" target="_blank">Docker compose file</a>, you can quickly configure PostgreSQL, the pgai Vectorizer worker, and Ollama services in your Docker environment.</p><p id="2d88" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">To get started, check out this <a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">quick start guide</a> for more on pgai Vectorizer’s integration with Ollama.</p><h2 id="0e42" class="pu ok gu bf ol pv pw dy op px py ea ot nv pz qa qb nz qc qd qe od qf qg qh qi bk">Configuring multiple vectorizers</h2><p id="a0ab" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">After running your PostgreSQL service, install the <a class="af oi" href="https://github.com/timescale/pgai?tab=readme-ov-file&amp;ref=timescale.ghost.io#quick-start" rel="noopener ugc nofollow" target="_blank">pgai</a> extension. Then, you can insert the evaluation dataset, <a class="af oi" href="https://huggingface.co/datasets/sgoel9/paul_graham_essays?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Paul Graham’s essays</a>, using the pgai function <code class="cx qp qq qr qs b"><a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/load_dataset_from_huggingface.md?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">load_datasets</a></code>, which loads datasets from Hugging Face directly into your database!</p><pre class="qk ql qm qn qo qt qs qu bp qv bb bk"><span id="eb5e" class="qw ok gu qs b bg qx qy l qz ra">with connect_db() as conn:<br/>   with conn.cursor() as cur:<br/>        # Load Paul Graham&#x27;s essays dataset into the &#x27;essays&#x27; table<br/>        cur.execute(&quot;&quot;&quot;<br/>            SELECT ai.load_dataset(<br/>                    &#x27;sgoel9/paul_graham_essays&#x27;, <br/>                    table_name =&gt; &#x27;essays&#x27;, <br/>                    if_table_exists =&gt; &#x27;append&#x27;);<br/>        &quot;&quot;&quot;)</span></pre><p id="7cf6" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Let’s configure a vectorizer for each embedding model using the <code class="cx qp qq qr qs b">create_vectorizer</code> function!</p><pre class="qk ql qm qn qo qt qs qu bp qv bb bk"><span id="e793" class="qw ok gu qs b bg qx qy l qz ra">EMBEDDING_MODELS = [<br/>    {&#x27;name&#x27;:&#x27;mxbai-embed-large&#x27;, &#x27;dimensions&#x27;: 1024},<br/>    {&#x27;name&#x27;:&#x27;nomic-embed-text&#x27;,&#x27;dimensions&#x27;: 768},<br/>    {&#x27;name&#x27;:&#x27;bge-m3&#x27;,&#x27;dimensions&#x27;: 1024},<br/>]<br/> <br/>for model in EMBEDDING_MODELS:<br/>    create_vectorizer(model[&#x27;name&#x27;], model[&#x27;dimensions&#x27;])</span></pre><p id="ee76" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">The order in which the vectorizers are created is the same as in the embedding generation queue. You can view the queue using the <code class="cx qp qq qr qs b"><a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/vectorizer.md?ref=timescale.ghost.io#monitor-a-vectorizer" rel="noopener ugc nofollow" target="_blank">vectorizer_status</a></code> function like this:</p><pre class="qk ql qm qn qo qt qs qu bp qv bb bk"><span id="ee50" class="qw ok gu qs b bg qx qy l qz ra">with connect_db() as conn:<br/>    with conn.cursor() as cur:<br/>        cur.execute(&quot;SELECT * FROM ai.vectorizer_status;&quot;)<br/><br/>        for row in cur.fetchall():<br/>print(f&quot;Vectorizer ID: {row[0]}, Embedding Table: {row[2]}, Pending Items: {row[4]}&quot;)</span></pre><h1 id="9551" class="oj ok gu bf ol om on oo op oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Evaluation Pipeline</h1><p id="35e8" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk"><strong class="nm gv">Rich embeddings</strong> — dense vector representations that capture text’s underlying meaning, relationships, and context — are essential for a RAG application to deliver accurate and relevant results. Our evaluation process focuses on two key aspects of embeddings:</p><ul class=""><li id="10eb" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><strong class="nm gv">Semantic understanding</strong>: The ability to capture meaning beyond exact word matches, including synonyms, paraphrases, and nuanced phrasing.</li><li id="c154" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><strong class="nm gv">Contextual retrieval</strong>: The ability to comprehend broader relationships, intent, and context within the text, ensuring the model retrieves results that align with the query’s meaning even when phrased differently.</li></ul><p id="d9ba" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">The evaluation pipeline consists of two main stages: <strong class="nm gv">test data generation</strong> and <strong class="nm gv">model evaluation</strong>.</p><h2 id="70f7" class="pu ok gu bf ol pv pw dy op px py ea ot nv pz qa qb nz qc qd qe od qf qg qh qi bk">Test data generation</h2><p id="525a" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">We create a testing dataset by leveraging the text chunks created by vectorizers during the embedding process. Here’s the step-by-step breakdown of our approach:</p><ol class=""><li id="b9df" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh rb pn po bk"><strong class="nm gv">Random chunk selection: </strong>We randomly selected <strong class="nm gv">20 text chunks</strong> by querying one of the embedding tables. Since the vectorizers used the same configurations for chunking and formatting, this ensured consistency across the data.</li><li id="3c10" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh rb pn po bk"><strong class="nm gv">Question generation:</strong> For each retrieved text chunk, we generated <strong class="nm gv">20 questions</strong> using <a class="af oi" href="https://ollama.com/library/llama3.2?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank"><strong class="nm gv">Llama3.2</strong></a>, a powerful and open-source generative LLM available through Ollama.</li></ol><p id="c69d" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">The questions were evenly distributed across the following five categories to mimic how humans ask questions. These questions allow us to simulate potential queries our RAG application would receive:</p><figure class="qk ql qm qn qo ne mw mx paragraph-image"><div role="button" tabindex="0" class="nf ng fj nh bh ni"><div class="mw mx rc"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wYQgEux6-CsW8FCc5K_uoQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*wYQgEux6-CsW8FCc5K_uoQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*wYQgEux6-CsW8FCc5K_uoQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*wYQgEux6-CsW8FCc5K_uoQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*wYQgEux6-CsW8FCc5K_uoQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*wYQgEux6-CsW8FCc5K_uoQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYQgEux6-CsW8FCc5K_uoQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*wYQgEux6-CsW8FCc5K_uoQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*wYQgEux6-CsW8FCc5K_uoQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*wYQgEux6-CsW8FCc5K_uoQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*wYQgEux6-CsW8FCc5K_uoQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*wYQgEux6-CsW8FCc5K_uoQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*wYQgEux6-CsW8FCc5K_uoQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*wYQgEux6-CsW8FCc5K_uoQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh md nj c" width="700" height="287" loading="lazy" role="presentation"/></picture></div></div></figure><p id="f3c4" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">This function generates questions of a specific type for each text chunk.</p><pre class="qk ql qm qn qo qt qs qu bp qv bb bk"><span id="dd02" class="qw ok gu qs b bg qx qy l qz ra">def generate_questions_by_question_type(chunk, question_type, num_questions):<br/>    prompts = {<br/>        &#x27;short&#x27;: &quot;Generate {count} short, simple questions about this text. Questions should be direct, under 10 words&quot;,<br/>        &#x27;long&#x27;: &quot;Generate {count} detailed, comprehensive questions about this text. Include specific details:&quot;,<br/>        &#x27;direct&#x27;: &quot;Generate {count} questions that directly ask about explicit information in this text&quot;,<br/>        &#x27;implied&#x27;: &quot;Generate {count} questions that require understanding context and implications of the text:&quot;,<br/>        &#x27;unclear&#x27;: &quot;Generate {count} vague, ambiguous questions about the general topic of this text:&quot;<br/>    }<br/><br/>    prompt = prompts[question_type].format(count=num_questions) + f&quot;\n\nText: {chunk}&quot;<br/><br/>    system_instructions = &quot;&quot;&quot;<br/>        Generate different types of questions about the given text following the prompt provided. <br/>        Each question must be on a new line. Do not include empty lines or blank questions.<br/>    &quot;&quot;&quot;<br/>    with connect_db() as conn:<br/>        with conn.cursor() as cur:<br/>            cur.execute(&quot;&quot;&quot;<br/>                SELECT ai.ollama_generate(<br/>                    &#x27;llama3.2&#x27;,<br/>                    %s,<br/>                    system_prompt=&gt;%s, <br/>                    host=&gt;%s<br/>                )-&gt;&gt;&#x27;response&#x27;;<br/>            &quot;&quot;&quot;,(prompt, system_instructions, OLLAMA_HOST))<br/>            generated_questions = [q.strip() for q in cur.fetchone()[0].split(&quot;\n&quot;) if q.strip()]<br/>            print(f&quot;Number of questions generated for {question_type}: {len(generated_questions)}&quot;)<br/>            return generated_questions</span></pre><p id="6450" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Here are some of the key insights:</p><ul class=""><li id="4773" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><strong class="nm gv">Prompt design matters</strong>: The quality of your testing dataset depends heavily on how direct and descriptive prompts and system instructions are. Being specific about your desired output leads to more accurate results from the generation question LLM.</li><li id="bbc6" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><strong class="nm gv">Integration with PostgreSQL and pgai:</strong> This function highlights the simplicity of using Ollama models within a PostgreSQL environment by leveraging the pgai function <a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/ollama.md?ref=timescale.ghost.io#generate" rel="noopener ugc nofollow" target="_blank">ollama_generate</a>.</li></ul><p id="5f0d" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Here is an example:</p><p id="22d7" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">A text chunk selected from Paul Graham’s<strong class="nm gv"> </strong><a class="af oi" href="https://paulgraham.com/start.html?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank"><strong class="nm gv">How to Start a Startup?</strong></a> (March 2005):</p><p id="7f78" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk"><em class="rd">I worried about how small and obscure we were. But in fact we were doing exactly the right thing. Once you get big (in users or employees) it gets hard to change your product. That year was effectively a laboratory for improving our software. By the end of it, we were so far ahead of our competitors that they never had a hope of catching up. And since all the hackers had spent many hours talking to users, we understood online commerce way better than anyone else.</em></p><p id="0961" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Questions generated from the text chunk and used to test it:</p><ul class=""><li id="8f62" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk">Were they ahead of their competitors by the end? <strong class="nm gv">(Short question)</strong></li><li id="9fc8" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">How did the author’s approach to product development during that year, which was referred to as a “laboratory,” enable them to gain a significant lead over their competitors in terms of software innovation? <strong class="nm gv">(Long question)</strong></li><li id="91c5" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">In what year was the startup’s lab phase concluded, and how far ahead of competitors were they by then?<strong class="nm gv"> (Direct question)</strong></li><li id="0e38" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">What motivated the author to initially worry about their startup’s small and obscure size? <strong class="nm gv">(Implied question)</strong></li><li id="2fe5" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk">In what ways did the growth of the startup force them to adapt and innovate? <strong class="nm gv">(Unclear question)</strong></li></ul><h2 id="76bb" class="pu ok gu bf ol pv pw dy op px py ea ot nv pz qa qb nz qc qd qe od qf qg qh qi bk">Model evaluation</h2><p id="68d8" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">We use vector similarity search to evaluate each embedding model’s ability to retrieve the correct parent text chunk. The goal is to check if the original text chunk appears among the <code class="cx qp qq qr qs b">top_K</code> closest matches (retrieval window) for each question in the testing dataset. Here are the steps involved:</p><ul class=""><li id="b032" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><strong class="nm gv">Performing vector similarity search:</strong> We use cosine similarity for each model and question to retrieve the <code class="cx qp qq qr qs b">top_K</code> closest embeddings.</li><li id="52f0" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><strong class="nm gv">Scoring</strong>: If the original text chunk appears in the <code class="cx qp qq qr qs b">top_K</code> results, a score of 1 is recorded. Otherwise, a score of 0 is recorded.</li><li id="b452" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><strong class="nm gv">Tallying results</strong>: We aggregate scores to compute the overall accuracy and the accuracy by question type. Breaking down results by question type provides deeper insight into where each model excels, as outliers can sometimes skew overall accuracy.</li></ul><p id="7d9c" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Selecting the size of the retrieval window is often a balance between precision and recall. A smaller window can miss correct results ranked slightly lower, while a larger one can skew the overall accuracy. We chose 10 as our <code class="cx qp qq qr qs b">top_K</code> because it strikes a balance: it’s large enough to account for semantic overlap in textual data, where many chunks may have similar embeddings yet small enough to maintain meaningful evaluation results.</p><h1 id="cf3b" class="oj ok gu bf ol om on oo op oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">The Results</h1><p id="c878" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">Our evaluation dataset, <a class="af oi" href="https://huggingface.co/datasets/sgoel9/paul_graham_essays/viewer/default/train?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Paul Graham’s essays</a>, offered a diverse mix of short, direct, and contextually rich text. The data was split into <strong class="nm gv">6,257 text chunks of 512 characters each, with a 50-character overlap</strong>. We completed this workflow using only open-source LLMs (embedding and generative models) and <strong class="nm gv">cost-free</strong> — from generation to evaluation!</p><figure class="qk ql qm qn qo ne mw mx paragraph-image"><div role="button" tabindex="0" class="nf ng fj nh bh ni"><div class="mw mx re"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*2tOXmRjGLcDt6XkR 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*2tOXmRjGLcDt6XkR 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*2tOXmRjGLcDt6XkR 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*2tOXmRjGLcDt6XkR 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*2tOXmRjGLcDt6XkR 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*2tOXmRjGLcDt6XkR 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2tOXmRjGLcDt6XkR 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*2tOXmRjGLcDt6XkR 640w, https://miro.medium.com/v2/resize:fit:720/0*2tOXmRjGLcDt6XkR 720w, https://miro.medium.com/v2/resize:fit:750/0*2tOXmRjGLcDt6XkR 750w, https://miro.medium.com/v2/resize:fit:786/0*2tOXmRjGLcDt6XkR 786w, https://miro.medium.com/v2/resize:fit:828/0*2tOXmRjGLcDt6XkR 828w, https://miro.medium.com/v2/resize:fit:1100/0*2tOXmRjGLcDt6XkR 1100w, https://miro.medium.com/v2/resize:fit:1400/0*2tOXmRjGLcDt6XkR 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="Open Source Embedding Model Overall Retrieval Accuracy" class="bh md nj c" width="700" height="423" loading="lazy"/></picture></div></div></figure><p id="5265" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk"><code class="cx qp qq qr qs b">bge-m3</code> achieved the highest overall retrieval accuracy at <strong class="nm gv">72 %</strong>, significantly outperforming the other models. <code class="cx qp qq qr qs b">mxbai-embed-large</code> followed with <strong class="nm gv">59.25 %</strong>, while <code class="cx qp qq qr qs b">nomic-embed-text</code> ranked last with <strong class="nm gv">57.25 %</strong>.</p><p id="9d80" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">While embedding models with higher dimensions (<strong class="nm gv">1,024</strong>) performed the best overall, <strong class="nm gv">the gap between </strong><code class="cx qp qq qr qs b"><strong class="nm gv">bge-m3</strong></code><strong class="nm gv"> and the other models across all question types is notable</strong>. This superior performance is likely due to <code class="cx qp qq qr qs b">bge-m3</code>’s <a class="af oi" href="https://huggingface.co/BAAI/bge-m3?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">multi-functionality</a>, allowing it to efficiently handle diverse embedding types such as <strong class="nm gv">dense, multi-factor, and sparse retrieval</strong>. This versatility enables better context comprehension, especially for long and implied questions.</p><p id="326b" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk"><code class="cx qp qq qr qs b">bge-m3</code> particularly excelled at long questions, achieving its <strong class="nm gv">highest retrieval accuracy of</strong> <strong class="nm gv">92.5 %</strong>, showcasing its strong contextual understanding. Similarly, <code class="cx qp qq qr qs b">mxbai-embed-large</code> performed well in this category, with an accuracy of <strong class="nm gv">82.5 %</strong>, further supporting <strong class="nm gv">the correlation between higher embedding dimensions and improved contextual capabilities</strong>. Interestingly, <code class="cx qp qq qr qs b">nomic-embed-text</code> also achieved its best performance on long questions, suggesting that embedding models, like humans, handle detailed and context-rich queries more effectively.</p><figure class="qk ql qm qn qo ne mw mx paragraph-image"><div role="button" tabindex="0" class="nf ng fj nh bh ni"><div class="mw mx rf"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*p4lls8F7Qm-8MYse 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*p4lls8F7Qm-8MYse 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*p4lls8F7Qm-8MYse 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*p4lls8F7Qm-8MYse 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*p4lls8F7Qm-8MYse 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*p4lls8F7Qm-8MYse 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*p4lls8F7Qm-8MYse 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*p4lls8F7Qm-8MYse 640w, https://miro.medium.com/v2/resize:fit:720/0*p4lls8F7Qm-8MYse 720w, https://miro.medium.com/v2/resize:fit:750/0*p4lls8F7Qm-8MYse 750w, https://miro.medium.com/v2/resize:fit:786/0*p4lls8F7Qm-8MYse 786w, https://miro.medium.com/v2/resize:fit:828/0*p4lls8F7Qm-8MYse 828w, https://miro.medium.com/v2/resize:fit:1100/0*p4lls8F7Qm-8MYse 1100w, https://miro.medium.com/v2/resize:fit:1400/0*p4lls8F7Qm-8MYse 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="Retrieval Accuracy by Question Type" class="bh md nj c" width="700" height="434" loading="lazy"/></picture></div></div></figure><p id="9ced" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">On the other hand, despite the difference in embedding dimensions between <code class="cx qp qq qr qs b">mxbai-embed-large</code> and <code class="cx qp qq qr qs b">nomic-embed-text</code>, their performances were comparable across all question types. <code class="cx qp qq qr qs b">nomic-embed-text</code> outperformed <code class="cx qp qq qr qs b">mxbai-embed-large</code> on short and direct questions, achieving retrieval accuracies of <strong class="nm gv">57.5 %</strong> and <strong class="nm gv">63.75 %</strong>, respectively, <strong class="nm gv">showcasing its strength in handling more minor semantic queries</strong>.</p><p id="60b4" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">While <code class="cx qp qq qr qs b">mxbai-embed-large</code> performed better on context-heavy questions, such as long and implied ones, <strong class="nm gv">the gap in accuracy was not significant</strong>. This suggests that while embedding dimensions contribute to performance, <strong class="nm gv">they are not the sole determining factor when selecting the best embedding model for your RAG application.</strong></p><p id="c1d6" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Finally, all three models performed poorly on unclear and vague questions, achieving the lowest accuracies ranging from 51.25 % for <code class="cx qp qq qr qs b">bge-m3</code> to 37.5 % for <code class="cx qp qq qr qs b">nomic-embed-text</code>.</p><h1 id="160b" class="oj ok gu bf ol om on oo op oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Choosing the Best Open-Source Embedding Model</h1><p id="ce15" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">Now that we have explored the evaluation results, how do you select the best open-source embedding model for your RAG application?</p><p id="b0ac" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Fortunately, <strong class="nm gv">cost</strong> is not part of the conversation here, as all these models are <strong class="nm gv">free to use</strong>. Instead, your choice should depend on the following key considerations:</p><ol class=""><li id="0689" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh rb pn po bk"><strong class="nm gv">What type of questions will your RAG application handle most often?</strong></li></ol><p id="80bb" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Will your queries be <strong class="nm gv">short and direct</strong>, or will they involve <strong class="nm gv">context-heavy and detailed questions</strong>?</p><p id="a142" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">This distinction helps determine the <strong class="nm gv">embedding dimensions</strong> you need. For example, models like <code class="cx qp qq qr qs b">bge-m3</code> excel at handling context-rich queries due to their higher embedding dimensions, while models like <code class="cx qp qq qr qs b">nomic-embed-text</code> are better suited for short semantic queries.</p><ul class=""><li id="03aa" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><strong class="nm gv">What resources are you willing to allocate?</strong></li></ul><p id="33a6" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">While <strong class="nm gv">embedding dimensions</strong> are critical for performance, you must also consider the <strong class="nm gv">model size</strong> and whether it fits your available resources (e.g., storage, computing).</p><p id="2662" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">For instance, if you’re constrained on storage but still need strong performance, <code class="cx qp qq qr qs b">mxbai-embed-large</code> is a good option. It balances size and sophistication, outperforming smaller models like <code class="cx qp qq qr qs b">nomic-embed-text</code> thanks to its higher dimensions.</p><ul class=""><li id="53b7" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><strong class="nm gv">How fast do you need embedding generation to be?</strong></li></ul><p id="ae58" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Another factor to consider is the <strong class="nm gv">speed at which the model generates embeddings</strong>. While embedding generation is often done <strong class="nm gv">asynchronously</strong>, creating the impression of instant processing for users, working with models <strong class="nm gv">locally</strong> can introduce challenges. Limited computational power on local machines can impact delivering a <strong class="nm gv">quick and seamless user experience</strong>.</p><p id="4034" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">For instance:</p><ul class=""><li id="cd8f" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><strong class="nm gv">Larger models</strong> like <code class="cx qp qq qr qs b">bge-m3</code> and <code class="cx qp qq qr qs b">mxbai-embed-large</code> take longer to generate embeddings due to their higher dimensions and complexity. However, they produce richer<strong class="nm gv">, </strong>more context-aware embeddings.</li><li id="44c3" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><strong class="nm gv">Smaller models</strong> like <code class="cx qp qq qr qs b">nomic-embed-text</code> generate embeddings much faster but at the cost of <strong class="nm gv">reduced richness and depth</strong>.</li></ul><p id="6673" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">When selecting an open-source embedding model, evaluating whether the embedding generation speed is critical for your use case and balancing it against the quality of embeddings needed is essential.</p><h1 id="5a5f" class="oj ok gu bf ol om on oo op oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg bk">Conclusion</h1><p id="8b46" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">This blog post explored an evaluation workflow demonstrating that choosing the best open-source embedding model for your RAG application requires balancing performance, resources, and query types.</p><p id="6ca4" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">Thanks to <strong class="nm gv">Ollama</strong> and <strong class="nm gv">pgai Vectorizer</strong>, implementing this workflow was simple and efficient. Ollama simplified model access and management, while pgai Vectorizer automated embedding generation and storage in PostgreSQL, removing the need for complex infrastructure.</p><p id="6aaa" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">These tools make evaluating and comparing open-source models more straightforward than ever, empowering you to find the best open-source solution for your needs — <strong class="nm gv">cost-free and with complete control over your data</strong>.</p><p id="a20c" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk">To try this workflow with your own data and models, check out <a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/vectorizer.md?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">pgai Vectorizer’s documentation</a>, <a class="af oi" href="https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">the quick start guide with Ollama</a>, and <a class="af oi" href="https://github.com/timescale/pgai?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">pgai’s GitHub repository</a>!</p><h2 id="8b55" class="pu ok gu bf ol pv pw dy op px py ea ot nv pz qa qb nz qc qd qe od qf qg qh qi bk">Recommended reading</h2><p id="7113" class="pw-post-body-paragraph nk nl gu nm b nn ph np nq nr pi nt nu nv pj nx ny nz pk ob oc od pl of og oh gn bk">To learn more, check out these blog posts on open-source LLMs and RAG applications with PostgreSQL:</p><ul class=""><li id="9342" class="nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh pm pn po bk"><a class="af oi" href="https://www.timescale.com/blog/open-source-vs-openai-embeddings-for-rag?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Evaluating Open-Source vs. OpenAI Embeddings for RAG: A How-To Guide</a></li><li id="a049" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><a class="af oi" href="https://www.timescale.com/blog/build-a-fully-local-rag-app-with-postgresql-mistral-and-ollama/?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Build a Fully Local RAG App With PostgreSQL, Mistral, and Ollama</a></li><li id="1e55" class="nk nl gu nm b nn pp np nq nr pq nt nu nv pr nx ny nz ps ob oc od pt of og oh pm pn po bk"><a class="af oi" href="https://www.timescale.com/blog/the-emerging-open-source-ai-stack?ref=timescale.ghost.io" rel="noopener ugc nofollow" target="_blank">Stop Paying the OpenAI Tax: The Emerging Open-Source AI Stack</a></li></ul></div></div></div><div class="ab cb rg rh ri rj" role="separator"><span class="rk by bm rl rm rn"></span><span class="rk by bm rl rm rn"></span><span class="rk by bm rl rm"></span></div><div class="gn go gp gq gr"><div class="ab cb"><div class="ci bh fz ga gb gc"><p id="45ae" class="pw-post-body-paragraph nk nl gu nm b nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh gn bk"><em class="rd">This article was written by Hervé Ishimwe</em> a<em class="rd">nd originally published </em><a class="af oi" href="https://www.timescale.com/blog/finding-the-best-open-source-embedding-model-for-rag" rel="noopener ugc nofollow" target="_blank"><em class="rd">here</em></a><em class="rd"> on the Timescale official blog on December 19, 2024.</em></p></div></div></div></div></section></div></div></article></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="ro rp ab ja"><div class="rq ab"><a class="rr ay am ao" rel="noopener follow" href="/tag/rag?source=post_page-----929d1656d331--------------------------------"><div class="rs fj cx rt ge ru rv bf b bg z bk rw">Rag</div></a></div><div class="rq ab"><a class="rr ay am ao" rel="noopener follow" href="/tag/openai?source=post_page-----929d1656d331--------------------------------"><div class="rs fj cx rt ge ru rv bf b bg z bk rw">OpenAI</div></a></div><div class="rq ab"><a class="rr ay am ao" rel="noopener follow" href="/tag/open-source?source=post_page-----929d1656d331--------------------------------"><div class="rs fj cx rt ge ru rv bf b bg z bk rw">Open Source</div></a></div><div class="rq ab"><a class="rr ay am ao" rel="noopener follow" href="/tag/programming?source=post_page-----929d1656d331--------------------------------"><div class="rs fj cx rt ge ru rv bf b bg z bk rw">Programming</div></a></div><div class="rq ab"><a class="rr ay am ao" rel="noopener follow" href="/tag/technology?source=post_page-----929d1656d331--------------------------------"><div class="rs fj cx rt ge ru rv bf b bg z bk rw">Technology</div></a></div></div></div></div><div class="l"></div><footer class="rx rh ry rz sa ab q sb ik c"><div class="l ae"><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="ab cp sc"><div class="ab q kv"><div class="sd l"><span class="l se sf sg e d"><div class="ab q kv kw"><div class="pw-multi-vote-icon fj je kx ky kz"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" rel="noopener follow" href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftimescale%2F929d1656d331&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Ftimescale%2Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331&amp;user=Team+Timescale&amp;userId=c84b80175451&amp;source=---footer_actions--929d1656d331---------------------clap_footer-----------"><div><div class="bm" aria-hidden="false"><div class="la ao lb lc ld le am lf lg lh kz"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l li lj lk ll lm ln lo"><p class="bf b dv z du"><span class="lp">--</span></p></div></div></span><span class="l h g f sh si"><div class="ab q kv kw"><div class="pw-multi-vote-icon fj je kx ky kz"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" rel="noopener follow" href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftimescale%2F929d1656d331&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Ftimescale%2Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331&amp;user=Team+Timescale&amp;userId=c84b80175451&amp;source=---footer_actions--929d1656d331---------------------clap_footer-----------"><div><div class="bm" aria-hidden="false"><div class="la ao lb lc ld le am lf lg lh kz"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l li lj lk ll lm ln lo"><p class="bf b dv z du"><span class="lp">--</span></p></div></div></span></div><div class="bq ab"><div><div class="bm" aria-hidden="false"><button class="ao la lq lr ab q fk ls lt" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="lu"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div></div><div class="ab q"><div class="rn l ix"><div><div class="bm" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" rel="noopener follow" href="/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F929d1656d331&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Ftimescale%2Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331&amp;source=---footer_actions--929d1656d331---------------------bookmark_footer-----------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du lw" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="rn l ix"><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fk ah ai aj ak al me an ao ap ex mf mg lt mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="sj sk sl sm sn l"><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="so bh r sp"></div><div class="sq l"><div class="ab sr ss st iz iy"><div class="su sv sw sx sy sz ta tb tc td ab cp"><div class="h k"><a href="https://medium.com/timescale?source=post_page---post_publication_info--929d1656d331--------------------------------" rel="noopener follow"><div class="fj ab"><img alt="Timescale" class="te ib ic cx" src="https://miro.medium.com/v2/resize:fill:96:96/1*1hiEAsTlce_ICvVpGm2Cgg.png" width="48" height="48" loading="lazy"/><div class="te l ic ib fs n fr tf"></div></div></a></div><div class="j i d"><a href="https://medium.com/timescale?source=post_page---post_publication_info--929d1656d331--------------------------------" rel="noopener follow"><div class="fj ab"><img alt="Timescale" class="te th tg cx" src="https://miro.medium.com/v2/resize:fill:128:128/1*1hiEAsTlce_ICvVpGm2Cgg.png" width="64" height="64" loading="lazy"/><div class="te l tg th fs n fr tf"></div></div></a></div><div class="j i d ti ix"><div class="ab"></div></div></div><div class="ab co tj"><div class="tk tl tm tn to l"><a class="af ag ah aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/timescale?source=post_page---post_publication_info--929d1656d331--------------------------------" rel="noopener follow"><h2 class="pw-author-name bf tq tr ts tt tu tv tw nv qa qb nz qd qe od qg qh bk"><span class="gn tp">Published in <!-- -->Timescale</span></h2></a><div class="rq ab ia"><div class="l ix"><span class="pw-follower-count bf b bg z du"><a class="af ag ah ai aj ak al am an ao ap aq ar iq" rel="noopener follow" href="/timescale/followers?source=post_page---post_publication_info--929d1656d331--------------------------------">3.3K Followers</a></span></div><div class="bf b bg z du ab jd"><span class="ir l" aria-hidden="true"><span class="bf b bg z du">·</span></span><a class="af ag ah ai aj ak al am an ao ap aq ar iq" rel="noopener follow" href="/timescale/finding-the-best-open-source-embedding-model-for-rag-929d1656d331?source=post_page---post_publication_info--929d1656d331--------------------------------">Last published <!-- -->just now</a></div></div><div class="tx l"><p class="bf b bg z bk"><span class="gn">Timescale is the cloud database engineered for performance and resource efficiency, even with large workloads — resulting in speed, scale, and savings.</span></p></div></div></div><div class="h k"><div class="ab"></div></div></div></div><div class="ab sr ss st iz iy"><div class="su sv sw sx sy sz ta tb tc td ab cp"><div class="h k"><a tabindex="0" rel="noopener follow" href="/@team-timescale?source=post_page---post_author_info--929d1656d331--------------------------------"><div class="l fj"><img alt="Team Timescale" class="l fd by ic ib cx" src="https://miro.medium.com/v2/resize:fill:96:96/1*1hiEAsTlce_ICvVpGm2Cgg.png" width="48" height="48" loading="lazy"/><div class="fr by l ic ib fs n ay tf"></div></div></a></div><div class="j i d"><a tabindex="0" rel="noopener follow" href="/@team-timescale?source=post_page---post_author_info--929d1656d331--------------------------------"><div class="l fj"><img alt="Team Timescale" class="l fd by tg th cx" src="https://miro.medium.com/v2/resize:fill:128:128/1*1hiEAsTlce_ICvVpGm2Cgg.png" width="64" height="64" loading="lazy"/><div class="fr by l tg th fs n ay tf"></div></div></a></div><div class="j i d ti ix"><div class="ab"><span><button class="bf b bg z ty rs tz ua ub uc ud ev ew ue uf ug fa fb fc fd bm fe ff">Follow</button></span></div></div></div><div class="ab co tj"><div class="tk tl tm tn to l"><a class="af ag ah aj ak al am an ao ap aq ar as at ab q" rel="noopener follow" href="/@team-timescale?source=post_page---post_author_info--929d1656d331--------------------------------"><h2 class="pw-author-name bf tq tr ts tt tu tv tw nv qa qb nz qd qe od qg qh bk"><span class="gn tp">Written by <!-- -->Team Timescale</span></h2></a><div class="rq ab ia"><div class="l ix"><span class="pw-follower-count bf b bg z du"><a class="af ag ah ai aj ak al am an ao ap aq ar iq" rel="noopener follow" href="/@team-timescale/followers?source=post_page---post_author_info--929d1656d331--------------------------------">6 Followers</a></span></div><div class="bf b bg z du ab jd"><span class="ir l" aria-hidden="true"><span class="bf b bg z du">·</span></span><a class="af ag ah ai aj ak al am an ao ap aq ar iq" rel="noopener follow" href="/@team-timescale/following?source=post_page---post_author_info--929d1656d331--------------------------------">43 Following</a></div></div><div class="tx l"><p class="bf b bg z bk"><span class="gn">Timescale blog posts, reposted for the Medium community interested in building time-series, real-time analytics, AI, and vector data applications.</span></p></div></div></div><div class="h k"><div class="ab"><span><button class="bf b bg z ty rs tz ua ub uc ud ev ew ue uf ug fa fb fc fd bm fe ff">Follow</button></span></div></div></div></div></div></div><div class="uh l"><div class="so bh r ui uj uk ul um"></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="ab q cp"><h2 class="bf tq om oo op oq os ot ou ow ox oy pa pb pc pe pf bk">No responses yet</h2><div class="ab un"><div><div class="bm" aria-hidden="false"><a class="uo up" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--929d1656d331--------------------------------" rel="noopener follow" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 25 25"><path fill-rule="evenodd" d="M11.987 5.036a.754.754 0 0 1 .914-.01c.972.721 1.767 1.218 2.6 1.543.828.322 1.719.485 2.887.505a.755.755 0 0 1 .741.757c-.018 3.623-.43 6.256-1.449 8.21-1.034 1.984-2.662 3.209-4.966 4.083a.75.75 0 0 1-.537-.003c-2.243-.874-3.858-2.095-4.897-4.074-1.024-1.951-1.457-4.583-1.476-8.216a.755.755 0 0 1 .741-.757c1.195-.02 2.1-.182 2.923-.503.827-.322 1.6-.815 2.519-1.535m.468.903c-.897.69-1.717 1.21-2.623 1.564-.898.35-1.856.527-3.026.565.037 3.45.469 5.817 1.36 7.515.884 1.684 2.25 2.762 4.284 3.571 2.092-.81 3.465-1.89 4.344-3.575.886-1.698 1.299-4.065 1.334-7.512-1.149-.039-2.091-.217-2.99-.567-.906-.353-1.745-.873-2.683-1.561m-.009 9.155a2.672 2.672 0 1 0 0-5.344 2.672 2.672 0 0 0 0 5.344m0 1a3.672 3.672 0 1 0 0-7.344 3.672 3.672 0 0 0 0 7.344m-1.813-3.777.525-.526.916.917 1.623-1.625.526.526-2.149 2.152z" clip-rule="evenodd"></path></svg></a></div></div></div></div><div class="uq ur us ut uu l"></div></div></div></div><div class="uv uw ux uy uz l bx"><div class="h k j"><div class="so bh va vb"></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="vc ab kv ja"><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----929d1656d331--------------------------------" rel="noopener follow"><p class="bf b dv z du">Help</p></a></div><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----929d1656d331--------------------------------" rel="noopener follow"><p class="bf b dv z du">Status</p></a></div><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/about?autoplay=1&amp;source=post_page-----929d1656d331--------------------------------"><p class="bf b dv z du">About</p></a></div><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----929d1656d331--------------------------------"><p class="bf b dv z du">Careers</p></a></div><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="pressinquiries@medium.com?source=post_page-----929d1656d331--------------------------------" rel="noopener follow"><p class="bf b dv z du">Press</p></a></div><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----929d1656d331--------------------------------" rel="noopener follow"><p class="bf b dv z du">Blog</p></a></div><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----929d1656d331--------------------------------" rel="noopener follow"><p class="bf b dv z du">Privacy</p></a></div><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----929d1656d331--------------------------------" rel="noopener follow"><p class="bf b dv z du">Terms</p></a></div><div class="vd ve l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----929d1656d331--------------------------------" rel="noopener follow"><p class="bf b dv z du">Text to speech</p></a></div><div class="vd l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/business?source=post_page-----929d1656d331--------------------------------"><p class="bf b dv z du">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20241218-235912-1e3024e5b3"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-929d1656d331","user-c84b80175451","collection-7fa310224bc5"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"lohpSummerUpsellEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"DEFAULT","explicit":false},"viewerIsBot":false},"debug":{"requestId":"b7e5ecaa-b539-4d21-ba69-04b182f38ab0","hybridDevServices":[],"originalSpanCarrier":{"traceparent":"00-51c9c00fc67327ee725a94e7d3f5c7a2-c9097cae6f2e7a03-01"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002Ftimescale\u002Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331","host":"medium.com","hostname":"medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20241218-235912-1e3024e5b3","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20241218-235912-1e3024e5b3","commit":"1e3024e5b30a200d8e607e363a93175b656225c2"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"7*V1_7XP4snlmqrc_0Njontw.png","height":110,"width":500},"postLogo":{"imageId":"bd978bb536350a710e8efb012513429cabdc4c28700604261aeda246d0f980b7","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"timescale\"})":{"__ref":"Collection:7fa310224bc5"},"postResult({\"id\":\"929d1656d331\"})":{"__ref":"Post:929d1656d331"}},"ImageMetadata:":{"__typename":"ImageMetadata","id":""},"Collection:7fa310224bc5":{"__typename":"Collection","id":"7fa310224bc5","favicon":{"__ref":"ImageMetadata:"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFF5F2F1","point":0},{"__typename":"ColorPoint","color":"#FFF3F0EF","point":0.1},{"__typename":"ColorPoint","color":"#FFF1EEED","point":0.2},{"__typename":"ColorPoint","color":"#FFEFECEC","point":0.3},{"__typename":"ColorPoint","color":"#FFEDEAEA","point":0.4},{"__typename":"ColorPoint","color":"#FFEBE8E8","point":0.5},{"__typename":"ColorPoint","color":"#FFE9E6E6","point":0.6},{"__typename":"ColorPoint","color":"#FFE7E5E4","point":0.7},{"__typename":"ColorPoint","color":"#FFE5E3E2","point":0.8},{"__typename":"ColorPoint","color":"#FFE4E1E0","point":0.9},{"__typename":"ColorPoint","color":"#FFE2DFDE","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF868484","point":0},{"__typename":"ColorPoint","color":"#FF7C7B7A","point":0.1},{"__typename":"ColorPoint","color":"#FF737171","point":0.2},{"__typename":"ColorPoint","color":"#FF696867","point":0.3},{"__typename":"ColorPoint","color":"#FF5F5E5E","point":0.4},{"__typename":"ColorPoint","color":"#FF555454","point":0.5},{"__typename":"ColorPoint","color":"#FF4A4949","point":0.6},{"__typename":"ColorPoint","color":"#FF3F3E3E","point":0.7},{"__typename":"ColorPoint","color":"#FF343333","point":0.8},{"__typename":"ColorPoint","color":"#FF272727","point":0.9},{"__typename":"ColorPoint","color":"#FF1A1A1A","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF000000","colorPoints":[{"__typename":"ColorPoint","color":"#FF000000","point":0},{"__typename":"ColorPoint","color":"#FF1E1D1D","point":0.1},{"__typename":"ColorPoint","color":"#FF3C3B3B","point":0.2},{"__typename":"ColorPoint","color":"#FF565555","point":0.3},{"__typename":"ColorPoint","color":"#FF6F6D6D","point":0.4},{"__typename":"ColorPoint","color":"#FF868484","point":0.5},{"__typename":"ColorPoint","color":"#FF9C9A99","point":0.6},{"__typename":"ColorPoint","color":"#FFB1AEAE","point":0.7},{"__typename":"ColorPoint","color":"#FFC5C3C2","point":0.8},{"__typename":"ColorPoint","color":"#FFD9D6D6","point":0.9},{"__typename":"ColorPoint","color":"#FFECE9E9","point":1}]}},"domain":null,"slug":"timescale","googleAnalyticsId":null,"name":"Timescale","subscriberCount":3355,"description":"Timescale is the cloud database engineered for performance and resource efficiency, even with large workloads — resulting in speed, scale, and savings.","avatar":{"__ref":"ImageMetadata:1*1hiEAsTlce_ICvVpGm2Cgg.png"},"latestPostsConnection({\"paging\":{\"limit\":1}})":{"__typename":"PostConnection","posts":[{"__ref":"Post:929d1656d331"}]},"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7fa310224bc5-viewerId:lo_e89bd7f27b39"},"twitterUsername":"timescaledb","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*gOEnwizcgWX1HSdbJslc9A.png"}},"ImageMetadata:1*1hiEAsTlce_ICvVpGm2Cgg.png":{"__typename":"ImageMetadata","id":"1*1hiEAsTlce_ICvVpGm2Cgg.png"},"User:c84b80175451":{"__typename":"User","id":"c84b80175451","customDomainState":null,"hasSubdomain":false,"username":"team-timescale","linkedAccounts":{"__ref":"LinkedAccounts:c84b80175451"},"isSuspended":false,"name":"Team Timescale","imageId":"1*1hiEAsTlce_ICvVpGm2Cgg.png","verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":6,"followingCount":38,"collectionFollowingCount":5},"bio":"Timescale blog posts, reposted for the Medium community interested in building time-series, real-time analytics, AI, and vector data applications.","membership":null,"allowNotes":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:c84b80175451-viewerId:lo_e89bd7f27b39"},"twitterScreenName":""},"Post:929d1656d331":{"__typename":"Post","id":"929d1656d331","firstPublishedAt":1734921040693,"creator":{"__ref":"User:c84b80175451"},"collection":{"__ref":"Collection:7fa310224bc5"},"isSeries":false,"mediumUrl":"https:\u002F\u002Fmedium.com\u002Ftimescale\u002Ffinding-the-best-open-source-embedding-model-for-rag-929d1656d331","sequence":null,"uniqueSlug":"finding-the-best-open-source-embedding-model-for-rag-929d1656d331","content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"6306","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"fb9e","startIndex":118,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:6845f83d273e_0"},{"__ref":"Paragraph:6845f83d273e_1"},{"__ref":"Paragraph:6845f83d273e_2"},{"__ref":"Paragraph:6845f83d273e_3"},{"__ref":"Paragraph:6845f83d273e_4"},{"__ref":"Paragraph:6845f83d273e_5"},{"__ref":"Paragraph:6845f83d273e_6"},{"__ref":"Paragraph:6845f83d273e_7"},{"__ref":"Paragraph:6845f83d273e_8"},{"__ref":"Paragraph:6845f83d273e_9"},{"__ref":"Paragraph:6845f83d273e_10"},{"__ref":"Paragraph:6845f83d273e_11"},{"__ref":"Paragraph:6845f83d273e_12"},{"__ref":"Paragraph:6845f83d273e_13"},{"__ref":"Paragraph:6845f83d273e_14"},{"__ref":"Paragraph:6845f83d273e_15"},{"__ref":"Paragraph:6845f83d273e_16"},{"__ref":"Paragraph:6845f83d273e_17"},{"__ref":"Paragraph:6845f83d273e_18"},{"__ref":"Paragraph:6845f83d273e_19"},{"__ref":"Paragraph:6845f83d273e_20"},{"__ref":"Paragraph:6845f83d273e_21"},{"__ref":"Paragraph:6845f83d273e_22"},{"__ref":"Paragraph:6845f83d273e_23"},{"__ref":"Paragraph:6845f83d273e_24"},{"__ref":"Paragraph:6845f83d273e_25"},{"__ref":"Paragraph:6845f83d273e_26"},{"__ref":"Paragraph:6845f83d273e_27"},{"__ref":"Paragraph:6845f83d273e_28"},{"__ref":"Paragraph:6845f83d273e_29"},{"__ref":"Paragraph:6845f83d273e_30"},{"__ref":"Paragraph:6845f83d273e_31"},{"__ref":"Paragraph:6845f83d273e_32"},{"__ref":"Paragraph:6845f83d273e_33"},{"__ref":"Paragraph:6845f83d273e_34"},{"__ref":"Paragraph:6845f83d273e_35"},{"__ref":"Paragraph:6845f83d273e_36"},{"__ref":"Paragraph:6845f83d273e_37"},{"__ref":"Paragraph:6845f83d273e_38"},{"__ref":"Paragraph:6845f83d273e_39"},{"__ref":"Paragraph:6845f83d273e_40"},{"__ref":"Paragraph:6845f83d273e_41"},{"__ref":"Paragraph:6845f83d273e_42"},{"__ref":"Paragraph:6845f83d273e_43"},{"__ref":"Paragraph:6845f83d273e_44"},{"__ref":"Paragraph:6845f83d273e_45"},{"__ref":"Paragraph:6845f83d273e_46"},{"__ref":"Paragraph:6845f83d273e_47"},{"__ref":"Paragraph:6845f83d273e_48"},{"__ref":"Paragraph:6845f83d273e_49"},{"__ref":"Paragraph:6845f83d273e_50"},{"__ref":"Paragraph:6845f83d273e_51"},{"__ref":"Paragraph:6845f83d273e_52"},{"__ref":"Paragraph:6845f83d273e_53"},{"__ref":"Paragraph:6845f83d273e_54"},{"__ref":"Paragraph:6845f83d273e_55"},{"__ref":"Paragraph:6845f83d273e_56"},{"__ref":"Paragraph:6845f83d273e_57"},{"__ref":"Paragraph:6845f83d273e_58"},{"__ref":"Paragraph:6845f83d273e_59"},{"__ref":"Paragraph:6845f83d273e_60"},{"__ref":"Paragraph:6845f83d273e_61"},{"__ref":"Paragraph:6845f83d273e_62"},{"__ref":"Paragraph:6845f83d273e_63"},{"__ref":"Paragraph:6845f83d273e_64"},{"__ref":"Paragraph:6845f83d273e_65"},{"__ref":"Paragraph:6845f83d273e_66"},{"__ref":"Paragraph:6845f83d273e_67"},{"__ref":"Paragraph:6845f83d273e_68"},{"__ref":"Paragraph:6845f83d273e_69"},{"__ref":"Paragraph:6845f83d273e_70"},{"__ref":"Paragraph:6845f83d273e_71"},{"__ref":"Paragraph:6845f83d273e_72"},{"__ref":"Paragraph:6845f83d273e_73"},{"__ref":"Paragraph:6845f83d273e_74"},{"__ref":"Paragraph:6845f83d273e_75"},{"__ref":"Paragraph:6845f83d273e_76"},{"__ref":"Paragraph:6845f83d273e_77"},{"__ref":"Paragraph:6845f83d273e_78"},{"__ref":"Paragraph:6845f83d273e_79"},{"__ref":"Paragraph:6845f83d273e_80"},{"__ref":"Paragraph:6845f83d273e_81"},{"__ref":"Paragraph:6845f83d273e_82"},{"__ref":"Paragraph:6845f83d273e_83"},{"__ref":"Paragraph:6845f83d273e_84"},{"__ref":"Paragraph:6845f83d273e_85"},{"__ref":"Paragraph:6845f83d273e_86"},{"__ref":"Paragraph:6845f83d273e_87"},{"__ref":"Paragraph:6845f83d273e_88"},{"__ref":"Paragraph:6845f83d273e_89"},{"__ref":"Paragraph:6845f83d273e_90"},{"__ref":"Paragraph:6845f83d273e_91"},{"__ref":"Paragraph:6845f83d273e_92"},{"__ref":"Paragraph:6845f83d273e_93"},{"__ref":"Paragraph:6845f83d273e_94"},{"__ref":"Paragraph:6845f83d273e_95"},{"__ref":"Paragraph:6845f83d273e_96"},{"__ref":"Paragraph:6845f83d273e_97"},{"__ref":"Paragraph:6845f83d273e_98"},{"__ref":"Paragraph:6845f83d273e_99"},{"__ref":"Paragraph:6845f83d273e_100"},{"__ref":"Paragraph:6845f83d273e_101"},{"__ref":"Paragraph:6845f83d273e_102"},{"__ref":"Paragraph:6845f83d273e_103"},{"__ref":"Paragraph:6845f83d273e_104"},{"__ref":"Paragraph:6845f83d273e_105"},{"__ref":"Paragraph:6845f83d273e_106"},{"__ref":"Paragraph:6845f83d273e_107"},{"__ref":"Paragraph:6845f83d273e_108"},{"__ref":"Paragraph:6845f83d273e_109"},{"__ref":"Paragraph:6845f83d273e_110"},{"__ref":"Paragraph:6845f83d273e_111"},{"__ref":"Paragraph:6845f83d273e_112"},{"__ref":"Paragraph:6845f83d273e_113"},{"__ref":"Paragraph:6845f83d273e_114"},{"__ref":"Paragraph:6845f83d273e_115"},{"__ref":"Paragraph:6845f83d273e_116"},{"__ref":"Paragraph:6845f83d273e_117"},{"__ref":"Paragraph:6845f83d273e_118"}]},"validatedShareKey":"","shareKeyCreator":null},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","primaryTopic":null,"topics":[],"isPublished":true,"latestPublishedVersion":"6845f83d273e","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":0},"clapCount":0,"allowResponses":true,"isLimitedState":false,"title":"Finding the Best Open-Source Embedding Model for RAG","socialTitle":"","socialDek":"","canonicalUrl":"https:\u002F\u002Fwww.timescale.com\u002Fblog\u002Ffinding-the-best-open-source-embedding-model-for-rag","metaDescription":"","latestPublishedAt":1734921040693,"readingTime":11.459748427672956,"previewContent":{"__typename":"PreviewContent","subtitle":"Looking for the best open-source embedding model for your RAG app? We share a comparison workflow so you can stop paying the OpenAI tax."},"previewImage":{"__ref":"ImageMetadata:0*bhXrFWJTiZEY_4UO"},"isShortform":false,"seoTitle":"","updatedAt":1734921040842,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"Looking for the best open-source embedding model for your RAG application? We share a simple comparison workflow so you can stop paying the OpenAI tax.","viewerEdge":{"__ref":"PostViewerEdge:postId:929d1656d331-viewerId:lo_e89bd7f27b39"},"isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:rag"},{"__ref":"Tag:openai"},{"__ref":"Tag:open-source"},{"__ref":"Tag:programming"},{"__ref":"Tag:technology"}],"isNewsletter":false,"statusForCollection":"APPROVED","pendingCollection":null,"detectedLanguage":"en","wordCount":2816,"layerCake":0,"responsesLocked":false},"LinkedAccounts:c84b80175451":{"__typename":"LinkedAccounts","mastodon":null,"id":"c84b80175451"},"Paragraph:6845f83d273e_0":{"__typename":"Paragraph","id":"6845f83d273e_0","name":"e5ab","type":"H3","href":null,"layout":null,"metadata":null,"text":"Finding the Best Open-Source Embedding Model for RAG","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*bhXrFWJTiZEY_4UO":{"__typename":"ImageMetadata","id":"0*bhXrFWJTiZEY_4UO","originalHeight":848,"originalWidth":1920,"focusPercentX":null,"focusPercentY":null,"alt":"Finding the Best Open-Source Embedding Model for RAG"},"Paragraph:6845f83d273e_1":{"__typename":"Paragraph","id":"6845f83d273e_1","name":"21da","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*bhXrFWJTiZEY_4UO"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_2":{"__typename":"Paragraph","id":"6845f83d273e_2","name":"062a","type":"P","href":null,"layout":null,"metadata":null,"text":"Proprietary embedding models like OpenAI’s text-embedding-large-3 and text-embedding-small are popular for retrieval-augmented augmentation (RAG) applications, but they come with added costs, third-party API dependencies, and potential data privacy concerns.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":34,"end":40,"href":"https:\u002F\u002Fplatform.openai.com\u002Fdocs\u002Fmodels?ref=timescale.ghost.io#embeddings","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":236,"end":248,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_3":{"__typename":"Paragraph","id":"6845f83d273e_3","name":"098a","type":"P","href":null,"layout":null,"metadata":null,"text":"On the other hand, open-source embedding models provide a cost-effective and customizable alternative. By running these models locally, you can stop paying the OpenAI tax and regain complete control over the embedding creation process, enhance data privacy, and tailor the models to your needs.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":144,"end":170,"href":"https:\u002F\u002Fwww.timescale.com\u002Fblog\u002Fthe-emerging-open-source-ai-stack?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_4":{"__typename":"Paragraph","id":"6845f83d273e_4","name":"dfff","type":"P","href":null,"layout":null,"metadata":null,"text":"However, evaluating open-source embedding models can be complex, time-consuming, and resource-intensive, causing many engineers to default to proprietary solutions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_5":{"__typename":"Paragraph","id":"6845f83d273e_5","name":"9e47","type":"P","href":null,"layout":null,"metadata":null,"text":"This blog post will walk you through an easy-to-replicate workflow for comparing open-source embedding models using Ollama, an open-source platform for running large language models (LLMs) locally, and pgai Vectorizer, a PostgreSQL-based tool for automating embedding generation and management with a single SQL command. Paul Graham’s essays will be our evaluation dataset to demonstrate this workflow.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":116,"end":122,"href":"https:\u002F\u002Follama.com\u002F?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":202,"end":217,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fvectorizer.md?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":321,"end":341,"href":"https:\u002F\u002Fpaulgraham.com\u002Farticles.html?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":40,"end":109,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_6":{"__typename":"Paragraph","id":"6845f83d273e_6","name":"a218","type":"H3","href":null,"layout":null,"metadata":null,"text":"Picking the Best Open-Source Embedding Model: Evaluation Workflow","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_7":{"__typename":"Paragraph","id":"6845f83d273e_7","name":"3d2c","type":"P","href":null,"layout":null,"metadata":null,"text":"An evaluation workflow for comparing open-source embedding models typically includes the following steps:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_8":{"__typename":"Paragraph","id":"6845f83d273e_8","name":"e083","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Preparing the evaluation dataset for embedding generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_9":{"__typename":"Paragraph","id":"6845f83d273e_9","name":"6806","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Downloading and setting up the embedding models on your local machine","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_10":{"__typename":"Paragraph","id":"6845f83d273e_10","name":"4012","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Setting up a vector database to store the embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_11":{"__typename":"Paragraph","id":"6845f83d273e_11","name":"857c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Generating and storing embeddings for each model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_12":{"__typename":"Paragraph","id":"6845f83d273e_12","name":"38db","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Designing the evaluation pipeline to assess the models","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_13":{"__typename":"Paragraph","id":"6845f83d273e_13","name":"94ee","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Running the embedding through the evaluation pipeline","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_14":{"__typename":"Paragraph","id":"6845f83d273e_14","name":"608d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Comparing the results to identify the best model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_15":{"__typename":"Paragraph","id":"6845f83d273e_15","name":"874a","type":"P","href":null,"layout":null,"metadata":null,"text":"While this workflow may sound straightforward, implementing it can quickly become complex and resource-intensive due to several challenges:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_16":{"__typename":"Paragraph","id":"6845f83d273e_16","name":"f308","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Access and management of open-source models: Installing dependencies and ensuring system compatibility for each embedding model can be tedious. Storage management is another concern, as large models can consume significant space on your local machine.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":43,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_17":{"__typename":"Paragraph","id":"6845f83d273e_17","name":"2f0a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Automating embedding generation: Building a reliable workflow to generate and ingest embeddings across multiple models is complex. You’ll need to handle resource limitations, monitor errors, and ensure efficiency, which can require significant effort.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_18":{"__typename":"Paragraph","id":"6845f83d273e_18","name":"e9d4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Creating a fair and robust evaluation pipeline: Selecting the proper evaluation dataset and defining clear and relevant criteria — like retrieval quality or search accuracy — are essential to ensuring consistent, unbiased, and meaningful evaluations across all models.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":46,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_19":{"__typename":"Paragraph","id":"6845f83d273e_19","name":"ce19","type":"P","href":null,"layout":null,"metadata":null,"text":"Fear not — we can make this easier!","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_20":{"__typename":"Paragraph","id":"6845f83d273e_20","name":"e4e4","type":"P","href":null,"layout":null,"metadata":null,"text":"While the specifics of a robust evaluation pipeline may vary depending on your RAG application, you can significantly reduce the complexity with just two tools: Ollama for accessing and managing the embedding models and pgai Vectorizer for automating embedding generation and management across multiple models (we shared how to automate embedding generation in a previous article).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":328,"end":357,"href":"https:\u002F\u002Fwww.timescale.com\u002Fblog\u002Fhow-to-automatically-create-update-embeddings-in-postgresql?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":161,"end":167,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":220,"end":235,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_21":{"__typename":"Paragraph","id":"6845f83d273e_21","name":"499e","type":"P","href":null,"layout":null,"metadata":null,"text":"Want to follow along? Check out this GitHub repository for all the code used in this post.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":37,"end":54,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Ftree\u002Fmain\u002Fexamples\u002Ffinding_best_open_source_embedding_model?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_22":{"__typename":"Paragraph","id":"6845f83d273e_22","name":"3a5e","type":"H3","href":null,"layout":null,"metadata":null,"text":"Ollama: Simplified Access to Open-Source Embedding Models","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_23":{"__typename":"Paragraph","id":"6845f83d273e_23","name":"b224","type":"P","href":null,"layout":null,"metadata":null,"text":"Ollama makes running open-source models effortless by eliminating dependency and compatibility headaches. Simply download and run the model — no complex setup required. It works seamlessly across macOS, Linux, Windows, and Docker environments. In this evaluation, we are running Ollama within a Docker container.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_24":{"__typename":"Paragraph","id":"6845f83d273e_24","name":"c0f8","type":"P","href":null,"layout":null,"metadata":null,"text":"Ollama simplifies model management by bundling a model’s configuration, data, and weights. This bundle makes cleanup and experimentation straightforward while ensuring full data ownership — you retain complete control over how your data is handled and where it flows.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_25":{"__typename":"Paragraph","id":"6845f83d273e_25","name":"001a","type":"H4","href":null,"layout":null,"metadata":null,"text":"Open-source embedding models compared","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_26":{"__typename":"Paragraph","id":"6845f83d273e_26","name":"1790","type":"P","href":null,"layout":null,"metadata":null,"text":"Ollama provides access to state-of-the-art large language models. In this evaluation, we compared three of the most popular embedding models available on Ollama:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":154,"end":160,"href":"https:\u002F\u002Follama.com\u002Fsearch?c=embedding&ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*paXYY4s_s_SvRReXVG7dLQ.png":{"__typename":"ImageMetadata","id":"1*paXYY4s_s_SvRReXVG7dLQ.png","originalHeight":144,"originalWidth":746,"focusPercentX":null,"focusPercentY":null,"alt":"Open-source embedding models compared"},"Paragraph:6845f83d273e_27":{"__typename":"Paragraph","id":"6845f83d273e_27","name":"6793","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*paXYY4s_s_SvRReXVG7dLQ.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_28":{"__typename":"Paragraph","id":"6845f83d273e_28","name":"d2e3","type":"P","href":null,"layout":null,"metadata":null,"text":"These open-source embedding models rival industry-standard proprietary embedding models like OpenAI’s:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_29":{"__typename":"Paragraph","id":"6845f83d273e_29","name":"0204","type":"ULI","href":null,"layout":null,"metadata":null,"text":"nomic-embed-text: outperforms text-embedding-ada-002 and text-embedding-3-small on both short and long-context text embedding tasks","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":16,"href":"https:\u002F\u002Fwww.nomic.ai\u002Fblog\u002Fposts\u002Fnomic-embed-text-v1?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":30,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":57,"end":79,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_30":{"__typename":"Paragraph","id":"6845f83d273e_30","name":"003f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"mxbai-embed-large: outperforms text-embedding-3-large while being significantly smaller than the latter.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":17,"href":"https:\u002F\u002Fhuggingface.co\u002Fmixedbread-ai\u002Fmxbai-embed-large-v1?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":31,"end":53,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_31":{"__typename":"Paragraph","id":"6845f83d273e_31","name":"f117","type":"H3","href":null,"layout":null,"metadata":null,"text":"Pgai Vectorizer: Automatic Embedding Management in PostgreSQL","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_32":{"__typename":"Paragraph","id":"6845f83d273e_32","name":"3ba3","type":"P","href":null,"layout":null,"metadata":null,"text":"Pgai Vectorizer eliminates the need to build complex automation infrastructure to generate and manage embeddings across multiple models. It is an open-source, powerful tool designed to automate embedding creation and management directly in PostgreSQL, a widely adopted and robust database with vector capabilities via extensions like pgvector and pgai.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":15,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fvectorizer.md?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":334,"end":342,"href":"https:\u002F\u002Fgithub.com\u002Fpgvector\u002Fpgvector?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":347,"end":351,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_33":{"__typename":"Paragraph","id":"6845f83d273e_33","name":"f7bb","type":"P","href":null,"layout":null,"metadata":null,"text":"In this evaluation, we use PostgreSQL as our database to store the evaluation dataset and its corresponding embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_34":{"__typename":"Paragraph","id":"6845f83d273e_34","name":"27fb","type":"P","href":null,"layout":null,"metadata":null,"text":"What sets pgai Vectorizer apart for this use case is its integration with Ollama, allowing you to generate embeddings using any open-source model supported by Ollama.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":57,"end":80,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_35":{"__typename":"Paragraph","id":"6845f83d273e_35","name":"1f86","type":"P","href":null,"layout":null,"metadata":null,"text":"To configure a vectorizer for each embedding model, just use one SQL command with all the configurations needed for your embeddings, as demonstrated below in the create_vectorizer function. You can find more about these configurations in pgai Vectorizer’s API reference.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":162,"end":179,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":238,"end":269,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fvectorizer-api-reference.md?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_36":{"__typename":"Paragraph","id":"6845f83d273e_36","name":"e722","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def create_vectorizer(embedding_model, embeddings_dimensions):\n    embeddings_view_name = f\"{'essays'}{'_'}{embedding_model.replace('-','_')}{'_'}{'embeddings'}\"\n\n    with connect_db() as conn:\n        with conn.cursor() as cur:\n            cur.execute(\"\"\"\n                SELECT ai.create_vectorizer(\n                'essays'::regclass,\n                destination =\u003E %s,\n                embedding =\u003E ai.embedding_ollama(%s, %s),\n                chunking =\u003E ai.chunking_recursive_character_text_splitter('text', 512, 50),\n                formatting =\u003E ai.formatting_python_template('title: $title $chunk')\n            );\n            \"\"\", (embeddings_view_name, embedding_model, embeddings_dimensions, )\n            )","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_37":{"__typename":"Paragraph","id":"6845f83d273e_37","name":"aa8a","type":"P","href":null,"layout":null,"metadata":null,"text":"From there, pgai Vectorizer handles all the heavy lifting:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_38":{"__typename":"Paragraph","id":"6845f83d273e_38","name":"5c5a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Automatically generating and updating embeddings as your dataset changes","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_39":{"__typename":"Paragraph","id":"6845f83d273e_39","name":"22fb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Splitting the data into chunks and formatting them","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_40":{"__typename":"Paragraph","id":"6845f83d273e_40","name":"58f3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Creating a table to store the embeddings with the specified name","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_41":{"__typename":"Paragraph","id":"6845f83d273e_41","name":"c843","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Generating a view that combines your data with its embeddings for easy access and querying","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_42":{"__typename":"Paragraph","id":"6845f83d273e_42","name":"c62a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Manages the embedding generation queue","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_43":{"__typename":"Paragraph","id":"6845f83d273e_43","name":"91bf","type":"P","href":null,"layout":null,"metadata":null,"text":"Using this Docker compose file, you can quickly configure PostgreSQL, the pgai Vectorizer worker, and Ollama services in your Docker environment.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":11,"end":30,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fvectorizer-quick-start.md?ref=timescale.ghost.io#setup-a-local-development-environment","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_44":{"__typename":"Paragraph","id":"6845f83d273e_44","name":"2d88","type":"P","href":null,"layout":null,"metadata":null,"text":"To get started, check out this quick start guide for more on pgai Vectorizer’s integration with Ollama.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":31,"end":48,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fvectorizer-quick-start.md?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_45":{"__typename":"Paragraph","id":"6845f83d273e_45","name":"0e42","type":"H4","href":null,"layout":null,"metadata":null,"text":"Configuring multiple vectorizers","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_46":{"__typename":"Paragraph","id":"6845f83d273e_46","name":"a0ab","type":"P","href":null,"layout":null,"metadata":null,"text":"After running your PostgreSQL service, install the pgai extension. Then, you can insert the evaluation dataset, Paul Graham’s essays, using the pgai function load_datasets, which loads datasets from Hugging Face directly into your database!","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":158,"end":171,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":51,"end":55,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai?tab=readme-ov-file&ref=timescale.ghost.io#quick-start","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":112,"end":132,"href":"https:\u002F\u002Fhuggingface.co\u002Fdatasets\u002Fsgoel9\u002Fpaul_graham_essays?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":158,"end":171,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fload_dataset_from_huggingface.md?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_47":{"__typename":"Paragraph","id":"6845f83d273e_47","name":"eb5e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"with connect_db() as conn:\n   with conn.cursor() as cur:\n        # Load Paul Graham's essays dataset into the 'essays' table\n        cur.execute(\"\"\"\n            SELECT ai.load_dataset(\n                    'sgoel9\u002Fpaul_graham_essays', \n                    table_name =\u003E 'essays', \n                    if_table_exists =\u003E 'append');\n        \"\"\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_48":{"__typename":"Paragraph","id":"6845f83d273e_48","name":"7cf6","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s configure a vectorizer for each embedding model using the create_vectorizer function!","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":64,"end":81,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_49":{"__typename":"Paragraph","id":"6845f83d273e_49","name":"e793","type":"PRE","href":null,"layout":null,"metadata":null,"text":"EMBEDDING_MODELS = [\n    {'name':'mxbai-embed-large', 'dimensions': 1024},\n    {'name':'nomic-embed-text','dimensions': 768},\n    {'name':'bge-m3','dimensions': 1024},\n]\n \nfor model in EMBEDDING_MODELS:\n    create_vectorizer(model['name'], model['dimensions'])","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"rust"},"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_50":{"__typename":"Paragraph","id":"6845f83d273e_50","name":"ee76","type":"P","href":null,"layout":null,"metadata":null,"text":"The order in which the vectorizers are created is the same as in the embedding generation queue. You can view the queue using the vectorizer_status function like this:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":130,"end":147,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":130,"end":147,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fvectorizer.md?ref=timescale.ghost.io#monitor-a-vectorizer","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_51":{"__typename":"Paragraph","id":"6845f83d273e_51","name":"ee50","type":"PRE","href":null,"layout":null,"metadata":null,"text":"with connect_db() as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT * FROM ai.vectorizer_status;\")\n\n        for row in cur.fetchall():\nprint(f\"Vectorizer ID: {row[0]}, Embedding Table: {row[2]}, Pending Items: {row[4]}\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_52":{"__typename":"Paragraph","id":"6845f83d273e_52","name":"9551","type":"H3","href":null,"layout":null,"metadata":null,"text":"Evaluation Pipeline","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_53":{"__typename":"Paragraph","id":"6845f83d273e_53","name":"35e8","type":"P","href":null,"layout":null,"metadata":null,"text":"Rich embeddings — dense vector representations that capture text’s underlying meaning, relationships, and context — are essential for a RAG application to deliver accurate and relevant results. Our evaluation process focuses on two key aspects of embeddings:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_54":{"__typename":"Paragraph","id":"6845f83d273e_54","name":"10eb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Semantic understanding: The ability to capture meaning beyond exact word matches, including synonyms, paraphrases, and nuanced phrasing.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_55":{"__typename":"Paragraph","id":"6845f83d273e_55","name":"c154","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Contextual retrieval: The ability to comprehend broader relationships, intent, and context within the text, ensuring the model retrieves results that align with the query’s meaning even when phrased differently.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_56":{"__typename":"Paragraph","id":"6845f83d273e_56","name":"d9ba","type":"P","href":null,"layout":null,"metadata":null,"text":"The evaluation pipeline consists of two main stages: test data generation and model evaluation.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":53,"end":73,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":78,"end":94,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_57":{"__typename":"Paragraph","id":"6845f83d273e_57","name":"70f7","type":"H4","href":null,"layout":null,"metadata":null,"text":"Test data generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_58":{"__typename":"Paragraph","id":"6845f83d273e_58","name":"525a","type":"P","href":null,"layout":null,"metadata":null,"text":"We create a testing dataset by leveraging the text chunks created by vectorizers during the embedding process. Here’s the step-by-step breakdown of our approach:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_59":{"__typename":"Paragraph","id":"6845f83d273e_59","name":"b9df","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Random chunk selection: We randomly selected 20 text chunks by querying one of the embedding tables. Since the vectorizers used the same configurations for chunking and formatting, this ensured consistency across the data.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":45,"end":59,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_60":{"__typename":"Paragraph","id":"6845f83d273e_60","name":"3c10","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Question generation: For each retrieved text chunk, we generated 20 questions using Llama3.2, a powerful and open-source generative LLM available through Ollama.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":84,"end":92,"href":"https:\u002F\u002Follama.com\u002Flibrary\u002Fllama3.2?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":65,"end":77,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":84,"end":92,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_61":{"__typename":"Paragraph","id":"6845f83d273e_61","name":"c69d","type":"P","href":null,"layout":null,"metadata":null,"text":"The questions were evenly distributed across the following five categories to mimic how humans ask questions. These questions allow us to simulate potential queries our RAG application would receive:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*wYQgEux6-CsW8FCc5K_uoQ.png":{"__typename":"ImageMetadata","id":"1*wYQgEux6-CsW8FCc5K_uoQ.png","originalHeight":340,"originalWidth":831,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:6845f83d273e_62":{"__typename":"Paragraph","id":"6845f83d273e_62","name":"8d4b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*wYQgEux6-CsW8FCc5K_uoQ.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_63":{"__typename":"Paragraph","id":"6845f83d273e_63","name":"f3c4","type":"P","href":null,"layout":null,"metadata":null,"text":"This function generates questions of a specific type for each text chunk.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_64":{"__typename":"Paragraph","id":"6845f83d273e_64","name":"dd02","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def generate_questions_by_question_type(chunk, question_type, num_questions):\n    prompts = {\n        'short': \"Generate {count} short, simple questions about this text. Questions should be direct, under 10 words\",\n        'long': \"Generate {count} detailed, comprehensive questions about this text. Include specific details:\",\n        'direct': \"Generate {count} questions that directly ask about explicit information in this text\",\n        'implied': \"Generate {count} questions that require understanding context and implications of the text:\",\n        'unclear': \"Generate {count} vague, ambiguous questions about the general topic of this text:\"\n    }\n\n    prompt = prompts[question_type].format(count=num_questions) + f\"\\n\\nText: {chunk}\"\n\n    system_instructions = \"\"\"\n        Generate different types of questions about the given text following the prompt provided. \n        Each question must be on a new line. Do not include empty lines or blank questions.\n    \"\"\"\n    with connect_db() as conn:\n        with conn.cursor() as cur:\n            cur.execute(\"\"\"\n                SELECT ai.ollama_generate(\n                    'llama3.2',\n                    %s,\n                    system_prompt=\u003E%s, \n                    host=\u003E%s\n                )-\u003E\u003E'response';\n            \"\"\",(prompt, system_instructions, OLLAMA_HOST))\n            generated_questions = [q.strip() for q in cur.fetchone()[0].split(\"\\n\") if q.strip()]\n            print(f\"Number of questions generated for {question_type}: {len(generated_questions)}\")\n            return generated_questions","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_65":{"__typename":"Paragraph","id":"6845f83d273e_65","name":"6450","type":"P","href":null,"layout":null,"metadata":null,"text":"Here are some of the key insights:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_66":{"__typename":"Paragraph","id":"6845f83d273e_66","name":"4773","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Prompt design matters: The quality of your testing dataset depends heavily on how direct and descriptive prompts and system instructions are. Being specific about your desired output leads to more accurate results from the generation question LLM.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_67":{"__typename":"Paragraph","id":"6845f83d273e_67","name":"bbc6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Integration with PostgreSQL and pgai: This function highlights the simplicity of using Ollama models within a PostgreSQL environment by leveraging the pgai function ollama_generate.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":165,"end":180,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Follama.md?ref=timescale.ghost.io#generate","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_68":{"__typename":"Paragraph","id":"6845f83d273e_68","name":"5f0d","type":"P","href":null,"layout":null,"metadata":null,"text":"Here is an example:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_69":{"__typename":"Paragraph","id":"6845f83d273e_69","name":"22d7","type":"P","href":null,"layout":null,"metadata":null,"text":"A text chunk selected from Paul Graham’s How to Start a Startup? (March 2005):","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":41,"end":64,"href":"https:\u002F\u002Fpaulgraham.com\u002Fstart.html?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":40,"end":64,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_70":{"__typename":"Paragraph","id":"6845f83d273e_70","name":"7f78","type":"P","href":null,"layout":null,"metadata":null,"text":"I worried about how small and obscure we were. But in fact we were doing exactly the right thing. Once you get big (in users or employees) it gets hard to change your product. That year was effectively a laboratory for improving our software. By the end of it, we were so far ahead of our competitors that they never had a hope of catching up. And since all the hackers had spent many hours talking to users, we understood online commerce way better than anyone else.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":467,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_71":{"__typename":"Paragraph","id":"6845f83d273e_71","name":"0961","type":"P","href":null,"layout":null,"metadata":null,"text":"Questions generated from the text chunk and used to test it:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_72":{"__typename":"Paragraph","id":"6845f83d273e_72","name":"8f62","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Were they ahead of their competitors by the end? (Short question)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":49,"end":65,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_73":{"__typename":"Paragraph","id":"6845f83d273e_73","name":"9fc8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"How did the author’s approach to product development during that year, which was referred to as a “laboratory,” enable them to gain a significant lead over their competitors in terms of software innovation? (Long question)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":207,"end":222,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_74":{"__typename":"Paragraph","id":"6845f83d273e_74","name":"91c5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"In what year was the startup’s lab phase concluded, and how far ahead of competitors were they by then? (Direct question)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":103,"end":121,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_75":{"__typename":"Paragraph","id":"6845f83d273e_75","name":"0e38","type":"ULI","href":null,"layout":null,"metadata":null,"text":"What motivated the author to initially worry about their startup’s small and obscure size? (Implied question)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":91,"end":109,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_76":{"__typename":"Paragraph","id":"6845f83d273e_76","name":"2fe5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"In what ways did the growth of the startup force them to adapt and innovate? (Unclear question)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":77,"end":95,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_77":{"__typename":"Paragraph","id":"6845f83d273e_77","name":"76bb","type":"H4","href":null,"layout":null,"metadata":null,"text":"Model evaluation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_78":{"__typename":"Paragraph","id":"6845f83d273e_78","name":"68d8","type":"P","href":null,"layout":null,"metadata":null,"text":"We use vector similarity search to evaluate each embedding model’s ability to retrieve the correct parent text chunk. The goal is to check if the original text chunk appears among the top_K closest matches (retrieval window) for each question in the testing dataset. Here are the steps involved:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":184,"end":189,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_79":{"__typename":"Paragraph","id":"6845f83d273e_79","name":"b032","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Performing vector similarity search: We use cosine similarity for each model and question to retrieve the top_K closest embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":106,"end":111,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_80":{"__typename":"Paragraph","id":"6845f83d273e_80","name":"52f0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Scoring: If the original text chunk appears in the top_K results, a score of 1 is recorded. Otherwise, a score of 0 is recorded.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":51,"end":56,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_81":{"__typename":"Paragraph","id":"6845f83d273e_81","name":"b452","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Tallying results: We aggregate scores to compute the overall accuracy and the accuracy by question type. Breaking down results by question type provides deeper insight into where each model excels, as outliers can sometimes skew overall accuracy.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_82":{"__typename":"Paragraph","id":"6845f83d273e_82","name":"7d9c","type":"P","href":null,"layout":null,"metadata":null,"text":"Selecting the size of the retrieval window is often a balance between precision and recall. A smaller window can miss correct results ranked slightly lower, while a larger one can skew the overall accuracy. We chose 10 as our top_K because it strikes a balance: it’s large enough to account for semantic overlap in textual data, where many chunks may have similar embeddings yet small enough to maintain meaningful evaluation results.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":226,"end":231,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_83":{"__typename":"Paragraph","id":"6845f83d273e_83","name":"cf3b","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Results","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_84":{"__typename":"Paragraph","id":"6845f83d273e_84","name":"c878","type":"P","href":null,"layout":null,"metadata":null,"text":"Our evaluation dataset, Paul Graham’s essays, offered a diverse mix of short, direct, and contextually rich text. The data was split into 6,257 text chunks of 512 characters each, with a 50-character overlap. We completed this workflow using only open-source LLMs (embedding and generative models) and cost-free — from generation to evaluation!","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":24,"end":44,"href":"https:\u002F\u002Fhuggingface.co\u002Fdatasets\u002Fsgoel9\u002Fpaul_graham_essays\u002Fviewer\u002Fdefault\u002Ftrain?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":138,"end":207,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":302,"end":311,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*2tOXmRjGLcDt6XkR":{"__typename":"ImageMetadata","id":"0*2tOXmRjGLcDt6XkR","originalHeight":663,"originalWidth":1099,"focusPercentX":null,"focusPercentY":null,"alt":"Open Source Embedding Model Overall Retrieval Accuracy"},"Paragraph:6845f83d273e_85":{"__typename":"Paragraph","id":"6845f83d273e_85","name":"daa7","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*2tOXmRjGLcDt6XkR"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_86":{"__typename":"Paragraph","id":"6845f83d273e_86","name":"5265","type":"P","href":null,"layout":null,"metadata":null,"text":"bge-m3 achieved the highest overall retrieval accuracy at 72 %, significantly outperforming the other models. mxbai-embed-large followed with 59.25 %, while nomic-embed-text ranked last with 57.25 %.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":6,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":110,"end":127,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":157,"end":173,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":58,"end":62,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":142,"end":149,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":191,"end":198,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_87":{"__typename":"Paragraph","id":"6845f83d273e_87","name":"9d80","type":"P","href":null,"layout":null,"metadata":null,"text":"While embedding models with higher dimensions (1,024) performed the best overall, the gap between bge-m3 and the other models across all question types is notable. This superior performance is likely due to bge-m3’s multi-functionality, allowing it to efficiently handle diverse embedding types such as dense, multi-factor, and sparse retrieval. This versatility enables better context comprehension, especially for long and implied questions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":98,"end":104,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":207,"end":213,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":216,"end":235,"href":"https:\u002F\u002Fhuggingface.co\u002FBAAI\u002Fbge-m3?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":47,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":82,"end":162,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":303,"end":344,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_88":{"__typename":"Paragraph","id":"6845f83d273e_88","name":"326b","type":"P","href":null,"layout":null,"metadata":null,"text":"bge-m3 particularly excelled at long questions, achieving its highest retrieval accuracy of 92.5 %, showcasing its strong contextual understanding. Similarly, mxbai-embed-large performed well in this category, with an accuracy of 82.5 %, further supporting the correlation between higher embedding dimensions and improved contextual capabilities. Interestingly, nomic-embed-text also achieved its best performance on long questions, suggesting that embedding models, like humans, handle detailed and context-rich queries more effectively.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":6,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":159,"end":176,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":362,"end":378,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":62,"end":91,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":92,"end":98,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":230,"end":236,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":257,"end":345,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*p4lls8F7Qm-8MYse":{"__typename":"ImageMetadata","id":"0*p4lls8F7Qm-8MYse","originalHeight":566,"originalWidth":914,"focusPercentX":null,"focusPercentY":null,"alt":"Retrieval Accuracy by Question Type"},"Paragraph:6845f83d273e_89":{"__typename":"Paragraph","id":"6845f83d273e_89","name":"1632","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*p4lls8F7Qm-8MYse"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_90":{"__typename":"Paragraph","id":"6845f83d273e_90","name":"9ced","type":"P","href":null,"layout":null,"metadata":null,"text":"On the other hand, despite the difference in embedding dimensions between mxbai-embed-large and nomic-embed-text, their performances were comparable across all question types. nomic-embed-text outperformed mxbai-embed-large on short and direct questions, achieving retrieval accuracies of 57.5 % and 63.75 %, respectively, showcasing its strength in handling more minor semantic queries.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":74,"end":91,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":96,"end":112,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":176,"end":192,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":206,"end":223,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":289,"end":295,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":300,"end":307,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":323,"end":386,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_91":{"__typename":"Paragraph","id":"6845f83d273e_91","name":"60b4","type":"P","href":null,"layout":null,"metadata":null,"text":"While mxbai-embed-large performed better on context-heavy questions, such as long and implied ones, the gap in accuracy was not significant. This suggests that while embedding dimensions contribute to performance, they are not the sole determining factor when selecting the best embedding model for your RAG application.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":6,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":100,"end":139,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":214,"end":320,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_92":{"__typename":"Paragraph","id":"6845f83d273e_92","name":"c1d6","type":"P","href":null,"layout":null,"metadata":null,"text":"Finally, all three models performed poorly on unclear and vague questions, achieving the lowest accuracies ranging from 51.25 % for bge-m3 to 37.5 % for nomic-embed-text.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":132,"end":138,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":153,"end":169,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_93":{"__typename":"Paragraph","id":"6845f83d273e_93","name":"160b","type":"H3","href":null,"layout":null,"metadata":null,"text":"Choosing the Best Open-Source Embedding Model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_94":{"__typename":"Paragraph","id":"6845f83d273e_94","name":"ce15","type":"P","href":null,"layout":null,"metadata":null,"text":"Now that we have explored the evaluation results, how do you select the best open-source embedding model for your RAG application?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_95":{"__typename":"Paragraph","id":"6845f83d273e_95","name":"b0ac","type":"P","href":null,"layout":null,"metadata":null,"text":"Fortunately, cost is not part of the conversation here, as all these models are free to use. Instead, your choice should depend on the following key considerations:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":13,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":80,"end":91,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_96":{"__typename":"Paragraph","id":"6845f83d273e_96","name":"0689","type":"OLI","href":null,"layout":null,"metadata":null,"text":"What type of questions will your RAG application handle most often?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":67,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_97":{"__typename":"Paragraph","id":"6845f83d273e_97","name":"80bb","type":"P","href":null,"layout":null,"metadata":null,"text":"Will your queries be short and direct, or will they involve context-heavy and detailed questions?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":21,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":60,"end":96,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_98":{"__typename":"Paragraph","id":"6845f83d273e_98","name":"a142","type":"P","href":null,"layout":null,"metadata":null,"text":"This distinction helps determine the embedding dimensions you need. For example, models like bge-m3 excel at handling context-rich queries due to their higher embedding dimensions, while models like nomic-embed-text are better suited for short semantic queries.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":93,"end":99,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":199,"end":215,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":37,"end":57,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_99":{"__typename":"Paragraph","id":"6845f83d273e_99","name":"03aa","type":"ULI","href":null,"layout":null,"metadata":null,"text":"What resources are you willing to allocate?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":43,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_100":{"__typename":"Paragraph","id":"6845f83d273e_100","name":"33a6","type":"P","href":null,"layout":null,"metadata":null,"text":"While embedding dimensions are critical for performance, you must also consider the model size and whether it fits your available resources (e.g., storage, computing).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":6,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":84,"end":94,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_101":{"__typename":"Paragraph","id":"6845f83d273e_101","name":"2662","type":"P","href":null,"layout":null,"metadata":null,"text":"For instance, if you’re constrained on storage but still need strong performance, mxbai-embed-large is a good option. It balances size and sophistication, outperforming smaller models like nomic-embed-text thanks to its higher dimensions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":82,"end":99,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":189,"end":205,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_102":{"__typename":"Paragraph","id":"6845f83d273e_102","name":"53b7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"How fast do you need embedding generation to be?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":48,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_103":{"__typename":"Paragraph","id":"6845f83d273e_103","name":"ae58","type":"P","href":null,"layout":null,"metadata":null,"text":"Another factor to consider is the speed at which the model generates embeddings. While embedding generation is often done asynchronously, creating the impression of instant processing for users, working with models locally can introduce challenges. Limited computational power on local machines can impact delivering a quick and seamless user experience.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":34,"end":79,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":122,"end":136,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":215,"end":222,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":319,"end":353,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_104":{"__typename":"Paragraph","id":"6845f83d273e_104","name":"4034","type":"P","href":null,"layout":null,"metadata":null,"text":"For instance:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_105":{"__typename":"Paragraph","id":"6845f83d273e_105","name":"cd8f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Larger models like bge-m3 and mxbai-embed-large take longer to generate embeddings due to their higher dimensions and complexity. However, they produce richer, more context-aware embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":19,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":30,"end":47,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":158,"end":160,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_106":{"__typename":"Paragraph","id":"6845f83d273e_106","name":"44c3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Smaller models like nomic-embed-text generate embeddings much faster but at the cost of reduced richness and depth.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":20,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":88,"end":114,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_107":{"__typename":"Paragraph","id":"6845f83d273e_107","name":"6673","type":"P","href":null,"layout":null,"metadata":null,"text":"When selecting an open-source embedding model, evaluating whether the embedding generation speed is critical for your use case and balancing it against the quality of embeddings needed is essential.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_108":{"__typename":"Paragraph","id":"6845f83d273e_108","name":"5a5f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_109":{"__typename":"Paragraph","id":"6845f83d273e_109","name":"8b46","type":"P","href":null,"layout":null,"metadata":null,"text":"This blog post explored an evaluation workflow demonstrating that choosing the best open-source embedding model for your RAG application requires balancing performance, resources, and query types.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_110":{"__typename":"Paragraph","id":"6845f83d273e_110","name":"6ca4","type":"P","href":null,"layout":null,"metadata":null,"text":"Thanks to Ollama and pgai Vectorizer, implementing this workflow was simple and efficient. Ollama simplified model access and management, while pgai Vectorizer automated embedding generation and storage in PostgreSQL, removing the need for complex infrastructure.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":10,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":21,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_111":{"__typename":"Paragraph","id":"6845f83d273e_111","name":"6aaa","type":"P","href":null,"layout":null,"metadata":null,"text":"These tools make evaluating and comparing open-source models more straightforward than ever, empowering you to find the best open-source solution for your needs — cost-free and with complete control over your data.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":163,"end":213,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_112":{"__typename":"Paragraph","id":"6845f83d273e_112","name":"a20c","type":"P","href":null,"layout":null,"metadata":null,"text":"To try this workflow with your own data and models, check out pgai Vectorizer’s documentation, the quick start guide with Ollama, and pgai’s GitHub repository!","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":62,"end":93,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fvectorizer.md?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":95,"end":128,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai\u002Fblob\u002Fmain\u002Fdocs\u002Fvectorizer-quick-start.md?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":134,"end":158,"href":"https:\u002F\u002Fgithub.com\u002Ftimescale\u002Fpgai?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_113":{"__typename":"Paragraph","id":"6845f83d273e_113","name":"8b55","type":"H4","href":null,"layout":null,"metadata":null,"text":"Recommended reading","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_114":{"__typename":"Paragraph","id":"6845f83d273e_114","name":"7113","type":"P","href":null,"layout":null,"metadata":null,"text":"To learn more, check out these blog posts on open-source LLMs and RAG applications with PostgreSQL:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_115":{"__typename":"Paragraph","id":"6845f83d273e_115","name":"9342","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Evaluating Open-Source vs. OpenAI Embeddings for RAG: A How-To Guide","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":68,"href":"https:\u002F\u002Fwww.timescale.com\u002Fblog\u002Fopen-source-vs-openai-embeddings-for-rag?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_116":{"__typename":"Paragraph","id":"6845f83d273e_116","name":"a049","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Build a Fully Local RAG App With PostgreSQL, Mistral, and Ollama","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":64,"href":"https:\u002F\u002Fwww.timescale.com\u002Fblog\u002Fbuild-a-fully-local-rag-app-with-postgresql-mistral-and-ollama\u002F?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_117":{"__typename":"Paragraph","id":"6845f83d273e_117","name":"1e55","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Stop Paying the OpenAI Tax: The Emerging Open-Source AI Stack","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":61,"href":"https:\u002F\u002Fwww.timescale.com\u002Fblog\u002Fthe-emerging-open-source-ai-stack?ref=timescale.ghost.io","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:6845f83d273e_118":{"__typename":"Paragraph","id":"6845f83d273e_118","name":"45ae","type":"P","href":null,"layout":null,"metadata":null,"text":"This article was written by Hervé Ishimwe and originally published here on the Timescale official blog on December 19, 2024.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":67,"end":71,"href":"https:\u002F\u002Fwww.timescale.com\u002Fblog\u002Ffinding-the-best-open-source-embedding-model-for-rag","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":43,"end":124,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7fa310224bc5-viewerId:lo_e89bd7f27b39":{"__typename":"CollectionViewerEdge","id":"collectionId:7fa310224bc5-viewerId:lo_e89bd7f27b39","isEditor":false,"isMuting":false},"UserViewerEdge:userId:c84b80175451-viewerId:lo_e89bd7f27b39":{"__typename":"UserViewerEdge","id":"userId:c84b80175451-viewerId:lo_e89bd7f27b39","isMuting":false},"ImageMetadata:1*gOEnwizcgWX1HSdbJslc9A.png":{"__typename":"ImageMetadata","id":"1*gOEnwizcgWX1HSdbJslc9A.png","originalWidth":1919,"originalHeight":703},"PostViewerEdge:postId:929d1656d331-viewerId:lo_e89bd7f27b39":{"__typename":"PostViewerEdge","shouldIndexPostForExternalSearch":true,"id":"postId:929d1656d331-viewerId:lo_e89bd7f27b39"},"Tag:rag":{"__typename":"Tag","id":"rag","displayTitle":"Rag","normalizedTagSlug":"rags"},"Tag:openai":{"__typename":"Tag","id":"openai","displayTitle":"OpenAI","normalizedTagSlug":"openai"},"Tag:open-source":{"__typename":"Tag","id":"open-source","displayTitle":"Open Source","normalizedTagSlug":"open-source"},"Tag:programming":{"__typename":"Tag","id":"programming","displayTitle":"Programming","normalizedTagSlug":"programming"},"Tag:technology":{"__typename":"Tag","id":"technology","displayTitle":"Technology","normalizedTagSlug":"technology"}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT"}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.48bdf878.js"></script><script src="https://cdn-client.medium.com/lite/static/js/9865.1496d74a.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.872afbe3.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.d9108df7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.ff22a7a5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9120.5df29668.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5049.d1ead72d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4810.6318add7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6618.db187378.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2707.a4e221ac.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9977.933c1c9a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8599.73cb8339.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5250.9f9e01d2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9898.d9e26c5e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2648.26563adf.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8393.826a25fb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4863.28ab43f6.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6589.247b1d02.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5642.0f82ef97.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6546.cd03f950.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6834.8aa8d357.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2420.2a5e2d95.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/839.1c286b32.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7975.60bcefe8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2106.0350840b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7394.73a57633.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5794.9e8ff5dd.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8204.7749bc66.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4391.59acaed3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.2dc8b1c6.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8414.6565ad5f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3974.8d3e0217.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2527.d5e0c2f5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostResponsesContent.7ad7ca92.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/responses.editor.5a11f4da.chunk.js"></script><script>window.main();</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'8f665d160b3678ec',t:'MTczNDkzNjA2Mi4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>