<!--
title: 边缘AI的精妙适配：功耗、模型与安全三维考量
cover: https://cdn.thenewstack.io/media/2025/10/6cad83f8-getty-images-wuhuzbqd1ju-unsplash-1.jpg
summary: 边缘AI将智能部署到数据源，降低延迟，实现实时决策。得益于专用芯片和标准化开源平台，应用广泛。未来重点关注功耗、安全和数据控制。
-->

边缘AI将智能部署到数据源，降低延迟，实现实时决策。得益于专用芯片和标准化开源平台，应用广泛。未来重点关注功耗、安全和数据控制。

> 译自：[Right-Sizing AI for the Edge: Power, Models and Security](https://thenewstack.io/right-sizing-ai-for-the-edge-power-models-and-security/)
> 
> 作者：Chris J. Preimesberger

MOUNTAIN VIEW, 加利福尼亚州 — 在 [Edge Impulse](https://edgeimpulse.com/) 最近关于 [边缘 AI](https://thenewstack.io/ai-is-coming-to-the-edge-but-it-will-look-different/) 的小组讨论中，三位行业领袖分享了他们对将 AI 部署到更靠近数据生成地点的机遇和挑战的看法。本次小组讨论由 The New Stack 的创始人兼出版商 Alex Williams 主持，小组成员包括 [IDT Solution](https://idtsolution.com/) 首席执行官 Margherita Ferragatta、[Ampere Computing](https://amperecomputing.com/) 首席布道师 Sean Varley 以及 [Canonical](https://canonical.com/) 软件合作负责人 Aniket Ponkshe。

他们共同描绘了一个快速转型中的生态系统——在这个生态系统中，标准化平台、专用芯片和 [开发者优先](https://thenewstack.io/comcast-cut-app-vulnerabilities-with-developer-first-approach/) 的方法正在重新定义企业如何将 AI 工作负载从云端迁移到边缘。

边缘 AI 指的是将 AI 模型直接部署到数据生成地点附近的设备或基础设施上，例如传感器、摄像头、车辆或工业机器，而不是集中式云数据中心。通过在本地处理数据，边缘 AI 降低了延迟、带宽成本，增强了隐私并实现了实时决策，即使在连接受限的情况下也能如此。它结合了机器学习 (ML) 的进步、专用芯片和轻量级软件框架，在网络边缘提供智能功能——为自动驾驶汽车、工业自动化、零售分析和智能能源系统等领域的应用提供支持。

从商店货架到工厂生产线，边缘 AI 在最需要的地方实现低延迟决策。正如本文后面的用例所示，边缘不仅是实验的前沿阵地——它正迅速成为一个可用于生产的环境。

[![](https://cdn.thenewstack.io/media/2025/10/1809fecd-edge-it-2-1.png)](https://cdn.thenewstack.io/media/2025/10/1809fecd-edge-it-2-1.png)

*从左到右：Alex Williams, Margherita Ferragatta, Aniket Ponkshe 和 Sean Varley.*

## 降低边缘 AI 的门槛

不久前，在边缘运行 AI 在技术上是难以实现的。模型受限于有限的计算能力，为云设计的框架不适用于嵌入式环境。如今已非如此。

自 2017 年以来，芯片架构和开源框架的创新极大地降低了进入门槛。Varley 表示：“你现在可以在非常小的设备上完成像 [YOLO](https://en.wikipedia.org/wiki/You_Only_Look_Once)（计算机视觉中的实时目标检测系统）这样的任务，或者在 CPU、GPU 和加速器上运行拥有万亿参数的大型语言模型 [LLM]。生态系统在整个技术栈——硬件、操作系统、框架和应用程序——中都得到了发展。”

这一演变开启了新的可能性：设备级的计算机视觉、工厂车间的实时分析，甚至为零售商提供支持边缘的推荐引擎。

## 边缘 Ubuntu

对于 Ubuntu 的制造商 Canonical 而言，边缘 AI 的兴起验证了多年来在轻量级、安全操作系统上的投入。Ponkshe 回忆起 Ubuntu Core 在 2010 年代中期推出时，就预见到了在边缘对开发者友好、类云环境的需求。

Ponkshe 说：“边缘 AI 有一系列独特的挑战。嵌入式开发者和云原生开发者常常使用不同的语言。技术栈也不同，企业越来越期望即使在小型设备上也能获得云级别的安全性。Ubuntu 的作用就是将这些世界融合在一起，这样你就可以在云端训练并在边缘部署相同的技术栈——用几周而非几个月的时间。”

Canonical 还在平台标准化方面大力推动，与芯片厂商合作，以确保在各种硬件上的优化性能。结果是：开发者可以专注于构建应用程序，而不是处理设备特定的集成问题。

## 开源遇见工业自动化

Ferragata 将 IDT 的使命描述为将开源硬件和软件引入工业自动化领域，这是一个历史上由专有系统和厂商锁定主导的行业。早期，IDT 转向了 [Arduino](https://www.arduino.cc/)，甚至在工业级板卡出现之前。Arduino 是一个开源硬件和软件平台，旨在简化电子项目的构建和原型开发。

Ferragata 说：“一开始很困难。在 2016 年和 2017 年，Arduino 尚未达到工业级水平。我们不得不自行进行大量合作和开发。但最终，Arduino Pro 出现了，我们交付了诸如为一家豪华汽车制造商开发的电池单元处理系统等项目——这些系统完全运行在 Arduino 硬件上。”

对于 Ferragata 而言，教训是清晰的：开源硬件和软件可以在曾经被认为过于严苛的环境中取得成功。在一个工厂和车辆要求确定性的离线响应时间的时代，支持边缘的开放系统可以减少对脆弱连接的依赖，并缩短上市时间。

## 硬件淘金热

如果说开源正在重塑软件，那么专用芯片正在重新定义硬件层。Varley 将其称为 AI 计算领域的一场“淘金热”，从超大规模数据中心到小型边缘设备无不如此。

他说：“每一层都有功耗成本。无论你是在 GPU 机架上运行 AI，还是在电池供电的传感器上运行，功耗现在是决定性的限制因素。从模型大小到容器占用空间，每个层面的优化都很重要。”

Ampere 的战略重点是构建具有高能效比的可持续处理器，从拥有近 200 个核心的服务器级 CPU 扩展到适用于边缘的配置。Varley 预测，很快，所有计算都将以功耗而非抽象的性能基准来衡量。业界巨星，如前 Intel 首席执行官 Pat Gelsinger 和 NVIDIA 首席执行官 Jensen Huang，也曾公开表示赞同这一理论。

## 新兴用例

凭借更快的芯片和优化的框架，企业正从概念验证阶段迈向生产阶段。Ponkshe 引用了实际部署案例：

*   **零售：** 一家主要的美国零售商利用 Canonical 的 ML 技术栈，在销售点实施了实时推荐系统，将转化率提高了 10%。
*   **能源：** Duke Energy 正在将边缘 AI 应用于可再生能源电网的实时负载平衡，在风能或太阳能输出波动时动态调整供应。
*   **汽车制造与运营：** 工厂和车辆正在成为边缘平台。IDT 基于 Arduino 的自动化系统工作展示了开源硬件和 AI 如何为豪华汽车制造商管理电池单元处理等流程。同时，车载 AI 承诺实现确定性的响应时间——在驾驶辅助或自动驾驶功能方面，毫秒级的响应至关重要。
*   **智能视频和安全系统：** 从内置神经网络的摄像头到跨电信基础设施的分布式分析，边缘 AI 正在改变视频的捕获和处理方式。系统不再将原始视频流发送到云端，而是在源头分析视频、标记异常并仅将相关数据发送到上游——从而减少带宽并实现更快的响应。
*   **工业自动化和机器人技术：** 边缘 AI 使工厂变得更智能，而不仅仅是更快。机器人现在可以实时协作，低延迟协调在边缘进行。这减少了对脆弱连接的依赖，即使在网络故障时也能确保连续性，并让操作员能够专注于更高价值的任务——推动从工业 4.0 向工业 5.0 的转变，其中以人为中心的设计和灵活性将是关键。

Ponkshe 说：“这些是五年前不可能实现的用例。现在它们在经济上是可行的，因为我们可以在靠近数据源的地方处理数据，降低延迟，并始终将安全性置于核心位置。”

## 模型尺寸优化

一个反复出现的主题是需要根据可用硬件“优化”AI 模型尺寸。大型 LLM 可能需要机架级计算能力，但小型、特定任务的模型可以在边缘高效运行。

Varley 说：“模型的尺寸决定了它可以在哪里运行。框架不仅要针对工作负载进行优化，还要针对特定的芯片架构进行优化。这样才能确保边缘设备完成其力所能及的工作，而云端只处理它必须处理的任务。”

随着传感器和设备数量激增，这种平衡变得越来越关键。数百万个生成数据的端点不能全部依赖集中式云处理。边缘部署提供了一种降低成本和延迟，同时提高韧性的方法。

## 汽车行业：缓慢但稳定

由于汽车是边缘设备，汽车行业现在是边缘计算的战场——但文化和技术惯性仍然减缓了其采用速度。Ferragata 观察到，虽然汽车制造商看到了更快上市时间和确定性离线功能的好处，但许多厂商仍然受限于传统的专有系统。

她说：“在制造业中，不能总是依赖连接性。响应时间需要是确定性的——有时甚至要达到毫秒级。这正是边缘 AI 真正体现其价值的地方，但其采用仍然是循序渐进的。”

尽管如此，随着车辆本身成为移动的边缘平台，大规模集成 AI 的压力也越来越大。

## 开发者想要什么

对于开发者而言，边缘 AI 的成功取决于平台简洁性和一致性。Ponkshe 说，标准化的技术栈——包括 [TensorFlow](https://thenewstack.io/python-tutorial-use-tensorflow-to-generate-predictive-text/)、[MLflow](https://thenewstack.io/address-common-machine-learning-challenges-with-managed-mlflow/) 或 [Kubeflow](https://thenewstack.io/smooth-sailing-for-kubeflow-1-9-thanks-to-cncf-red-hat-support/) 等熟悉的框架——让开发者将时间花在应用程序上，而不是调试操作系统启动或硬件问题上。

他说：“开发者想要一个针对边缘硬件优化的类云环境。这正是加速创新的关键。你可以在云端使用同样的工具，只是它们针对你部署的设备进行了调整。”

Canonical 的长期支持保证和生态系统合作伙伴关系旨在增强这种信任，帮助开发者放心地进行实验，而不必担心今天的工作明天就会过时。

## 展望未来：功耗、安全和控制

会议结束时，每位小组成员都分享了对边缘 AI 未来发展的“愿望清单”：

*   **Ferragata (IDT)：** 在工业环境中更容易采用开放技术，更大的灵活性，以及更多人认识到开源系统足够可靠，足以胜任关键任务的生产。
*   **Varley (Ampere)：** 以最小功耗提供最大性能的硬件，通过将 AI 加速、通用处理、传感器和存储结合到越来越小的 SoC 中的异构设计来实现。
*   **Ponkshe (Canonical)：** 赋予数据创建者更多控制权的平台——将处理保持在更靠近边缘的位置，以实现主权和货币化，同时通过设计嵌入安全性。

安全性尤其重要。从工厂到车辆，安全漏洞可能使运营瘫痪数月。监管压力正在上升，企业将要求边缘部署达到与云相同的安全标准。

## 边缘 AI 处于转折点

小组成员一致认为：边缘 AI 不再是实验性的。对于需要在数据中心之外实现低延迟、韧性和安全 AI 的企业来说，它正成为一种核心架构模式。各项要素正在汇集——标准化操作系统平台、可持续处理器、优化框架和工业级开放硬件。

Varley 总结道：“我们通过针对边缘优化模型和基础设施尺寸来简化 AI 的复杂性。最终，功耗将成为普遍的基准。这就是我们如何从超大规模到最小设备，可持续地扩展 AI 的方式。”