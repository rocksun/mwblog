Google is beginning to [launch Gemini 3 today](https://blog.google/products/gemini/gemini-3/), a new series of models the company says is its “most intelligent” and “factually accurate” AI systems yet. They’re also a chance for Google to leap ahead of OpenAI following the rocky launch of GPT-5, potentially putting the company at the forefront of consumer-focused AI models.

For the first time, Google is giving everyone access to its new flagship AI model — Gemini 3 Pro — in the Gemini app on day one. It’s also rolling out Gemini 3 Pro to subscribers inside Search. Tulsee Doshi, Google DeepMind’s senior director and head of product, says the new model will bring the company closer to making information “universally accessible and useful” as its search engine continues to evolve.

“I think the one really big step in that direction is to step out of the paradigm of just text responses and to give you a much richer, more complete view of what you can actually see.”

[![Gemini 3 Pro’s enhanced coding capabilities allow it to generate better visuals.](https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/gemini3-visualization.gif?quality=90&strip=all&crop=0%2C0%2C100%2C100&w=2400)](https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/gemini3-visualization.gif?quality=90&strip=all&crop=0,0,100,100)

*Gemini 3 Pro’s enhanced coding capabilities allow it to generate better visuals.*

 GIF: Google

Gemini 3 Pro is “natively multimodal,” meaning it can process text, images, and audio all at once, rather than handling them separately. As an example, Google says Gemini 3 Pro could be used to translate photos of recipes and then transform them into a cookbook, or it could create interactive flashcards based on a series of video lectures.

You’ll spot some of these improvements across Google’s suite of products, including the Gemini app, where you can build more “full-featured” [programs inside the built-in workspace, Canvas](/google/631726/google-gemini-canvas-audio-overview-notebooklm-coding). The upgraded AI model will also enable “generative interfaces,” a tool Google is testing in Gemini Labs that allows Gemini 3 Pro to create a visual, magazine-style format with pictures you can browse through, or a dynamic layout with a custom user interface tailored to your prompt.

[![An experimental “Dynamic View” in the Gemini app creates a webpage-like experience for certain queries.](https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/google-gemini-3-dynamic-view.gif?quality=90&strip=all&crop=0%2C0%2C100%2C100&w=2400)](https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/google-gemini-3-dynamic-view.gif?quality=90&strip=all&crop=0,0,100,100)

*An experimental “Dynamic View” in the Gemini app creates a webpage-like experience for certain queries.*

 GIF: Google

Gemini 3 Pro in AI Mode — the AI-powered Google Search feature — will similarly present you with visual elements, like images, tables, grids, and simulations based on your query. It’s also capable of performing more searches using an upgraded version of [Google’s “query fan-out technique,”](/google/671200/google-googling-ai-mode-project-mariner-i-o-2025) which now not only breaks down questions into bits it can search for on your behalf, but is better at understanding intent to help “find new content that it may have previously missed,” according to Google’s announcement.

Google is also not so subtly jabbing at OpenAI, describing Gemini 3 Pro as less prone to the type of empty flattery espoused by ChatGPT. Doshi says you’ll see “noticeable” changes to Gemini 3 Pro’s responses, which Google describes as offering a “smart, concise and direct, trading cliche and flattery for genuine insight — telling you what you need to hear, not just what you want to hear.” The company says it also shows “reduced sycophancy,” an issue [OpenAI had to address with ChatGPT earlier this year](/news/661422/openai-chatgpt-sycophancy-update-what-went-wrong).

Along with these improvements, Gemini 3 Pro comes with better reasoning and agentic capabilities, allowing it to complete more complex tasks and “reliably plan ahead over longer horizons,” according to Google. The AI model is powering an experimental Gemini Agent feature that can perform tasks on your behalf inside the Gemini app, such as reviewing and organizing emails, or researching and booking travel.

[![Gemini 3 Pro in AI Mode can embed interactive simulations into its responses.](https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/google-gemini-simulation.gif?quality=90&strip=all&crop=0%2C0%2C100%2C100&w=2400)](https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/google-gemini-simulation.gif?quality=90&strip=all&crop=0,0,100,100)

*Gemini 3 Pro in AI Mode can embed interactive simulations into its responses.*

 GIF: Google

Gemini 3 Pro now sits at the top of LMArena’s leaderboard, a popular platform used for benchmarking AI models. A Deep Think mode enhances the model’s reasoning capabilities even further, though it’s currently only available to safety testers.

Gemini 3 Pro is available inside the Gemini app for everyone starting today, while Google AI Pro and Ultra subscribers in the US can try out Gemini 3 Pro inside AI Mode by selecting “Thinking” from the model dropdown. Gemini Agent is rolling out first to AI Ultra subscribers.

**Follow topics and authors** from this story to see more like this in your personalized homepage feed and to receive email updates.

* Emma Roth
* AI
* Google
* News
* Tech