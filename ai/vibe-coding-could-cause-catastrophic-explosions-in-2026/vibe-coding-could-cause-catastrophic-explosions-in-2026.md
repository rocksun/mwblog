<!--
title: 2026年氛围编程危机：或引发灾难性“爆炸”
cover: https://cdn.thenewstack.io/media/2026/01/401dbc80-nasa-dcgbraqmtqa-unsplash.jpg
summary: 专家警告，2026年氛围编程将大量涌入生产环境，若对AI生成代码审查不力，恐引发灾难性安全问题，需加强测试并优先使用验证组件。
-->

专家警告，2026年氛围编程将大量涌入生产环境，若对AI生成代码审查不力，恐引发灾难性安全问题，需加强测试并优先使用验证组件。

> 译自：[Vibe coding could cause catastrophic ‘explosions' in 2026](https://thenewstack.io/vibe-coding-could-cause-catastrophic-explosions-in-2026/)
> 
> 作者：Darryl K. Taft

氛围编程应用程序在生产环境中的稳步构建将给那些未充分审查人工智能开发的软件的组织带来灾难性问题，一位软件安全专家预测。

开发者安全提供商 Arcjet 的创始人兼 CEO David Mytton 在一篇 LinkedIn 帖子中写道：“到2026年，我预计会有越来越多的氛围编程应用程序大量投入生产。这对提高速度很有利……但你仍然需要注意。将会有一些大‘爆炸’发生！”

我问他这是什么意思，Mytton 补充说，他预计氛围编程应用程序将“无处不在”地投入生产，这可能会带来问题。

“开发者正在编写更多代码并更快地部署它们，却不完全理解它们在做什么，” Mytton 告诉 *The New Stack*。“我同意 Simon Willison 的预测，即在某个时候我们将遭遇一场‘挑战者号’灾难。根本原因将是某个由人工智能编写的核心组件未被充分理解或检查。”

Willison 是一位英国程序员，也是 Django web 框架的共同创建者和社交会议目录 Lanyrd 的联合创始人。

这个比较可能有些夸张，但 Willison 在他的帖子中写道：“我认为，在编码代理安全方面，我们即将遭遇一场挑战者号灾难……我认为包括我在内的许多人，几乎都在以 root 权限运行这些编码代理，对吧？我们让他们做所有这些事情。每次我这样做的时候，我的电脑都没有被擦除。我就想，‘哦，没关系。’”

Willison 指的是1986年的挑战者号航天飞机灾难，当时航天飞机在起飞后不久爆炸，导致机上所有人员遇难。这场灾难发生于下周，即1986年1月28日，距今已有40年。

## 氛围编程“有时”奏效

同时，Mytton 认为“氛围编程确实有效。有时有效。但大多数开发者都忽略了一个区别。影响范围是不同的。”

他还解释说，氛围编程有其合理的使用场景，例如：

*   用于测试可行性并计划后续重写的抛弃式原型。
*   作为编辑器进行的小幅修改。
*   在有测试或经过验证的、行为可预测的库（例如使用已知 SDK 进行速率限制）的约束下实施。

然而，Mytton 指出，你并不总是知道人工智能为你的代码库带来了什么，并问道：你对返回的内容了解有多深？你如何测试它？它到底在做什么？

对此，Mytton 告诉 *The New Stack*，“强类型语言在使用 AI 编码器时具有优势，因为当出现错误时编译器会报错。对于像 Rust 这样的语言，当出现不正确的情况时编译器甚至会报错。这一直是该语言的一个优点，但代价是陡峭的学习曲线。现在 AI 可以编写可证明正确的代码，也许这就不再重要了？”

否则，你需要一个全面的测试套件来确保代码更改不会破坏功能。他指出，这可能意味着端到端测试。

## AI 不应从零开始发明安全性

“这对于安全关键型代码最为重要。如果你无法正确审查它，你将承担你可能没有意识到的风险，” Mytton 写道。“这就是为什么 AI 应该实施经过验证的组件，而不是从零开始发明安全性。”

此外，Mytton 在博文中表示，AI 应该实施经过验证的组件，而不是从零开始发明安全性。

在接受 *The New Stack* 采访时，他补充道：“如果有一个预构建的组件可以使用，你不一定非要从零开始编写。经典的例子是：不要自己编写加密。而是使用经过实战考验的库。这对于其他安全机制也适用，比如编写自己的机器人检测。AI 可以引入一个已知安全的组件并利用其功能，而不是从零开始编写。”

然而，在去年的一篇 博文中，提供氛围编程安全解决方案的 Mobb 创始人兼 CEO Eitan Worcel 写道：“在氛围编程之前的世界里，安全待办事项列表是你可能在下次审计前解决的已知问题清单。这很糟糕，但相对可控。现在，那些未解决的漏洞正在积极地塑造你的团队明天编写的代码。你的待办事项不再是静态债务；它是一种会影响每一行新代码的主动风险。”

在接受 *The New Stack* 采访时，Worcel 表示他同意 Mytton 的观点，即需要依赖验证过的安全最佳实践，而不是让人工智能提出一些开发人员可能难以审查且“肯定”未经实战检验的虚构方法。

此外，Worcel 表示他不一定同意将 AI 限制为向现有项目添加功能会比让它从零开始编写代码更安全。

“事实上，根据我的经验，并非如此，”他说。“大多数已存在多年（甚至数十年）的生产应用程序都带有大量到非常大量的安全待办事项。当你提示 大型语言模型 添加功能时，它会首先查看应用程序代码，如果它发现一个可用于实现所请求功能的模式，它就会将其视为‘已批准的模式’，并优先使用该模式，而不是利用其自身的知识，即使该模式是脆弱的。”

然而，Mytton 说，当你告诉 AI“我正在遭受机器人流量攻击，请修复它”时，它不应该编写你无法验证的新颖检测逻辑。它应该安装一个经过验证的库。编写配置。编写测试。运行它们。验证阻断是否有效。

最后，Mytton 问道：“那么底线在哪里？截至2026年1月：

*   围绕经过验证的组件进行脚手架搭建：可以。
*   你无法验证的新颖安全实现：不可以。
*   对现有代码进行的小型可审查更改：可以。
*   从零开始的整个代码库：仅在将其视为一次性使用时。