在大型语言模型的未来梦想中，将不再需要人工干预，它们将以我们无法阅读的高度高效形式编写代码。也许它们会直接用二进制编写。但目前，我们需要我们的LLM助手以既定的编程语言编写可读的代码。

那么，LLM如今更喜欢使用哪些语言呢？就人类开发者中最流行的编程语言而言（我们假设模型从中获取训练材料），选择应该在JavaScript/TypeScript、Java和Python之间。但实际上，我们并没有完全看到这一点。

## LLM代码生成中当前的Python偏好

我们现在看到的是巨大的Python偏好，正如一项[学术研究](https://arxiv.org/html/2503.17181v1)所指出。结论是直截了当的：“我们的发现表明，LLM对Python表现出强烈的偏好，无论是在基准任务还是项目初始化任务中都倾向于选择Python，即使存在更合适的选择。”

然而，同一项研究提出了一个更重要的主张：“LLM在选择编程库时范围有限，更偏爱成熟的选项而非高质量的替代方案。”Python越来越受欢迎，但有人怀疑LLM的创建者更青睐Python训练集。

这并不是特别令人担忧。在许多情况下，LLM工具会开始处理遗留代码，其中语言已经选定。或者所选语言是主要库或平台特性的一部分，而该特性在Python中不可用。

但该研究还发现，当对GPT-4o使用思维链提示（例如“*think step by step”*）时，用于项目初始化任务的编程语言对Python的偏好明显降低：

[![](https://cdn.thenewstack.io/media/2026/01/4df64806-image.png)](https://cdn.thenewstack.io/media/2026/01/4df64806-image.png)

[思维链](https://arxiv.org/html/2503.17181v1)

（图中标明了所使用的语言、使用该语言的响应百分比以及LLM分配给该语言的排名。）

但随着LLM在行业专业人士中的使用日益增长，人们认为Javascript和Java将确立其地位。

## 开源模型日益增长的影响力

更好的问题是：LLM*应该*选择哪些语言？这个问题的答案可能由两件事决定：开源模型的增加，以及开源组件日益增长的影响力。

我问了[Warp](https://thenewstack.io/warp-goes-agentic-a-developer-walk-through-of-warp-2-0/)（这款出色的终端工具）的CEO Zach Lloyd，Warp在2026年最可能利用哪些AI技术？他明确表示是开源模型。“随着它们不断改进，我们将把它们与专有选项一起使用，这给了我们更多的选择性和弹性，”他说。“这一层面的竞争对开发者生态系统也非常好，因为它提高了质量并降低了价格。”

开源模型没有公司项目可以偏袒。因此，你可能会认为OpenAI会温和地推动微软的C#，也许Gemini会更容易获得Golang。但开源模型只会倾向于使用开发者合法可用的代码进行训练。

## 为什么可维护性在AI生成代码中很重要

“适者生存”工具发出的最强烈信号将仅仅是生成代码需要减少“氛围化”并更易于维护。这意味着将偏好从当前流行的语言和框架转向那些具有久经考验的血统和更受信任的示例。

例如，我们看到Web Components的突出也是出于同样的原因。Web Components是一个[标准](https://thenewstack.io/web-components-are-the-comeback-nobody-saw-coming/)，它终于获得了大众的青睐。是的，它们一直[提供封装、可重用性和框架独立性](https://thenewstack.io/the-pros-and-cons-of-web-components-via-lit-and-shoelace/)，但直到最近一些粗糙之处才被磨平。

工程师，尤其是资深工程师，阅读和审查代码比他们编写的代码多；随着LLM生成代码的增多，这种情况可能会加剧。因此，如果酷炫的新模式使用过于频繁，实际上会造成摩擦。

## 降低LLM计算中的非确定性

坚持使用久经考验的代码的另一个原因是降低LLM计算的[非确定性性质](https://thenewstack.io/martin-fowler-on-preparing-for-ais-nondeterministic-computing/)——即它们根据日期的不同选择不同选项的倾向。虽然像编码助手这样的工具的[温度](https://thenewstack.io/what-temperature-means-in-natural-language-processing-and-ai/)总是设置得很低，但LLM逐令牌生成的性质意味着它们在完成生成之前不知道自己会写什么。

LLM模糊的“思维”可能在一个时间点产生一个答案，而在另一个时间点产生一个完全不同的答案。它在任何给定时间构建的答案都依赖于[统计推理](https://thenewstack.io/how-to-generate-ai-from-a-database-bruce-momjian/)，但这些使用概率集，而不是我们通常与计算相关的二进制方法。

因此，基于这些原因，我可以看到训练偏好转向更稳定的项目、更开放的项目以及拥有更长公开可用示例历史的项目。随着LLM走向商品化，或者在[Wardley图](https://thenewstack.io/wardley-mapping-and-strategy-for-software-developers/)上向右移动，稳定性将成为主导因素。

## 代码“种子库”的案例

我们被告知，世界所有重要的植物都出现在种子库中，以便我们可以在灾难后重新繁殖。种子库是一个在适宜稳定条件下储存来自各种植物物种（野生和栽培）种子的储存库。因此，它是一个“诺亚方舟”，但用于植物。我写这篇文章时，就坐在能够看到邱园的地方，邱园管理着[千年种子库](https://www.kew.org/wakehurst/whats-at-wakehurst/millennium-seed-bank)。

[![](https://cdn.thenewstack.io/media/2026/01/aaf427a6-image-1-1024x576.png)](https://cdn.thenewstack.io/media/2026/01/aaf427a6-image-1-1024x576.png)

千年种子库；图片来源：邱园。

每次我们说“训练数据”时，我们都会模糊地指向互联网上可用的论坛和页面。这就是为什么我们必须假设训练是基于现在互联网上的内容的。我们真正需要的是一个代码种子库。这对于一个受信任的组织来说应该很容易建立，这样就可以在没有供应商污染或第三方毒害风险的情况下维护一组不断增长的示例。虽然对大量互联网文本的平均处理将提供一个坚实的平均值，但显然，一套更紧凑的数据集将是新模型开始训练的更好起点。

我们不喜欢谈论互联网遭受严重损害，因为这可能暗示一些灾难性事件。而且我们知道其军事遗产中的设计使得这种情况不太可能发生。我们真正的意思是，应该存在一些“其他”地方，我们知道那里存在一个安全的数据池，以便训练不总是依赖于当前——且非常动态——的网络状态。

## LLM编程的未来

我们仍处于LLM之旅的起点；目前，它们在生成新示例代码时将使用训练数据中最常出现的代码和项目。目前，这意味着互联网上更丰富的部分，并且带有额外的Python偏好。

下一步将是使用那些最不可能随时间改变的项目的代码，以克服LLM的非确定性。我们现在可能正处于这一阶段的边缘。

只有在遥远的未来，AI才会彼此交流并开发自己的中间语言，届时人类可访问性将不再是优先事项。