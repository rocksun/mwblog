OpenAI 的全新 [GPT-5.3-Codex](https://openai.com/index/introducing-gpt-5-3-codex/) 模型是该公司迄今为止最强大的智能代理编程模型。然而，与之前的 Codex 模型不同，它不仅专注于编程。

OpenAI 于周四通过 Codex 支持的工具和 API 向其付费用户提供了该模型，该公司设定了一个新目标：创建一个能够编写代码并完成开发人员或任何专业人士在计算机上所做的一切工作的智能代理。

OpenAI 表示：“该模型在一个模型中同时提升了 GPT-5.2-Codex 的前沿编程性能以及 GPT-5.2 的推理和专业知识能力，并且速度也提高了 25%。”

构建该模型与以往努力的另一个不同之处在于：OpenAI 表示，该模型“在创建自身方面发挥了关键作用”。团队表示，他们使用该模型的早期版本来调试训练运行、管理模型部署以及分析测试结果和评估。

根据 OpenAI 的说法，构建该模型尤其具有挑战性，因为它结合了编程和通用智能代理能力，这使得训练和部署变得困难。

这正是 Codex 发挥作用的地方。“工程团队使用 Codex 来优化和调整 GPT-5.3-Codex 的运行框架，”团队在公告中写道。“当我们开始看到影响用户的奇怪边缘情况时，团队成员使用 Codex 来识别上下文渲染错误并找出缓存命中率低的原因。GPT-5.3-Codex 在整个发布过程中持续帮助团队，通过动态扩展 GPU 集群以适应流量高峰并保持延迟稳定。”

这只是让这些模型自我构建和改进的第一步。然而，正如我们所看到的，由于开发人员现在使用智能代理编程工具来创建它们，这些工具的功能发布速度加快了，我们很可能会在顶尖实验室的模型中看到更多此类情况。

## GPT-5.3-Codex 基准测试

毫不意外，新模型在编程基准测试中表现出色，但在今天的公告中，OpenAI 却恰当地淡化了它们，更侧重于这些改进带来的实际进展。该公司指出，新模型现在可以在几天内从零开始构建复杂的游戏和应用程序。OpenAI 还强调，该模型能更好地理解用户意图，并在存在歧义时选择更合理的默认设置。

OpenAI 还强调了新模型处理网络安全任务的能力，部分原因在于它是该公司第一个直接训练用于识别漏洞的模型。但这同时也意味着它应该非常擅长利用安全问题，对此 OpenAI 承认：“虽然我们没有确凿证据表明它可以端到端地自动化网络攻击，但我们正在采取预防措施，并部署迄今为止最全面的网络安全安全堆栈。我们的缓解措施包括安全培训、自动化监控、高级功能的受信任访问以及包括威胁情报在内的执行管道。”
![](https://cdn.thenewstack.io/media/2026/02/1016db44-screenshot-2026-02-05-at-10.09.05-am.png)

然而，为了比较不同模型，基准测试仍然很重要，而新模型在这方面表现相当出色。它在所有测试中都取得了领先分数，包括测试模型智能代理编程技能的 TerminalBench 2.0，以及 SWE-bench Verified（测试模型的 Python 技能）和 SWE-Bench Pro（测试四种编程语言）。

在 TerminalBench 2.0 上取得 77.3% 的分数，它轻松超越了 Anthropic [刚刚发布的 Opus 4.6 模型](https://thenewstack.io/anthropics-opus-4-6-is-a-step-change-for-the-enterprise/)。

![](https://cdn.thenewstack.io/media/2026/02/5c6a3c76-terminal-bench-2.0.png)

但由于 OpenAI 特别指出该模型不仅仅关乎编程，因此尤其值得注意的是，在测试智能代理在真实计算机环境中开放式任务的 [OSWorld-Verified 基准测试](https://os-world.github.io/)中，它取得了 64.7% 的分数。

OpenAI 团队在其公告中指出：“总而言之，这些在编程、前端、计算机使用和实际任务方面的结果表明，GPT-5.3-Codex 不仅仅在单个任务上表现更好，它标志着向一个单一的、通用目的智能代理迈出了里程碑式的一步，该代理能够在各种实际技术工作中进行推理、构建和执行。”