<!--
title: SLM与RAG：打造经济、安全、可审计的AI
cover: https://cdn.thenewstack.io/media/2026/01/721405dd-betterfaster.jpg
summary: 企业LLM面临高成本、难审计挑战。SLM+RAG结合模块化代理架构是实用替代方案，提供效率、准确性、可扩展性，实现可信赖AI系统部署。
-->

企业LLM面临高成本、难审计挑战。SLM+RAG结合模块化代理架构是实用替代方案，提供效率、准确性、可扩展性，实现可信赖AI系统部署。

> 译自：[Build Cheaper, Safer, Auditable AI with SLMs and RAG](https://thenewstack.io/build-cheaper-safer-auditable-ai-with-slms-and-rag/)
> 
> 作者：Syed Danish Ali

企业在试验大型语言模型 (LLM) 时，一旦试点项目进入生产阶段，通常会遇到相同的挑战。基础设施成本迅速攀升，负载下的响应时间变得不可预测，输出难以审计或解释。虽然 [大型语言模型仍然有用](https://thenewstack.io/introduction-to-llms/) 于探索和原型开发，但其庞大的规模和通用性使其难以在企业平台内持续运营。

生产系统中正在出现的一种实用替代方案是结合使用 [小型语言模型 (SLM)](https://thenewstack.io/the-rise-of-small-language-models/) 和 [检索增强生成 (RAG)](https://thenewstack.io/freshen-up-llms-with-retrieval-augmented-generation/)。SLM 是紧凑的、领域专注的模型，可在 CPU 或普通 GPU 上高效运行，提供可预测的性能和成本特性。RAG 通过将模型输出建立在检索到的、版本控制的数据源中来补充这种方法，从而提高准确性、可追溯性和可解释性。

以下是一个基于 SLM 和 RAG 构建的模块化、基于代理的 AI 系统的架构模式。每个代理都拥有自己的检索管道，通过安全、结构化的接口进行通信，并 [在明确的治理和可观测性控制下运行](https://thenewstack.io/from-cloud-native-to-ai-native-where-are-we-going/)。该架构不依赖于单一的巨石模型，而是将职责分解到与企业风险、合规性和运营边界相一致的专业组件中。

这种设计方法平衡了效率、准确性和控制，为架构师提供了一个在生产规模部署可信赖 AI 系统的实用蓝图。

## **为什么这对架构师很重要**

大型语言模型 (LLM) 提供了令人印象深刻的通用性，但也带来了高昂的运营成本、规模化下的延迟和有限的可审计性。对于架构师而言，这些直接转化为预算的不可预测性、用户体验风险和合规性漏洞。

SLM 与 RAG 管道结合提供了一条不同的路径：

*   **效率**：SLM 可以在 CPU 或普通 GPU 上运行，降低每次请求的基础设施成本。
*   **准确性**：RAG 将响应建立在版本化的权威数据源中，提高了信任度和可解释性。
*   **可扩展性**：添加新代理比重新训练或扩展中央模型更简单。
*   **集成**：它与现有的可观测性堆栈、CI/CD 和安全框架结合，依赖性更少。

对于受监管行业的架构师而言，这意味着可以部署具有可预测成本、可验证输出和企业实践中已熟悉的治理钩子的 AI 系统。

## **理解 SLM 和 RAG**

小型语言模型 (SLM) 是紧凑的、领域专用模型，可在 CPU 或普通 GPU 上高效运行。它们以通用性换取专注性，为架构师提供了可预测的成本概况和性能特性，完美地融入企业基础设施。与旨在处理广泛任务的大型语言模型 (LLM) 不同，SLM 针对效率和控制比纯粹规模更重要的目标工作负载进行了优化。

检索增强生成 (RAG) 通过将模型输出锚定在权威数据源中来补充这种方法。RAG 不仅仅依赖模型“记住”的内容，而是检索相关文档或记录，将其与查询合并，并生成基于实时上下文的响应。这种锚定使输出既可解释又可审计——这两种品质在受监管领域至关重要。最近的基准研究表明，与没有检索的微调模型相比，整合 RAG 可以将问答准确性提高约 5 个百分点。

SLM 和 RAG 共同形成了一个紧密的检索-生成循环，在推理时注入范围受限的上下文，使轻量级模型能够生成准确、可验证的输出，而无需依赖大型参数内存。对于架构师而言，这种组合为巨石型 LLM 部署提供了一个实用的替代方案：精益系统，在满足企业治理和合规性要求的同时，实现可预测的扩展。

## **模块化代理架构**

企业不再依赖单一模型来处理所有任务，而是可以将 AI 系统设计为模块化代理，每个代理负责一个限定的功能，例如合规性、人力资源或审计。代理作为一个服务打包，拥有自己的检索管道、推理逻辑和治理钩子。这种关注点分离使代理能够独立扩展，并且更容易演进，而不会破坏整个系统的稳定性。

这种设计的好处在于灵活性。合规代理可以根据政策和法规进行调整作为其检索基础，而客户服务代理可能会使用产品手册或案例历史。每个代理只加载其所需内容，从而保持成本和延迟的可预测性。当需要协调时，[代理通过互操作协议安全地交换信息](https://thenewstack.io/using-agent-in-the-middle-to-ride-herd-on-wayward-ai/)，而不是共享一个中央的巨石模型。

对于架构师而言，模块化方法反映了既定的企业设计实践：将系统分解为服务，定义清晰的边界，并强制执行通信和可观测性的契约。将这些原则应用于 AI 允许团队部署多个专业代理，而无需扩展单一的通用型 LLM 所带来的开销。

![Figure 1: Modular agentic architecture. ](https://cdn.thenewstack.io/media/2026/01/bbd843db-image1.png)

*图 1：模块化代理架构。*

每个代理都作为具有自己 RAG 索引的限定服务运行，而轻量级通信层 (Agent2Agent/ 代理名称服务) 可实现安全的互操作性，而无需集中化模型。

## **通信和互操作性**

一旦多个代理投入生产，问题就从“一个模型能做什么？”转变为“代理如何在不破坏信任或效率的情况下进行协作？”企业系统已经依赖服务契约、API 和注册表来管理分布式组件。AI 代理也需要同样的规范。

一个新兴的例子是 [Agent2Agent (A2A)](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/)，这是一个最初由谷歌宣布的开放协议，旨在探索结构化的代理间通信，并已贡献给 Linux 基金会以支持中立治理和更广泛的行业协作。通信不再是临时提示，而是作为类型良好的消息打包，保留了意图和上下文。这避免了一个代理将另一个代理视为普通用户查询时出现的模糊性。

与此方法相辅相成的是 [代理名称服务 (ANS)](https://www.theregister.com/2025/05/20/agent_name_service_proposal)，这是一个符合 OWASP（Open Worldwide Application Security Project）的框架，提供代理间的身份、信任和发现。ANS 确保审计代理知道它正在与经过验证的合规代理通信，而不是伪造的端点。这种信任层在受监管环境中至关重要，在这些环境中，问责制和不可否认性必须扩展到 AI 驱动的交互中。

对于架构师而言，其含义很明确：互操作性必须经过设计，而不是假设。如果模块化代理要保持可管理性，它们必须通过安全的标准协议进行通信。通过尽早采用 A2A 和 ANS 等框架，企业可以在不创建不透明或脆弱集成点的情况下扩展 AI 系统。

## **治理和结构化自治**

即使采用模块化设计和安全通信，企业也不能允许 AI 代理无边界运行。治理定义了授予代理多少自主权以及何时需要上报给人类。挑战在于取得正确的平衡：过度监督会减缓采用，而监督不足则会带来合规违规风险。

实际上，企业 AI 系统中的自主性很少是二元的。相反，组织采用分级的自主性水平，使自动化与风险承受能力和法规要求相一致：

*   **辅助操作**：代理支持分析和决策，但未经明确的人工批准绝不采取行动。此模式适用于高风险活动，例如法规备案、法律审查或财务审批。
*   **半自主操作**：代理可以在预定义策略下执行有限的操作，并在超出阈值或约束时上报异常。例如，合规监控代理可以自动标记异常，但在阻止交易之前仍需要人工批准。
*   **自主操作**：保留用于低风险、高容量的任务，例如分流日常查询、丰富元数据或更新非关键日志，在这些任务中，速度和一致性比人工监督更重要。

这些自主性级别通过策略门、漂移检测和审计日志强制执行，确保代理行为保持可观测性和可逆性。对于架构师而言，关键的见解是自主性应被视为一个设计参数，而不是一个二元开关。通过将结构化自主性直接嵌入到系统架构中，企业可以扩展 AI 能力，同时保持受监管环境所需的合规态势和运营控制。

## **部署模式和可扩展性**

采用 SLM + RAG 架构的企业需要部署代理的灵活性。该设计不限于单一的基础设施模型，而是可以适应本地部署、混合云和边缘环境。每种选项都有其权衡，架构师必须根据成本、合规性和性能目标进行权衡。

本地部署吸引了对数据驻留和可审计性不可协商的受监管行业。混合模型允许组织在本地部署敏感管道，同时利用云资源进行横向扩展任务，例如嵌入生成。边缘部署将代理置于更靠近用户的位置，从而减少了欺诈检测和交易时合规性监控等用例的延迟。

扩展遵循横向模式。新的代理可以针对新领域引入，每个代理都有自己的 RAG 索引和治理规则，而不是扩展单个大型模型。这种方法通过允许轻量级工作负载在 CPU 上运行来控制成本，而 GPU 加速则保留给专用或高容量代理。它还避免了重新训练或扩大中央模型的运营蔓延。实际上，转向小型语言模型 (SLM) 显著降低了基础设施要求。企业报告称，与 LLM 通常所需的数百万美元的 GPU 集群相比，他们能够 [仅用几块 GPU（数千美元）进行训练](https://www.weka.io/learn/ai-ml/slm-vs-llm/)。

对于架构师而言，主要优势在于可持续性。通过将部署模型与风险概况匹配，并通过添加代理而不是扩大模型进行扩展，企业可以在不牺牲可预测性或治理的情况下增加 AI 的采用。

## **可观测性和卓越运营**

随着模块化 AI 代理投入生产，可观测性变得与推理速度同样重要。企业不能将这些系统视为黑盒子；他们需要了解检索、增强和生成在实际工作负载下的行为。

对于 SLM + RAG 系统，可观测性侧重于三个维度。准确性要求监控检索的新鲜度以及查询与返回结果之间的一致性。必须按阶段（检索、增强和生成）跟踪延迟以识别瓶颈。治理合规性取决于对异常、策略门触发和上报事件的日志记录。

与巨石型 LLM 不同，模块化代理提供了自然的测量边界。每个代理都可以发出与其领域相关的指标：合规代理可以报告误报，而客户服务代理可以记录未解决的案例。聚合仪表板为架构师提供了系统级视图，同时保留了每个代理的问责制。

将可观测性嵌入到设计中可确保及早发现准确性漂移、过时索引或延迟峰值。更重要的是，它直接与治理相关联。用于性能监控的相同仪表板可以为策略执行提供信息，为企业提供一个统一的控制界面，用于实现运营和合规目标。

## **案例研究：大规模合规性监控**

受监管的企业环境需要 AI 系统，这些系统能够根据当前的政策、历史决策和组织规则进行推理，同时保持可审计性和运营控制。实际上，这通过将合规性工作流分解为模块化代理来实现，每个代理都运行自己的小型语言模型 (SLM) 和检索增强生成 (RAG) 管道。

典型的合规性架构将不同的职责分配给专门的代理。

*   合规代理检索和解释有效的监管指南。
*   审计代理维护以前的例外情况和执法行动的历史记录。
*   策略通信代理管理内部策略解释和传播。

这些代理作为限定服务运行，仅在合规性决策跨越多个领域时才进行协调。

代理间通信通过经过身份验证的结构化消息显式地进行，而不是临时的提示交换。这保留了意图，强制执行信任边界，并确保只有经过验证的代理参与合规性工作流。自主性通过策略门进行限制：代理可以自动发现违规或异常，但任何具有监管影响的行动都需要明确授权，并在适当时进行人工审查。

可观测性被视为一流关注点。持续监控检索新鲜度、推理延迟和编排行为，同时记录所有策略异常、覆盖和上报，以支持可追溯性和事件后分析。

此模式演示了 SLM + RAG 架构如何应用于对合规性敏感的工作负载。通过将职责分离到模块化代理中，通过明确的治理限制自主性，并将可观测性嵌入到执行流程中，企业可以部署满足监管要求且不牺牲可预测性或控制的 AI 系统。

## **经验教训和权衡**

SLM + RAG 在提供成本效率、低延迟推理和基于权威数据的输出方面表现出色。对于许多企业工作负载而言，这种平衡比扩展单一 LLM 更具可持续性。大型语言模型在探索性、开放式或跨领域推理任务中仍然发挥着重要作用，特别是在灵活性超越成本、延迟或治理限制的情况下。

这种方法并非没有缺陷。对 RAG 推理管道的研究表明，如果未经优化，检索可能会引入显著的延迟开销并增加存储需求。实际上，调优不当的索引会增加延迟，过时的索引会侵蚀准确性，以及 unchecked 的代理数量增长可能导致管道蔓延。

这些风险可以通过轻量级嵌入、检索缓存和版本化索引，以及围绕何时以及如何引入新代理的强有力治理来缓解。如果管理得当，模块化系统可以避免巨石型系统的脆弱性，同时不引入无限的复杂性。

## **未来方向**

SLM + RAG 生态系统正在快速发展。结合文本、图像和表格推理的多模态 SLM 开始出现。策略即代码框架可能会将治理与 DevSecOps 管道统一起来，将合规性检查直接嵌入到部署工作流中。跨代理语义搜索可以允许代理在不牺牲模块化的情况下共享知识，从而实现大规模的协作智能。

另一个趋势是可持续性。通过减少对大型 GPU 集群的依赖，SLM + RAG 系统与绿色软件实践以及企业日益关注的节能设计相一致。对于架构师而言，这意味着 AI 的采用可以负责任地扩展——不仅在成本和合规性方面，还在环境影响方面。

最后，与平台工程实践的集成将变得越来越重要。随着企业工具的整合，模块化 AI 代理将需要接入已经管理 CI/CD、可观测性和基础设施即代码的相同平台。这使得 SLM + RAG 不再是一个辅助实验，而是企业架构中的一等公民。

## **结论**

企业不再需要在脆弱的基于规则的系统和巨石型 LLM 部署之间做出选择。通过在模块化代理架构中结合 SLM 和 RAG，架构师可以构建精益、可信赖且符合治理要求的 AI 系统。

这是一个负责任地扩展系统的蓝图：足以满足生产工作负载的速度，足以满足合规性的基础，以及足够的灵活性以适应企业需求的变化。对于架构师而言，下一步很简单：开始在您自己的环境中试验 SLM + RAG 模块化模式，并验证它们在何处能带来最大价值。

展望未来，同样的设计还可以支持可持续发展目标和平台工程实践，确保 AI 系统干净地集成到更广泛的企业架构路线图中。

**作者注**：此实现基于作者根据独立技术研究得出的个人观点，不代表任何特定组织的架构。*