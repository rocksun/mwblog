<!--
title: Capital One 携手 OpenTelemetry，链路追踪数据狂降70%
cover: https://cdn.thenewstack.io/media/2025/12/09972dd9-observability-day-2.jpg
summary: Capital One采用OpenTelemetry解决遥测采样问题，将追踪数据量减少70%。通过尾部采样和数据标签，提高可观测性并降低成本，并计划动态调整采样策略。
-->

Capital One采用OpenTelemetry解决遥测采样问题，将追踪数据量减少70%。通过尾部采样和数据标签，提高可观测性并降低成本，并计划动态调整采样策略。

> 译自：[How Capital One Cut Tracing Data by 70% With OpenTelemetry](https://thenewstack.io/how-capital-one-cut-tracing-data-by-70-with-opentelemetry/)
> 
> 作者：B. Cameron Gain

组织绝对需要尽可能地从遥测数据中榨取价值，原因有多种。收集遥测数据或可观测性，至少可以说，也是[一个非常棘手的问题](https://thenewstack.io/how-can-we-solve-observabilitys-data-capture-and-spending-problem/)。

一方面，打开水龙头拉取环境生成的所有指标，很快就会变得——温和地说——笨拙和难以管理，更不用说对大多数（如果不是所有）组织而言是负担不起的。

对指标数据采样过少意味着数据可能缺少调试、解释或监控潜在中断及其他问题的关键要素。优化运营和开发会变得偏差、不准确或不可靠。此外，使用错误的指标采样数据几乎毫无帮助。

对于像本文中的Capital One银行这样的大型企业，这个问题，或者说这种动态或困境，会变得更加复杂。

在[北美KubeCon + CloudNativeCon](https://thenewstack.io/event/kubecon-cloudnativecon-na-2025/)之前的可观测性日活动中，Capital One的工程师Joseph Knight和Sateesh Mamidala展示了他们如何依靠[OpenTelemetry](https://thenewstack.io/what-is-opentelemetry-the-ultimate-guide/)来解决追踪采样数据问题，并将其应用于Capital One全球所有运营中。

他们的努力得到了回报：他们报告追踪数据量减少了70%。

这并非易事，但OpenTelemetry成为了他们这项庞大项目的骨干，他们在KubeCon的演讲中详细介绍了该项目。

正如Knight在演讲中所说，Capital One的指标涉及“每天处理超过一个PB的数据，且没有任何采样”。

该解决方案需要部署专用基础设施。Knight说，基于尾部的采样需要将其转化为一个水平扩展问题，因为你必须“在做出采样决策之前，将所有span汇集到一个追踪中”。

他补充说，这导致了收集器分层，包括一个负载均衡导出器、一个收集器层，然后是一个采样处理器层，所有这些都完全专注于追踪。

## 为什么Capital One选择OpenTelemetry而非供应商工具

在采用OpenTelemetry之前，Capital One的工程师依赖于供应商工具，这些工具实施各自的、通常是不同的采样策略，通常只提供基于头部的采样，即在请求开始时决定是否保留一个追踪。

Knight说，OpenTelemetry“给了我们新的视角，即基于头部的采样效率不高”。

Knight说，目前使用OTel的方法提供了两个主要优势。首先是集中式团队现在可以控制分布式追踪的成本。这种控制确保了在现有资源下，可以实现广泛采用。

其次，团队可以向应用团队提供保证，确保“他们将能够在他们的工具中看到某些行为”，例如特定的错误，这在“采样如何影响来自其应用的追踪”方面带来了“更大的安心”，Knight说。他补充说，“这无法通过微观、概率或致命采样实现。”

## 使采样追踪数据有用的最佳实践

使采样数据有用的关键是添加标签。Capital One的团队为采样追踪添加标签，以表明它们是如何被选择的，以及它们以何种概率比率被采样。Knight说，这在两个方面很有用。

*   **估算：** 团队可以通过将追踪值乘以概率比率来估算原始生成的追踪数据，这可以估算出采样前生成了多少追踪或请求。
*   **历史准确性：** Knight说，通过直接标记数据，如果采样比率随时间变化，原始比率会“与源数据一同固定”，从而使团队能够回溯查看而不会看到随时间产生的跳跃。

此外，团队不应依赖每个span来获取速率信息，而应被教导使用指标和span一起来获得更准确的系统行为图景。

Knight说：“我们从服务器和客户端导出语义发明指标，以及我们生成的每一个span的直方图。”

他说，使用这些指标进行准确计数意味着“你不需要每一个span来理解系统的速率”。“为转换工具、警报和仪表盘以使用指标而构建规则和指南可以使这种转变更容易。”

## 从基于头部到基于尾部采样的战略转变

Knight说，从基于头部到基于尾部的采样的转变，即采样发生在追踪的末尾，取得了成功。他说，团队现在“非常高兴能从追踪中获得比以前更清晰的图景”。这是因为尾部采样允许在接收所有span并查看整个追踪后做出决策。

尽管在高速率和低速率应用之间找到正确平衡存在挑战，但持续关注动态调整尾部采样处理器是关键。Capital One团队的目标是将这项研究作为开源贡献发布。

## 数据采样中的持续挑战和未来目标

Knight说，追踪量减少70%可能令人印象深刻，但团队正在审视剩余的30%，并问：“我们如何能做得更好？”

他说，核心挑战在于概率比率中高频（高速率）和低频（低速率）事件之间的“拉锯战”。高速率应用可以处理低得多的概率速率，而低速率应用在较低比率下会“挨饿”。在大规模应用中，为每个特定应用定制规则集是不可行的。

Knight说，目前的重点是增强尾部采样处理器，使其系统能够“动态适应我们看到的事件频率，而无需我们这边进行配置更改”。