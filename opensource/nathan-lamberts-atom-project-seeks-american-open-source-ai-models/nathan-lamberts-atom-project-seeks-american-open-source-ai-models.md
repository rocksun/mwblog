
<!--
title: Nathan Lambert的ATOM项目：打造美国开源AI模型
cover: https://cdn.thenewstack.io/media/2025/08/636ffa61-tim-mossholder-s-v_xmr0vhg-unsplash.jpg
summary: Nathan Lambert发起了“美国DeepSeek项目”，旨在对抗中国DeepSeek，构建美国开源AI模型。该项目强调全面开放的AI开发方法，需大量计算能力和资金。OpenAI发布了gpt-oss开源模型，但Lambert认为这不足以解决根本挑战。ATOM项目旨在推动美国在AI领域的领导地位，并呼吁更多人参与。
-->

Nathan Lambert发起了“美国DeepSeek项目”，旨在对抗中国DeepSeek，构建美国开源AI模型。该项目强调全面开放的AI开发方法，需大量计算能力和资金。OpenAI发布了gpt-oss开源模型，但Lambert认为这不足以解决根本挑战。ATOM项目旨在推动美国在AI领域的领导地位，并呼吁更多人参与。

> 译自：[Nathan Lambert's ATOM Project Seeks American Open Source AI Models](https://thenewstack.io/nathan-lamberts-atom-project-seeks-american-open-source-ai-models/)
> 
> 作者：David Cassel

在7月4日，[Nathan Lambert](https://www.linkedin.com/in/natolambert/) 发起了“[美国DeepSeek项目](https://www.interconnects.ai/p/the-american-deepseek-project)”，这是一项旨在对抗来自[中国DeepSeek](https://thenewstack.io/icymi-deepseek-is-an-open-source-success-story/)的开源权重AI [大型语言模型](https://thenewstack.io/llm/) (LLMs) 的计划，旨在支持美国在两年内建立一个“规模和性能与当前（公开可用）前沿模型相当的完全开源模型”。

这是他非常关心的问题。Lambert 曾是 Hugging Face 的研究科学家（也曾在 [Google](https://cloud.google.com/?utm_content=inline+mention) [DeepMind](https://thenewstack.io/googles-deepmind-extends-ai-with-faster-sort-algorithms/) 和 Facebook AI Research 工作过），现在是非营利组织艾伦人工智能研究所 ([Ai2](https://allenai.org/)) 的后期训练负责人。“我想在 Ai2 做这件事，”Lambert 在他的博客中写道，“但这需要比我们更多的人来实现。我们需要倡导者、同行、顾问和计算资源。”

“我们的策略从来不是寻求广泛的公众支持，”Lambert 上周在一次电子邮件采访中告诉 TNS，“而是瞄准 AI/ML [机器学习] 社区中的关键人物。我们已经有许多教授、创始人和 AI 领域有影响力的人物签约，还有一些意想不到的人，比如 OpenAI 的 C 级高管。我们也与一些重要的华盛顿特区政策制定者进行了交谈。”（该网站解释说：“有很多途径可以在多个利益相关者之间获取和分配这些资源”，包括私营公司、慈善机构、政府机构、私营部门合作伙伴，“以及潜在的新的公私合作模式，类似于其他关键国家基础设施项目的资金运作方式。”）

Lambert 的网站表示，他正在利用他在 AI 研究新闻通讯 Interconnects.ai 上的工作“课外”进行这项计划，一个月后，他的活动演变成了“[原子项目](https://atomproject.ai/)”，该项目希望引发“对美国开放 AI 模型生态系统投资的一个转折点”。

具有讽刺意味的是，在 Lambert 的项目启动后的第二天，OpenAI 发布了其新的 [gpt-oss 开源权重模型](https://openai.com/index/introducing-gpt-oss/) —— 在 Apache 2.0 许可下 —— 该项目网站承认这是一个“积极的步骤”。上周日，8 月 17 日，NVIDIA [发布](https://blogs.nvidia.com/blog/speech-ai-dataset-models/)了一个 [新的数据集和模型](https://huggingface.co/datasets/nvidia/Granary)，以支持为 25 种欧洲语言开发高质量的语音识别和翻译 AI。

“这两者都是巨大的进步，”Lambert 上周告诉我，并补充说，“此外，已宣布在开源模型生态系统中投资超过 1.5 亿美元。”

但 Lambert 的网站仍然认为“这并没有完全解决根本挑战”，并辩称“一次模型发布并不能建立起与 DeepSeek 等系统性努力竞争所需的可持续基础设施、研究文化和长期承诺。”

为了与中国的开放模型竞争，Lambert 说美国“需要一种全面的开放 AI 开发方法，而不仅仅是偶尔的发布。”

## “严肃的计算能力”

Lambert 说他的目标与 [国家人工智能研究资源试点](https://www.nsf.gov/focus-areas/ai/nairr) 类似，该试点由美国国家科学基金会和 12 个其他联邦机构以及 26 个非政府合作伙伴领导，旨在“提供政府资助、行业和其他贡献的资源，以支持国家的研究和教育界”。

但 Lambert 说他的项目仍然“专注于构建正确的模型；我们深信并非所有‘开放’模型都是平等创建的，我们需要确保不仅在美国制造的模型的质量与国外替代品相匹配，而且还要尊重做出完全开放模型决定的行为。

“我们的愿景是一个没有妥协的开放模型生态系统 —— 我们希望美国真正的开放模型能够引领世界。”

《华盛顿邮报》指出，该项目设想的 Lambert 的“雄心勃勃”的活动涉及“[获得严肃的计算能力](https://www.msn.com/en-us/technology/artificial-intelligence/an-ambitious-new-project-aims-to-win-back-the-u-s-lead-in-open-source-ai-from-china/ar-AA1JWQ9H)，拥有超过 10,000 个用于支持企业 AI 开发的尖端 GPU 芯片”—— 成本高达 1 亿美元。

[![ATOM 项目执行摘要的屏幕截图（引自黄仁勋）](https://cdn.thenewstack.io/media/2025/08/31ad19c3-screenshot-from-atom-project-executive-over-quote-from-jensen-huang.png)](https://cdn.thenewstack.io/media/2025/08/31ad19c3-screenshot-from-atom-project-executive-over-quote-from-jensen-huang.png)

*ATOM 项目执行摘要的屏幕截图。*

“其中很大一部分是一个协调问题，”Lambert 告诉《华盛顿邮报》，并指出美国现有的开放模型工作受到了缺乏资金的影响，包括 Hugging Face 的 Bloom 和来自 [EleutherAI](https://www.eleuther.ai/about) 的 Pythia，EleutherAI 是一家 AI 智库。“这个国家有一些人在做这件事，但他们一直无法扩大规模。”

最后，Lambert 设想的不仅仅是开放权重，还有一个共享其数据、训练代码和日志的模型 —— 完整训练 AI 模型所需的所有知识和材料。这甚至可能包括中间检查点和基本模型 —— 当然，还有宽松的许可。

ATOM 项目的官方网站现在拥有一个令人印象深刻的“知名签署人”名单，他们支持其构建真正开放的美国模型并“确保美国保持其在 AI 领域的领先地位”的目标。

## 开放致胜？

“如果你认为开源 LLM 将超越其他 LLM，那么这可能是一件大事，”TNS 分析师 [Lawrence Hecht](https://www.linkedin.com/in/lawrence-hecht/) 说，同时补充说，“我不认为有任何理由认为这可能发生。”[Menlo Ventures 在 7 月下旬发布的一份报告](https://menlovc.com/perspective/2025-mid-year-llm-market-update/#18aaeef7-0c05-404c-b36f-01edbc154d0f-link) 发现，如今 13% 的 AI 工作负载使用开源模型，“略低于 [六个月前](https://menlovc.com/2024-the-state-of-generative-ai-in-the-enterprise/) 的 19%。” Hecht 承认“这种情况可能会很快改变”，并且开源模型将来有可能获得大量的用户。但另一方面，在当今世界，“ChatGPT 不是开源的，但它已经拥有大量的用户。”

Lambert 反驳说，在开放模型方面，“有 [其他](https://www.linuxfoundation.org/hubfs/Research%20Reports/lfr_marketimpacts25_052725a.pdf?hsLang=en) [报告](https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/open%20source%20technology%20in%20the%20age%20of%20ai/open-source-technology-in-the-age-of-ai_final.pdf) 显示了更高的采用率。”

[![全球管理咨询公司麦肯锡公司的一项调查显示，63% 的组织表示他们使用了开放模型。](https://cdn.thenewstack.io/media/2025/08/9eee033e-mckinsey-stats-on-open-model-use-1024x439.png)](https://cdn.thenewstack.io/media/2025/08/9eee033e-mckinsey-stats-on-open-model-use-1024x439.png)

*全球管理咨询公司麦肯锡公司的一项调查显示，63% 的组织表示他们使用了开放模型。*

在 [5 月的另一篇博客文章](https://www.interconnects.ai/p/what-people-get-wrong-about-the-leading?utm_source=publication-search) 中，Lambert 还指出，在企业解决方案中部署中国的开放模型时，人们有所不愿，这表明人们担心“中国价值观对西方商业体系的间接影响的信息危害”，以及关于是否已证明它们可以安全运行的问题。但该项目网站提出了另一个论点：美国“必须在全球范围内领导 AI 研究，我们必须投资于制造我们的研究人员在美国开展工作所需的工具：一套领先的开放基础模型，可以重建研究生态系统的实力。”（这将“推动对基本 AI 进步的研究”，同时确保美国在 AI 领域的地位并最大程度地提高其在 AI 市场的份额。）

“美国的 AI 领导地位是通过成为全球中心和开放 AI 研究的领先生产者而建立的，”该网站解释说，“这项研究直接促成了 Transformer 架构、ChatGPT 以及推理模型和代理的最新创新等创新。”因此，缺乏开放模型将导致缺乏领导地位 —— 以及随之而来的可怕后果。

“AI 领导地位越来越与经济竞争力、军事能力和技术主权联系在一起。在 AI 领域领先的国家将在从经济生产力到国防能力的各个方面都具有显着优势，这使其成为一个关键的国家安全问题。”

该网站称开放语言模型“对于美国行业内的长期竞争至关重要”，因为封闭的 AI 实验室“只能涵盖如此多的潜在想法……更广泛的开放研究社区专注于在 2 年、5 年、10 年或更长时间内具有变革意义的创新。”

TNS 分析师 Hecht 认为基础 AI 研究的重要性被夸大了，因为在实践中，“近年来它已经退居工程解决方案的第二阶段。”

但 ATOM 项目认为，像 ChatGPT 和 Claude 这样的封闭模型“在几个关键方面限制了研究：你无法检查它们的架构、修改它们的行为、针对特定任务微调它们或了解它们的训练过程。研究人员需要完全访问模型权重和代码才能进行有意义的 AI 安全研究、开发新功能并以现有工作为基础。”

## OpenAI 的 gpt-oss

在宣布 ATOM 项目的第二天，Lambert 发现自己在写 [一篇关于 OpenAI 的两个新 gpt-oss 开源权重模型的博客文章](https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open)，这些模型是在 Apache 2.0 许可下发布的。Lambert 称这次发布是“开放模型性能和战略的巨大变化”和“生态系统的重要时刻……我会给 OpenAI 一段时间以来的第一次开放发布打一个非常高的分数 —— 他们肯定听取了社区的 [反馈](https://natolambert.substack.com/p/some-thoughts-on-openai-returning)。”

“对于开放生态系统来说，这是一个了不起的步骤，特别是对于西方及其盟友来说，AI 领域最知名的品牌已经回归到开放地发布模型。这是一个势头，并且可能是相对于中国而言，开放模型的采用和影响力的转折点的开始。美国及其盟友将不再越落越远，这原本是 2025 年的主要故事，但如果我们想在几个月而不是几年内拥有适用于所有用例的有竞争力的开放模型，我们需要在此基础上再接再厉。”

Lambert 写道，新的 OpenAI 模型揭示了“比迄今为止的任何版本都更多的技术堆栈”，并且它们的“大小可以有效地在从消费级 GPU 到云的各种硬件上运行。”但 Lambert 指出，OpenAI 没有发布模型的训练数据、基本模型、代码或技术报告。他指出，“许多人都在制造关于创建开放模型的噪音”—— 但始终作为次要目标。“原子项目的目标是为像我这样想要将该项目作为首要任务的人提供一个出口。

“从第一性原理设计为可修改、可解释和可扩展的模型将使 AI 研究的新十年得以诞生。这需要基本模型、训练细节、便捷的大小以及许多最近的开放模型版本（包括 OpenAI 的版本）中缺少的一些小细节。”

无论未来采取何种形式，Lambert 都看到了一个更大的运动，我们可以共同参与其中。“这里的行动号召很简单，”Lambert 在 7 月 4 日的博客文章中写道。“考虑一下你如何稍微改变你的决策，以使美国 DeepSeek 更有可能实现。

“这种方法之所以成功，不仅在于最终拥有一个模型，还在于社区围绕 AI 模型的构思、构建、共享和使用方式形成更好的习惯和规范。”

原子项目的网站仍然要求其访问者“考虑你的专业知识或资源如何为构建美国所需的基础设施做出贡献。”