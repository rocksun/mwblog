A large majority of [software development teams](https://thenewstack.io/building-high-performance-software-development-teams-7-tips/) are now [using AI](https://thenewstack.io/ai-for-developers-how-can-programmers-use-artificial-intelligence/), marking a fundamental [shift in how code gets written](https://thenewstack.io/should-your-team-be-vibe-coding/), according to [Google](https://cloud.google.com/?utm_content=inline+mention)‘s latest research.

The tech giant’s annual “[DevOps Research and Assessment (DORA)](https://dora.dev/)” report, released today, found that 90% of the nearly 5,000 technology professionals surveyed are using AI at work — up 14% from last year.

Moreover, the research showed that developers are spending about two hours each day actively working with AI tools.

“We won’t need to ask necessarily about AI adoption in the future,” said [Nathen Harvey](https://www.linkedin.com/in/nathen/), DORA lead and developer advocate at [Google Cloud](https://thenewstack.io/googles-cloud-idp-could-replace-platform-engineering/), told The New Stack. “We’ll just assume that it’s a thing, much like a computer is a thing or email is a thing that you use at work.”

Harvey noted that the median two-hour daily interaction time aligns closely with studies showing software engineers spend 30-40% of their time actually writing code.

“I don’t think it’s just a coincidence,” Harvey said. “I think that if you’re writing code, you’re likely interacting with AI.”

## Productivity Up, but Trust Remains Shaky

The adoption surge seems to be paying off. More than 80% of respondents said AI boosts their productivity, while 59% report it improves code quality. Only 10% say AI makes their code worse.

But trust in AI output remains mixed. While usage is near universal, 30% of developers said they trust AI output only “a little” or “not at all.” Another 24% said they trust it “a lot” or “a great deal.”

Harvey sees this as healthy skepticism rather than a problem. “Having 100% trust in the output is wrong. Having 0% trust is wrong. There’s something in the middle that’s right,” he said.

[![](https://cdn.thenewstack.io/media/2025/09/065e0b4e-screenshot_23-9-2025_171519_-1.jpg)](https://cdn.thenewstack.io/media/2025/09/065e0b4e-screenshot_23-9-2025_171519_-1.jpg)

Credit: Google.

The research team found that trust tends to build through experience. “The more you use a tool, the more you trust it,” Harvey explained. “That trust is almost an alignment of expectations.”

Even at Google, human oversight remains essential. Google CEO [Sundar Pichai](https://www.linkedin.com/in/sundarpichai/) recently disclosed that about [30% of new code at the company is](https://www.moneycontrol.com/technology/over-30-of-google-s-new-code-now-ai-generated-working-on-deeper-coding-experiences-sundar-pichai-article-13003845.html)AI-generated, but all of it gets reviewed by human engineers before reaching production, Harvey said.

## DORA AI Capabilities Model

While individual developers are embracing AI tools, many organizations haven’t figured out how to harness this technology effectively. The DORA research shows AI acts as what Harvey calls a “mirror and multiplier,” amplifying both strengths in well-run organizations and problems in dysfunctional ones.

“Simply using AI is not enough,” Harvey said. “AI adoption absolutely precedes any impact that you’re going to get from it, but AI adoption alone doesn’t guarantee you’re going to have impact or good outcomes.”

To address this gap, DORA developed what it calls the [AI Capabilities Model](https://cloud.google.com/blog/products/ai-machine-learning/introducing-doras-inaugural-ai-capabilities-model): seven specific organizational practices that amplify AI’s benefits. These range from having clear policies about AI use to maintaining strong version control practices that provide safety nets when AI makes mistakes.

[![](https://cdn.thenewstack.io/media/2025/09/718f7820-dora_inline_2.max-2200x2200-1.png)](https://cdn.thenewstack.io/media/2025/09/718f7820-dora_inline_2.max-2200x2200-1.png)

Credit: Google.

The analysis identified seven capabilities that substantially either amplify or unlock the benefits of AI:

* Clear and communicated AI stance
* Healthy data ecosystems
* AI-accessible internal data
* Strong version control practices
* Working in small batches
* User-centric focus
* Quality internal platforms

Moreover, “DORA’s research has long held that even the best tools and teams can’t succeed without the right organizational conditions,” Google wrote in a blog post about the model. “The findings of our inaugural DORA AI Capabilities Model are a reminder of this fact and suggest that successful AI-assisted development isn’t just a purchasing decision; it’s a decision to cultivate the conditions where AI-assisted developers thrive.”

Harvey emphasizes that organizations need explicit guidance. “Having that clear and communicated stance really alleviates a lot of friction,” he said, noting that uncertainty about when and how to use AI creates unnecessary workplace stress.

## The Real Story: Learning To Adapt

“This year’s report and this year’s research really is pointing to a story of adaption, or adaptation to the ways of working with AI,” Harvey told The New Stack. “It’s not a story of adoption of AI. That story is one that everyone knows. But how do we start adapting to this new way of working, these new tools, this new workflow? It’s about adaptation. We saw as an example, 14% higher adoption, right? Adoption is no longer a question. It’s not if you’re using it, but rather how you’re using it, and that adaptation is being led by that capabilities model. And to be clear, these are capabilities that we’re seeing teams using today, and the teams that are using them are getting better results.”

The research expanded beyond traditional software delivery metrics to identify seven different team “archetypes,” from those struggling with basic challenges to what DORA calls “harmonious high achievers” that excel across all performance measures.

About 10% of teams fall into the struggling category — stuck in what Harvey describes as “survival mode” with significant gaps in their processes. But 20% have reached the high-achiever level, demonstrating what is possible when organizations successfully adapt to [AI-assisted development](https://thenewstack.io/three-ai-assisted-development-skills-you-can-start-using-today/).

“I think this is what excellence looks like,” Harvey said of the top-performing teams, which show high productivity combined with low burnout and friction.

The findings suggest that while AI tools have become ubiquitous, learning to use them effectively remains a work in progress for most organizations. Success requires more than just buying the latest [AI coding assistant](https://thenewstack.io/what-are-ai-code-assistants-and-how-should-you-use-them/); it also requires rethinking workflows, policies and team practices around these powerful new capabilities.

As Harvey puts it, the question is no longer whether teams should use AI, but rather “how do we adopt AI in the best ways to get the best impacts, the best outcomes from this adoption?”

[YOUTUBE.COM/THENEWSTACK

Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.

SUBSCRIBE](https://youtube.com/thenewstack?sub_confirmation=1)

Group
Created with Sketch.

[![](https://thenewstack.io/wp-content/uploads/2021/06/a95bb5bc-image-576x600.png)

Darryl K. Taft covers DevOps, software development tools and developer-related issues from his office in the Baltimore area. He has more than 25 years of experience in the business and is always looking for the next scoop. He has worked...

Read more from Darryl K. Taft](https://thenewstack.io/author/darryl-taft/)