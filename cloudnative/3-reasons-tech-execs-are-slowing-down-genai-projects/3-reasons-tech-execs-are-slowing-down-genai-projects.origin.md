# 3 Reasons Tech Execs Are Slowing Down GenAI Projects
![Featued image for: 3 Reasons Tech Execs Are Slowing Down GenAI Projects](https://cdn.thenewstack.io/media/2024/04/45b1022d-slow-1024x714.jpg)
IT trends are notoriously difficult to predict, but generative AI (GenAI) has grown exponentially since ChatGPT was released in late 2022. IDC
[predicts](https://www.idc.com/getdoc.jsp?containerId=US51881324) enterprises will spend $40 billion on it globally this year, rising nearly four-fold to $151 billion in three years’ time. It is backed by a separate [PagerDuty study](https://www.pagerduty.com/assets/whitepaper-generative-ai-survey.pdf) that finds 64% of Fortune 1000 executives are deploying [GenAI](https://thenewstack.io/ai/) in most or all of their organization’s departments. Nearly all (98%) of these companies are experimenting with use cases.
But this is not the whole story. The same study conducted by Wakefield Research of 100 Fortune 1000 executives revealed that 98% of organizations are pausing internal initiatives while they establish guidelines and policies. It speaks to a growing awareness of the risks involved in the unmanaged use of GenAI and the need for enterprises to find trusted partners and solutions in this fast-emerging landscape.
## How GenAI Can Transform ITOps
GenAI is so new that organizations are still working out the most effective way to deploy the technology. IT has been touted as potentially transformative in use cases as diverse as marketing, software development and customer service. But it can also supercharge productivity for ITOps teams.
We see this in three key areas:
**Network operation centers**where manual toil and outdated processes can lead to excessive escalations and long mean time to resolve (MTTR). GenAI can help to pull diagnostic information together to generate regular status updates for stakeholders, streamlining incident management workflows and communication while freeing up ITOps to focus on the job at hand. **Major incident management**teams often [struggle with complexity](https://thenewstack.io/managing-complexity-and-avoiding-chaos-in-digital-operations/), alert noise and a lack of context, which lengthens MTTR. GenAI empowers responders to rapidly create workflows on the fly for status updates, routing high-priority incidents to the right experts. It can also assist by coding the process automation required to accelerate MTTR. **Distributed service-owning teams**are often under extreme pressure to deliver improved customer experiences, thanks to alert noise, disparate monitoring tools and limited context. GenAI can help by generating status updates and postmortem reports — the latter being critical to driving continuous improvement.
## Why Execs Are Cautious
The Fortune 1000 technology executives we spoke to are acutely aware of the need to harness these capabilities for competitive advantage. Almost half (46%) believe they risk falling behind if they don’t adopt GenAI as quickly as possible. Yet even so, there’s caution about doing it too rapidly. Speed is important, but not at any cost. The top three reasons organizations are pausing GenAI projects are:
**1.** **Copyright and Legal Exposure (51%)**
GenAI models may be trained on copyrighted works, meaning organizations that use such models’ output may unwittingly land themselves in legal trouble. The issue came to a head at the end of 2023 when the New York Times
[sued](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html) OpenAI and Microsoft for copyright infringement.
Organizations may increasingly need legal assurances written into their contracts with GenAI providers that stipulate any works a model was trained on are licensed and extend to users of the tool. They may also need to step up due diligence on prospective GenAI suppliers to check their risk exposure, and potentially run checks to ensure any AI-generated software does not infringe on previously published code.
**2.** **Sensitive Information Disclosure (48%)**
GenAI applications built on
[large language models (LLMs)](https://roadmap.sh/guides/introduction-to-llms) could disclose sensitive information accidentally, such as proprietary algorithms or other intellectual property (IP). Samsung [banned](https://www.cnbc.com/2023/05/02/samsung-bans-use-of-ai-like-chatgpt-for-staff-after-misuse-of-chatbot.html) the internal use of ChatGPT and similar tools last May after developers uploaded sensitive code to the tool to help them debug and optimize it. Among others, JPMorgan and Amazon have also restricted staff use of such tools.
Organizations must put in place acceptable use policies and updated staff-awareness training to regulate how employees use LLM-based tools. They may also want to update data loss-prevention (DLP) solutions to deploy fine-grained controls and restrict employee access in the first place. Enterprise licenses are likely to be increasingly important to mitigate this kind of risk by placing strict limits on what the AI model can do with any user inputs/prompts.
**3.** **Data Privacy Violations (47%)**
Similar to the example above, users may unwittingly input sensitive information into a GenAI model. If this is regulated personal information, it may put the enterprise at risk of breaking laws such as the GDPR or CCPA (the California Consumer Privacy Act).
[OpenAI states](https://www.weirfoulds.com/to-use-or-not-to-use-navigating-privacy-risks-associated-with-generative-ai-tools#_ftnref1) in its privacy policy that it might use such input to provide, analyze and improve its services, and to develop new programs and services. It may also share that information with third parties such as vendors and service providers without any further notice.
As above, enterprises will
[need to develop watertight user policies and procedures](https://thenewstack.io/ai-engineering-what-developers-need-to-think-about-in-2024/), combined with updated staff training, to minimize their risk exposure. They may even need to block the use of “leaky” models and stick only to rigorously vetted, enterprise-grade GenAI providers, which promise not to use personal info in this way.
## Trust Is Paramount
In the end, we should praise the tech executives that are slowing GenAI projects. More than half (51%) believe they should adopt GenAI only after they have the right guidelines in place. It shows they are aware of the risks and want to ensure that the technology is used in a responsible and compliant manner.
The next steps will be crucial: that is, the policies and procedures they put in place and the technology companies they choose to partner with. Increasingly, the direction of travel will be specialized providers able to offer tools with the right guardrails built in to mitigate copyright, data loss, compliance and other risks like hallucinations. The good news is that these providers already exist today.
[
YOUTUBE.COM/THENEWSTACK
Tech moves fast, don't miss an episode. Subscribe to our YouTube
channel to stream all our podcasts, interviews, demos, and more.
](https://youtube.com/thenewstack?sub_confirmation=1)