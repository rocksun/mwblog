OpenAI 周一发布了[新数据](https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations/)，说明了有多少 ChatGPT 用户正在与心理健康问题作斗争，并向 AI 聊天机器人倾诉。该公司表示，在给定的一周内，0.15% 的 ChatGPT 活跃用户“进行的对话包含潜在自杀计划或意图的明确指标”。考虑到 ChatGPT 每周活跃用户超过 8 亿，这意味着每周有超过一百万人。

该公司表示，类似比例的用户表现出“对 ChatGPT 情感依恋程度的提高”，并且每周与该 AI 聊天机器人的对话中，有数十万人表现出精神病或躁狂的迹象。

OpenAI 表示，ChatGPT 中这类对话“极为罕见”，因此难以衡量。尽管如此，该公司估计这些问题每周影响着数十万人。

OpenAI 分享这些信息，是其更广泛声明的一部分，该声明旨在说明其近期为改善模型对心理健康问题用户的响应所做的努力。该公司声称，其在 ChatGPT 上的最新工作涉及咨询了 170 多名心理健康专家。OpenAI 表示，这些临床医生观察到，最新版本的 ChatGPT“比早期版本响应更适当、更一致”。

近几个月来，一些报道揭示了 AI 聊天机器人如何[对](https://www.nytimes.com/2025/08/08/technology/ai-chatbots-delusions-chatgpt.html)[与心理健康挑战作斗争的用户产生不利影响](https://www.nytimes.com/2025/08/08/technology/ai-chatbots-delusions-chatgpt.html)。研究人员此前发现，[AI 聊天机器人可能通过奉承行为强化危险信念，从而导致一些用户陷入妄想的深渊](https://techcrunch.com/2025/10/02/ex-openai-researcher-dissects-one-of-chatgpts-delusional-spirals/)。

解决 ChatGPT 中的心理健康问题正迅速成为 OpenAI 的生存问题。该公司目前正[被一名 16 岁男孩的父母起诉](https://techcrunch.com/2025/08/26/parents-sue-openai-over-chatgpts-role-in-sons-suicide/)，该男孩在自杀前几周曾向 ChatGPT 倾诉了他的自杀念头。加利福尼亚州和特拉华州的州检察长（他们可能会阻止该公司的重组计划）也警告 OpenAI，它[需要保护](https://www.politico.com/news/2025/09/05/california-delaware-ags-blast-openai-over-youth-safety-00546677)[使用其产品的年轻人](https://www.politico.com/news/2025/09/05/california-delaware-ags-blast-openai-over-youth-safety-00546677)。

本月早些时候，OpenAI 首席执行官萨姆·奥特曼（Sam Altman）在 [X 上发帖](https://x.com/sama/status/1978129344598827128?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1978129344598827128%7Ctwgr%5E95fbf6288fb57a282d28e89d870a98e71a8387d5%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Ftechcrunch.com%2F2025%2F10%2F14%2Fsam-altman-says-chatgpt-will-soon-allow-erotica-for-adult-users%2F)声称，该公司“已经能够缓解 ChatGPT 中的严重心理健康问题”，但他没有提供具体细节。周一分享的数据似乎是这一说法的证据，尽管它引发了关于问题普遍性的更广泛讨论。尽管如此，奥特曼表示 OpenAI 将放宽一些限制，甚至允许成年用户开始与 AI 聊天机器人进行[色情对话](https://techcrunch.com/2025/10/14/sam-altman-says-chatgpt-will-soon-allow-erotica-for-adult-users/)。

Techcrunch 活动

旧金山
|
2025 年 10 月 27-29 日

在周一的声明中，OpenAI 声称最新更新的 GPT-5 版本在应对心理健康问题时，其“理想响应”比以前的版本高出约 65%。在评估 AI 在自杀相关对话中的响应测试中，OpenAI 表示其新的 GPT-5 模型与公司期望的行为有 91% 的符合度，而之前的 GPT‑5 模型为 77%。

该公司还表示，最新版本的 GPT-5 在长对话中更能有效遵守 OpenAI 的安全防护措施。OpenAI 此前曾指出，其安全防护措施在长对话中效果较差。

除了这些努力之外，OpenAI 表示正在增加[新的评估](https://cdn.openai.com/pdf/3da476af-b937-47fb-9931-88a851620101/addendum-to-gpt-5-system-card-sensitive-conversations.pdf)来衡量 ChatGPT 用户面临的一些最严重的心理健康挑战。该公司表示，其 AI 模型的基本安全测试现在将包括情感依赖和非自杀性心理健康紧急情况的基准。

OpenAI 最近还为使用 ChatGPT 的儿童的[父母推出了更多控制措施](https://openai.com/index/introducing-parental-controls/)。该公司表示正在构建一个年龄预测系统，以自动检测使用 ChatGPT 的儿童，并施加更严格的安全防护措施。

尽管如此，ChatGPT 相关的心理健康挑战将持续多久仍不清楚。虽然 GPT-5 在安全性方面似乎比以前的 AI 模型有所改进，但 ChatGPT 的响应中仍有一部分被 OpenAI 认为是“不理想的”。OpenAI 还继续向其数百万付费订阅者提供其较旧且安全性较低的 AI 模型，包括 GPT-4o。

---

*如果您或您认识的人需要帮助，请致电 1-800-273-8255 联系*[*全国预防自杀生命线*](https://suicidepreventionlifeline.org/)*。您也可以免费发送短信 HOME 到 741-741；发送短信 988；或从*[*危机短信热线*](http://www.crisistextline.org/)*获得 24 小时支持。在美国境外，请访问*[*国际自杀预防协会*](https://www.iasp.info/resources/Crisis_Centres/)*获取资源数据库。*