<!--
title: 2026科技巨头真章：告别预测，只看行动
cover: https://cdn.thenewstack.io/media/2026/01/8c647cca-newyear.jpg
summary: 本文分享了多位技术领袖的2026年新年技术决心，涵盖AI安全、数字习惯等。核心在于以意图性行动取代预测，推动技术进步与个人成长。
-->

本文分享了多位技术领袖的2026年新年技术决心，涵盖AI安全、数字习惯等。核心在于以意图性行动取代预测，推动技术进步与个人成长。

> 译自：[Forget Predictions: Tech Leaders' Actual 2026 Resolutions](https://thenewstack.io/forget-predictions-tech-leaders-actual-2026-resolutions/)
> 
> 作者：Kaylin Trychon

人们对新年决心抱有强烈的情绪。我认识一些人，他们整个十二月都在反思，然后在新年一月为未来一年做计划。我也认识一些人，他们认为这完全是浪费时间。无论你的观点处于这个光谱的哪一端，我们能否同意决心比预测更好？

在每年这个时候，我们都会被各种关于接下来会发生什么的预测轰炸。公开做出预测很容易，因为我们都知道没人能真正预测未来，所以当预测未能实现时，我们都非常宽容。我们也如此分心，以至于无论如何都会忘记人们预测了什么。而决心，则是关于我们将要做什么。或者，就像我少吃糖果的决心一样，是我们将*尝试*去做什么，因为说实话：完全放弃甜食感觉像犯罪。是行动而非空谈。

今年十二月，我与社区中的一些人进行了交流，了解他们为2026年制定的决心，特别是在技术领域。有些是商业导向的，有些是个人导向的。无论如何，我希望它们能一起给你带来一些启发和好奇心，当我们迈入2026年之际。

[**Jeremy Colvin**](https://www.linkedin.com/in/jgcolvin/)，Isovalent（思科旗下公司）高级技术市场工程师：

* “我2026年的新年技术决心是：超越[安全数据](https://thenewstack.io/leaky-data-pipelines-uncovering-the-hidden-security-risks/)的消防水带模式，专注于实际驱动决策的信号。

“多年来，安全团队一直被迫实时传输每一个事件，将大量数据从内核推送出去，传输到下游系统，希望价值稍后才会出现。事实是，大多数事件都不值得导出，而且这种方法为平台和安全团队都带来了不必要的开销、噪音和摩擦。

“在2026年，决心应该是让[运行时安全](https://thenewstack.io/hardened-containers-arent-enough-the-runtime-security-gap/)更轻量、更智能、更有意图。这意味着以极低的开销收集丰富的内核级遥测数据，通过实时警报立即呈现高风险行为，并导出聚合的、富含上下文的数据，这些数据对于调查、策略决策和响应实际上是有用的。”

[**Nadav Cornberg**](https://www.linkedin.com/in/nadav-cornberg/)，Eve Security 首席执行官兼联合创始人：

* “我2026年的新年技术决心很简单：我们必须停止将[AI代理](https://thenewstack.io/ai-agents-are-creating-a-new-security-nightmare-for-enterprises-and-starups/)视为工具，并开始像保护行为者一样保护它们。代理式AI正在我们的环境中运行，以机器速度做出决策，采取[行动并与系统交互](https://thenewstack.io/putting-ai-to-work-systems-of-intelligence-and-actionable-agency/)。然而，大多数安全工具和平台仍然是为了监控人类参与者而构建的，而不是自主代理。这个差距正成为企业安全中最危险的盲点之一。新[一年最重要的不是你是否在使用AI代理](https://thenewstack.io/openai-co-founder-ai-agents-are-still-10-years-away/)，而是你是否能够信任和控制它们。我的决心是确保企业能够做到这一点。”

[**Crystal Morin**](https://www.linkedin.com/in/crystal-morin/)，Sysdig 高级网络安全策略师：

* “在2026年，我的决心是以一种深思熟虑、适合年龄的方式，有意识地向我的孩子们介绍AI。从我10岁的孩子开始。我希望他理解AI和LLMs[大型语言模型]是什么，它们如何工作，我们输入到其中的数据会发生什么，以及如何将它们用作学习和创造的工具，而不是捷径。我的目标是在实践和[建模‘信任但验证’方法](https://thenewstack.io/how-zero-trust-models-work-in-container-security/)的同时做到这一点。对于我的两个8岁的小孩，我的决心是教他们如何更好地利用技术和AI来创造事物，比如手工艺品、设计、想法和项目，而不是仅仅被动地消费内容。”

[**Brian Proffitt,**](https://www.linkedin.com/in/brianproffitt/) Red Hat 社区外展高级经理：

* “我的技术决心是开始使用并[训练一些小型LLMs](https://thenewstack.io/meeting-the-operational-challenges-of-training-llms/)，使其与我现有的任务管理工具协同工作，帮助我同时进行的52亿（粗略估计 :) ）项任务保持井然有序。”

[**Conor Sherman**](https://www.linkedin.com/in/conordsherman/)，Sysdig 常驻首席信息安全官：

* “我2026年的技术决心是双重的。首先，我想为我的家人创造更多的数字留白时间。理想情况下，每周有一天完全或几乎不使用技术，以减少对屏幕的依赖，并建立真正的个人韧性。其次，作为一名安全负责人，我致力于对AI代理进行更深入、更有条理的探索。我的目标是更积极地帮助安全团队理解和利用AI能为现代基础设施带来的防御能力。”

[**Ross Turk**](https://www.linkedin.com/in/rossturk/)，开发者和社区关系，最近在 Flox 工作：

* “我2026年的个人决心是每天都建造一些新东西。30年来，我一直在脑海中构思各种想法，并决定哪些我有精力、专注力和技能去实现。现在我可以每天建造一个，看看哪些能够真正发展起来。软件开发并没有变得更容易，但它变得更快了。我计划构建一些工具，来完成我以前觉得不值得费力去做的事情。开源很长一段时间以来都是关于‘解决自己的痛点’，现在我们来看看这是否仍然适用。”

[**Alex Zenla**](https://www.linkedin.com/in/azenla/)，Edera 首席技术官兼联合创始人：

* “我2026年的技术决心：停止将AI视为一个神奇的类别，并开始解决它实际暴露出来的基础设施问题。当前的炒作周期并没有创造新的挑战，它只是让多年来我们忽视的数据中心和工作负载隔离问题变得无法再被忽视。与其追逐AI特有的解决方案，不如构建安全设计的地基，无论您是运行机器学习模型还是提供猫咪图片，这些地基都能发挥作用。问题是一样的；只是规模和审查程度发生了变化。”

最后，我要提醒你，并非所有决心都关乎我们将做什么。有时它们关乎我们将停止做什么。在她的[最新领英帖子](https://www.linkedin.com/posts/emily-long-7a194b4_the-last-two-weeks-of-2025-are-now-and-forever-activity-7413975922544021505-neRq?utm_source=share&utm_medium=member_desktop&rcm=ACoAAApBbZEBBKMddcCEto7DGld5qK7mfTC_ACY)中，Emily Long（Edera 首席执行官）反思了她自己2026年的决心：放下那些无论是在个人还是职业上都不再服务于她的事物。

无论你2026年的决心是关于数字留白、代理式AI安全、让过去成为过去还是每天建造新事物，共同的主线都是意图性。这些技术领导者并没有预测会发生什么——他们正在承诺他们将促成什么。这就是空谈与进步的区别。

新年快乐！到时候见。